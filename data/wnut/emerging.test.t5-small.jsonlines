[{"doc_id": "emerging.test_0", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581soldier", "\u2581was", "\u2581killed", "\u2581when", "\u2581another", "\u2581", "ava", "lan", "che", "\u2581hit", "\u2581an", "\u2581army", "\u2581bar", "rack", "s", "\u2581in", "\u2581the", "\u2581northern", "\u2581area", "\u2581of", "\u2581Son", "mar", "g", ",", "\u2581said", "\u2581", "a", "\u2581military", "\u2581", "s", "pokesman", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581soldier", "\u2581was", "\u2581killed", "\u2581when", "\u2581another", "\u2581", "ava", "lan", "che", "\u2581hit", "\u2581an", "\u2581army", "\u2581bar", "rack", "s", "\u2581in", "\u2581the", "\u2581northern", "\u2581area", "\u2581of", "\u2581Son", "mar", "g", ",", "\u2581said", "\u2581", "a", "\u2581military", "\u2581", "s", "pokesman", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581soldier", "\u2581was", "\u2581killed", "\u2581when", "\u2581another", "\u2581", "ava", "lan", "che", "\u2581hit", "\u2581an", "\u2581army", "\u2581bar", "rack", "s", "\u2581in", "\u2581the", "\u2581northern", "\u2581area", "\u2581of", "<m>", "\u2581Son", "mar", "g", "</m>", ",", "\u2581said", "\u2581", "a", "\u2581military", "\u2581", "s", "pokesman", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 14, 14, 14, 15, 16, 17, 18, 19, 20, 20, 20, 21, 22, 23, 23, 24, 25, 25, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581Police", "\u2581last", "\u2581week", "\u2581evacuate", "d", "\u258180", "\u2581", "villagers", "\u2581from", "\u2581Walt", "en", "go", "o", "\u2581Nar", "\u2581where", "\u2581", "dozens", "\u2581were", "\u2581killed", "\u2581after", "\u2581", "a", "\u2581series", "\u2581of", "\u2581", "ava", "lan", "ches", "\u2581hit", "\u2581the", "\u2581area", "\u2581in", "\u25812005", "\u2581in", "\u2581the", "\u2581south", "\u2581of", "\u2581the", "\u2581territory", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581Police", "\u2581last", "\u2581week", "\u2581evacuate", "d", "\u258180", "\u2581", "villagers", "\u2581from", "\u2581Walt", "en", "go", "o", "\u2581Nar", "\u2581where", "\u2581", "dozens", "\u2581were", "\u2581killed", "\u2581after", "\u2581", "a", "\u2581series", "\u2581of", "\u2581", "ava", "lan", "ches", "\u2581hit", "\u2581the", "\u2581area", "\u2581in", "\u25812005", "\u2581in", "\u2581the", "\u2581south", "\u2581of", "\u2581the", "\u2581territory", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581Police", "\u2581last", "\u2581week", "\u2581evacuate", "d", "\u258180", "\u2581", "villagers", "\u2581from", "<m>", "\u2581Walt", "en", "go", "o", "\u2581Nar", "</m>", "\u2581where", "\u2581", "dozens", "\u2581were", "\u2581killed", "\u2581after", "\u2581", "a", "\u2581series", "\u2581of", "\u2581", "ava", "lan", "ches", "\u2581hit", "\u2581the", "\u2581area", "\u2581in", "\u25812005", "\u2581in", "\u2581the", "\u2581south", "\u2581of", "\u2581the", "\u2581territory", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 9, 10, 11, 11, 11, 11, 12, 13, 14, 14, 15, 16, 17, 18, 18, 19, 20, 21, 21, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_2", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581army", "\u2581on", "\u2581Thursday", "\u2581recovered", "\u2581the", "\u2581bodies", "\u2581of", "\u2581", "ten", "\u2581of", "\u2581its", "\u2581men", "\u2581who", "\u2581were", "\u2581killed", "\u2581in", "\u2581an", "\u2581", "ava", "lan", "che", "\u2581the", "\u2581previous", "\u2581day", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581army", "\u2581on", "\u2581Thursday", "\u2581recovered", "\u2581the", "\u2581bodies", "\u2581of", "\u2581", "ten", "\u2581of", "\u2581its", "\u2581men", "\u2581who", "\u2581were", "\u2581killed", "\u2581in", "\u2581an", "\u2581", "ava", "lan", "che", "\u2581the", "\u2581previous", "\u2581day", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581army", "\u2581on", "\u2581Thursday", "\u2581recovered", "\u2581the", "\u2581bodies", "\u2581of", "\u2581", "ten", "\u2581of", "\u2581its", "\u2581men", "\u2581who", "\u2581were", "\u2581killed", "\u2581in", "\u2581an", "\u2581", "ava", "lan", "che", "\u2581the", "\u2581previous", "\u2581day", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_3", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581four", "\u2581civilian", "s", "\u2581killed", "\u2581included", "\u2581two", "\u2581children", "\u2581of", "\u2581", "a", "\u2581family", "\u2581", "whose", "\u2581house", "\u2581was", "\u2581hit", "\u2581by", "\u2581", "a", "\u2581separate", "\u2581", "ava", "lan", "che", ",", "\u2581also", "\u2581on", "\u2581Wednesday", ",", "\u2581", "a", "\u2581police", "\u2581", "s", "pokesman", "\u2581said", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581four", "\u2581civilian", "s", "\u2581killed", "\u2581included", "\u2581two", "\u2581children", "\u2581of", "\u2581", "a", "\u2581family", "\u2581", "whose", "\u2581house", "\u2581was", "\u2581hit", "\u2581by", "\u2581", "a", "\u2581separate", "\u2581", "ava", "lan", "che", ",", "\u2581also", "\u2581on", "\u2581Wednesday", ",", "\u2581", "a", "\u2581police", "\u2581", "s", "pokesman", "\u2581said", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581The", "\u2581four", "\u2581civilian", "s", "\u2581killed", "\u2581included", "\u2581two", "\u2581children", "\u2581of", "\u2581", "a", "\u2581family", "\u2581", "whose", "\u2581house", "\u2581was", "\u2581hit", "\u2581by", "\u2581", "a", "\u2581separate", "\u2581", "ava", "lan", "che", ",", "\u2581also", "\u2581on", "\u2581Wednesday", ",", "\u2581", "a", "\u2581police", "\u2581", "s", "pokesman", "\u2581said", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 14, 15, 16, 17, 18, 19, 19, 20, 21, 21, 21, 21, 22, 23, 24, 25, 26, 27, 27, 28, 29, 29, 29, 30, 31, 32], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_4", "sentence": ["\u2581The", "\u2581bodies", "\u2581of", "\u2581the", "\u2581soldiers", "\u2581were", "\u2581recovered", "\u2581after", "\u2581the", "\u2581concert", "e", "d", "\u2581efforts", "\u2581of", "\u2581the", "\u2581A", "val", "an", "che", "\u2581Rescue", "\u2581Teams", "\u2581(", "\u2581", "ART", ")", ",", "\u2581which", "\u2581is", "\u2581equipped", "\u2581to", "\u2581work", "\u2581in", "\u2581in", "hos", "pit", "able", "\u2581terrain", "\u2581and", "\u2581weather", "\u2581conditions", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581bodies", "\u2581of", "\u2581the", "\u2581soldiers", "\u2581were", "\u2581recovered", "\u2581after", "\u2581the", "\u2581concert", "e", "d", "\u2581efforts", "\u2581of", "\u2581the", "\u2581A", "val", "an", "che", "\u2581Rescue", "\u2581Teams", "\u2581(", "\u2581", "ART", ")", ",", "\u2581which", "\u2581is", "\u2581equipped", "\u2581to", "\u2581work", "\u2581in", "\u2581in", "hos", "pit", "able", "\u2581terrain", "\u2581and", "\u2581weather", "\u2581conditions", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581bodies", "\u2581of", "\u2581the", "\u2581soldiers", "\u2581were", "\u2581recovered", "\u2581after", "\u2581the", "\u2581concert", "e", "d", "\u2581efforts", "\u2581of", "\u2581the", "<m>", "\u2581A", "val", "an", "che", "\u2581Rescue", "\u2581Teams", "</m>", "\u2581(", "<m>", "\u2581", "ART", "</m>", ")", ",", "\u2581which", "\u2581is", "\u2581equipped", "\u2581to", "\u2581work", "\u2581in", "\u2581in", "hos", "pit", "able", "\u2581terrain", "\u2581and", "\u2581weather", "\u2581conditions", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10, 11, 12, 13, 13, 13, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 26, 27, 28, 29, 30, 31, 32], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_5", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581", "Arrangement", "s", "\u2581are", "\u2581in", "\u2581place", "\u2581to", "\u2581carry", "\u2581the", "\u2581mortal", "\u2581remains", "\u2581of", "\u2581the", "\u2581martyr", "s", "\u2581to", "\u2581their", "\u2581native", "\u2581places", "\u2581immediately", "\u2581after", "\u2581weather", "\u2581becomes", "\u2581clear", ",", "\u2581Defence", "\u2581S", "pokesman", "\u2581Colonel", "\u2581Raj", "e", "s", "h", "\u2581K", "alia", "\u2581said", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581", "Arrangement", "s", "\u2581are", "\u2581in", "\u2581place", "\u2581to", "\u2581carry", "\u2581the", "\u2581mortal", "\u2581remains", "\u2581of", "\u2581the", "\u2581martyr", "s", "\u2581to", "\u2581their", "\u2581native", "\u2581places", "\u2581immediately", "\u2581after", "\u2581weather", "\u2581becomes", "\u2581clear", ",", "\u2581Defence", "\u2581S", "pokesman", "\u2581Colonel", "\u2581Raj", "e", "s", "h", "\u2581K", "alia", "\u2581said", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581*", "\u2581", "Arrangement", "s", "\u2581are", "\u2581in", "\u2581place", "\u2581to", "\u2581carry", "\u2581the", "\u2581mortal", "\u2581remains", "\u2581of", "\u2581the", "\u2581martyr", "s", "\u2581to", "\u2581their", "\u2581native", "\u2581places", "\u2581immediately", "\u2581after", "\u2581weather", "\u2581becomes", "\u2581clear", ",", "\u2581Defence", "\u2581S", "pokesman", "<m>", "\u2581Colonel", "\u2581Raj", "e", "s", "h", "\u2581K", "alia", "</m>", "\u2581said", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 28, 29, 29, 29, 29, 30, 30, 31, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_6", "sentence": ["\u2581Visual", "s", "\u2581of", "\u2581the", "\u2581", "ava", "lan", "che", "\u2581site", "\u2581in", "\u2581Gu", "rez", "\u2581sector", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Visual", "s", "\u2581of", "\u2581the", "\u2581", "ava", "lan", "che", "\u2581site", "\u2581in", "\u2581Gu", "rez", "\u2581sector", ".", "</s>"], "target_sentence": ["\u2581Visual", "s", "\u2581of", "\u2581the", "\u2581", "ava", "lan", "che", "\u2581site", "\u2581in", "<m>", "\u2581Gu", "rez", "</m>", "\u2581sector", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_7", "sentence": ["\u2581(", "\u2581Source", ":", "\u2581", "ANI", ")", "\u2581Visual", "s", "\u2581of", "\u2581the", "\u2581", "ava", "lan", "che", "\u2581site", "\u2581in", "\u2581Gu", "rez", "\u2581sector", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581(", "\u2581Source", ":", "\u2581", "ANI", ")", "\u2581Visual", "s", "\u2581of", "\u2581the", "\u2581", "ava", "lan", "che", "\u2581site", "\u2581in", "\u2581Gu", "rez", "\u2581sector", ".", "</s>"], "target_sentence": ["\u2581(", "\u2581Source", ":", "\u2581", "ANI", ")", "\u2581Visual", "s", "\u2581of", "\u2581the", "<m>", "\u2581", "ava", "lan", "che", "\u2581site", "</m>", "\u2581in", "<m>", "<m>", "<m>", "\u2581Gu", "rez", "</m>", "</m>", "\u2581sector", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 8, 8, 9, 10, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 2, 3, -1, 0, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 3, 1, 2, -1, -1, 1, 2, -1, 3, -1, -1]}, {"doc_id": "emerging.test_8", "sentence": ["\u2581(", "\u2581Source", ":", "\u2581", "ANI", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581(", "\u2581Source", ":", "\u2581", "ANI", ")", "</s>"], "target_sentence": ["\u2581(", "\u2581Source", ":", "\u2581", "ANI", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_9", "sentence": ["\u2581\u201c", "\u2581", "Arrangement", "s", "\u2581are", "\u2581in", "\u2581place", "\u2581to", "\u2581carry", "\u2581the", "\u2581mortal", "\u2581remains", "\u2581of", "\u2581the", "\u2581martyr", "s", "\u2581to", "\u2581their", "\u2581native", "\u2581places", "\u2581immediately", "\u2581after", "\u2581weather", "\u2581becomes", "\u2581clear", ",", "\u2581", "\u201d", "\u2581Defence", "\u2581S", "pokesman", "\u2581Colonel", "\u2581Raj", "e", "s", "h", "\u2581K", "alia", "\u2581said", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\u201c", "\u2581", "Arrangement", "s", "\u2581are", "\u2581in", "\u2581place", "\u2581to", "\u2581carry", "\u2581the", "\u2581mortal", "\u2581remains", "\u2581of", "\u2581the", "\u2581martyr", "s", "\u2581to", "\u2581their", "\u2581native", "\u2581places", "\u2581immediately", "\u2581after", "\u2581weather", "\u2581becomes", "\u2581clear", ",", "\u2581", "\u201d", "\u2581Defence", "\u2581S", "pokesman", "\u2581Colonel", "\u2581Raj", "e", "s", "h", "\u2581K", "alia", "\u2581said", ".", "</s>"], "target_sentence": ["\u2581\u201c", "\u2581", "Arrangement", "s", "\u2581are", "\u2581in", "\u2581place", "\u2581to", "\u2581carry", "\u2581the", "\u2581mortal", "\u2581remains", "\u2581of", "\u2581the", "\u2581martyr", "s", "\u2581to", "\u2581their", "\u2581native", "\u2581places", "\u2581immediately", "\u2581after", "\u2581weather", "\u2581becomes", "\u2581clear", ",", "\u2581", "\u201d", "\u2581Defence", "\u2581S", "pokesman", "\u2581Colonel", "<m>", "\u2581Raj", "e", "s", "h", "\u2581K", "alia", "</m>", "\u2581said", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 25, 26, 27, 27, 27, 27, 28, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_10", "sentence": ["\u2581Watch", "\u2581What", "\u2581El", "s", "e", "\u2581is", "\u2581Making", "\u2581News", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Watch", "\u2581What", "\u2581El", "s", "e", "\u2581is", "\u2581Making", "\u2581News", "</s>"], "target_sentence": ["\u2581Watch", "\u2581What", "\u2581El", "s", "e", "\u2581is", "\u2581Making", "\u2581News", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_11", "sentence": ["\u2581\u201c", "\u2581Swift", "\u2581action", "\u2581by", "\u2581", "a", "\u2581few", "\u2581soldiers", "\u2581at", "\u2581the", "\u2581post", "\u2581and", "\u2581timely", "\u2581help", "\u2581from", "\u2581the", "\u2581", "villagers", "\u2581of", "\u2581Maha", "z", "g", "und", "\u2581ensure", "d", "\u2581saving", "\u2581of", "\u2581six", "\u2581soldiers", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\u201c", "\u2581Swift", "\u2581action", "\u2581by", "\u2581", "a", "\u2581few", "\u2581soldiers", "\u2581at", "\u2581the", "\u2581post", "\u2581and", "\u2581timely", "\u2581help", "\u2581from", "\u2581the", "\u2581", "villagers", "\u2581of", "\u2581Maha", "z", "g", "und", "\u2581ensure", "d", "\u2581saving", "\u2581of", "\u2581six", "\u2581soldiers", ".", "</s>"], "target_sentence": ["\u2581\u201c", "\u2581Swift", "\u2581action", "\u2581by", "\u2581", "a", "\u2581few", "\u2581soldiers", "\u2581at", "\u2581the", "\u2581post", "\u2581and", "\u2581timely", "\u2581help", "\u2581from", "\u2581the", "\u2581", "villagers", "\u2581of", "<m>", "\u2581Maha", "z", "g", "und", "</m>", "\u2581ensure", "d", "\u2581saving", "\u2581of", "\u2581six", "\u2581soldiers", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 17, 17, 17, 18, 18, 19, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_12", "sentence": ["\u2581Unfortunately", ",", "\u2581three", "\u2581soldiers", "\u2581could", "\u2581not", "\u2581be", "\u2581saved", "\u2581", "whose", "\u2581bodies", "\u2581were", "\u2581", "retrieved", "\u2581on", "\u2581January", "\u258126", "\u2581by", "\u2581the", "\u2581", "ART", "s", "\u2581that", "\u2581were", "\u2581", "rushed", "\u2581to", "\u2581the", "\u2581post", ",", "\u2581", "\u201d", "\u2581", "he", "\u2581said", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Unfortunately", ",", "\u2581three", "\u2581soldiers", "\u2581could", "\u2581not", "\u2581be", "\u2581saved", "\u2581", "whose", "\u2581bodies", "\u2581were", "\u2581", "retrieved", "\u2581on", "\u2581January", "\u258126", "\u2581by", "\u2581the", "\u2581", "ART", "s", "\u2581that", "\u2581were", "\u2581", "rushed", "\u2581to", "\u2581the", "\u2581post", ",", "\u2581", "\u201d", "\u2581", "he", "\u2581said", ".", "</s>"], "target_sentence": ["\u2581Unfortunately", ",", "\u2581three", "\u2581soldiers", "\u2581could", "\u2581not", "\u2581be", "\u2581saved", "\u2581", "whose", "\u2581bodies", "\u2581were", "\u2581", "retrieved", "\u2581on", "\u2581January", "\u258126", "\u2581by", "\u2581the", "<m>", "\u2581", "ART", "s", "</m>", "\u2581that", "\u2581were", "\u2581", "rushed", "\u2581to", "\u2581the", "\u2581post", ",", "\u2581", "\u201d", "\u2581", "he", "\u2581said", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 17, 17, 18, 19, 20, 20, 21, 22, 23, 24, 25, 25, 26, 26, 27, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_13", "sentence": ["\u2581", "^", "\u2581Function", "\u2581", "^", ":", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581post", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581article", "'", "\u2581", "s", "\u2581", "^", "\u2581text", "\u2581", "^", "\u2581as", "\u2581", "^", "\u2581", "a", "\u2581", "^", "\u2581comment", "\u2581", "^", "\u2581", "if", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581website", "\u2581", "^", "\u2581is", "\u2581", "^", "\u2581", "a", "d", "block", "er", "\u2581", "^", "\u2581un", "friendly", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "^", "\u2581Function", "\u2581", "^", ":", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581post", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581article", "'", "\u2581", "s", "\u2581", "^", "\u2581text", "\u2581", "^", "\u2581as", "\u2581", "^", "\u2581", "a", "\u2581", "^", "\u2581comment", "\u2581", "^", "\u2581", "if", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581website", "\u2581", "^", "\u2581is", "\u2581", "^", "\u2581", "a", "d", "block", "er", "\u2581", "^", "\u2581un", "friendly", ".", "</s>"], "target_sentence": ["\u2581", "^", "\u2581Function", "\u2581", "^", ":", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581post", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581article", "'", "\u2581", "s", "\u2581", "^", "\u2581text", "\u2581", "^", "\u2581as", "\u2581", "^", "\u2581", "a", "\u2581", "^", "\u2581comment", "\u2581", "^", "\u2581", "if", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581website", "\u2581", "^", "\u2581is", "\u2581", "^", "\u2581", "a", "d", "block", "er", "\u2581", "^", "\u2581un", "friendly", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 13, 14, 14, 15, 16, 16, 17, 18, 18, 19, 19, 20, 20, 21, 22, 22, 23, 23, 24, 24, 25, 26, 26, 27, 28, 28, 29, 30, 30, 31, 31, 31, 31, 31, 32, 32, 33, 33, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_14", "sentence": ["\u2581[", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581accept", "\u2581", "^", "\u2581commands", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581accept", "\u2581", "^", "\u2581commands", "!", "</s>"], "target_sentence": ["\u2581[", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581accept", "\u2581", "^", "\u2581commands", "!", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_15", "sentence": ["\u2581Road", "\u2581and", "\u2581airport", "\u2581closure", "\u2581isolate", "\u2581Sri", "n", "a", "gar", "\u2581as", "\u2581", "ava", "lan", "che", "\u2581risk", "\u2581remains", "\u2581high", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Road", "\u2581and", "\u2581airport", "\u2581closure", "\u2581isolate", "\u2581Sri", "n", "a", "gar", "\u2581as", "\u2581", "ava", "lan", "che", "\u2581risk", "\u2581remains", "\u2581high", "</s>"], "target_sentence": ["\u2581Road", "\u2581and", "\u2581airport", "\u2581closure", "\u2581isolate", "<m>", "<m>", "\u2581Sri", "n", "a", "gar", "</m>", "</m>", "\u2581as", "\u2581", "ava", "lan", "che", "\u2581risk", "\u2581remains", "\u2581high", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 6, 7, 7, 7, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_16", "sentence": ["\u2581[", "\u2581", "IM", "AGE", "]", "\u2581(", "\u2581http", "://", "image", "s", ".", "in", "dian", "ex", "press", ".", "com", "/", "2015", "/05/", "d", "r", "d", "o", "-", "log", "o", "-", "th", "umb", ".", "jpg", "?", "w", "=", "480", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "IM", "AGE", "]", "\u2581(", "\u2581http", "://", "image", "s", ".", "in", "dian", "ex", "press", ".", "com", "/", "2015", "/05/", "d", "r", "d", "o", "-", "log", "o", "-", "th", "umb", ".", "jpg", "?", "w", "=", "480", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581", "IM", "AGE", "]", "\u2581(", "\u2581http", "://", "image", "s", ".", "in", "dian", "ex", "press", ".", "com", "/", "2015", "/05/", "d", "r", "d", "o", "-", "log", "o", "-", "th", "umb", ".", "jpg", "?", "w", "=", "480", ")", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_17", "sentence": ["\u2581The", "\u2581", "DR", "DO", "\u2581is", "\u2581working", "\u2581on", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581to", "\u2581predict", "\u2581", "ava", "lan", "ches", "\u2581in", "\u2581", "a", "\u2581much", "\u2581precise", "\u2581manner", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581", "DR", "DO", "\u2581is", "\u2581working", "\u2581on", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581to", "\u2581predict", "\u2581", "ava", "lan", "ches", "\u2581in", "\u2581", "a", "\u2581much", "\u2581precise", "\u2581manner", ".", "</s>"], "target_sentence": ["\u2581The", "<m>", "<m>", "\u2581", "DR", "DO", "</m>", "</m>", "\u2581is", "\u2581working", "\u2581on", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581to", "\u2581predict", "\u2581", "ava", "lan", "ches", "\u2581in", "\u2581", "a", "\u2581much", "\u2581precise", "\u2581manner", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 13, 14, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 1, 0, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_18", "sentence": ["\u2581(", "\u2581File", "\u2581Photo", ")", "\u2581The", "\u2581", "DR", "DO", "\u2581is", "\u2581working", "\u2581on", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581to", "\u2581predict", "\u2581", "ava", "lan", "ches", "\u2581in", "\u2581", "a", "\u2581much", "\u2581precise", "\u2581manner", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581(", "\u2581File", "\u2581Photo", ")", "\u2581The", "\u2581", "DR", "DO", "\u2581is", "\u2581working", "\u2581on", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581to", "\u2581predict", "\u2581", "ava", "lan", "ches", "\u2581in", "\u2581", "a", "\u2581much", "\u2581precise", "\u2581manner", ".", "</s>"], "target_sentence": ["\u2581(", "\u2581File", "\u2581Photo", ")", "\u2581The", "<m>", "<m>", "<m>", "\u2581", "DR", "DO", "</m>", "</m>", "</m>", "\u2581is", "\u2581working", "\u2581on", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581to", "\u2581predict", "\u2581", "ava", "lan", "ches", "\u2581in", "\u2581", "a", "\u2581much", "\u2581precise", "\u2581manner", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 17, 18, 18, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 2, 1, 0, -1, -1, -1, 2, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_19", "sentence": ["\u2581(", "\u2581File", "\u2581Photo", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581(", "\u2581File", "\u2581Photo", ")", "</s>"], "target_sentence": ["\u2581(", "\u2581File", "\u2581Photo", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_20", "sentence": ["\u2581The", "\u2581Defence", "\u2581Research", "\u2581Development", "\u2581Organisation", "\u2581(", "\u2581", "DR", "DO", ")", "\u2581is", "\u2581working", "\u2581on", "\u2581four", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581for", "\u2581more", "\u2581accurate", "\u2581prediction", "\u2581of", "\u2581", "ava", "lan", "ches", ",", "\u2581the", "\u2581government", "\u2581said", "\u2581on", "\u2581Friday", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581Defence", "\u2581Research", "\u2581Development", "\u2581Organisation", "\u2581(", "\u2581", "DR", "DO", ")", "\u2581is", "\u2581working", "\u2581on", "\u2581four", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581for", "\u2581more", "\u2581accurate", "\u2581prediction", "\u2581of", "\u2581", "ava", "lan", "ches", ",", "\u2581the", "\u2581government", "\u2581said", "\u2581on", "\u2581Friday", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581Defence", "\u2581Research", "\u2581Development", "\u2581Organisation", "\u2581(", "\u2581", "DR", "DO", ")", "\u2581is", "\u2581working", "\u2581on", "\u2581four", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581for", "\u2581more", "\u2581accurate", "\u2581prediction", "\u2581of", "\u2581", "ava", "lan", "ches", ",", "\u2581the", "\u2581government", "\u2581said", "\u2581on", "\u2581Friday", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_21", "sentence": ["\u2581\u201c", "\u2581Present", "ly", ",", "\u2581the", "\u2581", "DR", "DO", "\u2581is", "\u2581working", "\u2581on", "\u2581four", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581for", "\u2581more", "\u2581accurate", "\u2581prediction", "\u2581of", "\u2581", "ava", "lan", "ches", ",", "\u2581", "\u201d", "\u2581", "he", "\u2581said", "\u2581in", "\u2581", "a", "\u2581written", "\u2581response", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\u201c", "\u2581Present", "ly", ",", "\u2581the", "\u2581", "DR", "DO", "\u2581is", "\u2581working", "\u2581on", "\u2581four", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581for", "\u2581more", "\u2581accurate", "\u2581prediction", "\u2581of", "\u2581", "ava", "lan", "ches", ",", "\u2581", "\u201d", "\u2581", "he", "\u2581said", "\u2581in", "\u2581", "a", "\u2581written", "\u2581response", ".", "</s>"], "target_sentence": ["\u2581\u201c", "\u2581Present", "ly", ",", "\u2581the", "<m>", "\u2581", "DR", "DO", "</m>", "\u2581is", "\u2581working", "\u2581on", "\u2581four", "\u2581projects", "\u2581to", "\u2581develop", "\u2581new", "\u2581technologies", "\u2581for", "\u2581more", "\u2581accurate", "\u2581prediction", "\u2581of", "\u2581", "ava", "lan", "ches", ",", "\u2581", "\u201d", "\u2581", "he", "\u2581said", "\u2581in", "\u2581", "a", "\u2581written", "\u2581response", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 20, 21, 21, 22, 22, 23, 24, 25, 25, 26, 27, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_22", "sentence": ["\u2581Rep", "ly", "ing", "\u2581to", "\u2581another", "\u2581question", ",", "\u2581B", "ham", "re", "\u2581said", "\u2581the", "\u2581jaw", "ans", "\u2581deployed", "\u2581at", "\u2581places", "\u2581such", "\u2581as", "\u2581Si", "a", "chen", "\u2581Gla", "cier", "\u2581are", "\u2581provided", "\u2581with", "\u2581the", "\u2581best", "-", "quality", "\u2581winter", "\u2581clothing", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Rep", "ly", "ing", "\u2581to", "\u2581another", "\u2581question", ",", "\u2581B", "ham", "re", "\u2581said", "\u2581the", "\u2581jaw", "ans", "\u2581deployed", "\u2581at", "\u2581places", "\u2581such", "\u2581as", "\u2581Si", "a", "chen", "\u2581Gla", "cier", "\u2581are", "\u2581provided", "\u2581with", "\u2581the", "\u2581best", "-", "quality", "\u2581winter", "\u2581clothing", ".", "</s>"], "target_sentence": ["\u2581Rep", "ly", "ing", "\u2581to", "\u2581another", "\u2581question", ",", "<m>", "<m>", "\u2581B", "ham", "re", "</m>", "</m>", "\u2581said", "\u2581the", "<m>", "\u2581jaw", "ans", "</m>", "\u2581deployed", "\u2581at", "\u2581places", "\u2581such", "\u2581as", "<m>", "<m>", "<m>", "\u2581Si", "a", "chen", "\u2581Gla", "cier", "</m>", "</m>", "</m>", "\u2581are", "\u2581provided", "\u2581with", "\u2581the", "\u2581best", "-", "quality", "\u2581winter", "\u2581clothing", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 14, 15, 15, 16, 17, 18, 19, 20, 20, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 1, 0, -1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, 4, 5, 3, -1, -1, -1, -1, -1, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_23", "sentence": ["\u2581He", "\u2581said", "\u2581the", "\u2581soldiers", "\u2581deployed", "\u2581in", "\u2581Si", "a", "chen", "\u2581are", "\u2581being", "\u2581provided", "\u2581pre", "-", "fabricated", "\u2581", "insulated", "\u2581shelter", "s", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581He", "\u2581said", "\u2581the", "\u2581soldiers", "\u2581deployed", "\u2581in", "\u2581Si", "a", "chen", "\u2581are", "\u2581being", "\u2581provided", "\u2581pre", "-", "fabricated", "\u2581", "insulated", "\u2581shelter", "s", ".", "</s>"], "target_sentence": ["\u2581He", "\u2581said", "\u2581the", "\u2581soldiers", "\u2581deployed", "\u2581in", "<m>", "<m>", "<m>", "\u2581Si", "a", "chen", "</m>", "</m>", "</m>", "\u2581are", "\u2581being", "\u2581provided", "\u2581pre", "-", "fabricated", "\u2581", "insulated", "\u2581shelter", "s", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 1, 2, 0, -1, -1, -1, 1, 2, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_24", "sentence": ["\u2581\u201c", "\u2581In", "\u2581Navy", ",", "\u2581advisor", "ies", "\u2581on", "\u2581mental", "\u2581health", "\u2581are", "\u2581issued", "\u2581from", "\u2581time", "\u2581to", "\u2581time", "\u2581and", "\u2581stress", "\u2581relie", "ving", "\u2581activities", "\u2581like", "\u2581yoga", ",", "\u2581art", "\u2581of", "\u2581living", "\u2581are", "\u2581conducted", "\u2581periodically", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\u201c", "\u2581In", "\u2581Navy", ",", "\u2581advisor", "ies", "\u2581on", "\u2581mental", "\u2581health", "\u2581are", "\u2581issued", "\u2581from", "\u2581time", "\u2581to", "\u2581time", "\u2581and", "\u2581stress", "\u2581relie", "ving", "\u2581activities", "\u2581like", "\u2581yoga", ",", "\u2581art", "\u2581of", "\u2581living", "\u2581are", "\u2581conducted", "\u2581periodically", ".", "</s>"], "target_sentence": ["\u2581\u201c", "\u2581In", "\u2581Navy", ",", "\u2581advisor", "ies", "\u2581on", "\u2581mental", "\u2581health", "\u2581are", "\u2581issued", "\u2581from", "\u2581time", "\u2581to", "\u2581time", "\u2581and", "\u2581stress", "\u2581relie", "ving", "\u2581activities", "\u2581like", "\u2581yoga", ",", "\u2581art", "\u2581of", "\u2581living", "\u2581are", "\u2581conducted", "\u2581periodically", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_25", "sentence": ["\u2581", "^", "\u2581Function", "\u2581", "^", ":", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581post", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581article", "'", "\u2581", "s", "\u2581", "^", "\u2581text", "\u2581", "^", "\u2581as", "\u2581", "^", "\u2581", "a", "\u2581", "^", "\u2581comment", "\u2581", "^", "\u2581", "if", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581website", "\u2581", "^", "\u2581is", "\u2581", "^", "\u2581", "a", "d", "block", "er", "\u2581", "^", "\u2581un", "friendly", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "^", "\u2581Function", "\u2581", "^", ":", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581post", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581article", "'", "\u2581", "s", "\u2581", "^", "\u2581text", "\u2581", "^", "\u2581as", "\u2581", "^", "\u2581", "a", "\u2581", "^", "\u2581comment", "\u2581", "^", "\u2581", "if", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581website", "\u2581", "^", "\u2581is", "\u2581", "^", "\u2581", "a", "d", "block", "er", "\u2581", "^", "\u2581un", "friendly", ".", "</s>"], "target_sentence": ["\u2581", "^", "\u2581Function", "\u2581", "^", ":", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581post", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581article", "'", "\u2581", "s", "\u2581", "^", "\u2581text", "\u2581", "^", "\u2581as", "\u2581", "^", "\u2581", "a", "\u2581", "^", "\u2581comment", "\u2581", "^", "\u2581", "if", "\u2581", "^", "\u2581the", "\u2581", "^", "\u2581website", "\u2581", "^", "\u2581is", "\u2581", "^", "\u2581", "a", "d", "block", "er", "\u2581", "^", "\u2581un", "friendly", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 13, 14, 14, 15, 16, 16, 17, 18, 18, 19, 19, 20, 20, 21, 22, 22, 23, 23, 24, 24, 25, 26, 26, 27, 28, 28, 29, 30, 30, 31, 31, 31, 31, 31, 32, 32, 33, 33, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_26", "sentence": ["\u2581[", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581accept", "\u2581", "^", "\u2581commands", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581accept", "\u2581", "^", "\u2581commands", "!", "</s>"], "target_sentence": ["\u2581[", "\u2581", "^", "\u2581I", "\u2581", "^", "\u2581accept", "\u2581", "^", "\u2581commands", "!", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_27", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Um", "m", ",", "\u2581where", "\u2581are", "\u2581all", "\u2581these", "\u2581", "alleged", "\u2581criticism", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581Um", "m", ",", "\u2581where", "\u2581are", "\u2581all", "\u2581these", "\u2581", "alleged", "\u2581criticism", "s", "?", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Um", "m", ",", "\u2581where", "\u2581are", "\u2581all", "\u2581these", "\u2581", "alleged", "\u2581criticism", "s", "?", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_28", "sentence": ["\u2581This", "\u2581fu", "cker", "\u2581should", "\u2581be", "\u2581sent", "\u2581up", "\u2581the", "\u2581", "f", "uck", "ing", "\u2581river", "\u2581because", "\u2581of", "\u2581what", "\u2581", "he", "\u2581did", "\u2581not", "\u2581because", "\u2581", "he", "\u2581like", "s", "\u2581Trump", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581fu", "cker", "\u2581should", "\u2581be", "\u2581sent", "\u2581up", "\u2581the", "\u2581", "f", "uck", "ing", "\u2581river", "\u2581because", "\u2581of", "\u2581what", "\u2581", "he", "\u2581did", "\u2581not", "\u2581because", "\u2581", "he", "\u2581like", "s", "\u2581Trump", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581fu", "cker", "\u2581should", "\u2581be", "\u2581sent", "\u2581up", "\u2581the", "\u2581", "f", "uck", "ing", "\u2581river", "\u2581because", "\u2581of", "\u2581what", "\u2581", "he", "\u2581did", "\u2581not", "\u2581because", "\u2581", "he", "\u2581like", "s", "<m>", "\u2581Trump", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 16, 17, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1]}, {"doc_id": "emerging.test_29", "sentence": ["\u2581B", "han", "gra", "\u2581is", "\u2581Punjab", "i", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581B", "han", "gra", "\u2581is", "\u2581Punjab", "i", ".", "</s>"], "target_sentence": ["<m>", "\u2581B", "han", "gra", "</m>", "\u2581is", "<m>", "\u2581Punjab", "i", "</m>", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, 1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_30", "sentence": ["\u2581A", "\u2581lot", "\u2581of", "\u2581people", "\u2581thought", "\u2581it", "\u2581was", "\u2581", "a", "\u2581joke", "\u2581but", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581it", "\u2581was", "\u2581appropriate", "\u2581for", "\u2581", "a", "\u2581PR", "\u2581", "exe", "c", "\u2581to", "\u2581make", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "\u2581lot", "\u2581of", "\u2581people", "\u2581thought", "\u2581it", "\u2581was", "\u2581", "a", "\u2581joke", "\u2581but", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581it", "\u2581was", "\u2581appropriate", "\u2581for", "\u2581", "a", "\u2581PR", "\u2581", "exe", "c", "\u2581to", "\u2581make", ".", "</s>"], "target_sentence": ["\u2581A", "\u2581lot", "\u2581of", "\u2581people", "\u2581thought", "\u2581it", "\u2581was", "\u2581", "a", "\u2581joke", "\u2581but", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581it", "\u2581was", "\u2581appropriate", "\u2581for", "\u2581", "a", "\u2581PR", "\u2581", "exe", "c", "\u2581to", "\u2581make", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 21, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_31", "sentence": ["\u2581Ton", "i", "\u2581Kro", "o", "s", "\u2581", "-", "\u2581[", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "my", "29", "a", "/", "n", "ear", "certain", "_", "f", "if", "pro", "_", "x", "i", "_", "for", "_", "2016", "_", "n", "euer", "_", "d", "ani", "_", "a", "lves", "/", ")", "\u2581is", "\u2581the", "\u2581(", "\u2581near", "-", "certain", ")", "\u2581full", "\u2581", "X", "I", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ton", "i", "\u2581Kro", "o", "s", "\u2581", "-", "\u2581[", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "my", "29", "a", "/", "n", "ear", "certain", "_", "f", "if", "pro", "_", "x", "i", "_", "for", "_", "2016", "_", "n", "euer", "_", "d", "ani", "_", "a", "lves", "/", ")", "\u2581is", "\u2581the", "\u2581(", "\u2581near", "-", "certain", ")", "\u2581full", "\u2581", "X", "I", ".", "</s>"], "target_sentence": ["<m>", "\u2581Ton", "i", "\u2581Kro", "o", "s", "</m>", "\u2581", "-", "\u2581[", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "my", "29", "a", "/", "n", "ear", "certain", "_", "f", "if", "pro", "_", "x", "i", "_", "for", "_", "2016", "_", "n", "euer", "_", "d", "ani", "_", "a", "lves", "/", ")", "\u2581is", "\u2581the", "\u2581(", "\u2581near", "-", "certain", ")", "\u2581full", "\u2581", "X", "I", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 12, 12, 12, 13, 14, 15, 15, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_32", "sentence": ["\u2581[", "\u2581Ri", "p", "\u2581Cha", "d", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "m", "i", "9", "b", "l", "/", "gra", "nada", "_", "and", "_", "me", "m", "o", "_", "o", "cho", "a", "_", "are", "_", "ready", "_", "to", "_", "end", "_", "real", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Ri", "p", "\u2581Cha", "d", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "m", "i", "9", "b", "l", "/", "gra", "nada", "_", "and", "_", "me", "m", "o", "_", "o", "cho", "a", "_", "are", "_", "ready", "_", "to", "_", "end", "_", "real", "/", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581Ri", "p", "<m>", "\u2581Cha", "d", "</m>", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "m", "i", "9", "b", "l", "/", "gra", "nada", "_", "and", "_", "me", "m", "o", "_", "o", "cho", "a", "_", "are", "_", "ready", "_", "to", "_", "end", "_", "real", "/", ")", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_33", "sentence": ["\u2581[", "\u2581link", "\u2581to", "\u2581thread", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "p", "c", "0", "r", "f", "/", "com", "ment", "/", "d", "c", "q", "17", "s", "w", "?", "s", "t", "=", "I", "Y", "7", "V", "W", "P", "YA", "&", "amp", ";", "s", "h", "=", "6", "e", "21", "e", "75", "1", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581link", "\u2581to", "\u2581thread", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "p", "c", "0", "r", "f", "/", "com", "ment", "/", "d", "c", "q", "17", "s", "w", "?", "s", "t", "=", "I", "Y", "7", "V", "W", "P", "YA", "&", "amp", ";", "s", "h", "=", "6", "e", "21", "e", "75", "1", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581link", "\u2581to", "\u2581thread", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "p", "c", "0", "r", "f", "/", "com", "ment", "/", "d", "c", "q", "17", "s", "w", "?", "s", "t", "=", "I", "Y", "7", "V", "W", "P", "YA", "&", "amp", ";", "s", "h", "=", "6", "e", "21", "e", "75", "1", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_34", "sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "o", "p", "2", "n", "/", "de", "y", "vers", "on", "_", "al", "%", "C", "3%", "A", "1", "ve", "s", "_", "and", "_", "go", "d", "%", "C", "3%", "AD", "n", "_", "at", "l", "%", "C", "3%", "A", "9", "tic", "o", "_", "spi", "tting", "_", "at", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "o", "p", "2", "n", "/", "de", "y", "vers", "on", "_", "al", "%", "C", "3%", "A", "1", "ve", "s", "_", "and", "_", "go", "d", "%", "C", "3%", "AD", "n", "_", "at", "l", "%", "C", "3%", "A", "9", "tic", "o", "_", "spi", "tting", "_", "at", "/", "</s>"], "target_sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "o", "p", "2", "n", "/", "de", "y", "vers", "on", "_", "al", "%", "C", "3%", "A", "1", "ve", "s", "_", "and", "_", "go", "d", "%", "C", "3%", "AD", "n", "_", "at", "l", "%", "C", "3%", "A", "9", "tic", "o", "_", "spi", "tting", "_", "at", "/", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_35", "sentence": ["\u2581No", "pe", ",", "\u2581[", "\u2581I", "\u2581have", "\u2581multiple", "\u2581sources", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581No", "pe", ",", "\u2581[", "\u2581I", "\u2581have", "\u2581multiple", "\u2581sources", ".", "</s>"], "target_sentence": ["\u2581No", "pe", ",", "\u2581[", "\u2581I", "\u2581have", "\u2581multiple", "\u2581sources", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_36", "sentence": ["\u2581[", "\u2581Action", "\u2581plan", "\u2581already", "\u2581in", "\u2581place", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "n", "v", "s", "w", "j", "/", "my", "_", "israel", "i", "_", "war", "_", "effort", "_", "and", "_", "money", "_", "saving", "_", "tip", "_", "how", "_", "to", "/", "?", "re", "f", "=", "search", "_", "post", "s", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Action", "\u2581plan", "\u2581already", "\u2581in", "\u2581place", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "n", "v", "s", "w", "j", "/", "my", "_", "israel", "i", "_", "war", "_", "effort", "_", "and", "_", "money", "_", "saving", "_", "tip", "_", "how", "_", "to", "/", "?", "re", "f", "=", "search", "_", "post", "s", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581Action", "\u2581plan", "\u2581already", "\u2581in", "\u2581place", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "n", "v", "s", "w", "j", "/", "my", "_", "israel", "i", "_", "war", "_", "effort", "_", "and", "_", "money", "_", "saving", "_", "tip", "_", "how", "_", "to", "/", "?", "re", "f", "=", "search", "_", "post", "s", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_37", "sentence": ["\u2581", "KE", "INE", "\u2581B", "REM", "SEN", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "KE", "INE", "\u2581B", "REM", "SEN", "!", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581", "KE", "INE", "\u2581B", "REM", "SEN", "</m>", "</m>", "!", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1], "ent_indices": [1, 0, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1]}, {"doc_id": "emerging.test_38", "sentence": ["\u2581All", "\u2581those", "\u2581in", "\u2581favor", "\u2581say", "\u2581\"", "\u2581Jin", "a", "\u2581did", "\u2581it", "\u2581\"", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581All", "\u2581those", "\u2581in", "\u2581favor", "\u2581say", "\u2581\"", "\u2581Jin", "a", "\u2581did", "\u2581it", "\u2581\"", ".", "</s>"], "target_sentence": ["\u2581All", "\u2581those", "\u2581in", "\u2581favor", "\u2581say", "\u2581\"", "<m>", "\u2581Jin", "a", "</m>", "\u2581did", "\u2581it", "\u2581\"", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_39", "sentence": ["\u2581What", "\u2581country", "\u2581in", "\u2581Europe", "\u2581has", "\u2581", "n", "'", "\u2581", "t", "\u2581she", "\u2581", "stab", "bed", "\u2581in", "\u2581the", "\u2581back", "\u2581or", "\u2581undermine", "d", "\u2581their", "\u2581interests", "?", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581country", "\u2581in", "\u2581Europe", "\u2581has", "\u2581", "n", "'", "\u2581", "t", "\u2581she", "\u2581", "stab", "bed", "\u2581in", "\u2581the", "\u2581back", "\u2581or", "\u2581undermine", "d", "\u2581their", "\u2581interests", "?", "\u2581\"", "</s>"], "target_sentence": ["\u2581What", "\u2581country", "\u2581in", "<m>", "<m>", "\u2581Europe", "</m>", "</m>", "\u2581has", "\u2581", "n", "'", "\u2581", "t", "\u2581she", "\u2581", "stab", "bed", "\u2581in", "\u2581the", "\u2581back", "\u2581or", "\u2581undermine", "d", "\u2581their", "\u2581interests", "?", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 9, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_40", "sentence": ["\u2581He", "\u2581got", "\u2581sent", "\u2581off", "\u2581in", "\u2581the", "\u2581last", "\u2581game", "\u2581", "v", "s", "\u2581Bordeaux", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581He", "\u2581got", "\u2581sent", "\u2581off", "\u2581in", "\u2581the", "\u2581last", "\u2581game", "\u2581", "v", "s", "\u2581Bordeaux", ".", "</s>"], "target_sentence": ["\u2581He", "\u2581got", "\u2581sent", "\u2581off", "\u2581in", "\u2581the", "\u2581last", "\u2581game", "\u2581", "v", "s", "<m>", "\u2581Bordeaux", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1]}, {"doc_id": "emerging.test_41", "sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "0", "e", "d", "k", "/", "com", "ment", "/", "d", "c", "n", "r", "f", "9", "t", "?", "s", "t", "=", "I", "Y", "5", "U", "4", "X", "SO", "&", "amp", ";", "s", "h", "=", "9", "f", "d", "7", "c", "3", "a", "9", "I", "just", "co", "ul", "d", "n", "'", "t", "see", "the", "edge", "of", "the", "New", "p", "ly", "mouth", "rada", "r", "circ", "le", "on", "OP", "'", "s", "pic", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "0", "e", "d", "k", "/", "com", "ment", "/", "d", "c", "n", "r", "f", "9", "t", "?", "s", "t", "=", "I", "Y", "5", "U", "4", "X", "SO", "&", "amp", ";", "s", "h", "=", "9", "f", "d", "7", "c", "3", "a", "9", "I", "just", "co", "ul", "d", "n", "'", "t", "see", "the", "edge", "of", "the", "New", "p", "ly", "mouth", "rada", "r", "circ", "le", "on", "OP", "'", "s", "pic", ".", "</s>"], "target_sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "0", "e", "d", "k", "/", "com", "ment", "/", "d", "c", "n", "r", "f", "9", "t", "?", "s", "t", "=", "I", "Y", "5", "U", "4", "X", "SO", "&", "amp", ";", "s", "h", "=", "9", "f", "d", "7", "c", "3", "a", "9", "I", "just", "co", "ul", "d", "n", "'", "t", "see", "the", "edge", "of", "the", "New", "p", "ly", "mouth", "rada", "r", "circ", "le", "on", "OP", "'", "s", "pic", ".", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_42", "sentence": ["\u2581CO", "Y", "B", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581CO", "Y", "B", "!", "</s>"], "target_sentence": ["\u2581CO", "Y", "B", "!", "</s>"], "subtoken_map": [0, 0, 0, 1, 2], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_43", "sentence": ["\u2581Oh", "\u2581well", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Oh", "\u2581well", ".", "</s>"], "target_sentence": ["\u2581Oh", "\u2581well", ".", "</s>"], "subtoken_map": [0, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1]}, {"doc_id": "emerging.test_44", "sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581yesterday", ":", "\u2581Trump", "\u2581has", "\u2581", "n", "'", "\u2581", "t", "\u2581had", "\u2581", "a", "\u2581press", "\u2581conference", "\u2581in", "\u2581", "a", "\u2581long", "\u2581time", ",", "\u2581", "he", "'", "\u2581", "s", "\u2581", "avoiding", "\u2581the", "\u2581media", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581yesterday", ":", "\u2581Trump", "\u2581has", "\u2581", "n", "'", "\u2581", "t", "\u2581had", "\u2581", "a", "\u2581press", "\u2581conference", "\u2581in", "\u2581", "a", "\u2581long", "\u2581time", ",", "\u2581", "he", "'", "\u2581", "s", "\u2581", "avoiding", "\u2581the", "\u2581media", "</s>"], "target_sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581yesterday", ":", "\u2581Trump", "\u2581has", "\u2581", "n", "'", "\u2581", "t", "\u2581had", "\u2581", "a", "\u2581press", "\u2581conference", "\u2581in", "\u2581", "a", "\u2581long", "\u2581time", ",", "\u2581", "he", "'", "\u2581", "s", "\u2581", "avoiding", "\u2581the", "\u2581media", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 20, 21, 22, 22, 23, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_45", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581been", "\u2581", "a", "\u2581hit", "\u2581out", "\u2581in", "\u2581the", "\u2581world", "\u2581since", "\u2581Fra", "gran", "t", "\u2581posted", "\u2581it", "\u2581here", ",", "\u2581Daily", "\u2581Edge", "\u2581Si", "d", "\u2581", "a", "\u2581piece", "\u2581too", "\u2581even", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "m", "6", "b", "s", "8", "/", "ker", "ry", "gold", "s", "_", "a", "f", "ric", "an", "_", "t", "v", "_", "a", "d", "s", "_", "are", "_", "a", "_", "little", "_", "bit", "_", "u", "h", "h", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581been", "\u2581", "a", "\u2581hit", "\u2581out", "\u2581in", "\u2581the", "\u2581world", "\u2581since", "\u2581Fra", "gran", "t", "\u2581posted", "\u2581it", "\u2581here", ",", "\u2581Daily", "\u2581Edge", "\u2581Si", "d", "\u2581", "a", "\u2581piece", "\u2581too", "\u2581even", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "m", "6", "b", "s", "8", "/", "ker", "ry", "gold", "s", "_", "a", "f", "ric", "an", "_", "t", "v", "_", "a", "d", "s", "_", "are", "_", "a", "_", "little", "_", "bit", "_", "u", "h", "h", "/", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581been", "\u2581", "a", "\u2581hit", "\u2581out", "\u2581in", "\u2581the", "\u2581world", "\u2581since", "<m>", "\u2581Fra", "gran", "t", "</m>", "\u2581posted", "\u2581it", "\u2581here", ",", "\u2581Daily", "\u2581Edge", "<m>", "\u2581Si", "d", "</m>", "\u2581", "a", "\u2581piece", "\u2581too", "\u2581even", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "m", "6", "b", "s", "8", "/", "ker", "ry", "gold", "s", "_", "a", "f", "ric", "an", "_", "t", "v", "_", "a", "d", "s", "_", "are", "_", "a", "_", "little", "_", "bit", "_", "u", "h", "h", "/", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 19, 20, 21, 22, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_46", "sentence": ["\u2581Guy", "\u2581sounds", "\u2581like", "\u2581", "a", "\u2581Grade", "\u2581A", "\u2581D", "ouche", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Guy", "\u2581sounds", "\u2581like", "\u2581", "a", "\u2581Grade", "\u2581A", "\u2581D", "ouche", "</s>"], "target_sentence": ["<m>", "\u2581Guy", "</m>", "\u2581sounds", "\u2581like", "\u2581", "a", "\u2581Grade", "\u2581A", "\u2581D", "ouche", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 6, 7], "ent_type_sequence": [-1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_47", "sentence": ["\u2581Bi", "a", "sed", ",", "\u2581but", "\u2581I", "\u2581think", "\u2581the", "\u2581best", "\u2581part", "\u2581of", "\u2581this", "\u2581is", "\u2581that", "\u2581", "a", "\u2581Meta", "Can", "a", "dian", "\u2581has", "\u2581the", "\u2581top", "\u2581comment", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Bi", "a", "sed", ",", "\u2581but", "\u2581I", "\u2581think", "\u2581the", "\u2581best", "\u2581part", "\u2581of", "\u2581this", "\u2581is", "\u2581that", "\u2581", "a", "\u2581Meta", "Can", "a", "dian", "\u2581has", "\u2581the", "\u2581top", "\u2581comment", ".", "</s>"], "target_sentence": ["\u2581Bi", "a", "sed", ",", "\u2581but", "\u2581I", "\u2581think", "\u2581the", "\u2581best", "\u2581part", "\u2581of", "\u2581this", "\u2581is", "\u2581that", "\u2581", "a", "\u2581Meta", "Can", "a", "dian", "\u2581has", "\u2581the", "\u2581top", "\u2581comment", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_48", "sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "h", "f", "8", "x", "/", "w", "alter", "_", "smith", "mes", "s", "i", "_", "was", "_", "right", "_", "we", "_", "did", "_", "play", "/", "d", "c", "b", "je", "v", "x", "/", "?", "con", "text", "=", "3", "on", "the", "con", "tra", "ry", "tru", "e", "M", "a", "d", "rid", "ist", "a", "s", "lov", "e", "me", ".", "\ud83d\ude22", "C", "ry", "M", "e", "s", "s", "if", "an", "boy", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "h", "f", "8", "x", "/", "w", "alter", "_", "smith", "mes", "s", "i", "_", "was", "_", "right", "_", "we", "_", "did", "_", "play", "/", "d", "c", "b", "je", "v", "x", "/", "?", "con", "text", "=", "3", "on", "the", "con", "tra", "ry", "tru", "e", "M", "a", "d", "rid", "ist", "a", "s", "lov", "e", "me", ".", "\ud83d\ude22", "C", "ry", "M", "e", "s", "s", "if", "an", "boy", "</s>"], "target_sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "h", "f", "8", "x", "/", "w", "alter", "_", "smith", "mes", "s", "i", "_", "was", "_", "right", "_", "we", "_", "did", "_", "play", "/", "d", "c", "b", "je", "v", "x", "/", "?", "con", "text", "=", "3", "on", "the", "con", "tra", "ry", "tru", "e", "M", "a", "d", "rid", "ist", "a", "s", "lov", "e", "me", ".", "\ud83d\ude22", "C", "ry", "M", "e", "s", "s", "if", "an", "boy", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_49", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581actually", "\u2581copy", "p", "asta", "\u2581from", "\u2581", "a", "\u2581post", "\u2581I", "\u2581did", "\u2581", "a", "\u2581couple", "\u2581April", "\u2581fool", "s", "\u2581ago", "\u2581when", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581was", "\u2581all", "\u2581", "t", "roll", "\u2581posts", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581actually", "\u2581copy", "p", "asta", "\u2581from", "\u2581", "a", "\u2581post", "\u2581I", "\u2581did", "\u2581", "a", "\u2581couple", "\u2581April", "\u2581fool", "s", "\u2581ago", "\u2581when", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581was", "\u2581all", "\u2581", "t", "roll", "\u2581posts", ".", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581actually", "\u2581copy", "p", "asta", "\u2581from", "\u2581", "a", "\u2581post", "\u2581I", "\u2581did", "\u2581", "a", "\u2581couple", "\u2581April", "\u2581fool", "s", "\u2581ago", "\u2581when", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581was", "\u2581all", "\u2581", "t", "roll", "\u2581posts", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 9, 10, 10, 11, 12, 13, 13, 14, 15, 16, 16, 17, 17, 18, 19, 20, 21, 21, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_50", "sentence": ["\u2581I", "\u2581hope", "\u2581", "y", "'", "\u2581all", "\u2581take", "\u2581back", "\u2581what", "\u2581you", "\u2581said", "\u2581at", "\u2581Glen", "n", "\u2581Green", "wald", "\u2581in", "\u2581the", "\u2581last", "\u2581thread", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581hope", "\u2581", "y", "'", "\u2581all", "\u2581take", "\u2581back", "\u2581what", "\u2581you", "\u2581said", "\u2581at", "\u2581Glen", "n", "\u2581Green", "wald", "\u2581in", "\u2581the", "\u2581last", "\u2581thread", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581hope", "\u2581", "y", "'", "\u2581all", "\u2581take", "\u2581back", "\u2581what", "\u2581you", "\u2581said", "\u2581at", "<m>", "\u2581Glen", "n", "\u2581Green", "wald", "</m>", "\u2581in", "\u2581the", "\u2581last", "\u2581thread", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_51", "sentence": ["\u2581Comme", "\u2581\u00e7a", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Comme", "\u2581\u00e7a", ":", "</s>"], "target_sentence": ["\u2581Comme", "\u2581\u00e7a", ":", "</s>"], "subtoken_map": [0, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1]}, {"doc_id": "emerging.test_52", "sentence": ["\u2581[", "\u2581New", "\u2581Match", "Th", "read", "\u2581here", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581New", "\u2581Match", "Th", "read", "\u2581here", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581New", "\u2581Match", "Th", "read", "\u2581here", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_53", "sentence": ["\u2581L", "MA", "OO", "OO", "OO", "OO", ",", "\u2581are", "\u2581the", "\u2581Democrats", "\u2581really", "\u2581", "doubling", "\u2581down", "\u2581on", "\u2581the", "\u2581thing", "\u2581that", "\u2581got", "\u2581Trump", "\u2581elected", "\u2581in", "\u2581first", "\u2581place", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581L", "MA", "OO", "OO", "OO", "OO", ",", "\u2581are", "\u2581the", "\u2581Democrats", "\u2581really", "\u2581", "doubling", "\u2581down", "\u2581on", "\u2581the", "\u2581thing", "\u2581that", "\u2581got", "\u2581Trump", "\u2581elected", "\u2581in", "\u2581first", "\u2581place", "?", "</s>"], "target_sentence": ["\u2581L", "MA", "OO", "OO", "OO", "OO", ",", "\u2581are", "\u2581the", "<m>", "\u2581Democrats", "</m>", "\u2581really", "\u2581", "doubling", "\u2581down", "\u2581on", "\u2581the", "\u2581thing", "\u2581that", "\u2581got", "<m>", "\u2581Trump", "</m>", "\u2581elected", "\u2581in", "\u2581first", "\u2581place", "?", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_54", "sentence": ["\u2581Living", "\u2581Computer", "\u2581Museum", "\u2581+", "\u2581Lab", "s", ",", "\u2581Sky", "view", "\u2581Observatory", ",", "\u2581Smith", "\u2581Tower", "\u2581and", "\u2581", "Observ", "ation", "\u2581Deck", ",", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Living", "\u2581Computer", "\u2581Museum", "\u2581+", "\u2581Lab", "s", ",", "\u2581Sky", "view", "\u2581Observatory", ",", "\u2581Smith", "\u2581Tower", "\u2581and", "\u2581", "Observ", "ation", "\u2581Deck", ",", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Living", "\u2581Computer", "\u2581Museum", "</m>", "</m>", "\u2581+", "\u2581Lab", "s", ",", "<m>", "\u2581Sky", "view", "\u2581Observatory", "</m>", ",", "<m>", "<m>", "\u2581Smith", "\u2581Tower", "</m>", "</m>", "\u2581and", "<m>", "\u2581", "Observ", "ation", "\u2581Deck", "</m>", ",", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, 3, 4, -1, -1, 3, 4, -1, 5, -1, -1, -1, -1, 5, -1, -1]}, {"doc_id": "emerging.test_55", "sentence": ["\u2581You", "\u2581posted", "\u2581this", "\u2581in", "\u2581", "TD", "\u2581so", "\u2581why", "\u2581are", "\u2581you", "\u2581still", "\u2581posting", "\u2581here", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581posted", "\u2581this", "\u2581in", "\u2581", "TD", "\u2581so", "\u2581why", "\u2581are", "\u2581you", "\u2581still", "\u2581posting", "\u2581here", "?", "</s>"], "target_sentence": ["\u2581You", "\u2581posted", "\u2581this", "\u2581in", "\u2581", "TD", "\u2581so", "\u2581why", "\u2581are", "\u2581you", "\u2581still", "\u2581posting", "\u2581here", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_56", "sentence": ["\u2581A", "w", "w", "\u2581", "s", "hit", "\u2581this", "\u2581", "gonna", "\u2581go", "\u2581into", "\u2581over", "drive", "\u2581now", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "w", "w", "\u2581", "s", "hit", "\u2581this", "\u2581", "gonna", "\u2581go", "\u2581into", "\u2581over", "drive", "\u2581now", "</s>"], "target_sentence": ["\u2581A", "w", "w", "\u2581", "s", "hit", "\u2581this", "\u2581", "gonna", "\u2581go", "\u2581into", "\u2581over", "drive", "\u2581now", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_57", "sentence": ["\u2581CV", "S", "\u2581selling", "\u2581their", "\u2581own", "\u2581version", "\u2581of", "\u2581epi", "pen", "\u2581at", "\u25811", "\u2581", "/", "\u25816", "\u2581", "th", "\u2581price", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581CV", "S", "\u2581selling", "\u2581their", "\u2581own", "\u2581version", "\u2581of", "\u2581epi", "pen", "\u2581at", "\u25811", "\u2581", "/", "\u25816", "\u2581", "th", "\u2581price", ".", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581CV", "S", "</m>", "</m>", "\u2581selling", "\u2581their", "\u2581own", "\u2581version", "\u2581of", "\u2581epi", "pen", "\u2581at", "\u25811", "\u2581", "/", "\u25816", "\u2581", "th", "\u2581price", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_58", "sentence": ["\u2581Trump", ":", "\u2581I", "'", "\u2581", "m", "\u2581going", "\u2581to", "\u2581bring", "\u2581back", "\u2581manufacturing", "\u2581jobs", "\u2581to", "\u2581Michigan", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Trump", ":", "\u2581I", "'", "\u2581", "m", "\u2581going", "\u2581to", "\u2581bring", "\u2581back", "\u2581manufacturing", "\u2581jobs", "\u2581to", "\u2581Michigan", "!", "</s>"], "target_sentence": ["<m>", "\u2581Trump", "</m>", ":", "\u2581I", "'", "\u2581", "m", "\u2581going", "\u2581to", "\u2581bring", "\u2581back", "\u2581manufacturing", "\u2581jobs", "\u2581to", "<m>", "\u2581Michigan", "</m>", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_59", "sentence": ["\u2581Beck", "y", "\u2581in", "\u2581", "a", "\u2581S", "nick", "ers", "\u2581advert", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Beck", "y", "\u2581in", "\u2581", "a", "\u2581S", "nick", "ers", "\u2581advert", "?", "</s>"], "target_sentence": ["<m>", "\u2581Beck", "y", "</m>", "\u2581in", "\u2581", "a", "<m>", "\u2581S", "nick", "ers", "</m>", "\u2581advert", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1]}, {"doc_id": "emerging.test_60", "sentence": ["]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/", "13", "x", "m", "s", "v", "/", "we", "_", "all", "_", "know", "_", "the", "_", "ney", "mar", "s", "_", "the", "_", "g", "%", "C", "3%", "B", "6", "t", "ze", "s", "_", "and", "_", "the", "_", "i", "sco", "s", "/", "c", "78", "5", "f", "f", "z", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "front", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "s", "occ", "er", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/", "13", "x", "m", "s", "v", "/", "we", "_", "all", "_", "know", "_", "the", "_", "ney", "mar", "s", "_", "the", "_", "g", "%", "C", "3%", "B", "6", "t", "ze", "s", "_", "and", "_", "the", "_", "i", "sco", "s", "/", "c", "78", "5", "f", "f", "z", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "front", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "s", "occ", "er", ")", "</s>"], "target_sentence": ["]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/", "13", "x", "m", "s", "v", "/", "we", "_", "all", "_", "know", "_", "the", "_", "ney", "mar", "s", "_", "the", "_", "g", "%", "C", "3%", "B", "6", "t", "ze", "s", "_", "and", "_", "the", "_", "i", "sco", "s", "/", "c", "78", "5", "f", "f", "z", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "front", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "s", "occ", "er", ")", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_61", "sentence": ["\u2581I", "\u2581looked", "\u2581this", "\u2581up", "\u2581yesterday", "\u2581actually", ";", "\u2581the", "\u2581average", "\u2581household", "\u2581income", "\u2581for", "\u2581Auckland", "\u2581in", "\u25812016", "\u2581was", "\u2581$", "\u2581", "104", "\u2581", "k", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581looked", "\u2581this", "\u2581up", "\u2581yesterday", "\u2581actually", ";", "\u2581the", "\u2581average", "\u2581household", "\u2581income", "\u2581for", "\u2581Auckland", "\u2581in", "\u25812016", "\u2581was", "\u2581$", "\u2581", "104", "\u2581", "k", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581looked", "\u2581this", "\u2581up", "\u2581yesterday", "\u2581actually", ";", "\u2581the", "\u2581average", "\u2581household", "\u2581income", "\u2581for", "<m>", "\u2581Auckland", "</m>", "\u2581in", "\u25812016", "\u2581was", "\u2581$", "\u2581", "104", "\u2581", "k", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_62", "sentence": ["\u2581You", "\u2581mean", "\u2581they", "\u2581had", "\u2581rain", "\u2581[", "\u25814", "\u2581years", "\u2581ago", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/11", "mm", "7", "z", "/", "plu", "n", "kett", "_", "station", "_", "water", "ford", "/", ")", "\u2581in", "\u2581Ireland", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581mean", "\u2581they", "\u2581had", "\u2581rain", "\u2581[", "\u25814", "\u2581years", "\u2581ago", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/11", "mm", "7", "z", "/", "plu", "n", "kett", "_", "station", "_", "water", "ford", "/", ")", "\u2581in", "\u2581Ireland", ".", "</s>"], "target_sentence": ["\u2581You", "\u2581mean", "\u2581they", "\u2581had", "\u2581rain", "\u2581[", "\u25814", "\u2581years", "\u2581ago", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/11", "mm", "7", "z", "/", "plu", "n", "kett", "_", "station", "_", "water", "ford", "/", ")", "\u2581in", "<m>", "\u2581Ireland", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1]}, {"doc_id": "emerging.test_63", "sentence": ["\u2581I", "\u2581remember", "\u2581having", "\u2581parliament", "\u2581on", "\u2581the", "\u2581radio", "\u2581in", "\u2581my", "\u2581car", "\u2581and", "\u2581hearing", "\u2581Le", "y", "on", "h", "je", "l", "m", "\u2581[", "\u2581give", "\u2581this", "\u2581spe", "ach", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/3", "07", "z", "4", "f", "/", "ley", "on", "h", "je", "l", "m", "_", "on", "_", "met", "a", "data", "/", ")", "\u2581which", "\u2581was", "\u2581impressive", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581remember", "\u2581having", "\u2581parliament", "\u2581on", "\u2581the", "\u2581radio", "\u2581in", "\u2581my", "\u2581car", "\u2581and", "\u2581hearing", "\u2581Le", "y", "on", "h", "je", "l", "m", "\u2581[", "\u2581give", "\u2581this", "\u2581spe", "ach", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/3", "07", "z", "4", "f", "/", "ley", "on", "h", "je", "l", "m", "_", "on", "_", "met", "a", "data", "/", ")", "\u2581which", "\u2581was", "\u2581impressive", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581remember", "\u2581having", "\u2581parliament", "\u2581on", "\u2581the", "\u2581radio", "\u2581in", "\u2581my", "\u2581car", "\u2581and", "\u2581hearing", "<m>", "\u2581Le", "y", "on", "h", "je", "l", "m", "</m>", "\u2581[", "\u2581give", "\u2581this", "\u2581spe", "ach", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/3", "07", "z", "4", "f", "/", "ley", "on", "h", "je", "l", "m", "_", "on", "_", "met", "a", "data", "/", ")", "\u2581which", "\u2581was", "\u2581impressive", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 13, 14, 15, 16, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_64", "sentence": ["\u2581Look", "s", "\u2581like", "\u2581Grim", "al", "d", "o", "\u2581is", "\u2581linked", "\u2581with", "\u2581", "MU", "\u2581too", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Look", "s", "\u2581like", "\u2581Grim", "al", "d", "o", "\u2581is", "\u2581linked", "\u2581with", "\u2581", "MU", "\u2581too", "</s>"], "target_sentence": ["\u2581Look", "s", "\u2581like", "<m>", "\u2581Grim", "al", "d", "o", "</m>", "\u2581is", "\u2581linked", "\u2581with", "<m>", "<m>", "\u2581", "MU", "</m>", "</m>", "\u2581too", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, 2, 1, -1, -1, 2, 1, -1, -1]}, {"doc_id": "emerging.test_65", "sentence": ["\u2581But", "\u2581I", "\u2581thought", "\u2581", "he", "\u2581had", "\u2581joined", "\u2581Bor", "o", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581But", "\u2581I", "\u2581thought", "\u2581", "he", "\u2581had", "\u2581joined", "\u2581Bor", "o", "?", "</s>"], "target_sentence": ["\u2581But", "\u2581I", "\u2581thought", "\u2581", "he", "\u2581had", "\u2581joined", "<m>", "<m>", "\u2581Bor", "o", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1]}, {"doc_id": "emerging.test_66", "sentence": ["\u2581You", "\u2581posted", "\u2581in", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581", "cal", "gar", "y", "\u2581too", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581posted", "\u2581in", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581", "cal", "gar", "y", "\u2581too", ".", ".", "</s>"], "target_sentence": ["\u2581You", "\u2581posted", "\u2581in", "\u2581", "/", "\u2581", "r", "\u2581", "/", "<m>", "\u2581", "cal", "gar", "y", "</m>", "\u2581too", ".", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 6, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1]}, {"doc_id": "emerging.test_67", "sentence": ["\u2581[", "\u2581This", "\u2581interview", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "Cal", "gar", "y", "/", "com", "ments", "/4", "m", "2", "l", "26", "/", "un", "believable", "_", "inter", "view", "_", "on", "_", "770", "_", "with", "_", "s", "e", "an", "_", "chu", "/", ")", "\u2581from", "\u2581June", "\u2581was", "\u2581hilarious", "\u2581until", "\u2581you", "\u2581realize", "\u2581that", "\u2581", "he", "\u2581makes", "\u2581decision", "\u2581that", "\u2581affect", "\u2581the", "\u2581direction", "\u2581the", "\u2581city", "\u2581moves", "\u2581in", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581This", "\u2581interview", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "Cal", "gar", "y", "/", "com", "ments", "/4", "m", "2", "l", "26", "/", "un", "believable", "_", "inter", "view", "_", "on", "_", "770", "_", "with", "_", "s", "e", "an", "_", "chu", "/", ")", "\u2581from", "\u2581June", "\u2581was", "\u2581hilarious", "\u2581until", "\u2581you", "\u2581realize", "\u2581that", "\u2581", "he", "\u2581makes", "\u2581decision", "\u2581that", "\u2581affect", "\u2581the", "\u2581direction", "\u2581the", "\u2581city", "\u2581moves", "\u2581in", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581This", "\u2581interview", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "Cal", "gar", "y", "/", "com", "ments", "/4", "m", "2", "l", "26", "/", "un", "believable", "_", "inter", "view", "_", "on", "_", "770", "_", "with", "_", "s", "e", "an", "_", "chu", "/", ")", "\u2581from", "\u2581June", "\u2581was", "\u2581hilarious", "\u2581until", "\u2581you", "\u2581realize", "\u2581that", "\u2581", "he", "\u2581makes", "\u2581decision", "\u2581that", "\u2581affect", "\u2581the", "\u2581direction", "\u2581the", "\u2581city", "\u2581moves", "\u2581in", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_68", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Ca", "vani", "\u2581has", "\u2581the", "\u2581highest", "\u2581conversion", "\u2581rate", "\u2581in", "\u2581Europe", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581Ca", "vani", "\u2581has", "\u2581the", "\u2581highest", "\u2581conversion", "\u2581rate", "\u2581in", "\u2581Europe", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "<m>", "<m>", "\u2581Ca", "vani", "</m>", "</m>", "\u2581has", "\u2581the", "\u2581highest", "\u2581conversion", "\u2581rate", "\u2581in", "<m>", "\u2581Europe", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, 2, -1, 2, -1]}, {"doc_id": "emerging.test_69", "sentence": ["\u2581Che", "ney", "'", "\u2581", "s", "\u2581back", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Che", "ney", "'", "\u2581", "s", "\u2581back", ".", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Che", "ney", "</m>", "'", "\u2581", "s", "</m>", "\u2581back", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, 2, -1, -1, -1], "ent_indices": [1, 0, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1]}, {"doc_id": "emerging.test_70", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581It", "\u2581will", "\u2581be", "\u2581very", "\u2581telling", "\u2581(", "\u2581though", "\u2581probably", "\u2581un", "sur", "pri", "s", "ing", ")", "\u2581how", "\u2581folks", "\u2581like", "\u2581Tre", "y", "\u2581Go", "w", "d", "y", "\u2581and", "\u2581Jason", "\u2581Ch", "aff", "etz", "\u2581react", "\u2581to", "\u2581this", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581It", "\u2581will", "\u2581be", "\u2581very", "\u2581telling", "\u2581(", "\u2581though", "\u2581probably", "\u2581un", "sur", "pri", "s", "ing", ")", "\u2581how", "\u2581folks", "\u2581like", "\u2581Tre", "y", "\u2581Go", "w", "d", "y", "\u2581and", "\u2581Jason", "\u2581Ch", "aff", "etz", "\u2581react", "\u2581to", "\u2581this", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581It", "\u2581will", "\u2581be", "\u2581very", "\u2581telling", "\u2581(", "\u2581though", "\u2581probably", "\u2581un", "sur", "pri", "s", "ing", ")", "\u2581how", "\u2581folks", "\u2581like", "<m>", "\u2581Tre", "y", "\u2581Go", "w", "d", "y", "</m>", "\u2581and", "<m>", "\u2581Jason", "\u2581Ch", "aff", "etz", "</m>", "\u2581react", "\u2581to", "\u2581this", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 12, 13, 14, 15, 16, 16, 17, 17, 17, 17, 18, 19, 20, 20, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_71", "sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581", "NL", "W", "a", "sted", "Link", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581", "NL", "W", "a", "sted", "Link", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581", "NL", "W", "a", "sted", "Link", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_72", "sentence": ["\u2581D", "z", "eko", "\u2581penalty", "\u2581miss", "\u2581will", "\u2581be", "\u2581[", "\u2581", "r", "\u2581", "/", "\u2581soccer", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", ")", "\u2581top", "\u2581post", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581D", "z", "eko", "\u2581penalty", "\u2581miss", "\u2581will", "\u2581be", "\u2581[", "\u2581", "r", "\u2581", "/", "\u2581soccer", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", ")", "\u2581top", "\u2581post", ".", "</s>"], "target_sentence": ["<m>", "\u2581D", "z", "eko", "</m>", "\u2581penalty", "\u2581miss", "\u2581will", "\u2581be", "\u2581[", "\u2581", "r", "\u2581", "/", "\u2581soccer", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", ")", "\u2581top", "\u2581post", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_73", "sentence": ["\u2581Wow", ",", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581news", "\u2581totally", "\u2581kicke", "d", "\u2581the", "\u2581", "s", "hit", "\u2581out", "\u2581of", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581on", "\u2581this", "\u2581topic", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Wow", ",", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581news", "\u2581totally", "\u2581kicke", "d", "\u2581the", "\u2581", "s", "hit", "\u2581out", "\u2581of", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581on", "\u2581this", "\u2581topic", ".", "</s>"], "target_sentence": ["\u2581Wow", ",", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581news", "\u2581totally", "\u2581kicke", "d", "\u2581the", "\u2581", "s", "hit", "\u2581out", "\u2581of", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581on", "\u2581this", "\u2581topic", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 5, 6, 7, 7, 8, 9, 9, 9, 10, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_74", "sentence": ["\u2581Love", "\u2581Ly", "nd", "a", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Love", "\u2581Ly", "nd", "a", ".", "</s>"], "target_sentence": ["\u2581Love", "<m>", "\u2581Ly", "nd", "a", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_75", "sentence": ["\u2581Here", "'", "\u2581", "s", "\u2581", "a", "\u2581link", "\u2581to", "\u2581", "a", "\u2581Red", "d", "it", "or", "'", "\u2581", "s", "\u2581experience", "\u2581in", "\u2581Calgary", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Here", "'", "\u2581", "s", "\u2581", "a", "\u2581link", "\u2581to", "\u2581", "a", "\u2581Red", "d", "it", "or", "'", "\u2581", "s", "\u2581experience", "\u2581in", "\u2581Calgary", ":", "</s>"], "target_sentence": ["\u2581Here", "'", "\u2581", "s", "\u2581", "a", "\u2581link", "\u2581to", "\u2581", "a", "<m>", "\u2581Red", "d", "it", "or", "</m>", "'", "\u2581", "s", "\u2581experience", "\u2581in", "<m>", "\u2581Calgary", "</m>", ":", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 6, 6, 7, 7, 7, 7, 8, 9, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_76", "sentence": ["\u2581[", "\u2581", "OP", "\u2581of", "\u2581the", "\u2581previous", "\u2581thread", "s", "\u2581could", "\u2581", "n", "'", "\u2581", "t", "\u2581handle", "\u2581the", "\u2581Ronald", "o", "\u2581criticism", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "OP", "\u2581of", "\u2581the", "\u2581previous", "\u2581thread", "s", "\u2581could", "\u2581", "n", "'", "\u2581", "t", "\u2581handle", "\u2581the", "\u2581Ronald", "o", "\u2581criticism", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581", "OP", "\u2581of", "\u2581the", "\u2581previous", "\u2581thread", "s", "\u2581could", "\u2581", "n", "'", "\u2581", "t", "\u2581handle", "\u2581the", "<m>", "<m>", "\u2581Ronald", "o", "</m>", "</m>", "\u2581criticism", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 9, 10, 11, 12, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1]}, {"doc_id": "emerging.test_77", "sentence": ["\u2581You", "'", "\u2581", "re", "\u2581speaking", "\u2581from", "\u2581", "a", "\u2581Brit", "'", "\u2581", "s", "\u2581point", "\u2581of", "\u2581view", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "'", "\u2581", "re", "\u2581speaking", "\u2581from", "\u2581", "a", "\u2581Brit", "'", "\u2581", "s", "\u2581point", "\u2581of", "\u2581view", ".", "</s>"], "target_sentence": ["\u2581You", "'", "\u2581", "re", "\u2581speaking", "\u2581from", "\u2581", "a", "\u2581Brit", "'", "\u2581", "s", "\u2581point", "\u2581of", "\u2581view", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_78", "sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581Quick", "l", "o", "o", "t", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581Quick", "l", "o", "o", "t", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "<m>", "\u2581Quick", "l", "o", "o", "t", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_79", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Battle", "\u2581underway", "\u2581for", "\u2581return", "\u2581of", "\u2581Napoleon", "'", "\u2581", "s", "\u2581horse", "\u2581Mar", "en", "go", "\u2581to", "\u2581Ireland", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Battle", "\u2581underway", "\u2581for", "\u2581return", "\u2581of", "\u2581Napoleon", "'", "\u2581", "s", "\u2581horse", "\u2581Mar", "en", "go", "\u2581to", "\u2581Ireland", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Battle", "\u2581underway", "\u2581for", "\u2581return", "\u2581of", "<m>", "<m>", "\u2581Napoleon", "</m>", "'", "\u2581", "s", "\u2581horse", "\u2581Mar", "en", "go", "</m>", "\u2581to", "<m>", "\u2581Ireland", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, 2, -1, 2, -1]}, {"doc_id": "emerging.test_80", "sentence": ["\u2581[", "\u2581Yo", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Yo", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581Yo", ".", "</s>"], "subtoken_map": [0, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1]}, {"doc_id": "emerging.test_81", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Does", "\u2581anyone", "\u2581know", "\u2581", "if", "\u2581anyone", "\u2581has", "\u2581started", "\u2581protest", "ing", "\u2581at", "\u2581C", "VG", "\u2581yet", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Does", "\u2581anyone", "\u2581know", "\u2581", "if", "\u2581anyone", "\u2581has", "\u2581started", "\u2581protest", "ing", "\u2581at", "\u2581C", "VG", "\u2581yet", "?", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Does", "\u2581anyone", "\u2581know", "\u2581", "if", "\u2581anyone", "\u2581has", "\u2581started", "\u2581protest", "ing", "\u2581at", "<m>", "<m>", "\u2581C", "VG", "</m>", "</m>", "\u2581yet", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 2, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_82", "sentence": ["\u2581Red", "d", "it", "'", "\u2581", "s", "\u2581tough", "\u2581guys", "\u2581say", "\u2581yes", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Red", "d", "it", "'", "\u2581", "s", "\u2581tough", "\u2581guys", "\u2581say", "\u2581yes", ".", "</s>"], "target_sentence": ["\u2581Red", "d", "it", "'", "\u2581", "s", "\u2581tough", "\u2581guys", "\u2581say", "\u2581yes", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_83", "sentence": ["\u2581Media", "\u2581", "p", "ounce", "s", "\u2581on", "\u2581it", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Media", "\u2581", "p", "ounce", "s", "\u2581on", "\u2581it", ".", "</s>"], "target_sentence": ["\u2581Media", "\u2581", "p", "ounce", "s", "\u2581on", "\u2581it", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_84", "sentence": ["\u2581they", "\u2581changed", "\u2581all", "\u2581the", "\u2581topics", "\u2581to", "\u2581Z", "l", "at", "an", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581they", "\u2581changed", "\u2581all", "\u2581the", "\u2581topics", "\u2581to", "\u2581Z", "l", "at", "an", ".", "</s>"], "target_sentence": ["\u2581they", "\u2581changed", "\u2581all", "\u2581the", "\u2581topics", "\u2581to", "<m>", "\u2581Z", "l", "at", "an", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_85", "sentence": ["\u2581The", "\u2581mod", "s", "\u2581deleted", "\u2581[", "\u2581this", "\u2581story", "\u2581about", "\u2581activists", "\u2581being", "\u2581", "beaten", "\u2581by", "\u2581Trump", "\u2581supporters", "]", "\u2581(", "\u2581https", "://", "m", ".", "red", "d", "it", ".", "com", "/", "r", "/", "poli", "tics", "/", "com", "ments", "/5", "m", "3", "r", "1", "c", "/", "activ", "ist", "s", "_", "bru", "t", "ally", "_", "attack", "e", "d", "_", "by", "_", "d", "onal", "d", "_", "tru", "mp", "/", ")", "\u2581for", "\u2581being", "\u2581off", "\u2581topic", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581mod", "s", "\u2581deleted", "\u2581[", "\u2581this", "\u2581story", "\u2581about", "\u2581activists", "\u2581being", "\u2581", "beaten", "\u2581by", "\u2581Trump", "\u2581supporters", "]", "\u2581(", "\u2581https", "://", "m", ".", "red", "d", "it", ".", "com", "/", "r", "/", "poli", "tics", "/", "com", "ments", "/5", "m", "3", "r", "1", "c", "/", "activ", "ist", "s", "_", "bru", "t", "ally", "_", "attack", "e", "d", "_", "by", "_", "d", "onal", "d", "_", "tru", "mp", "/", ")", "\u2581for", "\u2581being", "\u2581off", "\u2581topic", ".", "</s>"], "target_sentence": ["\u2581The", "<m>", "\u2581mod", "s", "</m>", "\u2581deleted", "\u2581[", "\u2581this", "\u2581story", "\u2581about", "\u2581activists", "\u2581being", "\u2581", "beaten", "\u2581by", "<m>", "\u2581Trump", "</m>", "\u2581supporters", "]", "\u2581(", "\u2581https", "://", "m", ".", "red", "d", "it", ".", "com", "/", "r", "/", "poli", "tics", "/", "com", "ments", "/5", "m", "3", "r", "1", "c", "/", "activ", "ist", "s", "_", "bru", "t", "ally", "_", "attack", "e", "d", "_", "by", "_", "d", "onal", "d", "_", "tru", "mp", "/", ")", "\u2581for", "\u2581being", "\u2581off", "\u2581topic", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 17, 18, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_86", "sentence": ["\u2581Yeah", ",", "\u2581and", "\u2581they", "\u2581get", "\u2581all", "\u2581mis", "t", "y", "-", "e", "yed", "\u2581about", "\u2581government", "-", "owned", "\u2581businesses", "\u2581and", "\u2581how", "\u2581awful", "\u2581it", "\u2581is", "\u2581that", "\u2581Cost", "ello", "\u2581sold", "\u2581them", "\u2581off", "\u2581etc", ",", "\u2581only", "\u2581because", "\u2581they", "'", "\u2581", "re", "\u2581not", "\u2581old", "\u2581enough", "\u2581to", "\u2581remember", "\u2581having", "\u2581to", "\u2581deal", "\u2581with", "\u2581government", "-", "owned", "\u2581businesses", "\u2581and", "\u2581how", "\u2581", "f", "uck", "ing", "\u2581useless", "\u2581they", "\u2581are", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Yeah", ",", "\u2581and", "\u2581they", "\u2581get", "\u2581all", "\u2581mis", "t", "y", "-", "e", "yed", "\u2581about", "\u2581government", "-", "owned", "\u2581businesses", "\u2581and", "\u2581how", "\u2581awful", "\u2581it", "\u2581is", "\u2581that", "\u2581Cost", "ello", "\u2581sold", "\u2581them", "\u2581off", "\u2581etc", ",", "\u2581only", "\u2581because", "\u2581they", "'", "\u2581", "re", "\u2581not", "\u2581old", "\u2581enough", "\u2581to", "\u2581remember", "\u2581having", "\u2581to", "\u2581deal", "\u2581with", "\u2581government", "-", "owned", "\u2581businesses", "\u2581and", "\u2581how", "\u2581", "f", "uck", "ing", "\u2581useless", "\u2581they", "\u2581are", ":", "</s>"], "target_sentence": ["\u2581Yeah", ",", "\u2581and", "\u2581they", "\u2581get", "\u2581all", "\u2581mis", "t", "y", "-", "e", "yed", "\u2581about", "\u2581government", "-", "owned", "\u2581businesses", "\u2581and", "\u2581how", "\u2581awful", "\u2581it", "\u2581is", "\u2581that", "<m>", "\u2581Cost", "ello", "</m>", "\u2581sold", "\u2581them", "\u2581off", "\u2581etc", ",", "\u2581only", "\u2581because", "\u2581they", "'", "\u2581", "re", "\u2581not", "\u2581old", "\u2581enough", "\u2581to", "\u2581remember", "\u2581having", "\u2581to", "\u2581deal", "\u2581with", "\u2581government", "-", "owned", "\u2581businesses", "\u2581and", "\u2581how", "\u2581", "f", "uck", "ing", "\u2581useless", "\u2581they", "\u2581are", ":", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 36, 36, 37, 38, 39, 40, 40, 40, 40, 41, 42, 43, 44, 45], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_87", "sentence": ["\u2581Step", "\u25812", ":", "\u2581[", "\u2581Google", "]", "\u2581(", "\u2581http", "://", "www", ".", "go", "o", "gle", ".", "co", ".", "n", "z", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Step", "\u25812", ":", "\u2581[", "\u2581Google", "]", "\u2581(", "\u2581http", "://", "www", ".", "go", "o", "gle", ".", "co", ".", "n", "z", ")", "</s>"], "target_sentence": ["\u2581Step", "\u25812", ":", "\u2581[", "<m>", "\u2581Google", "</m>", "]", "\u2581(", "\u2581http", "://", "www", ".", "go", "o", "gle", ".", "co", ".", "n", "z", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_88", "sentence": ["\u2581Lo", "l", "\u2581this", "\u2581is", "\u2581what", "\u2581city", "\u2581pus", "s", "is", "\u2581think", "\u2581of", "\u2581living", "\u2581outside", "\u2581", "a", "\u2581major", "\u2581city", "\u2581is", "\u2581like", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Lo", "l", "\u2581this", "\u2581is", "\u2581what", "\u2581city", "\u2581pus", "s", "is", "\u2581think", "\u2581of", "\u2581living", "\u2581outside", "\u2581", "a", "\u2581major", "\u2581city", "\u2581is", "\u2581like", "</s>"], "target_sentence": ["\u2581Lo", "l", "\u2581this", "\u2581is", "\u2581what", "\u2581city", "\u2581pus", "s", "is", "\u2581think", "\u2581of", "\u2581living", "\u2581outside", "\u2581", "a", "\u2581major", "\u2581city", "\u2581is", "\u2581like", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_89", "sentence": ["\u2581You", "\u2581could", "\u2581try", "\u2581and", "\u2581send", "\u2581an", "\u2581email", "\u2581to", "\u2581the", "\u2581teams", "\u2581and", "\u2581see", "\u2581what", "\u2581they", "\u2581reply", ":", "\u2581D", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581could", "\u2581try", "\u2581and", "\u2581send", "\u2581an", "\u2581email", "\u2581to", "\u2581the", "\u2581teams", "\u2581and", "\u2581see", "\u2581what", "\u2581they", "\u2581reply", ":", "\u2581D", "</s>"], "target_sentence": ["\u2581You", "\u2581could", "\u2581try", "\u2581and", "\u2581send", "\u2581an", "\u2581email", "\u2581to", "\u2581the", "\u2581teams", "\u2581and", "\u2581see", "\u2581what", "\u2581they", "\u2581reply", ":", "\u2581D", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_90", "sentence": ["\u2581", "Result", "at", ".", "\u2581", "d", "k", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Result", "at", ".", "\u2581", "d", "k", "</s>"], "target_sentence": ["\u2581", "Result", "at", ".", "\u2581", "d", "k", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_91", "sentence": ["\u2581*", "\u2581*", "\u2581Edit", ":", "\u2581*", "\u2581*", "\u2581Wow", ",", "\u2581that", "\u2581", "blew", "\u2581up", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581Edit", ":", "\u2581*", "\u2581*", "\u2581Wow", ",", "\u2581that", "\u2581", "blew", "\u2581up", ".", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581Edit", ":", "\u2581*", "\u2581*", "\u2581Wow", ",", "\u2581that", "\u2581", "blew", "\u2581up", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_92", "sentence": ["\u2581I", "\u2581asked", "\u2581Bell", "erin", "\u2581", "v", "\u2581", "walker", "\u2581in", "\u2581", "a", "\u2581match", "\u2581thread", "\u2581", "a", "\u2581few", "\u2581months", "\u2581ago", ",", "\u2581the", "\u2581results", "\u2581might", "\u2581surprise", "\u2581you", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581asked", "\u2581Bell", "erin", "\u2581", "v", "\u2581", "walker", "\u2581in", "\u2581", "a", "\u2581match", "\u2581thread", "\u2581", "a", "\u2581few", "\u2581months", "\u2581ago", ",", "\u2581the", "\u2581results", "\u2581might", "\u2581surprise", "\u2581you", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581asked", "<m>", "\u2581Bell", "erin", "\u2581", "v", "\u2581", "walker", "</m>", "\u2581in", "\u2581", "a", "\u2581match", "\u2581thread", "\u2581", "a", "\u2581few", "\u2581months", "\u2581ago", ",", "\u2581the", "\u2581results", "\u2581might", "\u2581surprise", "\u2581you", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 5, 6, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_93", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Bar", "ca", "\u2581flair", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581Bar", "ca", "\u2581flair", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "<m>", "<m>", "\u2581Bar", "ca", "\u2581flair", "</m>", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, 1, -1]}, {"doc_id": "emerging.test_94", "sentence": ["\u2581Where", "'", "\u2581", "s", "\u2581the", "\u2581one", "\u2581from", "\u2581", "~", "\u2581", "~", "\u2581Syria", "\u2581", "~", "\u2581", "~", "\u2581Serbia", "\u2581where", "\u2581some", "\u2581guy", "\u2581ban", "ged", "\u2581it", "\u2581over", "\u2581the", "\u2581bar", "\u2581from", "\u2581the", "\u2581goal", "line", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Where", "'", "\u2581", "s", "\u2581the", "\u2581one", "\u2581from", "\u2581", "~", "\u2581", "~", "\u2581Syria", "\u2581", "~", "\u2581", "~", "\u2581Serbia", "\u2581where", "\u2581some", "\u2581guy", "\u2581ban", "ged", "\u2581it", "\u2581over", "\u2581the", "\u2581bar", "\u2581from", "\u2581the", "\u2581goal", "line", "?", "</s>"], "target_sentence": ["\u2581Where", "'", "\u2581", "s", "\u2581the", "\u2581one", "\u2581from", "\u2581", "~", "\u2581", "~", "<m>", "\u2581Syria", "</m>", "\u2581", "~", "\u2581", "~", "<m>", "\u2581Serbia", "</m>", "\u2581where", "\u2581some", "\u2581guy", "\u2581ban", "ged", "\u2581it", "\u2581over", "\u2581the", "\u2581bar", "\u2581from", "\u2581the", "\u2581goal", "line", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 9, 10, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_95", "sentence": ["\u2581Hey", "\u2581Tom", ",", "\u2581can", "\u2581you", "\u2581comment", "\u2581on", "\u2581this", "\u2581thread", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hey", "\u2581Tom", ",", "\u2581can", "\u2581you", "\u2581comment", "\u2581on", "\u2581this", "\u2581thread", "?", "</s>"], "target_sentence": ["\u2581Hey", "<m>", "\u2581Tom", "</m>", ",", "\u2581can", "\u2581you", "\u2581comment", "\u2581on", "\u2581this", "\u2581thread", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_96", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581you", "\u2581cannot", "\u2581in", "fer", "\u2581much", "\u2581from", "\u2581", "a", "\u2581single", "\u2581quarter", "'", "\u2581", "s", "\u2581GDP", "\u2581statistics", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581you", "\u2581cannot", "\u2581in", "fer", "\u2581much", "\u2581from", "\u2581", "a", "\u2581single", "\u2581quarter", "'", "\u2581", "s", "\u2581GDP", "\u2581statistics", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581you", "\u2581cannot", "\u2581in", "fer", "\u2581much", "\u2581from", "\u2581", "a", "\u2581single", "\u2581quarter", "'", "\u2581", "s", "<m>", "\u2581GDP", "</m>", "\u2581statistics", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_97", "sentence": ["\u2581True", ",", "\u2581but", "\u2581I", "\u2581imagine", "\u2581it", "\u2581would", "\u2581be", "\u2581", "a", "\u2581lot", "\u2581lower", "\u2581and", "\u2581as", "\u2581I", "\u2581pointed", "\u2581out", "\u2581to", "\u2581Andrew", "\u2581Little", "\u2581would", "\u2581be", "\u2581cheaper", "\u2581than", "\u2581[", "\u2581eliminating", "\u2581fees", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581True", ",", "\u2581but", "\u2581I", "\u2581imagine", "\u2581it", "\u2581would", "\u2581be", "\u2581", "a", "\u2581lot", "\u2581lower", "\u2581and", "\u2581as", "\u2581I", "\u2581pointed", "\u2581out", "\u2581to", "\u2581Andrew", "\u2581Little", "\u2581would", "\u2581be", "\u2581cheaper", "\u2581than", "\u2581[", "\u2581eliminating", "\u2581fees", ".", "</s>"], "target_sentence": ["\u2581True", ",", "\u2581but", "\u2581I", "\u2581imagine", "\u2581it", "\u2581would", "\u2581be", "\u2581", "a", "\u2581lot", "\u2581lower", "\u2581and", "\u2581as", "\u2581I", "\u2581pointed", "\u2581out", "\u2581to", "<m>", "\u2581Andrew", "\u2581Little", "</m>", "\u2581would", "\u2581be", "\u2581cheaper", "\u2581than", "\u2581[", "\u2581eliminating", "\u2581fees", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_98", "sentence": ["\u2581She", "'", "\u2581", "s", "\u2581been", "\u2581making", "\u2581me", "\u2581question", "\u2581my", "\u2581sexual", "ity", "\u2581since", "\u2581The", "\u2581", "X", "-", "Fi", "les", "\u2581started", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581She", "'", "\u2581", "s", "\u2581been", "\u2581making", "\u2581me", "\u2581question", "\u2581my", "\u2581sexual", "ity", "\u2581since", "\u2581The", "\u2581", "X", "-", "Fi", "les", "\u2581started", ".", "</s>"], "target_sentence": ["\u2581She", "'", "\u2581", "s", "\u2581been", "\u2581making", "\u2581me", "\u2581question", "\u2581my", "\u2581sexual", "ity", "\u2581since", "<m>", "\u2581The", "<m>", "\u2581", "X", "-", "Fi", "les", "</m>", "</m>", "\u2581started", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 11, 11, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_99", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581P", "SG", "\u2581tell", "\u2581Inter", "\u2581", "&", "\u2581amp", ";", "\u2581Ju", "ve", "\u2581Ver", "r", "atti", "\u2581will", "\u2581cost", "\u2581\u20ac", "\u2581100", "\u2581M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581P", "SG", "\u2581tell", "\u2581Inter", "\u2581", "&", "\u2581amp", ";", "\u2581Ju", "ve", "\u2581Ver", "r", "atti", "\u2581will", "\u2581cost", "\u2581\u20ac", "\u2581100", "\u2581M", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581P", "SG", "\u2581tell", "\u2581Inter", "\u2581", "&", "\u2581amp", ";", "<m>", "\u2581Ju", "ve", "<m>", "\u2581Ver", "r", "atti", "</m>", "</m>", "\u2581will", "\u2581cost", "\u2581\u20ac", "\u2581100", "\u2581M", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 11, 12, 13, 13, 14, 14, 14, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 5, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_100", "sentence": ["\u2581Not", "\u2581sure", "\u2581", "if", "\u2581trust", "\u2581Donald", "\u2581on", "\u2581this", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Not", "\u2581sure", "\u2581", "if", "\u2581trust", "\u2581Donald", "\u2581on", "\u2581this", ".", "</s>"], "target_sentence": ["\u2581Not", "\u2581sure", "\u2581", "if", "\u2581trust", "<m>", "\u2581Donald", "</m>", "\u2581on", "\u2581this", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1]}, {"doc_id": "emerging.test_101", "sentence": ["\u2581", "EDIT", ":", "\u2581No", "\u2581actually", "\u2581screw", "\u2581that", ",", "\u2581", "i", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581ask", "\u2581why", "\u2581you", "'", "\u2581", "d", "\u2581want", "\u2581attacks", "\u2581on", "\u2581Trump", "\u2581supporters", "\u2581to", "\u2581continue", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "EDIT", ":", "\u2581No", "\u2581actually", "\u2581screw", "\u2581that", ",", "\u2581", "i", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581ask", "\u2581why", "\u2581you", "'", "\u2581", "d", "\u2581want", "\u2581attacks", "\u2581on", "\u2581Trump", "\u2581supporters", "\u2581to", "\u2581continue", "?", "</s>"], "target_sentence": ["\u2581", "EDIT", ":", "\u2581No", "\u2581actually", "\u2581screw", "\u2581that", ",", "\u2581", "i", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581ask", "\u2581why", "\u2581you", "'", "\u2581", "d", "\u2581want", "\u2581attacks", "\u2581on", "<m>", "<m>", "<m>", "\u2581Trump", "</m>", "</m>", "\u2581supporters", "</m>", "\u2581to", "\u2581continue", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, 1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 0, 1, -1, 0, 1, -1, 2, -1, -1, -1, -1]}, {"doc_id": "emerging.test_102", "sentence": ["\u2581Perhaps", "\u2581this", "\u2581paper", "\u2581instead", "\u2581actually", "\u2581suggests", "\u2581that", "\u2581students", "\u2581born", "\u2581in", "\u2581July", "\u2581are", "\u2581under", "diag", "nose", "d", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Perhaps", "\u2581this", "\u2581paper", "\u2581instead", "\u2581actually", "\u2581suggests", "\u2581that", "\u2581students", "\u2581born", "\u2581in", "\u2581July", "\u2581are", "\u2581under", "diag", "nose", "d", "?", "</s>"], "target_sentence": ["\u2581Perhaps", "<m>", "\u2581this", "\u2581paper", "</m>", "\u2581instead", "\u2581actually", "\u2581suggests", "\u2581that", "\u2581students", "\u2581born", "\u2581in", "\u2581July", "\u2581are", "\u2581under", "diag", "nose", "d", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_103", "sentence": ["\u2581If", "\u2581P", "NG", "\u2581is", "\u2581un", "developed", ",", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581", "re", "settling", "\u2581the", "\u2581boats", "\u2581full", "\u2581of", "\u2581surgeon", "s", "\u2581be", "\u2581exactly", "\u2581what", "\u2581they", "\u2581need", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581P", "NG", "\u2581is", "\u2581un", "developed", ",", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581", "re", "settling", "\u2581the", "\u2581boats", "\u2581full", "\u2581of", "\u2581surgeon", "s", "\u2581be", "\u2581exactly", "\u2581what", "\u2581they", "\u2581need", "?", "</s>"], "target_sentence": ["\u2581If", "<m>", "\u2581P", "NG", "</m>", "\u2581is", "\u2581un", "developed", ",", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581", "re", "settling", "\u2581the", "\u2581boats", "\u2581full", "\u2581of", "\u2581surgeon", "s", "\u2581be", "\u2581exactly", "\u2581what", "\u2581they", "\u2581need", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8, 8, 9, 9, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_104", "sentence": ["\u2581Maybe", "\u2581you", "\u2581could", "\u2581try", "\u2581", "contacting", "\u2581the", "\u2581producer", "\u2581(", "\u2581Great", "\u2581Southern", "\u2581Television", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Maybe", "\u2581you", "\u2581could", "\u2581try", "\u2581", "contacting", "\u2581the", "\u2581producer", "\u2581(", "\u2581Great", "\u2581Southern", "\u2581Television", ")", "</s>"], "target_sentence": ["\u2581Maybe", "\u2581you", "\u2581could", "\u2581try", "\u2581", "contacting", "\u2581the", "\u2581producer", "\u2581(", "<m>", "<m>", "\u2581Great", "\u2581Southern", "\u2581Television", "</m>", "</m>", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 1, 0, -1, -1]}, {"doc_id": "emerging.test_105", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581I", "'", "\u2581", "m", "\u2581an", "\u2581ex", "\u2581Muslim", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581I", "'", "\u2581", "m", "\u2581an", "\u2581ex", "\u2581Muslim", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581I", "'", "\u2581", "m", "\u2581an", "\u2581ex", "<m>", "\u2581Muslim", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1]}, {"doc_id": "emerging.test_106", "sentence": ["\u2581There", "\u2581is", "\u2581nothing", "\u2581wrong", "\u2581with", "\u2581the", "\u2581Hur", "on", "\u2581disposal", "\u2581site", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581There", "\u2581is", "\u2581nothing", "\u2581wrong", "\u2581with", "\u2581the", "\u2581Hur", "on", "\u2581disposal", "\u2581site", ".", "</s>"], "target_sentence": ["\u2581There", "\u2581is", "\u2581nothing", "\u2581wrong", "\u2581with", "\u2581the", "<m>", "<m>", "\u2581Hur", "on", "</m>", "</m>", "\u2581disposal", "\u2581site", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 4, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1]}, {"doc_id": "emerging.test_107", "sentence": ["\u2581Her", "\u2581name", "\u2581is", "\u2581Scout", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Her", "\u2581name", "\u2581is", "\u2581Scout", ".", "</s>"], "target_sentence": ["\u2581Her", "\u2581name", "\u2581is", "<m>", "<m>", "\u2581Scout", "</m>", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, 4, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, 1, 0, -1, -1]}, {"doc_id": "emerging.test_108", "sentence": ["\u2581Morocco", "\u2581here", "\u2581we", "\u2581come", "\u2581let", "'", "\u2581", "s", "\u2581make", "\u2581that", "\u25814", "\u2581", "-", "\u258111", "\u2581", "-", "\u258113", "\u2581not", "\u258114", "\u2581loss", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Morocco", "\u2581here", "\u2581we", "\u2581come", "\u2581let", "'", "\u2581", "s", "\u2581make", "\u2581that", "\u25814", "\u2581", "-", "\u258111", "\u2581", "-", "\u258113", "\u2581not", "\u258114", "\u2581loss", "</s>"], "target_sentence": ["<m>", "<m>", "<m>", "\u2581Morocco", "</m>", "</m>", "</m>", "\u2581here", "\u2581we", "\u2581come", "\u2581let", "'", "\u2581", "s", "\u2581make", "\u2581that", "\u25814", "\u2581", "-", "\u258111", "\u2581", "-", "\u258113", "\u2581not", "\u258114", "\u2581loss", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, 0, 1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [1, 2, 0, -1, 1, 2, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_109", "sentence": ["\u2581", "98", ".", "\u25812", "\u2581", "%", "\u2581of", "\u2581Costa", "\u2581Rica", "'", "\u2581", "s", "\u2581electricity", "\u2581came", "\u2581from", "\u2581renewable", "\u2581sources", "\u2581in", "\u25812016", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "98", ".", "\u25812", "\u2581", "%", "\u2581of", "\u2581Costa", "\u2581Rica", "'", "\u2581", "s", "\u2581electricity", "\u2581came", "\u2581from", "\u2581renewable", "\u2581sources", "\u2581in", "\u25812016", ".", "</s>"], "target_sentence": ["\u2581", "98", ".", "\u25812", "\u2581", "%", "\u2581of", "<m>", "<m>", "\u2581Costa", "\u2581Rica", "</m>", "</m>", "'", "\u2581", "s", "\u2581electricity", "\u2581came", "\u2581from", "\u2581renewable", "\u2581sources", "\u2581in", "\u25812016", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_110", "sentence": ["\u2581Was", "\u2581on", "\u2581the", "\u2581D", "SP", "\u2581and", "\u2581found", "\u2581his", "\u2581", "/", "\u2581her", "\u2581way", "\u2581back", "\u2581to", "\u2581", "a", "\u2581normal", "\u2581life", "\u2581with", "\u2581his", "\u2581", "/", "\u2581her", "\u2581own", "\u2581income", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Was", "\u2581on", "\u2581the", "\u2581D", "SP", "\u2581and", "\u2581found", "\u2581his", "\u2581", "/", "\u2581her", "\u2581way", "\u2581back", "\u2581to", "\u2581", "a", "\u2581normal", "\u2581life", "\u2581with", "\u2581his", "\u2581", "/", "\u2581her", "\u2581own", "\u2581income", ".", "</s>"], "target_sentence": ["\u2581Was", "\u2581on", "\u2581the", "\u2581D", "SP", "\u2581and", "\u2581found", "\u2581his", "\u2581", "/", "\u2581her", "\u2581way", "\u2581back", "\u2581to", "\u2581", "a", "\u2581normal", "\u2581life", "\u2581with", "\u2581his", "\u2581", "/", "\u2581her", "\u2581own", "\u2581income", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_111", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Pro", "posed", "\u2581class", "\u2581action", "\u2581against", "\u2581B", ".", "\u2581C", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Pro", "posed", "\u2581class", "\u2581action", "\u2581against", "\u2581B", ".", "\u2581C", ".", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Pro", "posed", "\u2581class", "\u2581action", "\u2581against", "\u2581B", ".", "\u2581C", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_112", "sentence": ["\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "s", "d", "w", "m", "2/", "breaking", "_", "jo", "ost", "_", "van", "_", "der", "_", "west", "hui", "zen", "_", "dies", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581south", "a", "f", "ric", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "s", "d", "w", "m", "2/", "breaking", "_", "jo", "ost", "_", "van", "_", "der", "_", "west", "hui", "zen", "_", "dies", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581south", "a", "f", "ric", "a", "</s>"], "target_sentence": ["\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "s", "d", "w", "m", "2/", "breaking", "_", "jo", "ost", "_", "van", "_", "der", "_", "west", "hui", "zen", "_", "dies", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581south", "a", "f", "ric", "a", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 7, 7, 8, 8, 9, 9, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_113", "sentence": ["\u2581The", "\u2581idea", "\u2581that", "\u2581one", "\u2581", "IRA", "\u2581was", "\u2581", "kinder", "\u2581or", "\u2581more", "\u2581moral", "\u2581than", "\u2581the", "\u2581other", "\u2581is", "\u2581", "l", "u", "dic", "rous", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581idea", "\u2581that", "\u2581one", "\u2581", "IRA", "\u2581was", "\u2581", "kinder", "\u2581or", "\u2581more", "\u2581moral", "\u2581than", "\u2581the", "\u2581other", "\u2581is", "\u2581", "l", "u", "dic", "rous", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581idea", "\u2581that", "\u2581one", "<m>", "\u2581", "IRA", "</m>", "\u2581was", "\u2581", "kinder", "\u2581or", "\u2581more", "\u2581moral", "\u2581than", "\u2581the", "\u2581other", "\u2581is", "\u2581", "l", "u", "dic", "rous", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_114", "sentence": ["\u2581I", "\u2581hear", "\u2581audio", "\u2581in", "\u2581the", "\u2581first", "\u2581", "AA", "\u2581stream", "able", "\u2581link", "\u2581but", "\u2581not", "\u2581the", "\u2581one", "\u2581with", "\u2581full", "\u2581build", "\u2581up", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581hear", "\u2581audio", "\u2581in", "\u2581the", "\u2581first", "\u2581", "AA", "\u2581stream", "able", "\u2581link", "\u2581but", "\u2581not", "\u2581the", "\u2581one", "\u2581with", "\u2581full", "\u2581build", "\u2581up", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581hear", "\u2581audio", "\u2581in", "\u2581the", "\u2581first", "<m>", "\u2581", "AA", "</m>", "\u2581stream", "able", "\u2581link", "\u2581but", "\u2581not", "\u2581the", "\u2581one", "\u2581with", "\u2581full", "\u2581build", "\u2581up", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_115", "sentence": ["\u2581Sur", "pri", "s", "ing", "ly", "\u2581no", "\u2581PM", "s", "\u2581yet", ",", "\u2581got", "\u2581", "tagged", "\u2581in", "\u2581[", "\u2581this", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "f", "q", "f", "w", "h", "/", "pla", "typ", "us", "_", "ve", "nom", "_", "p", "aves", "_", "way", "_", "to", "_", "pos", "s", "ible", "_", "d", "i", "a", "be", "tes", "/", "dam", "d", "pro", "/", ")", "\u2581though", ",", "\u2581and", "\u2581it", "'", "\u2581", "s", "\u2581pretty", "\u2581thorough", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Sur", "pri", "s", "ing", "ly", "\u2581no", "\u2581PM", "s", "\u2581yet", ",", "\u2581got", "\u2581", "tagged", "\u2581in", "\u2581[", "\u2581this", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "f", "q", "f", "w", "h", "/", "pla", "typ", "us", "_", "ve", "nom", "_", "p", "aves", "_", "way", "_", "to", "_", "pos", "s", "ible", "_", "d", "i", "a", "be", "tes", "/", "dam", "d", "pro", "/", ")", "\u2581though", ",", "\u2581and", "\u2581it", "'", "\u2581", "s", "\u2581pretty", "\u2581thorough", ".", "</s>"], "target_sentence": ["\u2581Sur", "pri", "s", "ing", "ly", "\u2581no", "\u2581PM", "s", "\u2581yet", ",", "\u2581got", "\u2581", "tagged", "\u2581in", "\u2581[", "\u2581this", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "f", "q", "f", "w", "h", "/", "pla", "typ", "us", "_", "ve", "nom", "_", "p", "aves", "_", "way", "_", "to", "_", "pos", "s", "ible", "_", "d", "i", "a", "be", "tes", "/", "dam", "d", "pro", "/", ")", "\u2581though", ",", "\u2581and", "\u2581it", "'", "\u2581", "s", "\u2581pretty", "\u2581thorough", ".", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_116", "sentence": ["\u2581The", "\u2581rest", "\u2581of", "\u2581your", "\u2581post", "\u2581has", "\u2581already", "\u2581been", "\u2581ref", "ute", "d", "\u2581by", "\u2581yourself", ",", "\u2581as", "\u2581you", "\u2581acknowledged", "\u2581[", "\u2581in", "\u2581another", "\u2581post", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "n", "ur", "87", "/", "form", "er", "_", "m", "i", "6", "_", "s", "p", "y", "_", "known", "_", "to", "_", "us", "_", "a", "g", "encies", "_", "is", "_", "author", "_", "of", "/", "d", "c", "f", "1", "k", "74", "/", ")", "\u2581that", "\u2581what", "\u2581Paul", "\u2581Man", "a", "for", "t", "\u2581did", "\u2581is", "\u2581*", "\u2581*", "\u2581", "a", "\u2581", "f", "uck", "ing", "\u2581crime", "\u2581*", "\u2581*", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581rest", "\u2581of", "\u2581your", "\u2581post", "\u2581has", "\u2581already", "\u2581been", "\u2581ref", "ute", "d", "\u2581by", "\u2581yourself", ",", "\u2581as", "\u2581you", "\u2581acknowledged", "\u2581[", "\u2581in", "\u2581another", "\u2581post", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "n", "ur", "87", "/", "form", "er", "_", "m", "i", "6", "_", "s", "p", "y", "_", "known", "_", "to", "_", "us", "_", "a", "g", "encies", "_", "is", "_", "author", "_", "of", "/", "d", "c", "f", "1", "k", "74", "/", ")", "\u2581that", "\u2581what", "\u2581Paul", "\u2581Man", "a", "for", "t", "\u2581did", "\u2581is", "\u2581*", "\u2581*", "\u2581", "a", "\u2581", "f", "uck", "ing", "\u2581crime", "\u2581*", "\u2581*", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581rest", "\u2581of", "\u2581your", "\u2581post", "\u2581has", "\u2581already", "\u2581been", "\u2581ref", "ute", "d", "\u2581by", "\u2581yourself", ",", "\u2581as", "\u2581you", "\u2581acknowledged", "\u2581[", "\u2581in", "\u2581another", "\u2581post", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "n", "ur", "87", "/", "form", "er", "_", "m", "i", "6", "_", "s", "p", "y", "_", "known", "_", "to", "_", "us", "_", "a", "g", "encies", "_", "is", "_", "author", "_", "of", "/", "d", "c", "f", "1", "k", "74", "/", ")", "\u2581that", "\u2581what", "<m>", "\u2581Paul", "\u2581Man", "a", "for", "t", "</m>", "\u2581did", "\u2581is", "\u2581*", "\u2581*", "\u2581", "a", "\u2581", "f", "uck", "ing", "\u2581crime", "\u2581*", "\u2581*", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 23, 24, 25, 26, 26, 26, 26, 27, 28, 29, 30, 31, 31, 32, 32, 32, 32, 33, 34, 35, 36, 37], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_117", "sentence": ["\u2581For", "\u2581those", "\u2581complaining", "\u2581about", "\u2581Rule", "\u25816", "\u2581(", "\u2581not", "\u2581related", "\u2581to", "\u2581Calgary", ")", ".", ".", ".", ".", "\u2581this", "\u2581story", "\u2581is", "\u2581an", "\u2581update", "\u2581to", "\u2581this", "\u2581previous", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581Calgary", "\u2581submission", "\u2581which", "\u2581did", "\u2581not", "\u2581get", "\u2581removed", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581For", "\u2581those", "\u2581complaining", "\u2581about", "\u2581Rule", "\u25816", "\u2581(", "\u2581not", "\u2581related", "\u2581to", "\u2581Calgary", ")", ".", ".", ".", ".", "\u2581this", "\u2581story", "\u2581is", "\u2581an", "\u2581update", "\u2581to", "\u2581this", "\u2581previous", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581Calgary", "\u2581submission", "\u2581which", "\u2581did", "\u2581not", "\u2581get", "\u2581removed", ":", "</s>"], "target_sentence": ["\u2581For", "\u2581those", "\u2581complaining", "\u2581about", "\u2581Rule", "\u25816", "\u2581(", "\u2581not", "\u2581related", "\u2581to", "\u2581Calgary", ")", ".", ".", ".", ".", "\u2581this", "\u2581story", "\u2581is", "\u2581an", "\u2581update", "\u2581to", "\u2581this", "\u2581previous", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581Calgary", "\u2581submission", "\u2581which", "\u2581did", "\u2581not", "\u2581get", "\u2581removed", ":", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 25, 26, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_118", "sentence": ["\u2581You", "\u2581do", "\u2581realize", "\u2581this", "\u2581was", "\u2581published", "\u2581by", "\u2581", "CBC", "\u2581Manitoba", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581do", "\u2581realize", "\u2581this", "\u2581was", "\u2581published", "\u2581by", "\u2581", "CBC", "\u2581Manitoba", ".", "</s>"], "target_sentence": ["\u2581You", "\u2581do", "\u2581realize", "\u2581this", "\u2581was", "\u2581published", "\u2581by", "<m>", "<m>", "\u2581", "CBC", "</m>", "<m>", "\u2581Manitoba", "</m>", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, 0, 2, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 0, 2, -1, 2, 1, -1, -1]}, {"doc_id": "emerging.test_119", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Diego", "\u2581Ro", "lan", "\u2581goal", "\u2581", "v", "s", "\u2581P", "SG", "\u2581(", "\u25811", "\u2581", "-", "\u25811", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Diego", "\u2581Ro", "lan", "\u2581goal", "\u2581", "v", "s", "\u2581P", "SG", "\u2581(", "\u25811", "\u2581", "-", "\u25811", ")", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "<m>", "\u2581Diego", "\u2581Ro", "lan", "</m>", "\u2581goal", "\u2581", "v", "s", "<m>", "\u2581P", "SG", "</m>", "\u2581(", "\u25811", "\u2581", "-", "\u25811", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 10, 11, 11, 12, 13, 14, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_120", "sentence": ["\u2581Du", "de", "\u2581[", "\u2581definitely", "\u2581definitely", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "f", "w", "b", "o", "2/", "can", "_", "some", "one", "_", "ex", "plain", "_", "why", "_", "cap", "it", "alism", "_", "is", "n", "t", "_", "solv", "ing", "/", ")", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581understand", "\u2581the", "\u2581housing", "\u2581market", "\u2581at", "\u2581all", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Du", "de", "\u2581[", "\u2581definitely", "\u2581definitely", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "f", "w", "b", "o", "2/", "can", "_", "some", "one", "_", "ex", "plain", "_", "why", "_", "cap", "it", "alism", "_", "is", "n", "t", "_", "solv", "ing", "/", ")", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581understand", "\u2581the", "\u2581housing", "\u2581market", "\u2581at", "\u2581all", ".", "</s>"], "target_sentence": ["\u2581Du", "de", "\u2581[", "\u2581definitely", "\u2581definitely", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "f", "w", "b", "o", "2/", "can", "_", "some", "one", "_", "ex", "plain", "_", "why", "_", "cap", "it", "alism", "_", "is", "n", "t", "_", "solv", "ing", "/", ")", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581understand", "\u2581the", "\u2581housing", "\u2581market", "\u2581at", "\u2581all", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_121", "sentence": ["\u2581Here", "\u2581is", "\u2581the", "\u2581background", "\u2581on", "\u2581Ras", "t", "us", "\u2581and", "\u2581Pete", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Here", "\u2581is", "\u2581the", "\u2581background", "\u2581on", "\u2581Ras", "t", "us", "\u2581and", "\u2581Pete", ".", "</s>"], "target_sentence": ["\u2581Here", "\u2581is", "\u2581the", "\u2581background", "\u2581on", "<m>", "\u2581Ras", "t", "us", "</m>", "\u2581and", "<m>", "\u2581Pete", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, 1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_122", "sentence": ["\u2581For", "\u2581people", "\u2581asking", "\u2581about", "\u2581the", "\u2581torture", "\u2581video", ":", "\u2581[", "\u2581Click", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "2", "i", "v", "k", "/", "chi", "ca", "go", "_", "poli", "ce", "_", "4", "_", "in", "_", "cu", "s", "t", "ody", "_", "after", "_", "you", "ng", "_", "man", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581For", "\u2581people", "\u2581asking", "\u2581about", "\u2581the", "\u2581torture", "\u2581video", ":", "\u2581[", "\u2581Click", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "2", "i", "v", "k", "/", "chi", "ca", "go", "_", "poli", "ce", "_", "4", "_", "in", "_", "cu", "s", "t", "ody", "_", "after", "_", "you", "ng", "_", "man", "/", ")", "</s>"], "target_sentence": ["\u2581For", "\u2581people", "\u2581asking", "\u2581about", "\u2581the", "\u2581torture", "\u2581video", ":", "\u2581[", "\u2581Click", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "2", "i", "v", "k", "/", "chi", "ca", "go", "_", "poli", "ce", "_", "4", "_", "in", "_", "cu", "s", "t", "ody", "_", "after", "_", "you", "ng", "_", "man", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_123", "sentence": ["\u2581Rud", "der", "\u2581breaks", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Rud", "der", "\u2581breaks", ".", "</s>"], "target_sentence": ["\u2581Rud", "der", "\u2581breaks", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_124", "sentence": ["\u2581Hey", "\u2581check", "\u2581out", "\u2581this", ":", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "ly", "5", "c", "y", "/", "rock", "_", "hard", "_", "bre", "x", "it", "/", "d", "b", "z", "k", "92", "t", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hey", "\u2581check", "\u2581out", "\u2581this", ":", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "ly", "5", "c", "y", "/", "rock", "_", "hard", "_", "bre", "x", "it", "/", "d", "b", "z", "k", "92", "t", "/", "</s>"], "target_sentence": ["\u2581Hey", "\u2581check", "\u2581out", "\u2581this", ":", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "ly", "5", "c", "y", "/", "rock", "_", "hard", "_", "bre", "x", "it", "/", "d", "b", "z", "k", "92", "t", "/", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_125", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Concord", "e", "\u2581over", "\u2581Calgary", "\u25811977", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Concord", "e", "\u2581over", "\u2581Calgary", "\u25811977", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "<m>", "<m>", "<m>", "\u2581Concord", "e", "</m>", "</m>", "\u2581over", "<m>", "<m>", "\u2581Calgary", "</m>", "\u25811977", "</m>", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 5, -1, -1, -1, -1, 0, -1, 4, 5, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, 3, 1, -1, -1, 0, 1, -1, 2, 4, -1, 2, -1, 3, 4, -1]}, {"doc_id": "emerging.test_126", "sentence": ["\u2581That", "'", "\u2581", "s", "\u2581why", "\u2581I", "\u2581have", "\u2581", "n", "p", "\u2581at", "\u2581the", "\u2581start", "\u2581of", "\u2581the", "\u2581URL", "\u2581as", "\u2581per", "\u2581the", "\u2581sub", "'", "\u2581", "s", "\u2581T", "\u2581", "&", "\u2581amp", ";", "\u2581C", "'", "\u2581", "s", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581That", "'", "\u2581", "s", "\u2581why", "\u2581I", "\u2581have", "\u2581", "n", "p", "\u2581at", "\u2581the", "\u2581start", "\u2581of", "\u2581the", "\u2581URL", "\u2581as", "\u2581per", "\u2581the", "\u2581sub", "'", "\u2581", "s", "\u2581T", "\u2581", "&", "\u2581amp", ";", "\u2581C", "'", "\u2581", "s", ".", "</s>"], "target_sentence": ["\u2581That", "'", "\u2581", "s", "\u2581why", "\u2581I", "\u2581have", "\u2581", "n", "p", "\u2581at", "\u2581the", "\u2581start", "\u2581of", "\u2581the", "\u2581URL", "\u2581as", "\u2581per", "\u2581the", "\u2581sub", "'", "\u2581", "s", "\u2581T", "\u2581", "&", "\u2581amp", ";", "\u2581C", "'", "\u2581", "s", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 20, 21, 22, 23, 24, 25, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_127", "sentence": ["\u2581[", "\u2581Oh", "\u2581look", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Oh", "\u2581look", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581Oh", "\u2581look", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_128", "sentence": ["\u2581[", "\u2581St", "a", "a", "a", "a", "h", "p", "]", "\u2581(", "\u2581http", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "86", "3", "w", "/", "-", "/", "d", "c", "25", "x", "f", "j", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581St", "a", "a", "a", "a", "h", "p", "]", "\u2581(", "\u2581http", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "86", "3", "w", "/", "-", "/", "d", "c", "25", "x", "f", "j", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581St", "a", "a", "a", "a", "h", "p", "]", "\u2581(", "\u2581http", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "86", "3", "w", "/", "-", "/", "d", "c", "25", "x", "f", "j", ")", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_129", "sentence": ["\u2581[", "\u2581It", "'", "\u2581", "s", "\u2581compulsory", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "n", "e", "8", "b", "r", "/", "x", "post", "_", "off", "my", "ches", "t", "_", "i", "_", "f", "uck", "ing", "_", "hat", "e", "_", "s", "us", "i", "/", "d", "ca", "x", "2", "78", "/", ")", "\u2581for", "\u2581", "OP", "'", "\u2581", "s", "\u2581course", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581It", "'", "\u2581", "s", "\u2581compulsory", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "n", "e", "8", "b", "r", "/", "x", "post", "_", "off", "my", "ches", "t", "_", "i", "_", "f", "uck", "ing", "_", "hat", "e", "_", "s", "us", "i", "/", "d", "ca", "x", "2", "78", "/", ")", "\u2581for", "\u2581", "OP", "'", "\u2581", "s", "\u2581course", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581It", "'", "\u2581", "s", "\u2581compulsory", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "n", "e", "8", "b", "r", "/", "x", "post", "_", "off", "my", "ches", "t", "_", "i", "_", "f", "uck", "ing", "_", "hat", "e", "_", "s", "us", "i", "/", "d", "ca", "x", "2", "78", "/", ")", "\u2581for", "\u2581", "OP", "'", "\u2581", "s", "\u2581course", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_130", "sentence": ["\u2581[", "\u2581The", "\u2581link", "\u2581to", "\u2581the", "\u2581Am", "A", "\u2581is", "\u2581at", "\u2581the", "\u2581top", "\u2581of", "\u2581this", "\u2581thread", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581The", "\u2581link", "\u2581to", "\u2581the", "\u2581Am", "A", "\u2581is", "\u2581at", "\u2581the", "\u2581top", "\u2581of", "\u2581this", "\u2581thread", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581The", "\u2581link", "\u2581to", "\u2581the", "\u2581Am", "A", "\u2581is", "\u2581at", "\u2581the", "\u2581top", "\u2581of", "\u2581this", "\u2581thread", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_131", "sentence": ["\u2581Ah", ",", "\u2581the", "\u2581", "o", "l", "'", "\u2581Adelaide", "\u2581[", "\u2581Dig", "e", "rid", "o", "o", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ah", ",", "\u2581the", "\u2581", "o", "l", "'", "\u2581Adelaide", "\u2581[", "\u2581Dig", "e", "rid", "o", "o", "!", "</s>"], "target_sentence": ["\u2581Ah", ",", "\u2581the", "\u2581", "o", "l", "'", "<m>", "<m>", "\u2581Adelaide", "</m>", "</m>", "\u2581[", "<m>", "\u2581Dig", "e", "rid", "o", "o", "</m>", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 7, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, 2, -1, -1, -1, -1, -1, 2, -1, -1]}, {"doc_id": "emerging.test_132", "sentence": ["\u2581Would", "\u2581take", "\u2581N", "t", "e", "p", "\u2581in", "\u2581", "a", "\u2581heart", "beat", "\u2581and", "\u2581frankly", "\u2581Cost", "il", "\u2581and", "\u2581Sa", "gna", "\u2581would", "\u2581fix", "\u2581two", "\u2581of", "\u2581the", "\u2581weak", "est", "\u2581spots", "\u2581in", "\u2581the", "\u2581team", "\u2581right", "\u2581now", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Would", "\u2581take", "\u2581N", "t", "e", "p", "\u2581in", "\u2581", "a", "\u2581heart", "beat", "\u2581and", "\u2581frankly", "\u2581Cost", "il", "\u2581and", "\u2581Sa", "gna", "\u2581would", "\u2581fix", "\u2581two", "\u2581of", "\u2581the", "\u2581weak", "est", "\u2581spots", "\u2581in", "\u2581the", "\u2581team", "\u2581right", "\u2581now", ".", "</s>"], "target_sentence": ["\u2581Would", "\u2581take", "<m>", "\u2581N", "t", "e", "p", "</m>", "\u2581in", "\u2581", "a", "\u2581heart", "beat", "\u2581and", "\u2581frankly", "<m>", "\u2581Cost", "il", "</m>", "\u2581and", "<m>", "\u2581Sa", "gna", "</m>", "\u2581would", "\u2581fix", "\u2581two", "\u2581of", "\u2581the", "\u2581weak", "est", "\u2581spots", "\u2581in", "\u2581the", "\u2581team", "\u2581right", "\u2581now", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 4, 5, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_133", "sentence": ["\u2581", "\u041e\u0431", "\u0441", "\u0443", "\u0436", "\u0434", "\u0435\u043d\u0438", "\u0435", "\u2581", "\u043d\u0430", "\u2581", "\u0430\u043d", "\u0433", "\u043b\u0438", "\u0439", "\u0441\u043a\u043e", "\u043c", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ca", "nada", "/", "com", "ments", "/5", "p", "52", "w", "h", "/", "ste", "phen", "_", "har", "per", "_", "tru", "mp", "_", "will", "_", "re", "verse", "_", "the", "_", "corn", "er", "stone", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "\u041e\u0431", "\u0441", "\u0443", "\u0436", "\u0434", "\u0435\u043d\u0438", "\u0435", "\u2581", "\u043d\u0430", "\u2581", "\u0430\u043d", "\u0433", "\u043b\u0438", "\u0439", "\u0441\u043a\u043e", "\u043c", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ca", "nada", "/", "com", "ments", "/5", "p", "52", "w", "h", "/", "ste", "phen", "_", "har", "per", "_", "tru", "mp", "_", "will", "_", "re", "verse", "_", "the", "_", "corn", "er", "stone", "/", "</s>"], "target_sentence": ["\u2581", "\u041e\u0431", "\u0441", "\u0443", "\u0436", "\u0434", "\u0435\u043d\u0438", "\u0435", "\u2581", "\u043d\u0430", "\u2581", "\u0430\u043d", "\u0433", "\u043b\u0438", "\u0439", "\u0441\u043a\u043e", "\u043c", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ca", "nada", "/", "com", "ments", "/5", "p", "52", "w", "h", "/", "ste", "phen", "_", "har", "per", "_", "tru", "mp", "_", "will", "_", "re", "verse", "_", "the", "_", "corn", "er", "stone", "/", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_134", "sentence": ["\u2581Just", "\u2581ask", "\u2581him", "\u2581about", "\u2581his", "\u2581[", "\u2581trip", "\u2581to", "\u2581North", "\u2581Korea", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "AMA", "/", "com", "ments", "/5", "h", "y", "w", "f", "x", "/", "i", "_", "have", "_", "just", "_", "got", "_", "back", "_", "from", "_", "a", "_", "trip", "_", "to", "_", "n", "or", "th", "_", "kor", "e", "a", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Just", "\u2581ask", "\u2581him", "\u2581about", "\u2581his", "\u2581[", "\u2581trip", "\u2581to", "\u2581North", "\u2581Korea", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "AMA", "/", "com", "ments", "/5", "h", "y", "w", "f", "x", "/", "i", "_", "have", "_", "just", "_", "got", "_", "back", "_", "from", "_", "a", "_", "trip", "_", "to", "_", "n", "or", "th", "_", "kor", "e", "a", "/", ")", "</s>"], "target_sentence": ["\u2581Just", "\u2581ask", "\u2581him", "\u2581about", "\u2581his", "\u2581[", "\u2581trip", "\u2581to", "<m>", "\u2581North", "\u2581Korea", "</m>", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "AMA", "/", "com", "ments", "/5", "h", "y", "w", "f", "x", "/", "i", "_", "have", "_", "just", "_", "got", "_", "back", "_", "from", "_", "a", "_", "trip", "_", "to", "_", "n", "or", "th", "_", "kor", "e", "a", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_135", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Lost", "\u2581", "RC", "\u2581plane", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Lost", "\u2581", "RC", "\u2581plane", ".", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Lost", "<m>", "\u2581", "RC", "</m>", "\u2581plane", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_136", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581I", "\u2581believe", "\u2581Peter", "\u2581Hit", "chen", "s", "\u2581(", "\u2581Fer", "vent", "\u2581euros", "k", "eptic", "\u2581who", "\u2581", "voted", "\u2581remain", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581I", "\u2581believe", "\u2581Peter", "\u2581Hit", "chen", "s", "\u2581(", "\u2581Fer", "vent", "\u2581euros", "k", "eptic", "\u2581who", "\u2581", "voted", "\u2581remain", ")", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581I", "\u2581believe", "<m>", "\u2581Peter", "\u2581Hit", "chen", "s", "</m>", "\u2581(", "\u2581Fer", "vent", "\u2581euros", "k", "eptic", "\u2581who", "\u2581", "voted", "\u2581remain", ")", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 8, 9, 9, 9, 10, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_137", "sentence": ["\u2581Long", "\u2581story", "\u2581short", ",", "\u2581what", "s", "\u2581to", "\u2581keep", "\u2581republic", "ans", "\u2581from", "\u2581scrap", "ping", "\u2581the", "\u2581pre", "exist", "ing", "\u2581conditions", "\u2581clause", "\u2581for", "\u2581those", "\u2581with", "\u2581B", "LD", "\u2581", "\u2013", "\u2581paid", "\u2581for", "\u2581from", "\u2581some", "\u2581other", "\u2581pocket", "\u2581of", "\u2581", "gov", "t", "\u2581money", "\u2581", "\u2013", "\u2581but", "\u2581not", "\u2581for", "\u2581everyone", "\u2581else", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Long", "\u2581story", "\u2581short", ",", "\u2581what", "s", "\u2581to", "\u2581keep", "\u2581republic", "ans", "\u2581from", "\u2581scrap", "ping", "\u2581the", "\u2581pre", "exist", "ing", "\u2581conditions", "\u2581clause", "\u2581for", "\u2581those", "\u2581with", "\u2581B", "LD", "\u2581", "\u2013", "\u2581paid", "\u2581for", "\u2581from", "\u2581some", "\u2581other", "\u2581pocket", "\u2581of", "\u2581", "gov", "t", "\u2581money", "\u2581", "\u2013", "\u2581but", "\u2581not", "\u2581for", "\u2581everyone", "\u2581else", "?", "</s>"], "target_sentence": ["\u2581Long", "\u2581story", "\u2581short", ",", "\u2581what", "s", "\u2581to", "\u2581keep", "<m>", "\u2581republic", "ans", "</m>", "\u2581from", "\u2581scrap", "ping", "\u2581the", "\u2581pre", "exist", "ing", "\u2581conditions", "\u2581clause", "\u2581for", "\u2581those", "\u2581with", "<m>", "\u2581B", "LD", "</m>", "\u2581", "\u2013", "\u2581paid", "\u2581for", "\u2581from", "\u2581some", "\u2581other", "\u2581pocket", "\u2581of", "<m>", "\u2581", "gov", "t", "</m>", "\u2581money", "\u2581", "\u2013", "\u2581but", "\u2581not", "\u2581for", "\u2581everyone", "\u2581else", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 27, 28, 28, 29, 30, 31, 32, 33, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_138", "sentence": ["\u2581*", "\u2581[", "\u2581Ste", "w", "'", "\u2581", "s", "\u2581Self", "\u2581Service", "\u2581Garage", "]", "\u2581(", "\u2581http", "://", "ste", "w", "s", "gar", "age", ".", "com", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581[", "\u2581Ste", "w", "'", "\u2581", "s", "\u2581Self", "\u2581Service", "\u2581Garage", "]", "\u2581(", "\u2581http", "://", "ste", "w", "s", "gar", "age", ".", "com", "/", ")", "</s>"], "target_sentence": ["\u2581*", "\u2581[", "<m>", "<m>", "\u2581Ste", "w", "</m>", "'", "\u2581", "s", "\u2581Self", "\u2581Service", "\u2581Garage", "</m>", "]", "\u2581(", "\u2581http", "://", "ste", "w", "s", "gar", "age", ".", "com", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_139", "sentence": ["\u2581It", "\u2581is", "\u2581well", "-", "known", "\u2581that", "\u2581S", "nick", "ers", "\u2581be", "wild", "er", "\u2581and", "\u2581[", "\u2581delight", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", ")", "\u2581the", "\u2581Irish", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "\u2581is", "\u2581well", "-", "known", "\u2581that", "\u2581S", "nick", "ers", "\u2581be", "wild", "er", "\u2581and", "\u2581[", "\u2581delight", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", ")", "\u2581the", "\u2581Irish", ".", "</s>"], "target_sentence": ["\u2581It", "\u2581is", "\u2581well", "-", "known", "\u2581that", "<m>", "<m>", "\u2581S", "nick", "ers", "</m>", "</m>", "\u2581be", "wild", "er", "\u2581and", "\u2581[", "\u2581delight", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", ")", "\u2581the", "\u2581Irish", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 4, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_140", "sentence": ["\u2581Coll", "u", "d", "ing", "\u2581with", "\u2581Putin", ",", "\u2581ha", "ha", "ha", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Coll", "u", "d", "ing", "\u2581with", "\u2581Putin", ",", "\u2581ha", "ha", "ha", "!", "</s>"], "target_sentence": ["\u2581Coll", "u", "d", "ing", "\u2581with", "<m>", "\u2581Putin", "</m>", ",", "\u2581ha", "ha", "ha", "!", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 3, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_141", "sentence": ["\u2581Source", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "t", "04", "x", "c", "/", "there", "_", "was", "_", "an", "_", "at", "t", "empt", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Source", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "t", "04", "x", "c", "/", "there", "_", "was", "_", "an", "_", "at", "t", "empt", "/", "</s>"], "target_sentence": ["\u2581Source", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "t", "04", "x", "c", "/", "there", "_", "was", "_", "an", "_", "at", "t", "empt", "/", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_142", "sentence": ["\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581see", "\u2581him", "\u2581try", "\u2581that", "\u2581in", "\u2581the", "\u2581NHL", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581see", "\u2581him", "\u2581try", "\u2581that", "\u2581in", "\u2581the", "\u2581NHL", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581see", "\u2581him", "\u2581try", "\u2581that", "\u2581in", "\u2581the", "<m>", "<m>", "\u2581NHL", "</m>", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 5, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1]}, {"doc_id": "emerging.test_143", "sentence": ["\u2581", "TL", ";", "\u2581D", "\u2581R", "\u2581", "-", "\u2581Do", "\u2581", "n", "'", "\u2581", "t", "\u2581get", "\u2581your", "\u2581phone", "\u2581from", "\u2581your", "\u2581carrier", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "TL", ";", "\u2581D", "\u2581R", "\u2581", "-", "\u2581Do", "\u2581", "n", "'", "\u2581", "t", "\u2581get", "\u2581your", "\u2581phone", "\u2581from", "\u2581your", "\u2581carrier", ".", "</s>"], "target_sentence": ["\u2581", "TL", ";", "\u2581D", "\u2581R", "\u2581", "-", "\u2581Do", "\u2581", "n", "'", "\u2581", "t", "\u2581get", "\u2581your", "\u2581phone", "\u2581from", "\u2581your", "\u2581carrier", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_144", "sentence": ["\u2581There", "\u2581has", "\u2581been", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581discussion", "\u2581about", "\u2581Uber", "\u2581in", "\u2581general", ",", "\u2581but", "\u2581I", "\u2581have", "\u2581", "n", "'", "\u2581", "t", "\u2581seen", "\u2581much", "\u2581in", "\u2581the", "\u2581way", "\u2581of", "\u2581people", "\u2581talking", "\u2581about", "\u2581becoming", "\u2581", "a", "\u2581driver", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581There", "\u2581has", "\u2581been", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581discussion", "\u2581about", "\u2581Uber", "\u2581in", "\u2581general", ",", "\u2581but", "\u2581I", "\u2581have", "\u2581", "n", "'", "\u2581", "t", "\u2581seen", "\u2581much", "\u2581in", "\u2581the", "\u2581way", "\u2581of", "\u2581people", "\u2581talking", "\u2581about", "\u2581becoming", "\u2581", "a", "\u2581driver", ".", "</s>"], "target_sentence": ["\u2581There", "\u2581has", "\u2581been", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581discussion", "\u2581about", "<m>", "<m>", "\u2581Uber", "</m>", "</m>", "\u2581in", "\u2581general", ",", "\u2581but", "\u2581I", "\u2581have", "\u2581", "n", "'", "\u2581", "t", "\u2581seen", "\u2581much", "\u2581in", "\u2581the", "\u2581way", "\u2581of", "\u2581people", "\u2581talking", "\u2581about", "\u2581becoming", "\u2581", "a", "\u2581driver", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_145", "sentence": ["\u2581you", "'", "\u2581", "re", "\u2581really", "\u2581late", ",", "\u2581", "OP", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581you", "'", "\u2581", "re", "\u2581really", "\u2581late", ",", "\u2581", "OP", ":", "</s>"], "target_sentence": ["\u2581you", "'", "\u2581", "re", "\u2581really", "\u2581late", ",", "\u2581", "OP", ":", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_146", "sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "o", "v", "le", "/", "s", "in", "an", "_", "g", "%", "C", "3%", "BC", "m", "%", "C", "3%", "BC", "%", "C", "5%", "9", "F", "_", "go", "al", "_", "s", "n", "e", "i", "j", "der", "_", "assi", "s", "t", "_", "gal", "at", "a", "s", "a", "ray", "_", "6", "_", "0", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "o", "v", "le", "/", "s", "in", "an", "_", "g", "%", "C", "3%", "BC", "m", "%", "C", "3%", "BC", "%", "C", "5%", "9", "F", "_", "go", "al", "_", "s", "n", "e", "i", "j", "der", "_", "assi", "s", "t", "_", "gal", "at", "a", "s", "a", "ray", "_", "6", "_", "0", "/", "</s>"], "target_sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "o", "v", "le", "/", "s", "in", "an", "_", "g", "%", "C", "3%", "BC", "m", "%", "C", "3%", "BC", "%", "C", "5%", "9", "F", "_", "go", "al", "_", "s", "n", "e", "i", "j", "der", "_", "assi", "s", "t", "_", "gal", "at", "a", "s", "a", "ray", "_", "6", "_", "0", "/", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_147", "sentence": ["\u2581[", "\u2581", "Warum", "\u2581das", "\u2581eine", "\u2581absolut", "\u2581be", "sch", "issen", "e", "\u2581Idee", "\u2581ist", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "Warum", "\u2581das", "\u2581eine", "\u2581absolut", "\u2581be", "sch", "issen", "e", "\u2581Idee", "\u2581ist", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581", "Warum", "\u2581das", "\u2581eine", "\u2581absolut", "\u2581be", "sch", "issen", "e", "\u2581Idee", "\u2581ist", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 5, 5, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_148", "sentence": ["\u2581(", "\u2581personally", ",", "\u2581I", "\u2581think", "\u2581Ras", "t", "us", "\u2581is", "\u2581his", "\u2581", "j", "il", "ted", "\u2581lover", ".", ".", ".", ";", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581(", "\u2581personally", ",", "\u2581I", "\u2581think", "\u2581Ras", "t", "us", "\u2581is", "\u2581his", "\u2581", "j", "il", "ted", "\u2581lover", ".", ".", ".", ";", ")", "</s>"], "target_sentence": ["\u2581(", "\u2581personally", ",", "\u2581I", "\u2581think", "<m>", "\u2581Ras", "t", "us", "</m>", "\u2581is", "\u2581his", "\u2581", "j", "il", "ted", "\u2581lover", ".", ".", ".", ";", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_149", "sentence": ["\u2581Edit", ":", "\u2581[", "\u2581Con", "text", "\u2581in", "\u2581case", "\u2581anyone", "\u2581was", "\u2581wondering", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "p", "w", "o", "s", "9", "/", "s", "lug", "/", "d", "cu", "er", "z", "p", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Edit", ":", "\u2581[", "\u2581Con", "text", "\u2581in", "\u2581case", "\u2581anyone", "\u2581was", "\u2581wondering", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "p", "w", "o", "s", "9", "/", "s", "lug", "/", "d", "cu", "er", "z", "p", ")", "</s>"], "target_sentence": ["\u2581Edit", ":", "\u2581[", "\u2581Con", "text", "\u2581in", "\u2581case", "\u2581anyone", "\u2581was", "\u2581wondering", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "p", "w", "o", "s", "9", "/", "s", "lug", "/", "d", "cu", "er", "z", "p", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_150", "sentence": ["\u2581Yet", "\u2581in", "\u2581[", "\u2581another", "\u2581post", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "m", "9", "h", "s", "3/", "labor", "s", "_", "lind", "a", "_", "bur", "ney", "_", "re", "quest", "s", "_", "a", "udi", "t", "or", "general", "/", "d", "c", "2", "at", "z", "g", "/", ")", "\u2581you", "\u2581lamb", "a", "s", "t", "\u2581Labor", "\u2581for", "\u2581*", "\u2581*", "\u2581only", "\u2581*", "\u2581*", "\u2581three", "\u2581of", "\u2581their", "\u2581front", "\u2581bench", "\u2581publicly", "\u2581den", "ou", "ncing", "\u2581this", "\u2581de", "bac", "le", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Yet", "\u2581in", "\u2581[", "\u2581another", "\u2581post", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "m", "9", "h", "s", "3/", "labor", "s", "_", "lind", "a", "_", "bur", "ney", "_", "re", "quest", "s", "_", "a", "udi", "t", "or", "general", "/", "d", "c", "2", "at", "z", "g", "/", ")", "\u2581you", "\u2581lamb", "a", "s", "t", "\u2581Labor", "\u2581for", "\u2581*", "\u2581*", "\u2581only", "\u2581*", "\u2581*", "\u2581three", "\u2581of", "\u2581their", "\u2581front", "\u2581bench", "\u2581publicly", "\u2581den", "ou", "ncing", "\u2581this", "\u2581de", "bac", "le", ".", "</s>"], "target_sentence": ["\u2581Yet", "\u2581in", "\u2581[", "\u2581another", "\u2581post", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "m", "9", "h", "s", "3/", "labor", "s", "_", "lind", "a", "_", "bur", "ney", "_", "re", "quest", "s", "_", "a", "udi", "t", "or", "general", "/", "d", "c", "2", "at", "z", "g", "/", ")", "\u2581you", "\u2581lamb", "a", "s", "t", "\u2581Labor", "\u2581for", "\u2581*", "\u2581*", "\u2581only", "\u2581*", "\u2581*", "\u2581three", "\u2581of", "\u2581their", "\u2581front", "\u2581bench", "\u2581publicly", "\u2581den", "ou", "ncing", "\u2581this", "\u2581de", "bac", "le", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 24, 25, 26, 26, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_151", "sentence": ["\u2581[", "\u2581A", "a", "a", "a", "a", "and", "\u2581there", "\u2581it", "\u2581is", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "z", "h", "b", "0", "d", "/", "a", "uck", "l", "and", "_", "univers", "ity", "_", "has", "_", "intr", "o", "duce", "d", "_", "all", "g", "ender", "/", "de", "y", "d", "f", "z", "7", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "front", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "new", "ze", "al", "and", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581A", "a", "a", "a", "a", "and", "\u2581there", "\u2581it", "\u2581is", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "z", "h", "b", "0", "d", "/", "a", "uck", "l", "and", "_", "univers", "ity", "_", "has", "_", "intr", "o", "duce", "d", "_", "all", "g", "ender", "/", "de", "y", "d", "f", "z", "7", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "front", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "new", "ze", "al", "and", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581A", "a", "a", "a", "a", "and", "\u2581there", "\u2581it", "\u2581is", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "z", "h", "b", "0", "d", "/", "a", "uck", "l", "and", "_", "univers", "ity", "_", "has", "_", "intr", "o", "duce", "d", "_", "all", "g", "ender", "/", "de", "y", "d", "f", "z", "7", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "front", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "new", "ze", "al", "and", ")", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_152", "sentence": ["\u2581Buzz", "F", "eed", "\u2581took", "\u2581the", "\u2581bait", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Buzz", "F", "eed", "\u2581took", "\u2581the", "\u2581bait", ".", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Buzz", "F", "eed", "</m>", "</m>", "\u2581took", "\u2581the", "\u2581bait", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, 2, 4, -1, -1, -1, -1, -1], "ent_indices": [1, 0, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_153", "sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581canada", "\u2581used", "\u2581to", "\u2581say", "\u2581the", "\u2581", "CBC", "\u2581went", "\u2581click", "bai", "t", "\u2581because", "\u2581those", "\u2581evil", "\u2581cons", "\u2581tried", "\u2581to", "\u2581de", "fund", "\u2581them", ",", "\u2581but", "\u2581the", "\u2581", "rut", "\u2581is", "\u2581clearly", "\u2581much", "\u2581deeper", "\u2581and", "\u2581more", "\u2581permanent", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581canada", "\u2581used", "\u2581to", "\u2581say", "\u2581the", "\u2581", "CBC", "\u2581went", "\u2581click", "bai", "t", "\u2581because", "\u2581those", "\u2581evil", "\u2581cons", "\u2581tried", "\u2581to", "\u2581de", "fund", "\u2581them", ",", "\u2581but", "\u2581the", "\u2581", "rut", "\u2581is", "\u2581clearly", "\u2581much", "\u2581deeper", "\u2581and", "\u2581more", "\u2581permanent", ".", "</s>"], "target_sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "<m>", "\u2581canada", "</m>", "\u2581used", "\u2581to", "\u2581say", "\u2581the", "\u2581", "CBC", "\u2581went", "\u2581click", "bai", "t", "\u2581because", "\u2581those", "\u2581evil", "\u2581cons", "\u2581tried", "\u2581to", "\u2581de", "fund", "\u2581them", ",", "\u2581but", "\u2581the", "\u2581", "rut", "\u2581is", "\u2581clearly", "\u2581much", "\u2581deeper", "\u2581and", "\u2581more", "\u2581permanent", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_154", "sentence": ["\u2581*", "\u2581*", "\u2581comment", "\u2581content", "\u2581*", "\u2581*", ":", "\u2581Marseille", "\u2581has", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581comment", "\u2581content", "\u2581*", "\u2581*", ":", "\u2581Marseille", "\u2581has", ".", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581comment", "\u2581content", "\u2581*", "\u2581*", ":", "<m>", "<m>", "\u2581Marseille", "</m>", "</m>", "\u2581has", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 3, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_155", "sentence": ["\u2581Original", "\u2581post", ":", "\u2581[", "'", "\u2581Many", "\u2581wounded", "'", "\u2581in", "\u2581Istanbul", "\u2581night", "club", "\u2581attack", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "l", "ca", "e", "d", "/", "man", "y", "_", "w", "ounded", "_", "in", "_", "ist", "an", "bul", "_", "night", "club", "_", "attack", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Original", "\u2581post", ":", "\u2581[", "'", "\u2581Many", "\u2581wounded", "'", "\u2581in", "\u2581Istanbul", "\u2581night", "club", "\u2581attack", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "l", "ca", "e", "d", "/", "man", "y", "_", "w", "ounded", "_", "in", "_", "ist", "an", "bul", "_", "night", "club", "_", "attack", "/", ")", "</s>"], "target_sentence": ["\u2581Original", "\u2581post", ":", "\u2581[", "'", "\u2581Many", "\u2581wounded", "'", "\u2581in", "<m>", "\u2581Istanbul", "</m>", "\u2581night", "club", "\u2581attack", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "l", "ca", "e", "d", "/", "man", "y", "_", "w", "ounded", "_", "in", "_", "ist", "an", "bul", "_", "night", "club", "_", "attack", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_156", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581got", "\u2581the", "\u2581G", "IF", "s", "\u2581of", "\u2581the", "\u2581goals", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581got", "\u2581the", "\u2581G", "IF", "s", "\u2581of", "\u2581the", "\u2581goals", ".", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581got", "\u2581the", "\u2581G", "IF", "s", "\u2581of", "\u2581the", "\u2581goals", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_157", "sentence": ["\u2581Vel", "ve", "t", "\u2581has", "\u2581such", "\u2581", "a", "\u2581thin", "\u2581skin", "\u2581", "he", "\u2581actually", "\u2581deleted", "\u2581and", "\u2581", "re", "sub", "mitted", "\u2581an", "\u2581article", "\u2581because", "\u2581someone", "\u2581disagree", "d", "\u2581with", "\u2581him", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Vel", "ve", "t", "\u2581has", "\u2581such", "\u2581", "a", "\u2581thin", "\u2581skin", "\u2581", "he", "\u2581actually", "\u2581deleted", "\u2581and", "\u2581", "re", "sub", "mitted", "\u2581an", "\u2581article", "\u2581because", "\u2581someone", "\u2581disagree", "d", "\u2581with", "\u2581him", ":", "</s>"], "target_sentence": ["<m>", "\u2581Vel", "ve", "t", "</m>", "\u2581has", "\u2581such", "\u2581", "a", "\u2581thin", "\u2581skin", "\u2581", "he", "\u2581actually", "\u2581deleted", "\u2581and", "\u2581", "re", "sub", "mitted", "\u2581an", "\u2581article", "\u2581because", "\u2581someone", "\u2581disagree", "d", "\u2581with", "\u2581him", ":", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_158", "sentence": ["\u2581He", "ctor", "\u2581was", "\u2581holding", "\u2581back", "\u2581I", "\u2581assume", "\u2581playing", "\u2581it", "\u2581safe", "\u2581with", "\u2581injuries", "\u2581", "/", "\u2581fitness", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581He", "ctor", "\u2581was", "\u2581holding", "\u2581back", "\u2581I", "\u2581assume", "\u2581playing", "\u2581it", "\u2581safe", "\u2581with", "\u2581injuries", "\u2581", "/", "\u2581fitness", ".", "</s>"], "target_sentence": ["<m>", "\u2581He", "ctor", "</m>", "\u2581was", "\u2581holding", "\u2581back", "\u2581I", "\u2581assume", "\u2581playing", "\u2581it", "\u2581safe", "\u2581with", "\u2581injuries", "\u2581", "/", "\u2581fitness", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_159", "sentence": ["\u2581Ex", "at", "amente", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ex", "at", "amente", ".", "</s>"], "target_sentence": ["\u2581Ex", "at", "amente", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_160", "sentence": ["\u2581Nar", "s", "ing", "h", "\u2581to", "\u2581see", "\u2581here", ",", "\u2581[", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581thread", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "e", "3", "e", "d", "/", "p", "s", "v", "_", "right", "_", "wing", "er", "_", "luc", "iano", "_", "n", "ar", "s", "ing", "h", "_", "set", "_", "to", "_", "mov", "e", "_", "to", "/", ")", "\u2581totally", "\u2581brutal", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Nar", "s", "ing", "h", "\u2581to", "\u2581see", "\u2581here", ",", "\u2581[", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581thread", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "e", "3", "e", "d", "/", "p", "s", "v", "_", "right", "_", "wing", "er", "_", "luc", "iano", "_", "n", "ar", "s", "ing", "h", "_", "set", "_", "to", "_", "mov", "e", "_", "to", "/", ")", "\u2581totally", "\u2581brutal", "</s>"], "target_sentence": ["<m>", "\u2581Nar", "s", "ing", "h", "</m>", "\u2581to", "\u2581see", "\u2581here", ",", "\u2581[", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581thread", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "e", "3", "e", "d", "/", "p", "s", "v", "_", "right", "_", "wing", "er", "_", "luc", "iano", "_", "n", "ar", "s", "ing", "h", "_", "set", "_", "to", "_", "mov", "e", "_", "to", "/", ")", "\u2581totally", "\u2581brutal", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_161", "sentence": ["\u2581you", "\u2581mean", "\u2581Tom", "i", "\u2581La", "hren", ",", "\u2581I", "\u2581just", "\u2581reference", "d", "\u2581her", "\u2581here", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581you", "\u2581mean", "\u2581Tom", "i", "\u2581La", "hren", ",", "\u2581I", "\u2581just", "\u2581reference", "d", "\u2581her", "\u2581here", "</s>"], "target_sentence": ["\u2581you", "\u2581mean", "<m>", "\u2581Tom", "i", "\u2581La", "hren", "</m>", ",", "\u2581I", "\u2581just", "\u2581reference", "d", "\u2581her", "\u2581here", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_162", "sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581James", "aka", "No", "a", "h", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581James", "aka", "No", "a", "h", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "<m>", "\u2581James", "aka", "No", "a", "h", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_163", "sentence": ["\u2581Wow", ",", "\u2581I", "'", "\u2581", "m", "\u2581an", "\u2581idiot", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Wow", ",", "\u2581I", "'", "\u2581", "m", "\u2581an", "\u2581idiot", ".", "</s>"], "target_sentence": ["\u2581Wow", ",", "\u2581I", "'", "\u2581", "m", "\u2581an", "\u2581idiot", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_164", "sentence": ["\u2581Most", "\u2581women", "\u2581in", "\u2581Muslim", "\u2581countries", "\u2581are", "\u2581[", "\u2581happy", "\u2581with", "\u2581their", "\u2581situation", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/", "54", "k", "h", "w", "0", "/", "s", "a", "udi", "_", "w", "o", "men", "_", "file", "_", "pet", "ition", "_", "to", "_", "end", "_", "male", "/", "d", "82", "y", "g", "z", "g", "/", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Most", "\u2581women", "\u2581in", "\u2581Muslim", "\u2581countries", "\u2581are", "\u2581[", "\u2581happy", "\u2581with", "\u2581their", "\u2581situation", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/", "54", "k", "h", "w", "0", "/", "s", "a", "udi", "_", "w", "o", "men", "_", "file", "_", "pet", "ition", "_", "to", "_", "end", "_", "male", "/", "d", "82", "y", "g", "z", "g", "/", ")", ".", "</s>"], "target_sentence": ["\u2581Most", "\u2581women", "\u2581in", "<m>", "\u2581Muslim", "\u2581countries", "</m>", "\u2581are", "\u2581[", "\u2581happy", "\u2581with", "\u2581their", "\u2581situation", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/", "54", "k", "h", "w", "0", "/", "s", "a", "udi", "_", "w", "o", "men", "_", "file", "_", "pet", "ition", "_", "to", "_", "end", "_", "male", "/", "d", "82", "y", "g", "z", "g", "/", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_165", "sentence": ["\u2581I", "\u2581remember", "\u2581around", "\u2581", "a", "\u2581year", "\u2581ago", "\u2581there", "\u2581was", "\u2581", "a", "\u2581post", "\u2581about", "\u2581how", "\u2581Ronald", "o", "\u2581had", "\u2581scored", "\u2581over", "\u258140", "\u2581", "%", "\u2581of", "\u2581Madrid", "'", "\u2581", "s", "\u2581goals", "\u2581since", "\u25812009", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581remember", "\u2581around", "\u2581", "a", "\u2581year", "\u2581ago", "\u2581there", "\u2581was", "\u2581", "a", "\u2581post", "\u2581about", "\u2581how", "\u2581Ronald", "o", "\u2581had", "\u2581scored", "\u2581over", "\u258140", "\u2581", "%", "\u2581of", "\u2581Madrid", "'", "\u2581", "s", "\u2581goals", "\u2581since", "\u25812009", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581remember", "\u2581around", "\u2581", "a", "\u2581year", "\u2581ago", "\u2581there", "\u2581was", "\u2581", "a", "\u2581post", "\u2581about", "\u2581how", "<m>", "\u2581Ronald", "o", "</m>", "\u2581had", "\u2581scored", "\u2581over", "\u258140", "\u2581", "%", "\u2581of", "<m>", "<m>", "\u2581Madrid", "</m>", "</m>", "'", "\u2581", "s", "\u2581goals", "\u2581since", "\u25812009", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_166", "sentence": ["\u2581They", "\u2581actually", "\u2581regularly", "\u2581up", "vo", "t", "e", "\u2581posts", "\u2581to", "\u2581the", "\u2581front", "\u2581page", "\u2581asking", "\u2581\"", "\u2581why", "\u2581do", "\u2581so", "\u2581many", "\u2581right", "\u2581le", "an", "ing", "\u2581people", "\u2581post", "\u2581here", "\u2581RE", "EE", "E", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581They", "\u2581actually", "\u2581regularly", "\u2581up", "vo", "t", "e", "\u2581posts", "\u2581to", "\u2581the", "\u2581front", "\u2581page", "\u2581asking", "\u2581\"", "\u2581why", "\u2581do", "\u2581so", "\u2581many", "\u2581right", "\u2581le", "an", "ing", "\u2581people", "\u2581post", "\u2581here", "\u2581RE", "EE", "E", "\u2581\"", "</s>"], "target_sentence": ["\u2581They", "\u2581actually", "\u2581regularly", "\u2581up", "vo", "t", "e", "\u2581posts", "\u2581to", "\u2581the", "\u2581front", "\u2581page", "\u2581asking", "\u2581\"", "\u2581why", "\u2581do", "\u2581so", "\u2581many", "\u2581right", "\u2581le", "an", "ing", "\u2581people", "\u2581post", "\u2581here", "\u2581RE", "EE", "E", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 17, 18, 19, 20, 20, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_167", "sentence": ["\u2581As", "\u2581you", "\u2581can", "\u2581see", "\u2581the", "\u2581Stoke", "\u2581ma", "f", "i", "a", "\u2581", "gang", "e", "d", "\u2581up", "\u2581on", "\u2581him", "\u2581big", "\u2581time", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581As", "\u2581you", "\u2581can", "\u2581see", "\u2581the", "\u2581Stoke", "\u2581ma", "f", "i", "a", "\u2581", "gang", "e", "d", "\u2581up", "\u2581on", "\u2581him", "\u2581big", "\u2581time", ".", "</s>"], "target_sentence": ["\u2581As", "\u2581you", "\u2581can", "\u2581see", "\u2581the", "<m>", "<m>", "<m>", "\u2581Stoke", "</m>", "</m>", "\u2581ma", "f", "i", "a", "</m>", "\u2581", "gang", "e", "d", "\u2581up", "\u2581on", "\u2581him", "\u2581big", "\u2581time", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 3, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 1, 2, 0, -1, 1, 0, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_168", "sentence": ["\u2581Best", "\u2581Ph", "o", "\u2581in", "\u2581Calgary", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Best", "\u2581Ph", "o", "\u2581in", "\u2581Calgary", "</s>"], "target_sentence": ["\u2581Best", "\u2581Ph", "o", "\u2581in", "<m>", "\u2581Calgary", "</m>", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, 0, -1]}, {"doc_id": "emerging.test_169", "sentence": ["\u2581The", "\u2581title", "\u2581should", "\u2581just", "\u2581be", "\u2581", "a", "\u2581literal", "\u2581copy", "\u2581of", "\u2581the", "\u2581tweet", ",", "\u2581which", "\u2581mention", "s", "\u2581Swan", "s", "e", "a", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581title", "\u2581should", "\u2581just", "\u2581be", "\u2581", "a", "\u2581literal", "\u2581copy", "\u2581of", "\u2581the", "\u2581tweet", ",", "\u2581which", "\u2581mention", "s", "\u2581Swan", "s", "e", "a", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581title", "\u2581should", "\u2581just", "\u2581be", "\u2581", "a", "\u2581literal", "\u2581copy", "\u2581of", "\u2581the", "\u2581tweet", ",", "\u2581which", "\u2581mention", "s", "<m>", "\u2581Swan", "s", "e", "a", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 14, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_170", "sentence": ["\u2581", "Hopefully", ",", "\u2581Be", "x", "\u2581", "negotiated", "\u2581", "a", "\u2581deal", "\u2581with", "\u2581the", "\u2581S", "nick", "ers", "\u2581company", "\u2581to", "\u2581supply", "\u2581our", "\u2581island", "\u2581with", "\u2581their", "\u2581delicious", "\u2581choc", "a", "late", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Hopefully", ",", "\u2581Be", "x", "\u2581", "negotiated", "\u2581", "a", "\u2581deal", "\u2581with", "\u2581the", "\u2581S", "nick", "ers", "\u2581company", "\u2581to", "\u2581supply", "\u2581our", "\u2581island", "\u2581with", "\u2581their", "\u2581delicious", "\u2581choc", "a", "late", ".", "</s>"], "target_sentence": ["\u2581", "Hopefully", ",", "<m>", "\u2581Be", "x", "</m>", "\u2581", "negotiated", "\u2581", "a", "\u2581deal", "\u2581with", "\u2581the", "<m>", "<m>", "<m>", "\u2581S", "nick", "ers", "</m>", "</m>", "\u2581company", "</m>", "\u2581to", "\u2581supply", "\u2581our", "\u2581island", "\u2581with", "\u2581their", "\u2581delicious", "\u2581choc", "a", "late", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 3, 1, 2, -1, -1, -1, 1, 2, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_171", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Ireland", "\u2581votes", "\u2581to", "\u2581be", "\u2581world", "\u2581", "\u2019", "\u2581", "s", "\u2581first", "\u2581country", "\u2581to", "\u2581fully", "\u2581dive", "s", "t", "\u2581from", "\u2581fossil", "\u2581fuel", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Ireland", "\u2581votes", "\u2581to", "\u2581be", "\u2581world", "\u2581", "\u2019", "\u2581", "s", "\u2581first", "\u2581country", "\u2581to", "\u2581fully", "\u2581dive", "s", "t", "\u2581from", "\u2581fossil", "\u2581fuel", "s", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "<m>", "\u2581Ireland", "</m>", "\u2581votes", "\u2581to", "\u2581be", "\u2581world", "\u2581", "\u2019", "\u2581", "s", "\u2581first", "\u2581country", "\u2581to", "\u2581fully", "\u2581dive", "s", "t", "\u2581from", "\u2581fossil", "\u2581fuel", "s", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16, 17, 18, 18, 18, 19, 20, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_172", "sentence": ["\u2581Pl", "s", "\u2581no", "\u2581Tom", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Pl", "s", "\u2581no", "\u2581Tom", "</s>"], "target_sentence": ["\u2581Pl", "s", "\u2581no", "<m>", "\u2581Tom", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, 0, -1, 0, -1]}, {"doc_id": "emerging.test_173", "sentence": ["\u2581[", "\u2581S", "nick", "ers", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581S", "nick", "ers", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", ")", "</s>"], "target_sentence": ["\u2581[", "<m>", "\u2581S", "nick", "ers", "</m>", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", ")", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_174", "sentence": ["\u2581Original", "\u2581post", ":", "\u2581[", "\u2581Andy", "\u2581Carroll", "\u2581goal", "\u2581", "v", "s", "\u2581Crystal", "\u2581Palace", "\u2581(", "\u25812", "\u2581", "-", "\u2581", "0", ")", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "y", "9", "t", "j", "/", "and", "y", "_", "car", "roll", "_", "go", "al", "_", "v", "s", "_", "c", "ry", "stal", "_", "pala", "ce", "20", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Original", "\u2581post", ":", "\u2581[", "\u2581Andy", "\u2581Carroll", "\u2581goal", "\u2581", "v", "s", "\u2581Crystal", "\u2581Palace", "\u2581(", "\u25812", "\u2581", "-", "\u2581", "0", ")", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "y", "9", "t", "j", "/", "and", "y", "_", "car", "roll", "_", "go", "al", "_", "v", "s", "_", "c", "ry", "stal", "_", "pala", "ce", "20", "/", ")", "</s>"], "target_sentence": ["\u2581Original", "\u2581post", ":", "\u2581[", "<m>", "<m>", "\u2581Andy", "\u2581Carroll", "</m>", "\u2581goal", "</m>", "\u2581", "v", "s", "<m>", "<m>", "<m>", "<m>", "\u2581Crystal", "\u2581Palace", "</m>", "</m>", "</m>", "</m>", "\u2581(", "\u25812", "\u2581", "-", "\u2581", "0", ")", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "y", "9", "t", "j", "/", "and", "y", "_", "car", "roll", "_", "go", "al", "_", "v", "s", "_", "c", "ry", "stal", "_", "pala", "ce", "20", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, 1, -1, -1, 0, -1, 1, -1, -1, -1, 5, 4, 3, 2, -1, -1, 5, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_175", "sentence": ["\u2581U", "h", ",", "\u2581they", "'", "\u2581", "re", "\u2581actually", "\u2581pretty", "\u2581well", "\u2581off", "\u2581", "compared", "\u2581to", "\u2581the", "\u2581rest", "\u2581of", "\u2581the", "\u2581country", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581U", "h", ",", "\u2581they", "'", "\u2581", "re", "\u2581actually", "\u2581pretty", "\u2581well", "\u2581off", "\u2581", "compared", "\u2581to", "\u2581the", "\u2581rest", "\u2581of", "\u2581the", "\u2581country", ".", "</s>"], "target_sentence": ["\u2581U", "h", ",", "\u2581they", "'", "\u2581", "re", "\u2581actually", "\u2581pretty", "\u2581well", "\u2581off", "\u2581", "compared", "\u2581to", "\u2581the", "\u2581rest", "\u2581of", "\u2581the", "\u2581country", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_176", "sentence": ["\u2581Did", "\u2581you", "\u2581miss", "\u2581[", "\u2581this", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "l", "r", "d", "k", "r", "/", "ar", "s", "%", "C", "3%", "A", "8", "n", "e", "_", "we", "nger", "_", "in", "_", "20", "_", "year", "s", "_", "it", "_", "is", "_", "the", "_", "most", "_", "une", "ven", "/", "?", "re", "f", "=", "search", "_", "post", "s", ")", "\u2581yesterday", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Did", "\u2581you", "\u2581miss", "\u2581[", "\u2581this", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "l", "r", "d", "k", "r", "/", "ar", "s", "%", "C", "3%", "A", "8", "n", "e", "_", "we", "nger", "_", "in", "_", "20", "_", "year", "s", "_", "it", "_", "is", "_", "the", "_", "most", "_", "une", "ven", "/", "?", "re", "f", "=", "search", "_", "post", "s", ")", "\u2581yesterday", "?", "</s>"], "target_sentence": ["\u2581Did", "\u2581you", "\u2581miss", "\u2581[", "\u2581this", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "l", "r", "d", "k", "r", "/", "ar", "s", "%", "C", "3%", "A", "8", "n", "e", "_", "we", "nger", "_", "in", "_", "20", "_", "year", "s", "_", "it", "_", "is", "_", "the", "_", "most", "_", "une", "ven", "/", "?", "re", "f", "=", "search", "_", "post", "s", ")", "\u2581yesterday", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_177", "sentence": ["\u2581[", "\u2581Rit", "chie", "\u2581McC", "law", "]", "\u2581(", "\u2581https", "://", "im", "gur", ".", "com", "/", "a", "/", "x", "P", "0", "T", "a", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Rit", "chie", "\u2581McC", "law", "]", "\u2581(", "\u2581https", "://", "im", "gur", ".", "com", "/", "a", "/", "x", "P", "0", "T", "a", ")", "</s>"], "target_sentence": ["\u2581[", "<m>", "<m>", "\u2581Rit", "chie", "\u2581McC", "law", "</m>", "</m>", "]", "\u2581(", "\u2581https", "://", "im", "gur", ".", "com", "/", "a", "/", "x", "P", "0", "T", "a", ")", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_178", "sentence": ["\u2581Cross", "post", "\u2581do", "\u2581", "r", "\u2581", "/", "\u2581world", "news", ",", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "n", "k", "t", "t", "8", "/", "bra", "zi", "lian", "_", "far", "m", "_", "owner", "s", "_", "form", "_", "mili", "t", "i", "a", "s", "_", "to", "_", "attack", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Cross", "post", "\u2581do", "\u2581", "r", "\u2581", "/", "\u2581world", "news", ",", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "n", "k", "t", "t", "8", "/", "bra", "zi", "lian", "_", "far", "m", "_", "owner", "s", "_", "form", "_", "mili", "t", "i", "a", "s", "_", "to", "_", "attack", "/", "</s>"], "target_sentence": ["<m>", "\u2581Cross", "post", "</m>", "\u2581do", "\u2581", "r", "\u2581", "/", "\u2581world", "news", ",", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "n", "k", "t", "t", "8", "/", "bra", "zi", "lian", "_", "far", "m", "_", "owner", "s", "_", "form", "_", "mili", "t", "i", "a", "s", "_", "to", "_", "attack", "/", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_179", "sentence": ["\u2581Ca", "\u2581", "serait", "\u2581meme", "\u2581plu", "to", "t", "\u2581le", "\u2581contraire", ",", "\u2581sans", "\u2581ce", "\u2581feu", ",", "\u2581", "il", "\u2581", "n", "'", "\u2581", "y", "\u2581", "aurait", "\u2581", "e", "u", "\u2581probablement", "\u2581pas", "\u2581de", "\u2581sur", "viv", "ant", ":", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "l", "f", "41", "g", "/", "t", "it", "a", "nic", "_", "s", "ank", "_", "du", "e", "_", "to", "_", "en", "or", "m", "ous", "_", "un", "control", "l", "able", "_", "fire", "/", "d", "b", "v", "l", "t", "e", "g", "/", "?", "con", "tex", "=", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ca", "\u2581", "serait", "\u2581meme", "\u2581plu", "to", "t", "\u2581le", "\u2581contraire", ",", "\u2581sans", "\u2581ce", "\u2581feu", ",", "\u2581", "il", "\u2581", "n", "'", "\u2581", "y", "\u2581", "aurait", "\u2581", "e", "u", "\u2581probablement", "\u2581pas", "\u2581de", "\u2581sur", "viv", "ant", ":", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "l", "f", "41", "g", "/", "t", "it", "a", "nic", "_", "s", "ank", "_", "du", "e", "_", "to", "_", "en", "or", "m", "ous", "_", "un", "control", "l", "able", "_", "fire", "/", "d", "b", "v", "l", "t", "e", "g", "/", "?", "con", "tex", "=", "7", "</s>"], "target_sentence": ["\u2581Ca", "\u2581", "serait", "\u2581meme", "\u2581plu", "to", "t", "\u2581le", "\u2581contraire", ",", "\u2581sans", "\u2581ce", "\u2581feu", ",", "\u2581", "il", "\u2581", "n", "'", "\u2581", "y", "\u2581", "aurait", "\u2581", "e", "u", "\u2581probablement", "\u2581pas", "\u2581de", "\u2581sur", "viv", "ant", ":", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "l", "f", "41", "g", "/", "t", "it", "a", "nic", "_", "s", "ank", "_", "du", "e", "_", "to", "_", "en", "or", "m", "ous", "_", "un", "control", "l", "able", "_", "fire", "/", "d", "b", "v", "l", "t", "e", "g", "/", "?", "con", "tex", "=", "7", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 14, 14, 15, 15, 16, 16, 16, 17, 18, 19, 20, 20, 20, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_180", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581saying", "\u2581this", "\u2581guy", "\u2581is", "\u2581", "assuming", "\u2581that", "\u2581they", "\u2581assumed", "\u2581", "he", "\u2581supported", "\u2581Trump", "\u2581because", "\u2581", "he", "'", "\u2581", "s", "\u2581white", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581saying", "\u2581this", "\u2581guy", "\u2581is", "\u2581", "assuming", "\u2581that", "\u2581they", "\u2581assumed", "\u2581", "he", "\u2581supported", "\u2581Trump", "\u2581because", "\u2581", "he", "'", "\u2581", "s", "\u2581white", ".", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "m", "\u2581saying", "\u2581this", "\u2581guy", "\u2581is", "\u2581", "assuming", "\u2581that", "\u2581they", "\u2581assumed", "\u2581", "he", "\u2581supported", "<m>", "\u2581Trump", "</m>", "\u2581because", "\u2581", "he", "'", "\u2581", "s", "\u2581white", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 15, 16, 17, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_181", "sentence": ["\u2581Hey", "\u2581", "u", "\u2581", "/", "\u2581", "nick", "lov", "e", "t", "t", "n", "z", "\u2581", "-", "\u2581St", "uff", "\u2581have", "\u2581[", "\u2581", "nic", "ked", "\u2581your", "\u2581picture", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hey", "\u2581", "u", "\u2581", "/", "\u2581", "nick", "lov", "e", "t", "t", "n", "z", "\u2581", "-", "\u2581St", "uff", "\u2581have", "\u2581[", "\u2581", "nic", "ked", "\u2581your", "\u2581picture", ".", "</s>"], "target_sentence": ["\u2581Hey", "\u2581", "u", "\u2581", "/", "\u2581", "nick", "lov", "e", "t", "t", "n", "z", "\u2581", "-", "\u2581St", "uff", "\u2581have", "\u2581[", "\u2581", "nic", "ked", "\u2581your", "\u2581picture", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_182", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Middle", "borough", "\u2581in", "\u2581talks", "\u2581to", "\u2581sign", "\u2581Je", "s", "e", "\u2581Rodriguez", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Middle", "borough", "\u2581in", "\u2581talks", "\u2581to", "\u2581sign", "\u2581Je", "s", "e", "\u2581Rodriguez", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "<m>", "<m>", "\u2581Middle", "borough", "</m>", "</m>", "\u2581in", "\u2581talks", "\u2581to", "\u2581sign", "<m>", "\u2581Je", "s", "e", "\u2581Rodriguez", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, 2, -1, -1, -1, -1, 2, -1]}, {"doc_id": "emerging.test_183", "sentence": ["\u2581The", "\u2581", "TL", "DR", "\u2581is", "\u2581all", "\u2581you", "\u2581really", "\u2581need", ",", "\u2581but", "\u2581the", "\u2581best", "\u25813", "\u2581word", "\u2581definition", "\u2581is", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581", "TL", "DR", "\u2581is", "\u2581all", "\u2581you", "\u2581really", "\u2581need", ",", "\u2581but", "\u2581the", "\u2581best", "\u25813", "\u2581word", "\u2581definition", "\u2581is", "</s>"], "target_sentence": ["\u2581The", "\u2581", "TL", "DR", "\u2581is", "\u2581all", "\u2581you", "\u2581really", "\u2581need", ",", "\u2581but", "\u2581the", "\u2581best", "\u25813", "\u2581word", "\u2581definition", "\u2581is", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_184", "sentence": ["\u2581[", "\u2581From", "\u2581Barcelona", ",", "\u2581the", "\u2581stand", "-", "out", "\u2581youngsters", "\u2581are", "\u2581De", "ul", "of", "e", "u", ",", "\u2581Don", "go", "u", "\u2581and", "\u2581Grim", "al", "d", "o", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581From", "\u2581Barcelona", ",", "\u2581the", "\u2581stand", "-", "out", "\u2581youngsters", "\u2581are", "\u2581De", "ul", "of", "e", "u", ",", "\u2581Don", "go", "u", "\u2581and", "\u2581Grim", "al", "d", "o", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581From", "\u2581Barcelona", ",", "\u2581the", "\u2581stand", "-", "out", "\u2581youngsters", "\u2581are", "<m>", "\u2581De", "ul", "of", "e", "u", "</m>", ",", "<m>", "\u2581Don", "go", "u", "</m>", "\u2581and", "<m>", "\u2581Grim", "al", "d", "o", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 8, 8, 8, 8, 9, 10, 10, 10, 11, 12, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, 1, -1, 2, -1, -1, -1, -1, 2, -1, -1]}, {"doc_id": "emerging.test_185", "sentence": ["\u2581", "-", "\u2581J", "\u00fcr", "gen", "\u2581Klo", "pp", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "-", "\u2581J", "\u00fcr", "gen", "\u2581Klo", "pp", "</s>"], "target_sentence": ["\u2581", "-", "<m>", "\u2581J", "\u00fcr", "gen", "\u2581Klo", "pp", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_186", "sentence": ["\u2581It", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581even", "\u2581funny", "\u2581like", "\u2581the", "\u2581Multi", "national", "\u2581Corporation", "\u2581one", "\u2581yesterday", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581even", "\u2581funny", "\u2581like", "\u2581the", "\u2581Multi", "national", "\u2581Corporation", "\u2581one", "\u2581yesterday", ".", "</s>"], "target_sentence": ["\u2581It", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581even", "\u2581funny", "\u2581like", "\u2581the", "<m>", "<m>", "\u2581Multi", "national", "\u2581Corporation", "</m>", "</m>", "\u2581one", "\u2581yesterday", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 5, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 1, 0, -1, -1, -1, -1]}, {"doc_id": "emerging.test_187", "sentence": ["\u2581Lo", "l", ",", "\u2581this", "\u2581is", "\u2581the", "\u2581", "d", "ick", "\u2581", "whose", "\u2581parents", "\u2581left", "\u2581him", "\u2581", "a", "\u2581house", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Lo", "l", ",", "\u2581this", "\u2581is", "\u2581the", "\u2581", "d", "ick", "\u2581", "whose", "\u2581parents", "\u2581left", "\u2581him", "\u2581", "a", "\u2581house", "</s>"], "target_sentence": ["\u2581Lo", "l", ",", "\u2581this", "\u2581is", "\u2581the", "\u2581", "d", "ick", "\u2581", "whose", "\u2581parents", "\u2581left", "\u2581him", "\u2581", "a", "\u2581house", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 5, 5, 6, 6, 7, 8, 9, 10, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_188", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Official", ":", "\u2581P", "SG", "\u2581sign", "\u2581Go", "n", "\u00e7a", "l", "o", "\u2581Gu", "e", "des", "\u2581for", "\u258125", "\u2581million", "\u2581\u20ac", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Official", ":", "\u2581P", "SG", "\u2581sign", "\u2581Go", "n", "\u00e7a", "l", "o", "\u2581Gu", "e", "des", "\u2581for", "\u258125", "\u2581million", "\u2581\u20ac", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Official", ":", "<m>", "\u2581P", "SG", "</m>", "\u2581sign", "\u2581Go", "n", "\u00e7a", "l", "o", "\u2581Gu", "e", "des", "\u2581for", "\u258125", "\u2581million", "\u2581\u20ac", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 11, 11, 11, 11, 12, 12, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_189", "sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/1", "u", "1", "e", "p", "b", "/", "le", "w", "and", "owski", "_", "about", "_", "contract", "_", "n", "ego", "t", "i", "ations", "_", "with", "_", "b", "v", "b", "/", "Now", "he", "is", "best", "paid", "player", "in", "BL", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/1", "u", "1", "e", "p", "b", "/", "le", "w", "and", "owski", "_", "about", "_", "contract", "_", "n", "ego", "t", "i", "ations", "_", "with", "_", "b", "v", "b", "/", "Now", "he", "is", "best", "paid", "player", "in", "BL", "</s>"], "target_sentence": ["\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/1", "u", "1", "e", "p", "b", "/", "le", "w", "and", "owski", "_", "about", "_", "contract", "_", "n", "ego", "t", "i", "ations", "_", "with", "_", "b", "v", "b", "/", "Now", "he", "is", "best", "paid", "player", "in", "BL", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_190", "sentence": ["\u2581I", "s", "\u2581it", "\u2581the", "\u2581Shi", "b", "a", "\u2581In", "u", "\u2581extensively", "\u2581described", "\u2581in", "\u2581the", "\u2581top", "\u2581post", "\u2581right", "\u2581now", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581it", "\u2581the", "\u2581Shi", "b", "a", "\u2581In", "u", "\u2581extensively", "\u2581described", "\u2581in", "\u2581the", "\u2581top", "\u2581post", "\u2581right", "\u2581now", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581it", "\u2581the", "<m>", "\u2581Shi", "b", "a", "\u2581In", "u", "</m>", "\u2581extensively", "\u2581described", "\u2581in", "\u2581the", "\u2581top", "\u2581post", "\u2581right", "\u2581now", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_191", "sentence": ["\u2581The", "\u2581main", "\u2581problems", "\u2581can", "\u2581be", "\u2581", "summe", "d", "\u2581up", "\u2581with", "\u2581Peter", "\u2581Lim", "\u2581though", "\u2581from", "\u2581my", "\u2581limited", "\u2581knowledge", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581main", "\u2581problems", "\u2581can", "\u2581be", "\u2581", "summe", "d", "\u2581up", "\u2581with", "\u2581Peter", "\u2581Lim", "\u2581though", "\u2581from", "\u2581my", "\u2581limited", "\u2581knowledge", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581main", "\u2581problems", "\u2581can", "\u2581be", "\u2581", "summe", "d", "\u2581up", "\u2581with", "\u2581Peter", "\u2581Lim", "\u2581though", "\u2581from", "\u2581my", "\u2581limited", "\u2581knowledge", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_192", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Z", "M", "\u2581(", "\u2581possibly", "\u2581other", "\u2581radio", "\u2581stations", ")", "\u2581adding", "\u2581", "rap", "\u2581features", "\u2581to", "\u2581normal", "\u2581songs", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Z", "M", "\u2581(", "\u2581possibly", "\u2581other", "\u2581radio", "\u2581stations", ")", "\u2581adding", "\u2581", "rap", "\u2581features", "\u2581to", "\u2581normal", "\u2581songs", "?", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "<m>", "\u2581Z", "M", "</m>", "\u2581(", "\u2581possibly", "\u2581other", "\u2581radio", "\u2581stations", ")", "\u2581adding", "\u2581", "rap", "\u2581features", "\u2581to", "\u2581normal", "\u2581songs", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_193", "sentence": ["\u2581Well", "\u2581looks", "\u2581like", "\u2581Demo", "l", "ition", "\u2581Man", "\u2581has", "\u2581come", "\u2581true", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Well", "\u2581looks", "\u2581like", "\u2581Demo", "l", "ition", "\u2581Man", "\u2581has", "\u2581come", "\u2581true", ".", "</s>"], "target_sentence": ["\u2581Well", "\u2581looks", "\u2581like", "<m>", "<m>", "\u2581Demo", "l", "ition", "\u2581Man", "</m>", "</m>", "\u2581has", "\u2581come", "\u2581true", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_194", "sentence": ["\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581really", "\u2581understand", "\u2581your", "\u2581problem", "\u2581with", "\u2581the", "\u2581SP", "LC", "\u2581though", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581really", "\u2581understand", "\u2581your", "\u2581problem", "\u2581with", "\u2581the", "\u2581SP", "LC", "\u2581though", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581really", "\u2581understand", "\u2581your", "\u2581problem", "\u2581with", "\u2581the", "<m>", "\u2581SP", "LC", "</m>", "\u2581though", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_195", "sentence": ["\u2581[", "\u2581Ah", ",", "\u2581the", "\u2581", "o", "l", "'", "\u2581red", "d", "it", "\u2581skin", "-", "a", "-", "r", "o", "o", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Ah", ",", "\u2581the", "\u2581", "o", "l", "'", "\u2581red", "d", "it", "\u2581skin", "-", "a", "-", "r", "o", "o", "!", "</s>"], "target_sentence": ["\u2581[", "\u2581Ah", ",", "\u2581the", "\u2581", "o", "l", "'", "<m>", "<m>", "\u2581red", "d", "it", "</m>", "</m>", "\u2581skin", "-", "a", "-", "r", "o", "o", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_196", "sentence": ["\u2581Also", ",", "\u2581check", "\u2581the", "\u2581FIFA", "\u2581", "X", "I", "\u2581thread", "\u2581where", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581people", "\u2581were", "\u2581", "shi", "tting", "\u2581on", "\u2581him", "\u2581when", "\u2581", "he", "\u2581actually", "\u2581had", "\u2581", "a", "\u2581fantastic", "\u25812016", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Also", ",", "\u2581check", "\u2581the", "\u2581FIFA", "\u2581", "X", "I", "\u2581thread", "\u2581where", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581people", "\u2581were", "\u2581", "shi", "tting", "\u2581on", "\u2581him", "\u2581when", "\u2581", "he", "\u2581actually", "\u2581had", "\u2581", "a", "\u2581fantastic", "\u25812016", "</s>"], "target_sentence": ["\u2581Also", ",", "\u2581check", "\u2581the", "<m>", "<m>", "\u2581FIFA", "</m>", "\u2581", "X", "I", "</m>", "\u2581thread", "\u2581where", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581people", "\u2581were", "\u2581", "shi", "tting", "\u2581on", "\u2581him", "\u2581when", "\u2581", "he", "\u2581actually", "\u2581had", "\u2581", "a", "\u2581fantastic", "\u25812016", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, 17, 18, 19, 20, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, 1, -1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_197", "sentence": ["\u2581Will", "\u2581you", "\u2581critic", "ize", "\u2581Trump", "\u2581when", "\u2581", "he", "\u2581makes", "\u2581mistakes", "\u2581or", "\u2581will", "\u2581you", "\u2581be", "\u2581silent", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Will", "\u2581you", "\u2581critic", "ize", "\u2581Trump", "\u2581when", "\u2581", "he", "\u2581makes", "\u2581mistakes", "\u2581or", "\u2581will", "\u2581you", "\u2581be", "\u2581silent", "</s>"], "target_sentence": ["\u2581Will", "\u2581you", "\u2581critic", "ize", "<m>", "\u2581Trump", "</m>", "\u2581when", "\u2581", "he", "\u2581makes", "\u2581mistakes", "\u2581or", "\u2581will", "\u2581you", "\u2581be", "\u2581silent", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_198", "sentence": ["\u2581On", "\u2581Red", "d", "it", ",", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581people", "\u2581care", "\u2581as", "\u2581much", "\u2581as", "\u2581they", "\u2581think", "\u2581they", "\u2581do", "\u2581regarding", "\u2581minor", "ities", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581On", "\u2581Red", "d", "it", ",", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581people", "\u2581care", "\u2581as", "\u2581much", "\u2581as", "\u2581they", "\u2581think", "\u2581they", "\u2581do", "\u2581regarding", "\u2581minor", "ities", ".", "</s>"], "target_sentence": ["\u2581On", "<m>", "<m>", "\u2581Red", "d", "it", "</m>", "</m>", ",", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581people", "\u2581care", "\u2581as", "\u2581much", "\u2581as", "\u2581they", "\u2581think", "\u2581they", "\u2581do", "\u2581regarding", "\u2581minor", "ities", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_199", "sentence": ["\u2581It", "\u2581came", "\u2581into", "\u2581effect", "\u2581on", "\u2581the", "\u258130", "\u2581", "th", "\u2581of", "\u2581December", "\u25812016", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "\u2581came", "\u2581into", "\u2581effect", "\u2581on", "\u2581the", "\u258130", "\u2581", "th", "\u2581of", "\u2581December", "\u25812016", ".", "</s>"], "target_sentence": ["\u2581It", "\u2581came", "\u2581into", "\u2581effect", "\u2581on", "\u2581the", "\u258130", "\u2581", "th", "\u2581of", "\u2581December", "\u25812016", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_200", "sentence": ["\u2581More", "\u2581at", "\u2581https", "://", "www", ".", "f", "lick", "r", ".", "com", "/", "photo", "s", "/", "100", "28", "97", "69", "@", "N", "08", "/", "album", "s", "/", "72", "157", "67", "58", "63", "39", "260", "4", "/", "with", "/", "32", "39", "57", "69", "75", "1/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581More", "\u2581at", "\u2581https", "://", "www", ".", "f", "lick", "r", ".", "com", "/", "photo", "s", "/", "100", "28", "97", "69", "@", "N", "08", "/", "album", "s", "/", "72", "157", "67", "58", "63", "39", "260", "4", "/", "with", "/", "32", "39", "57", "69", "75", "1/", "</s>"], "target_sentence": ["\u2581More", "\u2581at", "\u2581https", "://", "www", ".", "f", "lick", "r", ".", "com", "/", "photo", "s", "/", "100", "28", "97", "69", "@", "N", "08", "/", "album", "s", "/", "72", "157", "67", "58", "63", "39", "260", "4", "/", "with", "/", "32", "39", "57", "69", "75", "1/", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_201", "sentence": ["\u2581", "EDIT", ":", "\u2581He", "h", "\u2581guess", "\u2581who", "\u2581is", "\u2581already", "\u2581at", "\u2581", "-", "\u25812", "\u2581in", "\u25815", "\u2581minutes", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "EDIT", ":", "\u2581He", "h", "\u2581guess", "\u2581who", "\u2581is", "\u2581already", "\u2581at", "\u2581", "-", "\u25812", "\u2581in", "\u25815", "\u2581minutes", ".", "</s>"], "target_sentence": ["\u2581", "EDIT", ":", "\u2581He", "h", "\u2581guess", "\u2581who", "\u2581is", "\u2581already", "\u2581at", "\u2581", "-", "\u25812", "\u2581in", "\u25815", "\u2581minutes", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_202", "sentence": ["\u2581[", "\u2581I", "\u2581know", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "7", "a", "we", "/", "whi", "le", "_", "the", "_", "rest", "_", "of", "_", "red", "d", "it", "_", "is", "_", "col", "lap", "s", "ing", "_", "in", "/", "d", "c", "p", "1", "n", "1", "x", "/", ")", "\u2581Part", "\u2581of", "\u2581the", "\u2581problem", "\u2581is", "\u2581my", "\u2581brief", "\u2581ski", "m", "\u2581meant", "\u2581that", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581notice", "\u2581they", "\u2581had", "\u2581it", "\u2581because", ",", "\u2581like", "\u2581Italy", ",", "\u2581they", "\u2581called", "\u2581it", "\u2581something", "\u2581else", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581I", "\u2581know", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "7", "a", "we", "/", "whi", "le", "_", "the", "_", "rest", "_", "of", "_", "red", "d", "it", "_", "is", "_", "col", "lap", "s", "ing", "_", "in", "/", "d", "c", "p", "1", "n", "1", "x", "/", ")", "\u2581Part", "\u2581of", "\u2581the", "\u2581problem", "\u2581is", "\u2581my", "\u2581brief", "\u2581ski", "m", "\u2581meant", "\u2581that", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581notice", "\u2581they", "\u2581had", "\u2581it", "\u2581because", ",", "\u2581like", "\u2581Italy", ",", "\u2581they", "\u2581called", "\u2581it", "\u2581something", "\u2581else", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581I", "\u2581know", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "7", "a", "we", "/", "whi", "le", "_", "the", "_", "rest", "_", "of", "_", "red", "d", "it", "_", "is", "_", "col", "lap", "s", "ing", "_", "in", "/", "d", "c", "p", "1", "n", "1", "x", "/", ")", "\u2581Part", "\u2581of", "\u2581the", "\u2581problem", "\u2581is", "\u2581my", "\u2581brief", "\u2581ski", "m", "\u2581meant", "\u2581that", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581notice", "\u2581they", "\u2581had", "\u2581it", "\u2581because", ",", "\u2581like", "<m>", "\u2581Italy", "</m>", ",", "\u2581they", "\u2581called", "\u2581it", "\u2581something", "\u2581else", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_203", "sentence": ["\u2581[", "\u2581Credit", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "y", "lbs", "0", "/", "two", "_", "r", "s", "out", "ha", "f", "ric", "a", "_", "user", "s", "_", "lose", "_", "t", "heir", "_", "s", "hit", "_", "over", "_", "a", "/", "der", "8", "p", "ky", "/", "?", "con", "text", "=", "100", "00", ")", "\u2581to", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581uncle", "\u2581", "_", "\u2581retard", "o", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Credit", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "y", "lbs", "0", "/", "two", "_", "r", "s", "out", "ha", "f", "ric", "a", "_", "user", "s", "_", "lose", "_", "t", "heir", "_", "s", "hit", "_", "over", "_", "a", "/", "der", "8", "p", "ky", "/", "?", "con", "text", "=", "100", "00", ")", "\u2581to", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581uncle", "\u2581", "_", "\u2581retard", "o", "</s>"], "target_sentence": ["\u2581[", "\u2581Credit", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "y", "lbs", "0", "/", "two", "_", "r", "s", "out", "ha", "f", "ric", "a", "_", "user", "s", "_", "lose", "_", "t", "heir", "_", "s", "hit", "_", "over", "_", "a", "/", "der", "8", "p", "ky", "/", "?", "con", "text", "=", "100", "00", ")", "\u2581to", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581uncle", "\u2581", "_", "\u2581retard", "o", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 7, 7, 8, 8, 9, 9, 10, 11, 11, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_204", "sentence": ["\u2581For", "\u2581more", "\u2581info", "\u2581about", "\u2581this", "\u2581and", "\u2581local", "\u2581views", "\u2581on", "\u2581the", "\u2581matter", "\u2581check", "\u2581out", "\u2581where", "\u2581", "OP", "\u2581took", "\u2581this", "\u2581from", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581For", "\u2581more", "\u2581info", "\u2581about", "\u2581this", "\u2581and", "\u2581local", "\u2581views", "\u2581on", "\u2581the", "\u2581matter", "\u2581check", "\u2581out", "\u2581where", "\u2581", "OP", "\u2581took", "\u2581this", "\u2581from", ".", "</s>"], "target_sentence": ["\u2581For", "\u2581more", "\u2581info", "\u2581about", "\u2581this", "\u2581and", "<m>", "\u2581local", "\u2581views", "</m>", "\u2581on", "\u2581the", "\u2581matter", "\u2581check", "\u2581out", "\u2581where", "\u2581", "OP", "\u2581took", "\u2581this", "\u2581from", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_205", "sentence": ["\u2581Edit", ":", "\u2581Because", "\u2581", "OP", "'", "\u2581", "s", "\u2581kindness", "\u2581and", "\u2581interest", "\u2581in", "\u2581accommodating", "\u2581other", "\u2581people", "\u2581might", "\u2581rub", "\u2581off", "\u2581on", "\u2581the", "\u2581entitled", "\u2581", "p", "rick", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Edit", ":", "\u2581Because", "\u2581", "OP", "'", "\u2581", "s", "\u2581kindness", "\u2581and", "\u2581interest", "\u2581in", "\u2581accommodating", "\u2581other", "\u2581people", "\u2581might", "\u2581rub", "\u2581off", "\u2581on", "\u2581the", "\u2581entitled", "\u2581", "p", "rick", ".", "</s>"], "target_sentence": ["\u2581Edit", ":", "\u2581Because", "\u2581", "OP", "'", "\u2581", "s", "\u2581kindness", "\u2581and", "\u2581interest", "\u2581in", "\u2581accommodating", "\u2581other", "\u2581people", "\u2581might", "\u2581rub", "\u2581off", "\u2581on", "\u2581the", "\u2581entitled", "\u2581", "p", "rick", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_206", "sentence": ["\u2581There", "\u2581is", "\u2581[", "\u2581literally", "\u2581", "a", "\u2581Mis", "e", "s", "\u2581quote", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ca", "nada", "/", "com", "ments", "/5", "o", "j", "c", "65", "/", "van", "guard", "_", "say", "s", "_", "bank", "_", "of", "_", "ca", "nada", "_", "will", "_", "hik", "e", "_", "rate", "s", "_", "this", "/", "d", "ck", "h", "g", "n", "5", "/", ")", "\u2581in", "\u2581the", "\u2581thread", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581There", "\u2581is", "\u2581[", "\u2581literally", "\u2581", "a", "\u2581Mis", "e", "s", "\u2581quote", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ca", "nada", "/", "com", "ments", "/5", "o", "j", "c", "65", "/", "van", "guard", "_", "say", "s", "_", "bank", "_", "of", "_", "ca", "nada", "_", "will", "_", "hik", "e", "_", "rate", "s", "_", "this", "/", "d", "ck", "h", "g", "n", "5", "/", ")", "\u2581in", "\u2581the", "\u2581thread", ".", "</s>"], "target_sentence": ["\u2581There", "\u2581is", "\u2581[", "\u2581literally", "\u2581", "a", "\u2581Mis", "e", "s", "\u2581quote", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ca", "nada", "/", "com", "ments", "/5", "o", "j", "c", "65", "/", "van", "guard", "_", "say", "s", "_", "bank", "_", "of", "_", "ca", "nada", "_", "will", "_", "hik", "e", "_", "rate", "s", "_", "this", "/", "d", "ck", "h", "g", "n", "5", "/", ")", "\u2581in", "\u2581the", "\u2581thread", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_207", "sentence": ["\u2581I", "s", "\u2581doch", "\u2581", "e", "h", "\u2581nur", "\u2581hei\u00df", "e", "\u2581Luft", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581doch", "\u2581", "e", "h", "\u2581nur", "\u2581hei\u00df", "e", "\u2581Luft", ".", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581doch", "\u2581", "e", "h", "\u2581nur", "\u2581hei\u00df", "e", "\u2581Luft", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_208", "sentence": ["\u2581@", "\u2581Mar", "ont", "i", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Mar", "ont", "i", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Mar", "ont", "i", "</m>", "</s>"], "subtoken_map": [0, 1, 1, 1, 2], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_209", "sentence": ["\u2581Hi", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hi", ".", "</s>"], "target_sentence": ["\u2581Hi", ".", "</s>"], "subtoken_map": [0, 1, 2], "ent_type_sequence": [-1, -1, -1], "ent_indices": [-1, -1, -1]}, {"doc_id": "emerging.test_210", "sentence": ["\u2581FY", "I", "\u2581about", "\u2581", "a", "\u2581month", "\u2581ago", "\u2581there", "\u2581was", "\u2581", "a", "\u2581post", "\u2581about", "\u2581general", "\u2581info", "\u2581on", "\u2581protection", "\u2581orders", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581FY", "I", "\u2581about", "\u2581", "a", "\u2581month", "\u2581ago", "\u2581there", "\u2581was", "\u2581", "a", "\u2581post", "\u2581about", "\u2581general", "\u2581info", "\u2581on", "\u2581protection", "\u2581orders", ":", "</s>"], "target_sentence": ["\u2581FY", "I", "\u2581about", "\u2581", "a", "\u2581month", "\u2581ago", "\u2581there", "\u2581was", "\u2581", "a", "\u2581post", "\u2581about", "\u2581general", "\u2581info", "\u2581on", "\u2581protection", "\u2581orders", ":", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_211", "sentence": ["\u2581[", "\u2581Live", "\u2581Goal", "\u2581+", "\u2581Re", "play", "s", "\u2581", "-", "\u2581", "AA", "\u2581Mirror", "\u2581HD", "]", "\u2581(", "\u2581https", "://", "stream", "able", ".", "com", "/", "q", "l", "w", "o", "q", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Live", "\u2581Goal", "\u2581+", "\u2581Re", "play", "s", "\u2581", "-", "\u2581", "AA", "\u2581Mirror", "\u2581HD", "]", "\u2581(", "\u2581https", "://", "stream", "able", ".", "com", "/", "q", "l", "w", "o", "q", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581Live", "\u2581Goal", "\u2581+", "\u2581Re", "play", "s", "\u2581", "-", "<m>", "\u2581", "AA", "</m>", "\u2581Mirror", "\u2581HD", "]", "\u2581(", "\u2581https", "://", "stream", "able", ".", "com", "/", "q", "l", "w", "o", "q", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5, 5, 6, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_212", "sentence": ["\u2581[", "\u2581", "AA", "\u2581Mirror", "\u2581Re", "play", "s", "\u2581HD", "\u2581", "-", "\u2581Mix", "tap", "e", "]", "\u2581(", "\u2581https", "://", "my", ".", "mix", "tap", "e", ".", "m", "o", "e", "/", "i", "v", "w", "b", "f", "d", ".", "mp", "4", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "AA", "\u2581Mirror", "\u2581Re", "play", "s", "\u2581HD", "\u2581", "-", "\u2581Mix", "tap", "e", "]", "\u2581(", "\u2581https", "://", "my", ".", "mix", "tap", "e", ".", "m", "o", "e", "/", "i", "v", "w", "b", "f", "d", ".", "mp", "4", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581", "AA", "\u2581Mirror", "\u2581Re", "play", "s", "\u2581HD", "\u2581", "-", "\u2581Mix", "tap", "e", "]", "\u2581(", "\u2581https", "://", "my", ".", "mix", "tap", "e", ".", "m", "o", "e", "/", "i", "v", "w", "b", "f", "d", ".", "mp", "4", ")", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 4, 5, 5, 6, 6, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_213", "sentence": ["\u2581one", "\u2581of", "\u2581the", "\u2581[", "\u2581top", "\u2581posts", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "h", "lub", "/", "world", "_", "cup", "_", "2002", "_", "im", "_", "still", "_", "standing", "/", "?", "u", "t", "m", "_", "content", "=", "title", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "hot", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "s", "occ", "er", ")", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581right", "\u2581now", "\u2581is", "\u2581about", "\u2581who", "\u2581is", "\u2581still", "\u2581playing", "\u2581from", "\u2581the", "\u25812002", "\u2581World", "\u2581Cup", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581one", "\u2581of", "\u2581the", "\u2581[", "\u2581top", "\u2581posts", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "h", "lub", "/", "world", "_", "cup", "_", "2002", "_", "im", "_", "still", "_", "standing", "/", "?", "u", "t", "m", "_", "content", "=", "title", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "hot", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "s", "occ", "er", ")", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581right", "\u2581now", "\u2581is", "\u2581about", "\u2581who", "\u2581is", "\u2581still", "\u2581playing", "\u2581from", "\u2581the", "\u25812002", "\u2581World", "\u2581Cup", ".", "</s>"], "target_sentence": ["\u2581one", "\u2581of", "\u2581the", "\u2581[", "\u2581top", "\u2581posts", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "q", "h", "lub", "/", "world", "_", "cup", "_", "2002", "_", "im", "_", "still", "_", "standing", "/", "?", "u", "t", "m", "_", "content", "=", "title", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "hot", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "s", "occ", "er", ")", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581right", "\u2581now", "\u2581is", "\u2581about", "\u2581who", "\u2581is", "\u2581still", "\u2581playing", "\u2581from", "\u2581the", "\u25812002", "\u2581World", "\u2581Cup", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 11, 11, 12, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_214", "sentence": ["\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581Ireland", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", ")", "\u2581", "-", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581Iceland", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "I", "cel", "and", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581Ireland", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", ")", "\u2581", "-", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581Iceland", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "I", "cel", "and", "/", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "<m>", "\u2581Ireland", "</m>", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", ")", "\u2581", "-", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581Iceland", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "I", "cel", "and", "/", ")", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 9, 10, 10, 11, 11, 11, 12, 13, 14, 14, 15, 15, 16, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_215", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581British", "\u2581man", "\u2581die", "s", "\u2581working", "\u2581on", "\u2581Qatar", "\u258120", "22", "\u2581World", "\u2581Cup", "\u2581stadium", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581British", "\u2581man", "\u2581die", "s", "\u2581working", "\u2581on", "\u2581Qatar", "\u258120", "22", "\u2581World", "\u2581Cup", "\u2581stadium", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581British", "\u2581man", "\u2581die", "s", "\u2581working", "\u2581on", "<m>", "\u2581Qatar", "</m>", "\u258120", "22", "\u2581World", "\u2581Cup", "\u2581stadium", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_216", "sentence": ["\u2581[", "\u2581I", "\u2581just", "\u2581think", "\u2581Trump", "\u2581is", "\u2581better", "\u2581than", "\u2581Hillary", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "m", "im", "c", "4", "/", "ca", "nada", "_", "j", "udge", "_", "s", "us", "p", "ended", "_", "for", "_", "wear", "ing", "_", "tru", "mp", "_", "cap", "_", "in", "/", "d", "c", "4", "o", "8", "v", "0", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "user", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "front", "page", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581I", "\u2581just", "\u2581think", "\u2581Trump", "\u2581is", "\u2581better", "\u2581than", "\u2581Hillary", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "m", "im", "c", "4", "/", "ca", "nada", "_", "j", "udge", "_", "s", "us", "p", "ended", "_", "for", "_", "wear", "ing", "_", "tru", "mp", "_", "cap", "_", "in", "/", "d", "c", "4", "o", "8", "v", "0", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "user", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "front", "page", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581I", "\u2581just", "\u2581think", "<m>", "\u2581Trump", "</m>", "\u2581is", "\u2581better", "\u2581than", "<m>", "\u2581Hillary", "</m>", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "m", "im", "c", "4", "/", "ca", "nada", "_", "j", "udge", "_", "s", "us", "p", "ended", "_", "for", "_", "wear", "ing", "_", "tru", "mp", "_", "cap", "_", "in", "/", "d", "c", "4", "o", "8", "v", "0", "/", "?", "u", "t", "m", "_", "content", "=", "permalink", "&", "amp", ";", "u", "t", "m", "_", "medi", "um", "=", "user", "&", "amp", ";", "u", "t", "m", "_", "source", "=", "red", "d", "it", "&", "amp", ";", "u", "t", "m", "_", "name", "=", "front", "page", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, 0, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_217", "sentence": ["\u2581Also", ",", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581forget", "\u2581[", "\u2581drinks", "\u2581this", "\u2581Friday", "\u2581at", "\u2581Kelly", "'", "\u2581", "s", "\u2581in", "\u2581New", "town", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "z", "1", "a", "h", "m", "/", "s", "t", "_", "pat", "rick", "s", "_", "day", "_", "d", "rink", "s", "_", "kel", "ly", "s", "_", "on", "_", "king", "_", "new", "town", "/", "?", "s", "t", "=", "j", "0", "98", "cho", "s", "&", "amp", ";", "s", "h", "=", "f", "6", "39", "80", "b", "5", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Also", ",", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581forget", "\u2581[", "\u2581drinks", "\u2581this", "\u2581Friday", "\u2581at", "\u2581Kelly", "'", "\u2581", "s", "\u2581in", "\u2581New", "town", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "z", "1", "a", "h", "m", "/", "s", "t", "_", "pat", "rick", "s", "_", "day", "_", "d", "rink", "s", "_", "kel", "ly", "s", "_", "on", "_", "king", "_", "new", "town", "/", "?", "s", "t", "=", "j", "0", "98", "cho", "s", "&", "amp", ";", "s", "h", "=", "f", "6", "39", "80", "b", "5", ")", "</s>"], "target_sentence": ["\u2581Also", ",", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581forget", "\u2581[", "\u2581drinks", "\u2581this", "\u2581Friday", "\u2581at", "<m>", "<m>", "\u2581Kelly", "</m>", "</m>", "'", "\u2581", "s", "\u2581in", "<m>", "\u2581New", "town", "</m>", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "z", "1", "a", "h", "m", "/", "s", "t", "_", "pat", "rick", "s", "_", "day", "_", "d", "rink", "s", "_", "kel", "ly", "s", "_", "on", "_", "king", "_", "new", "town", "/", "?", "s", "t", "=", "j", "0", "98", "cho", "s", "&", "amp", ";", "s", "h", "=", "f", "6", "39", "80", "b", "5", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, -1, -1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_218", "sentence": ["\u2581How", "\u2581do", "\u2581you", "\u2581know", "\u2581your", "\u2581RO", "Z", "\u2581post", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581be", "\u2581removed", "\u2581for", "\u2581editorial", "ising", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581do", "\u2581you", "\u2581know", "\u2581your", "\u2581RO", "Z", "\u2581post", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581be", "\u2581removed", "\u2581for", "\u2581editorial", "ising", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581do", "\u2581you", "\u2581know", "\u2581your", "<m>", "\u2581RO", "Z", "</m>", "\u2581post", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581be", "\u2581removed", "\u2581for", "\u2581editorial", "ising", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_219", "sentence": ["\u2581[", "\u2581Ha", "ha", ",", "\u2581because", "\u2581", "he", "\u2581deserves", "\u2581it", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "sport", "s", "/", "com", "ments", "/5", "m", "14", "q", "m", "/", "to", "day", "_", "mark", "s", "_", "the", "_", "10", "th", "_", "anni", "vers", "ary", "_", "of", "_", "one", "_", "of", "_", "the", "/", "d", "c", "0", "m", "5", "b", "a", "/", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Ha", "ha", ",", "\u2581because", "\u2581", "he", "\u2581deserves", "\u2581it", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "sport", "s", "/", "com", "ments", "/5", "m", "14", "q", "m", "/", "to", "day", "_", "mark", "s", "_", "the", "_", "10", "th", "_", "anni", "vers", "ary", "_", "of", "_", "one", "_", "of", "_", "the", "/", "d", "c", "0", "m", "5", "b", "a", "/", ")", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581Ha", "ha", ",", "\u2581because", "\u2581", "he", "\u2581deserves", "\u2581it", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "sport", "s", "/", "com", "ments", "/5", "m", "14", "q", "m", "/", "to", "day", "_", "mark", "s", "_", "the", "_", "10", "th", "_", "anni", "vers", "ary", "_", "of", "_", "one", "_", "of", "_", "the", "/", "d", "c", "0", "m", "5", "b", "a", "/", ")", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_220", "sentence": ["\u2581He", "h", ",", "\u2581it", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581go", "\u2581down", "\u2581[", "\u2581well", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "o", "7", "y", "r", "4", "/", "hey", "_", "gu", "y", "s", "_", "im", "_", "try", "ing", "_", "to", "_", "collect", "_", "photo", "s", "_", "of", "_", "people", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581He", "h", ",", "\u2581it", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581go", "\u2581down", "\u2581[", "\u2581well", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "o", "7", "y", "r", "4", "/", "hey", "_", "gu", "y", "s", "_", "im", "_", "try", "ing", "_", "to", "_", "collect", "_", "photo", "s", "_", "of", "_", "people", "/", ")", "</s>"], "target_sentence": ["\u2581He", "h", ",", "\u2581it", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581go", "\u2581down", "\u2581[", "\u2581well", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "out", "ha", "f", "ric", "a", "/", "com", "ments", "/5", "o", "7", "y", "r", "4", "/", "hey", "_", "gu", "y", "s", "_", "im", "_", "try", "ing", "_", "to", "_", "collect", "_", "photo", "s", "_", "of", "_", "people", "/", ")", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_221", "sentence": ["\u2581[", "\u2581A", "a", "h", ",", "\u2581the", "\u2581old", "\u2581Red", "d", "it", "\u2581death", "ar", "o", "o", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "m", "9", "m", "am", "/", "ki", "a", "_", "or", "a", "_", "r", "bra", "s", "il", "_", "cultural", "_", "ex", "change", "_", "with", "_", "r", "bra", "s", "il", "/", "d", "c", "3", "d", "g", "in", "/", "?", "con", "text", "=", "3", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581A", "a", "h", ",", "\u2581the", "\u2581old", "\u2581Red", "d", "it", "\u2581death", "ar", "o", "o", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "m", "9", "m", "am", "/", "ki", "a", "_", "or", "a", "_", "r", "bra", "s", "il", "_", "cultural", "_", "ex", "change", "_", "with", "_", "r", "bra", "s", "il", "/", "d", "c", "3", "d", "g", "in", "/", "?", "con", "text", "=", "3", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581A", "a", "h", ",", "\u2581the", "\u2581old", "\u2581Red", "d", "it", "\u2581death", "ar", "o", "o", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "m", "9", "m", "am", "/", "ki", "a", "_", "or", "a", "_", "r", "bra", "s", "il", "_", "cultural", "_", "ex", "change", "_", "with", "_", "r", "bra", "s", "il", "/", "d", "c", "3", "d", "g", "in", "/", "?", "con", "text", "=", "3", ")", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 5, 5, 6, 6, 6, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_222", "sentence": ["\u2581I", "\u2581could", "\u2581only", "\u2581find", "\u2581this", "\u2581Red", "d", "it", "\u2581thread", "\u2581with", "\u2581the", "\u2581most", "\u2581comments", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/4", "ky", "y", "l", "o", "/", "white", "_", "high", "_", "school", "_", "foot", "ball", "_", "player", "s", "_", "in", "_", "i", "d", "a", "h", "o", "/", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581could", "\u2581only", "\u2581find", "\u2581this", "\u2581Red", "d", "it", "\u2581thread", "\u2581with", "\u2581the", "\u2581most", "\u2581comments", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/4", "ky", "y", "l", "o", "/", "white", "_", "high", "_", "school", "_", "foot", "ball", "_", "player", "s", "_", "in", "_", "i", "d", "a", "h", "o", "/", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581could", "\u2581only", "\u2581find", "\u2581this", "<m>", "\u2581Red", "d", "it", "</m>", "\u2581thread", "\u2581with", "\u2581the", "\u2581most", "\u2581comments", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/4", "ky", "y", "l", "o", "/", "white", "_", "high", "_", "school", "_", "foot", "ball", "_", "player", "s", "_", "in", "_", "i", "d", "a", "h", "o", "/", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_223", "sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581Thor", "vir", "d", "h", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581Thor", "vir", "d", "h", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581Thor", "vir", "d", "h", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_224", "sentence": ["\u2581Search", "ing", ".", ".", ".", "\u2581searching", ".", ".", ".", "\u2581No", "pe", ",", "\u2581not", "\u2581an", "\u2581argument", "\u2581in", "\u2581sight", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Search", "ing", ".", ".", ".", "\u2581searching", ".", ".", ".", "\u2581No", "pe", ",", "\u2581not", "\u2581an", "\u2581argument", "\u2581in", "\u2581sight", ".", "</s>"], "target_sentence": ["\u2581Search", "ing", ".", ".", ".", "\u2581searching", ".", ".", ".", "\u2581No", "pe", ",", "\u2581not", "\u2581an", "\u2581argument", "\u2581in", "\u2581sight", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_225", "sentence": ["\u2581See", "\u2581response", "\u2581from", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581im", "kat", "not", "cat", "\u2581[", "\u2581above", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "l", "7", "f", "8", "/", "why", "_", "d", "o", "_", "i", "_", "have", "_", "to", "_", "give", "_", "30", "_", "day", "s", "_", "not", "ice", "_", "to", "_", "mov", "e", "_", "is", "p", "s", "/", "d", "c", "s", "13", "je", "/", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581See", "\u2581response", "\u2581from", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581im", "kat", "not", "cat", "\u2581[", "\u2581above", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "l", "7", "f", "8", "/", "why", "_", "d", "o", "_", "i", "_", "have", "_", "to", "_", "give", "_", "30", "_", "day", "s", "_", "not", "ice", "_", "to", "_", "mov", "e", "_", "is", "p", "s", "/", "d", "c", "s", "13", "je", "/", ")", ".", "</s>"], "target_sentence": ["\u2581See", "\u2581response", "\u2581from", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581im", "kat", "not", "cat", "\u2581[", "\u2581above", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "p", "l", "7", "f", "8", "/", "why", "_", "d", "o", "_", "i", "_", "have", "_", "to", "_", "give", "_", "30", "_", "day", "s", "_", "not", "ice", "_", "to", "_", "mov", "e", "_", "is", "p", "s", "/", "d", "c", "s", "13", "je", "/", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 6, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_226", "sentence": ["\u2581They", "\u2581charged", "\u2581him", "\u2581douche", "bag", "ger", "y", ",", "\u2581and", "\u2581", "he", "\u2581[", "\u2581proved", "\u2581it", ",", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "sport", "s", "/", "com", "ments", "/5", "m", "r", "4", "w", "n", "/", "r", "o", "nnie", "_", "o", "s", "ul", "liv", "an", "_", "cle", "ar", "s", "_", "a", "_", "chal", "l", "en", "ging", "_", "table", "_", "after", "/", "d", "c", "5", "t", "r", "b", "m", "/", ")", "\u2581so", "\u2581they", "\u2581had", "\u2581to", "\u2581ST", "FU", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581They", "\u2581charged", "\u2581him", "\u2581douche", "bag", "ger", "y", ",", "\u2581and", "\u2581", "he", "\u2581[", "\u2581proved", "\u2581it", ",", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "sport", "s", "/", "com", "ments", "/5", "m", "r", "4", "w", "n", "/", "r", "o", "nnie", "_", "o", "s", "ul", "liv", "an", "_", "cle", "ar", "s", "_", "a", "_", "chal", "l", "en", "ging", "_", "table", "_", "after", "/", "d", "c", "5", "t", "r", "b", "m", "/", ")", "\u2581so", "\u2581they", "\u2581had", "\u2581to", "\u2581ST", "FU", ".", "</s>"], "target_sentence": ["\u2581They", "\u2581charged", "\u2581him", "\u2581douche", "bag", "ger", "y", ",", "\u2581and", "\u2581", "he", "\u2581[", "\u2581proved", "\u2581it", ",", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "sport", "s", "/", "com", "ments", "/5", "m", "r", "4", "w", "n", "/", "r", "o", "nnie", "_", "o", "s", "ul", "liv", "an", "_", "cle", "ar", "s", "_", "a", "_", "chal", "l", "en", "ging", "_", "table", "_", "after", "/", "d", "c", "5", "t", "r", "b", "m", "/", ")", "\u2581so", "\u2581they", "\u2581had", "\u2581to", "\u2581ST", "FU", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_227", "sentence": ["\u2581[", "\u2581Reference", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/3", "x", "c", "r", "j", "c", "/", "after", "_", "not", "_", "pass", "ing", "_", "r", "v", "p", "_", "a", "s", "k", "s", "_", "me", "mph", "is", "_", "d", "o", "_", "you", "_", "think", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Reference", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/3", "x", "c", "r", "j", "c", "/", "after", "_", "not", "_", "pass", "ing", "_", "r", "v", "p", "_", "a", "s", "k", "s", "_", "me", "mph", "is", "_", "d", "o", "_", "you", "_", "think", "/", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581Reference", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/3", "x", "c", "r", "j", "c", "/", "after", "_", "not", "_", "pass", "ing", "_", "r", "v", "p", "_", "a", "s", "k", "s", "_", "me", "mph", "is", "_", "d", "o", "_", "you", "_", "think", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_228", "sentence": ["\u2581The", "\u2581", "OP", "\u2581here", "\u2581deleted", "\u2581it", "\u2581(", "\u2581du", "n", "n", "o", "\u2581why", ")", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "n", "ner", "o", "/", "you", "_", "will", "_", "for", "ever", "_", "be", "_", "in", "_", "my", "_", "he", "art", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581", "OP", "\u2581here", "\u2581deleted", "\u2581it", "\u2581(", "\u2581du", "n", "n", "o", "\u2581why", ")", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "n", "ner", "o", "/", "you", "_", "will", "_", "for", "ever", "_", "be", "_", "in", "_", "my", "_", "he", "art", "/", "</s>"], "target_sentence": ["\u2581The", "\u2581", "OP", "\u2581here", "\u2581deleted", "\u2581it", "\u2581(", "\u2581du", "n", "n", "o", "\u2581why", ")", "\u2581", "-", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "n", "ner", "o", "/", "you", "_", "will", "_", "for", "ever", "_", "be", "_", "in", "_", "my", "_", "he", "art", "/", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_229", "sentence": ["\u2581Ob", "lig", "atory", "\u2581", "s", "pru", "i", "k", "\u2581for", "\u2581drinks", "\u2581Friday", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ob", "lig", "atory", "\u2581", "s", "pru", "i", "k", "\u2581for", "\u2581drinks", "\u2581Friday", "</s>"], "target_sentence": ["\u2581Ob", "lig", "atory", "\u2581", "s", "pru", "i", "k", "\u2581for", "\u2581drinks", "\u2581Friday", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 1, 1, 1, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_230", "sentence": ["\u2581[", "\u2581", "OP", "\u2581is", "\u2581", "a", "\u2581dirty", "\u2581", "k", "arma", "\u2581who", "ring", "\u2581bundle", "\u2581of", "\u2581sticks", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "v", "t", "a", "f", "1/", "_", "/", "de", "5", "j", "4", "t", "5", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "OP", "\u2581is", "\u2581", "a", "\u2581dirty", "\u2581", "k", "arma", "\u2581who", "ring", "\u2581bundle", "\u2581of", "\u2581sticks", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "v", "t", "a", "f", "1/", "_", "/", "de", "5", "j", "4", "t", "5", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581", "OP", "\u2581is", "\u2581", "a", "\u2581dirty", "\u2581", "k", "arma", "\u2581who", "ring", "\u2581bundle", "\u2581of", "\u2581sticks", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "v", "t", "a", "f", "1/", "_", "/", "de", "5", "j", "4", "t", "5", ")", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 5, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_231", "sentence": ["\u2581Ob", "lig", "atory", "\u2581link", "\u2581to", "\u2581[", "\u2581Old", "ies", "\u2581Night", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "x", "l", "59", "i", "/", "old", "ies", "_", "night", "_", "18", "_", "m", "arch", "_", "2017", "_", "b", "ava", "rian", "_", "b", "ier", "_", "ca", "f", "e", "/", ")", "\u2581next", "\u2581week", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ob", "lig", "atory", "\u2581link", "\u2581to", "\u2581[", "\u2581Old", "ies", "\u2581Night", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "x", "l", "59", "i", "/", "old", "ies", "_", "night", "_", "18", "_", "m", "arch", "_", "2017", "_", "b", "ava", "rian", "_", "b", "ier", "_", "ca", "f", "e", "/", ")", "\u2581next", "\u2581week", ".", "</s>"], "target_sentence": ["\u2581Ob", "lig", "atory", "\u2581link", "\u2581to", "\u2581[", "\u2581Old", "ies", "\u2581Night", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "x", "l", "59", "i", "/", "old", "ies", "_", "night", "_", "18", "_", "m", "arch", "_", "2017", "_", "b", "ava", "rian", "_", "b", "ier", "_", "ca", "f", "e", "/", ")", "\u2581next", "\u2581week", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_232", "sentence": ["\u2581They", "\u2581are", "\u2581having", "\u2581", "a", "\u2581field", "\u2581day", "\u2581over", "\u2581in", "\u2581News", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581They", "\u2581are", "\u2581having", "\u2581", "a", "\u2581field", "\u2581day", "\u2581over", "\u2581in", "\u2581News", ".", "</s>"], "target_sentence": ["\u2581They", "\u2581are", "\u2581having", "\u2581", "a", "\u2581field", "\u2581day", "\u2581over", "\u2581in", "\u2581News", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_233", "sentence": ["\u2581I", "\u2581want", "\u2581any", "team", "\u2581to", "\u2581win", "\u2581it", "\u2581except", "\u2581P", "SG", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581want", "\u2581any", "team", "\u2581to", "\u2581win", "\u2581it", "\u2581except", "\u2581P", "SG", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581want", "<m>", "\u2581any", "team", "\u2581to", "\u2581win", "</m>", "\u2581it", "\u2581except", "\u2581P", "SG", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_234", "sentence": ["\u2581See", "\u2581also", "\u2581[", "\u2581Will", "\u2581Ant", "\u00f3n", "i", "o", "\u2581Gut", "er", "re", "s", "\u2581be", "\u2581the", "\u2581UN", "'", "\u2581", "s", "\u2581best", "\u2581ever", "\u2581secretary", "\u2581general", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581See", "\u2581also", "\u2581[", "\u2581Will", "\u2581Ant", "\u00f3n", "i", "o", "\u2581Gut", "er", "re", "s", "\u2581be", "\u2581the", "\u2581UN", "'", "\u2581", "s", "\u2581best", "\u2581ever", "\u2581secretary", "\u2581general", "?", "</s>"], "target_sentence": ["\u2581See", "\u2581also", "\u2581[", "\u2581Will", "<m>", "\u2581Ant", "\u00f3n", "i", "o", "\u2581Gut", "er", "re", "s", "</m>", "\u2581be", "\u2581the", "\u2581UN", "'", "\u2581", "s", "\u2581best", "\u2581ever", "\u2581secretary", "\u2581general", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_235", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581Uber", ",", "\u2581but", "\u2581for", "\u2581", "chi", "nes", "e", "\u2581speaking", "\u2581folk", "\u2581only", "\u2581and", "\u2581its", "\u2581illegal", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581Uber", ",", "\u2581but", "\u2581for", "\u2581", "chi", "nes", "e", "\u2581speaking", "\u2581folk", "\u2581only", "\u2581and", "\u2581its", "\u2581illegal", ".", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "<m>", "<m>", "<m>", "\u2581Uber", "</m>", "</m>", "</m>", ",", "\u2581but", "\u2581for", "\u2581", "chi", "nes", "e", "\u2581speaking", "\u2581folk", "\u2581only", "\u2581and", "\u2581its", "\u2581illegal", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 2, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 2, 0, 1, -1, 2, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_236", "sentence": ["\u2581The", "\u2581media", "'", "\u2581", "s", "\u2581narrative", "\u2581was", "\u2581not", "\u2581that", "\u2581that", "\u2581extreme", "\u2581but", "\u2581it", "\u2581definitely", "\u2581was", "\u2581attacking", "\u2581Trump", "\u2581and", "\u2581his", "\u2581supporters", "\u2581pretty", "\u2581much", "\u2581non", "-", "\u2581stop", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581media", "'", "\u2581", "s", "\u2581narrative", "\u2581was", "\u2581not", "\u2581that", "\u2581that", "\u2581extreme", "\u2581but", "\u2581it", "\u2581definitely", "\u2581was", "\u2581attacking", "\u2581Trump", "\u2581and", "\u2581his", "\u2581supporters", "\u2581pretty", "\u2581much", "\u2581non", "-", "\u2581stop", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581media", "'", "\u2581", "s", "\u2581narrative", "\u2581was", "\u2581not", "\u2581that", "\u2581that", "\u2581extreme", "\u2581but", "\u2581it", "\u2581definitely", "\u2581was", "\u2581attacking", "<m>", "\u2581Trump", "</m>", "\u2581and", "\u2581his", "\u2581supporters", "\u2581pretty", "\u2581much", "\u2581non", "-", "\u2581stop", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_237", "sentence": ["\u2581That", "\u2581seems", "\u2581like", "\u2581something", "\u2581someone", "\u2581who", "\u2581", "supposedly", "\u2581[", "\u2581works", "\u2581in", "\u2581Sand", "r", "ingham", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "k", "7", "nd", "n", "/", "the", "_", "que", "en", "_", "has", "_", "pass", "e", "d", "_", "away", "_", "and", "_", "the", "_", "news", "_", "is", "_", "being", "/", "d", "b", "l", "x", "u", "0", "p", "/", ")", "\u2581would", "\u2581know", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581That", "\u2581seems", "\u2581like", "\u2581something", "\u2581someone", "\u2581who", "\u2581", "supposedly", "\u2581[", "\u2581works", "\u2581in", "\u2581Sand", "r", "ingham", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "k", "7", "nd", "n", "/", "the", "_", "que", "en", "_", "has", "_", "pass", "e", "d", "_", "away", "_", "and", "_", "the", "_", "news", "_", "is", "_", "being", "/", "d", "b", "l", "x", "u", "0", "p", "/", ")", "\u2581would", "\u2581know", ".", "</s>"], "target_sentence": ["\u2581That", "\u2581seems", "\u2581like", "\u2581something", "\u2581someone", "\u2581who", "\u2581", "supposedly", "\u2581[", "\u2581works", "\u2581in", "<m>", "\u2581Sand", "r", "ingham", "</m>", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "unit", "e", "d", "king", "dom", "/", "com", "ments", "/5", "k", "7", "nd", "n", "/", "the", "_", "que", "en", "_", "has", "_", "pass", "e", "d", "_", "away", "_", "and", "_", "the", "_", "news", "_", "is", "_", "being", "/", "d", "b", "l", "x", "u", "0", "p", "/", ")", "\u2581would", "\u2581know", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_238", "sentence": ["\u2581This", "\u2581is", "\u2581", "a", "\u2581post", "\u2581I", "\u2581made", "\u2581in", "\u2581December", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581is", "\u2581", "a", "\u2581post", "\u2581I", "\u2581made", "\u2581in", "\u2581December", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581is", "\u2581", "a", "\u2581post", "\u2581I", "\u2581made", "\u2581in", "\u2581December", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_239", "sentence": ["\u2581It", "\u2581was", "\u2581removed", "\u2581within", "\u25812", "\u2581minutes", ",", "\u2581flag", "ged", "\u2581as", "\u2581\"", "\u2581Off", "-", "topic", "\u2581\"", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "\u2581was", "\u2581removed", "\u2581within", "\u25812", "\u2581minutes", ",", "\u2581flag", "ged", "\u2581as", "\u2581\"", "\u2581Off", "-", "topic", "\u2581\"", ".", "</s>"], "target_sentence": ["\u2581It", "\u2581was", "\u2581removed", "\u2581within", "\u25812", "\u2581minutes", ",", "\u2581flag", "ged", "\u2581as", "\u2581\"", "\u2581Off", "-", "topic", "\u2581\"", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_240", "sentence": ["\u2581Hey", ",", "\u2581", "whoever", "\u2581screen", "\u2581captured", "\u2581the", "\u2581page", "\u2581with", "\u2581the", "\u25816", "\u2581months", "\u2581listed", "\u2581want", "\u2581to", "\u2581link", "\u2581it", "\u2581again", "\u2581for", "\u2581the", "\u2581people", "\u2581who", "\u2581are", "\u2581going", "\u2581to", "\u2581get", "\u2581owned", "\u2581in", "\u2581the", "\u2581coming", "\u2581months", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hey", ",", "\u2581", "whoever", "\u2581screen", "\u2581captured", "\u2581the", "\u2581page", "\u2581with", "\u2581the", "\u25816", "\u2581months", "\u2581listed", "\u2581want", "\u2581to", "\u2581link", "\u2581it", "\u2581again", "\u2581for", "\u2581the", "\u2581people", "\u2581who", "\u2581are", "\u2581going", "\u2581to", "\u2581get", "\u2581owned", "\u2581in", "\u2581the", "\u2581coming", "\u2581months", "?", "</s>"], "target_sentence": ["\u2581Hey", ",", "\u2581", "whoever", "\u2581screen", "\u2581captured", "\u2581the", "\u2581page", "\u2581with", "\u2581the", "\u25816", "\u2581months", "\u2581listed", "\u2581want", "\u2581to", "\u2581link", "\u2581it", "\u2581again", "\u2581for", "\u2581the", "\u2581people", "\u2581who", "\u2581are", "\u2581going", "\u2581to", "\u2581get", "\u2581owned", "\u2581in", "\u2581the", "\u2581coming", "\u2581months", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_241", "sentence": ["\u2581[", "\u2581World", "news", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "search", "?", "q", "=", "T", "ur", "key", "+", "N", "ight", "club", "&", "amp", ";", "re", "strict", "_", "s", "r", "=", "on", "&", "amp", ";", "sort", "=", "re", "lev", "ance", "&", "amp", ";", "t", "=", "all", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581World", "news", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "search", "?", "q", "=", "T", "ur", "key", "+", "N", "ight", "club", "&", "amp", ";", "re", "strict", "_", "s", "r", "=", "on", "&", "amp", ";", "sort", "=", "re", "lev", "ance", "&", "amp", ";", "t", "=", "all", ")", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581World", "news", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "search", "?", "q", "=", "T", "ur", "key", "+", "N", "ight", "club", "&", "amp", ";", "re", "strict", "_", "s", "r", "=", "on", "&", "amp", ";", "sort", "=", "re", "lev", "ance", "&", "amp", ";", "t", "=", "all", ")", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_242", "sentence": ["\u2581Hi", "\u2581there", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581Mo", "-", "bot", ",", "\u2581the", "\u2581actual", "\u2581", "AMA", "\u2581[", "\u2581can", "\u2581be", "\u2581found", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "q", "10", "g", "c", "/", "a", "s", "k", "_", "me", "_", "any", "thing", "_", "act", "_", "leader", "_", "d", "a", "vid", "_", "s", "e", "y", "m", "our", "/", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hi", "\u2581there", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581Mo", "-", "bot", ",", "\u2581the", "\u2581actual", "\u2581", "AMA", "\u2581[", "\u2581can", "\u2581be", "\u2581found", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "q", "10", "g", "c", "/", "a", "s", "k", "_", "me", "_", "any", "thing", "_", "act", "_", "leader", "_", "d", "a", "vid", "_", "s", "e", "y", "m", "our", "/", ")", ".", "</s>"], "target_sentence": ["\u2581Hi", "\u2581there", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581Mo", "-", "bot", ",", "\u2581the", "\u2581actual", "\u2581", "AMA", "\u2581[", "\u2581can", "\u2581be", "\u2581found", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "q", "10", "g", "c", "/", "a", "s", "k", "_", "me", "_", "any", "thing", "_", "act", "_", "leader", "_", "d", "a", "vid", "_", "s", "e", "y", "m", "our", "/", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 5, 5, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_243", "sentence": ["\u2581", "AMA", "\u2581with", "\u2581the", "\u2581leader", "\u2581of", "\u2581the", "\u2581Conservative", "\u2581Party", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "AMA", "\u2581with", "\u2581the", "\u2581leader", "\u2581of", "\u2581the", "\u2581Conservative", "\u2581Party", ".", "</s>"], "target_sentence": ["\u2581", "AMA", "\u2581with", "\u2581the", "\u2581leader", "\u2581of", "\u2581the", "\u2581Conservative", "\u2581Party", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_244", "sentence": ["\u2581[", "\u2581Live", "\u2581in", "\u2581Dal", "hou", "sie", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "Cal", "gar", "y", "/", "com", "ments", "/5", "l", "g", "5", "b", "b", "/", "s", "now", "_", "ang", "els", "/", ")", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Live", "\u2581in", "\u2581Dal", "hou", "sie", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "Cal", "gar", "y", "/", "com", "ments", "/5", "l", "g", "5", "b", "b", "/", "s", "now", "_", "ang", "els", "/", ")", "?", "</s>"], "target_sentence": ["\u2581[", "\u2581Live", "\u2581in", "<m>", "\u2581Dal", "hou", "sie", "</m>", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "Cal", "gar", "y", "/", "com", "ments", "/5", "l", "g", "5", "b", "b", "/", "s", "now", "_", "ang", "els", "/", ")", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_245", "sentence": ["\u2581I", "\u2581was", "\u2581just", "\u2581looking", "\u2581at", "\u2581the", "\u2581way", "back", "\u2581machine", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "\u2581here", "'", "\u2581", "s", "\u2581the", "\u2581front", "\u2581page", "\u2581for", "\u2581September", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581was", "\u2581just", "\u2581looking", "\u2581at", "\u2581the", "\u2581way", "back", "\u2581machine", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "\u2581here", "'", "\u2581", "s", "\u2581the", "\u2581front", "\u2581page", "\u2581for", "\u2581September", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "</s>"], "target_sentence": ["\u2581I", "\u2581was", "\u2581just", "\u2581looking", "\u2581at", "\u2581the", "\u2581way", "back", "\u2581machine", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "\u2581here", "'", "\u2581", "s", "\u2581the", "\u2581front", "\u2581page", "\u2581for", "\u2581September", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 9, 10, 10, 11, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 24, 25, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_246", "sentence": ["\u2581Hey", "\u2581", "jack", "a", "s", "s", ",", "\u2581[", "\u2581check", "\u2581this", "\u2581out", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "n", "k", "8", "h", "6", "/", "e", "xx", "on", "mobil", "_", "has", "_", "los", "t", "_", "a", "_", "key", "_", "b", "a", "ttle", "_", "in", "_", "an", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hey", "\u2581", "jack", "a", "s", "s", ",", "\u2581[", "\u2581check", "\u2581this", "\u2581out", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "n", "k", "8", "h", "6", "/", "e", "xx", "on", "mobil", "_", "has", "_", "los", "t", "_", "a", "_", "key", "_", "b", "a", "ttle", "_", "in", "_", "an", "/", ")", "</s>"], "target_sentence": ["\u2581Hey", "\u2581", "jack", "a", "s", "s", ",", "\u2581[", "\u2581check", "\u2581this", "\u2581out", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "n", "k", "8", "h", "6", "/", "e", "xx", "on", "mobil", "_", "has", "_", "los", "t", "_", "a", "_", "key", "_", "b", "a", "ttle", "_", "in", "_", "an", "/", ")", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_247", "sentence": ["\u2581[", "\u2581Da", "\u2581", "n", "A", "h", "\u2581NA", "H", "\u2581NA", "A", "AH", "HH", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Da", "\u2581", "n", "A", "h", "\u2581NA", "H", "\u2581NA", "A", "AH", "HH", "!", "</s>"], "target_sentence": ["\u2581[", "\u2581Da", "\u2581", "n", "A", "h", "\u2581NA", "H", "\u2581NA", "A", "AH", "HH", "!", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_248", "sentence": ["\u2581This", "\u2581", "appar", "tent", "ly", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581political", "\u2581enough", "\u2581to", "\u2581be", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581", "despite", "\u2581the", "\u2581man", "\u2581being", "\u2581forced", "\u2581to", "\u2581", "y", "ell", "\u2581\"", "\u2581", "f", "uck", "\u2581Trump", "\u2581\"", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581", "appar", "tent", "ly", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581political", "\u2581enough", "\u2581to", "\u2581be", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581", "despite", "\u2581the", "\u2581man", "\u2581being", "\u2581forced", "\u2581to", "\u2581", "y", "ell", "\u2581\"", "\u2581", "f", "uck", "\u2581Trump", "\u2581\"", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581", "appar", "tent", "ly", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581political", "\u2581enough", "\u2581to", "\u2581be", "\u2581on", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581", "despite", "\u2581the", "\u2581man", "\u2581being", "\u2581forced", "\u2581to", "\u2581", "y", "ell", "\u2581\"", "\u2581", "f", "uck", "<m>", "\u2581Trump", "</m>", "\u2581\"", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 21, 21, 22, 23, 23, 23, 24, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_249", "sentence": ["\u2581To", "\u2581their", "\u2581credit", ",", "\u2581they", "\u2581recently", "\u2581double", "d", "\u2581their", "\u2581space", "\u2581in", "\u2581Yale", "town", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581To", "\u2581their", "\u2581credit", ",", "\u2581they", "\u2581recently", "\u2581double", "d", "\u2581their", "\u2581space", "\u2581in", "\u2581Yale", "town", ".", "</s>"], "target_sentence": ["\u2581To", "\u2581their", "\u2581credit", ",", "\u2581they", "\u2581recently", "\u2581double", "d", "\u2581their", "\u2581space", "\u2581in", "<m>", "<m>", "\u2581Yale", "town", "</m>", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1]}, {"doc_id": "emerging.test_250", "sentence": ["\u2581The", "\u2581Pre", "m", "\u2581is", "\u2581better", ",", "\u2581but", "\u2581only", "\u2581slightly", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581Pre", "m", "\u2581is", "\u2581better", ",", "\u2581but", "\u2581only", "\u2581slightly", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581Pre", "m", "\u2581is", "\u2581better", ",", "\u2581but", "\u2581only", "\u2581slightly", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_251", "sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581is", "\u2581not", "\u2581at", "\u2581all", "\u2581alt", "-", "left", "\u2581at", "\u2581present", ",", "\u2581", "IMO", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581is", "\u2581not", "\u2581at", "\u2581all", "\u2581alt", "-", "left", "\u2581at", "\u2581present", ",", "\u2581", "IMO", ".", "</s>"], "target_sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581is", "\u2581not", "\u2581at", "\u2581all", "\u2581alt", "-", "left", "\u2581at", "\u2581present", ",", "\u2581", "IMO", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_252", "sentence": ["\u25813", "\u2581weeks", "\u2581from", "\u2581now", "\u2581", "a", "\u2581Centre", "link", "\u2581recipient", "\u2581kill", "s", "\u2581himself", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u25813", "\u2581weeks", "\u2581from", "\u2581now", "\u2581", "a", "\u2581Centre", "link", "\u2581recipient", "\u2581kill", "s", "\u2581himself", ".", "</s>"], "target_sentence": ["\u25813", "\u2581weeks", "\u2581from", "\u2581now", "\u2581", "a", "<m>", "\u2581Centre", "link", "</m>", "\u2581recipient", "\u2581kill", "s", "\u2581himself", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 6, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_253", "sentence": ["\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "l", "q", "z", "o", "e", "/", "found", "_", "this", "_", "kind", "_", "of", "_", "cool", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581", "ire", "l", "and", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "l", "q", "z", "o", "e", "/", "found", "_", "this", "_", "kind", "_", "of", "_", "cool", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581", "ire", "l", "and", "</s>"], "target_sentence": ["\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/5", "l", "q", "z", "o", "e", "/", "found", "_", "this", "_", "kind", "_", "of", "_", "cool", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "<m>", "\u2581", "ire", "l", "and", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 7, 7, 8, 8, 9, 9, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_254", "sentence": ["\u2581Hello", "\u2581and", "\u2581welcome", "\u2581to", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581south", "a", "f", "ric", "a", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hello", "\u2581and", "\u2581welcome", "\u2581to", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581south", "a", "f", "ric", "a", "!", "</s>"], "target_sentence": ["\u2581Hello", "\u2581and", "\u2581welcome", "\u2581to", "\u2581", "/", "\u2581", "r", "\u2581", "/", "<m>", "\u2581south", "a", "f", "ric", "a", "</m>", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_255", "sentence": ["\u2581Edit", ":", "\u2581[", "\u2581Bingo", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Edit", ":", "\u2581[", "\u2581Bingo", ".", "</s>"], "target_sentence": ["\u2581Edit", ":", "\u2581[", "<m>", "\u2581Bingo", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, 0, -1, -1]}, {"doc_id": "emerging.test_256", "sentence": ["\u2581[", "\u2581Well", "\u2581", "s", "hit", "\u2581I", "\u2581was", "\u2581wrong", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "m", "l", "h", "y", "7", "/", "match", "_", "th", "read", "_", "pre", "ston", "_", "n", "or", "th", "_", "end", "_", "v", "s", "_", "ar", "s", "en", "al", "/", "d", "c", "4", "h", "57", "s", "/", "?", "con", "text", "=", "3", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Well", "\u2581", "s", "hit", "\u2581I", "\u2581was", "\u2581wrong", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "m", "l", "h", "y", "7", "/", "match", "_", "th", "read", "_", "pre", "ston", "_", "n", "or", "th", "_", "end", "_", "v", "s", "_", "ar", "s", "en", "al", "/", "d", "c", "4", "h", "57", "s", "/", "?", "con", "text", "=", "3", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581Well", "\u2581", "s", "hit", "\u2581I", "\u2581was", "\u2581wrong", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "m", "l", "h", "y", "7", "/", "match", "_", "th", "read", "_", "pre", "ston", "_", "n", "or", "th", "_", "end", "_", "v", "s", "_", "ar", "s", "en", "al", "/", "d", "c", "4", "h", "57", "s", "/", "?", "con", "text", "=", "3", ")", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_257", "sentence": ["\u2581Here", "\u2581you", "\u2581go", "\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "86", "3", "w", "/", "hat", "e", "_", "cri", "me", "_", "charge", "s", "_", "file", "d", "_", "a", "gain", "s", "t", "_", "4", "_", "in", "_", "t", "or", "ture", "_", "of", "/", "d", "c", "1", "n", "6", "t", "7", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Here", "\u2581you", "\u2581go", "\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "86", "3", "w", "/", "hat", "e", "_", "cri", "me", "_", "charge", "s", "_", "file", "d", "_", "a", "gain", "s", "t", "_", "4", "_", "in", "_", "t", "or", "ture", "_", "of", "/", "d", "c", "1", "n", "6", "t", "7", "/", ")", "</s>"], "target_sentence": ["\u2581Here", "\u2581you", "\u2581go", "\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "news", "/", "com", "ments", "/5", "m", "86", "3", "w", "/", "hat", "e", "_", "cri", "me", "_", "charge", "s", "_", "file", "d", "_", "a", "gain", "s", "t", "_", "4", "_", "in", "_", "t", "or", "ture", "_", "of", "/", "d", "c", "1", "n", "6", "t", "7", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_258", "sentence": ["\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "t", "2", "pu", "j", "/", "m", "a", "ori", "_", "storm", "t", "r", "oop", "er", "_", "helm", "e", "t", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581new", "ze", "al", "and", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "t", "2", "pu", "j", "/", "m", "a", "ori", "_", "storm", "t", "r", "oop", "er", "_", "helm", "e", "t", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581new", "ze", "al", "and", "</s>"], "target_sentence": ["\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "t", "2", "pu", "j", "/", "m", "a", "ori", "_", "storm", "t", "r", "oop", "er", "_", "helm", "e", "t", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "<m>", "\u2581new", "ze", "al", "and", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 7, 7, 8, 8, 9, 9, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_259", "sentence": ["\u2581Wow", ",", "\u2581just", "\u2581wo", "w", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Wow", ",", "\u2581just", "\u2581wo", "w", ".", "</s>"], "target_sentence": ["\u2581Wow", ",", "\u2581just", "\u2581wo", "w", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_260", "sentence": ["\u2581The", "\u2581guy", "\u2581who", "\u2581", "ate", "\u2581Su", "doc", "re", "m", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581guy", "\u2581who", "\u2581", "ate", "\u2581Su", "doc", "re", "m", ":", "</s>"], "target_sentence": ["\u2581The", "\u2581guy", "\u2581who", "\u2581", "ate", "<m>", "<m>", "\u2581Su", "doc", "re", "m", "</m>", "</m>", ":", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 0, 1, -1, -1]}, {"doc_id": "emerging.test_261", "sentence": ["\u2581Bingo", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Bingo", ".", "</s>"], "target_sentence": ["\u2581Bingo", ".", "</s>"], "subtoken_map": [0, 1, 2], "ent_type_sequence": [-1, -1, -1], "ent_indices": [-1, -1, -1]}, {"doc_id": "emerging.test_262", "sentence": ["\u2581I", "\u2581like", "\u2581", "u", "\u2581", "/", "\u2581Wo", "m", "ble", "\u2581", "_", "\u2581Don", "'", "\u2581", "s", "\u2581post", "\u2581about", "\u2581why", "\u2581La", "h", "m", "\u2581is", "\u2581", "a", "\u2581good", "\u2581captain", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581like", "\u2581", "u", "\u2581", "/", "\u2581Wo", "m", "ble", "\u2581", "_", "\u2581Don", "'", "\u2581", "s", "\u2581post", "\u2581about", "\u2581why", "\u2581La", "h", "m", "\u2581is", "\u2581", "a", "\u2581good", "\u2581captain", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581like", "\u2581", "u", "\u2581", "/", "\u2581Wo", "m", "ble", "\u2581", "_", "<m>", "\u2581Don", "</m>", "'", "\u2581", "s", "\u2581post", "\u2581about", "\u2581why", "<m>", "<m>", "\u2581La", "h", "m", "</m>", "</m>", "\u2581is", "\u2581", "a", "\u2581good", "\u2581captain", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 12, 13, 14, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, 2, 1, -1, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_263", "sentence": ["\u2581Chuck", "\u2581this", "\u2581", "a", "\u2581read", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "wiki", "/", "title", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Chuck", "\u2581this", "\u2581", "a", "\u2581read", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "wiki", "/", "title", "s", "</s>"], "target_sentence": ["\u2581Chuck", "\u2581this", "\u2581", "a", "\u2581read", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "wiki", "/", "title", "s", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_264", "sentence": ["\u2581They", "\u2581said", "\u2581\"", "\u2581Ye", "a", "\u2581because", "\u2581", "catching", "\u2581the", "\u2581entire", "\u2581force", "\u2581of", "\u2581your", "\u2581body", "\u2581with", "\u2581your", "\u2581arms", "\u2581is", "\u2581always", "\u2581", "a", "\u2581great", "\u2581idea", ".", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581They", "\u2581said", "\u2581\"", "\u2581Ye", "a", "\u2581because", "\u2581", "catching", "\u2581the", "\u2581entire", "\u2581force", "\u2581of", "\u2581your", "\u2581body", "\u2581with", "\u2581your", "\u2581arms", "\u2581is", "\u2581always", "\u2581", "a", "\u2581great", "\u2581idea", ".", "\u2581\"", "</s>"], "target_sentence": ["\u2581They", "\u2581said", "\u2581\"", "\u2581Ye", "a", "\u2581because", "\u2581", "catching", "\u2581the", "\u2581entire", "\u2581force", "\u2581of", "\u2581your", "\u2581body", "\u2581with", "\u2581your", "\u2581arms", "\u2581is", "\u2581always", "\u2581", "a", "\u2581great", "\u2581idea", ".", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_265", "sentence": ["\u2581[", "\u2581Alternative", "\u2581format", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "5", "f", "g", "7", "/", "o", "c", "_", "an", "_", "in", "nov", "ative", "_", "format", "_", "to", "_", "s", "a", "ve", "_", "the", "_", "world", "_", "cup", "_", "and", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Alternative", "\u2581format", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "5", "f", "g", "7", "/", "o", "c", "_", "an", "_", "in", "nov", "ative", "_", "format", "_", "to", "_", "s", "a", "ve", "_", "the", "_", "world", "_", "cup", "_", "and", "/", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581Alternative", "\u2581format", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "n", "5", "f", "g", "7", "/", "o", "c", "_", "an", "_", "in", "nov", "ative", "_", "format", "_", "to", "_", "s", "a", "ve", "_", "the", "_", "world", "_", "cup", "_", "and", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_266", "sentence": ["\u2581Thanks", "\u2581to", "\u2581", "u", "\u2581", "/", "\u2581Bord", "N", "a", "Mon", "a", "L", "is", "a", "\u2581for", "\u2581remind", "ing", "\u2581me", "\u2581of", "\u2581this", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Thanks", "\u2581to", "\u2581", "u", "\u2581", "/", "\u2581Bord", "N", "a", "Mon", "a", "L", "is", "a", "\u2581for", "\u2581remind", "ing", "\u2581me", "\u2581of", "\u2581this", ".", "</s>"], "target_sentence": ["\u2581Thanks", "\u2581to", "\u2581", "u", "\u2581", "/", "\u2581Bord", "N", "a", "Mon", "a", "L", "is", "a", "\u2581for", "\u2581remind", "ing", "\u2581me", "\u2581of", "\u2581this", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_267", "sentence": ["\u2581I", "\u2581just", "\u2581wrote", "\u2581", "a", "\u2581", "f", "uck", "ing", "\u2581novel", "\u2581regarding", "\u2581B", "LM", "'", "\u2581", "s", "\u2581use", "\u2581of", "\u2581blanket", "\u2581statements", "\u2581[", "\u2581here", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581just", "\u2581wrote", "\u2581", "a", "\u2581", "f", "uck", "ing", "\u2581novel", "\u2581regarding", "\u2581B", "LM", "'", "\u2581", "s", "\u2581use", "\u2581of", "\u2581blanket", "\u2581statements", "\u2581[", "\u2581here", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581just", "\u2581wrote", "\u2581", "a", "\u2581", "f", "uck", "ing", "\u2581novel", "\u2581regarding", "<m>", "\u2581B", "LM", "</m>", "'", "\u2581", "s", "\u2581use", "\u2581of", "\u2581blanket", "\u2581statements", "\u2581[", "\u2581here", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 4, 4, 5, 6, 7, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_268", "sentence": ["'", "\u2581Many", "\u2581wounded", "'", "\u2581in", "\u2581Istanbul", "\u2581night", "club", "\u2581attack", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "'", "\u2581Many", "\u2581wounded", "'", "\u2581in", "\u2581Istanbul", "\u2581night", "club", "\u2581attack", "</s>"], "target_sentence": ["'", "\u2581Many", "\u2581wounded", "'", "\u2581in", "<m>", "\u2581Istanbul", "</m>", "\u2581night", "club", "\u2581attack", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1]}, {"doc_id": "emerging.test_269", "sentence": ["\u2581It", "s", "\u2581in", "con", "clu", "s", "ive", "\u2581", "IMO", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "s", "\u2581in", "con", "clu", "s", "ive", "\u2581", "IMO", ".", "</s>"], "target_sentence": ["\u2581It", "s", "\u2581in", "con", "clu", "s", "ive", "\u2581", "IMO", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_270", "sentence": ["\u2581So", "\u2581discussion", "\u2581related", "\u2581to", ",", "\u2581say", ",", "\u2581\"", "\u2581New", "\u2581Zealand", "\u2581\"", "\u2581could", "\u2581all", "\u2581go", "\u2581in", "\u2581one", "\u2581place", ",", "\u2581such", "\u2581as", "\u2581red", "d", "it", ".", "\u2581", "com", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581new", "ze", "al", "and", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581So", "\u2581discussion", "\u2581related", "\u2581to", ",", "\u2581say", ",", "\u2581\"", "\u2581New", "\u2581Zealand", "\u2581\"", "\u2581could", "\u2581all", "\u2581go", "\u2581in", "\u2581one", "\u2581place", ",", "\u2581such", "\u2581as", "\u2581red", "d", "it", ".", "\u2581", "com", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581new", "ze", "al", "and", ".", "</s>"], "target_sentence": ["\u2581So", "\u2581discussion", "\u2581related", "\u2581to", ",", "\u2581say", ",", "\u2581\"", "<m>", "<m>", "\u2581New", "\u2581Zealand", "</m>", "</m>", "\u2581\"", "\u2581could", "\u2581all", "\u2581go", "\u2581in", "\u2581one", "\u2581place", ",", "\u2581such", "\u2581as", "\u2581red", "d", "it", ".", "\u2581", "com", "\u2581", "/", "\u2581", "r", "\u2581", "/", "<m>", "\u2581new", "ze", "al", "and", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26, 26, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, 2, -1, -1]}, {"doc_id": "emerging.test_271", "sentence": ["\u2581Best", "\u2581of", "\u2581all", "\u2581", "^", "\u2581", "^", "\u2581", "^", "\u2581(", "\u2581", "/", "\u2581", "s", ")", ",", "\u2581they", "'", "\u2581", "ve", "\u2581completely", "\u2581", "f", "ucked", "\u2581over", "\u2581the", "\u2581[", "\u2581Statut", "or", "y", "\u2581Limit", "ation", "\u2581Period", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "l", "w", "w", "d", "1/", "for", "_", "t", "hose", "_", "c", "aught", "_", "up", "_", "in", "_", "the", "_", "cent", "re", "link", "_", "wave", "_", "a", "s", "_", "of", "/", "d", "c", "0", "o", "3", "q", "7", "/", ")", "\u2581that", "\u2581limited", "\u2581them", "\u2581from", "\u2581", "chasing", "\u2581you", "\u2581up", "\u2581to", "\u2581within", "\u2581six", "\u2581years", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Best", "\u2581of", "\u2581all", "\u2581", "^", "\u2581", "^", "\u2581", "^", "\u2581(", "\u2581", "/", "\u2581", "s", ")", ",", "\u2581they", "'", "\u2581", "ve", "\u2581completely", "\u2581", "f", "ucked", "\u2581over", "\u2581the", "\u2581[", "\u2581Statut", "or", "y", "\u2581Limit", "ation", "\u2581Period", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "l", "w", "w", "d", "1/", "for", "_", "t", "hose", "_", "c", "aught", "_", "up", "_", "in", "_", "the", "_", "cent", "re", "link", "_", "wave", "_", "a", "s", "_", "of", "/", "d", "c", "0", "o", "3", "q", "7", "/", ")", "\u2581that", "\u2581limited", "\u2581them", "\u2581from", "\u2581", "chasing", "\u2581you", "\u2581up", "\u2581to", "\u2581within", "\u2581six", "\u2581years", ".", "</s>"], "target_sentence": ["\u2581Best", "\u2581of", "\u2581all", "\u2581", "^", "\u2581", "^", "\u2581", "^", "\u2581(", "\u2581", "/", "\u2581", "s", ")", ",", "<m>", "\u2581they", "</m>", "'", "\u2581", "ve", "\u2581completely", "\u2581", "f", "ucked", "\u2581over", "\u2581the", "\u2581[", "\u2581Statut", "or", "y", "\u2581Limit", "ation", "\u2581Period", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "l", "w", "w", "d", "1/", "for", "_", "t", "hose", "_", "c", "aught", "_", "up", "_", "in", "_", "the", "_", "cent", "re", "link", "_", "wave", "_", "a", "s", "_", "of", "/", "d", "c", "0", "o", "3", "q", "7", "/", ")", "\u2581that", "\u2581limited", "<m>", "\u2581them", "</m>", "\u2581from", "\u2581", "chasing", "\u2581you", "\u2581up", "\u2581to", "\u2581within", "\u2581six", "\u2581years", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 15, 15, 15, 16, 17, 18, 19, 19, 19, 20, 20, 21, 22, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_272", "sentence": ["\u2581", "Possibly", "\u2581some", "\u2581Inter", "n", "o", "de", "\u2581solutions", "\u2581for", "\u2581you", "\u2581[", "\u2581here", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "k", "d", "1", "z", "1/", "go", "o", "gle", "_", "d", "n", "s", "_", "did", "_", "not", "_", "work", "_", "for", "_", "t", "p", "b", "/", ")", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Possibly", "\u2581some", "\u2581Inter", "n", "o", "de", "\u2581solutions", "\u2581for", "\u2581you", "\u2581[", "\u2581here", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "k", "d", "1", "z", "1/", "go", "o", "gle", "_", "d", "n", "s", "_", "did", "_", "not", "_", "work", "_", "for", "_", "t", "p", "b", "/", ")", "?", "</s>"], "target_sentence": ["\u2581", "Possibly", "\u2581some", "\u2581Inter", "n", "o", "de", "\u2581solutions", "\u2581for", "\u2581you", "\u2581[", "\u2581here", "]", "\u2581(", "\u2581https", "://", "n", "p", ".", "red", "d", "it", ".", "com", "/", "r", "/", "aus", "tral", "i", "a", "/", "com", "ments", "/5", "k", "d", "1", "z", "1/", "go", "o", "gle", "_", "d", "n", "s", "_", "did", "_", "not", "_", "work", "_", "for", "_", "t", "p", "b", "/", ")", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_273", "sentence": ["\u2581I", "\u2581wonder", "\u2581how", "\u2581many", "\u2581[", "\u2581", "Ticket", "\u2581Operations", "\u2581Coordinator", "s", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "g", "4", "b", "n", "f", "/", "m", "l", "s", "_", "to", "ok", "_", "my", "_", "de", "cade", "_", "long", "_", "season", "_", "s", "eat", "s", "_", "away", "_", "for", "_", "the", "/", "d", "a", "q", "1", "s", "y", "s", "/", ")", "\u2581work", "\u2581for", "\u2581the", "\u2581Clip", "pers", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581wonder", "\u2581how", "\u2581many", "\u2581[", "\u2581", "Ticket", "\u2581Operations", "\u2581Coordinator", "s", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "g", "4", "b", "n", "f", "/", "m", "l", "s", "_", "to", "ok", "_", "my", "_", "de", "cade", "_", "long", "_", "season", "_", "s", "eat", "s", "_", "away", "_", "for", "_", "the", "/", "d", "a", "q", "1", "s", "y", "s", "/", ")", "\u2581work", "\u2581for", "\u2581the", "\u2581Clip", "pers", "</s>"], "target_sentence": ["\u2581I", "\u2581wonder", "\u2581how", "\u2581many", "\u2581[", "\u2581", "Ticket", "\u2581Operations", "\u2581Coordinator", "s", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "g", "4", "b", "n", "f", "/", "m", "l", "s", "_", "to", "ok", "_", "my", "_", "de", "cade", "_", "long", "_", "season", "_", "s", "eat", "s", "_", "away", "_", "for", "_", "the", "/", "d", "a", "q", "1", "s", "y", "s", "/", ")", "\u2581work", "\u2581for", "<m>", "\u2581the", "\u2581Clip", "pers", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 13, 14, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_274", "sentence": ["\u2581I", "TT", ":", "\u2581mutual", "\u2581respect", "\u2581between", "\u2581Tottenham", "\u2581and", "\u2581Chelsea", "\u2581fans", "\u2581and", "\u2581everyone", "\u2581else", "\u2581", "shi", "tting", "\u2581on", "\u2581Gi", "rou", "d", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "TT", ":", "\u2581mutual", "\u2581respect", "\u2581between", "\u2581Tottenham", "\u2581and", "\u2581Chelsea", "\u2581fans", "\u2581and", "\u2581everyone", "\u2581else", "\u2581", "shi", "tting", "\u2581on", "\u2581Gi", "rou", "d", ".", "</s>"], "target_sentence": ["\u2581I", "TT", ":", "\u2581mutual", "\u2581respect", "\u2581between", "<m>", "<m>", "\u2581Tottenham", "</m>", "</m>", "\u2581and", "<m>", "<m>", "\u2581Chelsea", "</m>", "</m>", "\u2581fans", "\u2581and", "\u2581everyone", "\u2581else", "\u2581", "shi", "tting", "\u2581on", "<m>", "\u2581Gi", "rou", "d", "</m>", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 13, 14, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, 3, 2, -1, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, 4, -1, -1]}, {"doc_id": "emerging.test_275", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Well", "\u2581like", "\u2581you", "\u2581say", "\u2581they", "\u2581put", "\u2581", "a", "\u2581", "bald", "-", "face", "d", "\u2581lie", "\u2581right", "\u2581in", "\u2581the", "\u2581headline", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581Well", "\u2581like", "\u2581you", "\u2581say", "\u2581they", "\u2581put", "\u2581", "a", "\u2581", "bald", "-", "face", "d", "\u2581lie", "\u2581right", "\u2581in", "\u2581the", "\u2581headline", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Well", "\u2581like", "\u2581you", "\u2581say", "\u2581they", "\u2581put", "\u2581", "a", "\u2581", "bald", "-", "face", "d", "\u2581lie", "\u2581right", "\u2581in", "\u2581the", "\u2581headline", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_276", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Report", "\u2581an", "tag", "on", "izing", "\u2581comments", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581Report", "\u2581an", "tag", "on", "izing", "\u2581comments", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Report", "\u2581an", "tag", "on", "izing", "\u2581comments", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 4, 4, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_277", "sentence": ["\u2581Just", "\u2581remember", "\u2581we", "\u2581should", "\u2581be", "\u2581war", "ier", "\u2581of", "\u2581Trump", "\u2581opponents", ",", "\u2581who", "\u2581also", "\u2581ignore", "\u2581facts", ",", "\u2581and", "\u2581are", "\u2581[", "\u2581bigger", "\u2581Nazi", "s", "\u2581than", "\u2581Trump", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Just", "\u2581remember", "\u2581we", "\u2581should", "\u2581be", "\u2581war", "ier", "\u2581of", "\u2581Trump", "\u2581opponents", ",", "\u2581who", "\u2581also", "\u2581ignore", "\u2581facts", ",", "\u2581and", "\u2581are", "\u2581[", "\u2581bigger", "\u2581Nazi", "s", "\u2581than", "\u2581Trump", ".", "</s>"], "target_sentence": ["\u2581Just", "\u2581remember", "\u2581we", "\u2581should", "\u2581be", "\u2581war", "ier", "\u2581of", "<m>", "\u2581Trump", "</m>", "\u2581opponents", ",", "\u2581who", "\u2581also", "\u2581ignore", "\u2581facts", ",", "\u2581and", "\u2581are", "\u2581[", "\u2581bigger", "\u2581Nazi", "s", "\u2581than", "<m>", "\u2581Trump", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_278", "sentence": ["\u2581*", "\u2581*", "\u2581sub", "red", "d", "it", "\u2581*", "\u2581*", ":", "\u2581Wellington", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581sub", "red", "d", "it", "\u2581*", "\u2581*", ":", "\u2581Wellington", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581sub", "red", "d", "it", "\u2581*", "\u2581*", ":", "<m>", "\u2581Wellington", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1]}, {"doc_id": "emerging.test_279", "sentence": ["\u2581Also", ",", "\u2581", "a", "\u2581shame", "less", "\u2581reminder", "\u2581that", "\u2581[", "\u2581Ladies", "'", "\u2581Night", "\u2581is", "\u2581on", "\u2581this", "\u2581Friday", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "y", "l", "m", "1", "r", "/", "la", "dies", "_", "night", "_", "round", "_", "two", "_", "f", "r", "i", "day", "_", "m", "arch", "_", "24", "th", "/", ")", "\u2581rain", "\u2581or", "\u2581shine", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Also", ",", "\u2581", "a", "\u2581shame", "less", "\u2581reminder", "\u2581that", "\u2581[", "\u2581Ladies", "'", "\u2581Night", "\u2581is", "\u2581on", "\u2581this", "\u2581Friday", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "y", "l", "m", "1", "r", "/", "la", "dies", "_", "night", "_", "round", "_", "two", "_", "f", "r", "i", "day", "_", "m", "arch", "_", "24", "th", "/", ")", "\u2581rain", "\u2581or", "\u2581shine", "!", "</s>"], "target_sentence": ["\u2581Also", ",", "\u2581", "a", "\u2581shame", "less", "\u2581reminder", "\u2581that", "\u2581[", "<m>", "\u2581Ladies", "</m>", "'", "\u2581Night", "\u2581is", "\u2581on", "\u2581this", "\u2581Friday", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "y", "l", "m", "1", "r", "/", "la", "dies", "_", "night", "_", "round", "_", "two", "_", "f", "r", "i", "day", "_", "m", "arch", "_", "24", "th", "/", ")", "\u2581rain", "\u2581or", "\u2581shine", "!", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 18, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_280", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581like", "\u2581the", "\u2581Twi", "light", "\u2581Zone", "\u2581of", "\u2581red", "d", "it", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581like", "\u2581the", "\u2581Twi", "light", "\u2581Zone", "\u2581of", "\u2581red", "d", "it", ".", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581like", "<m>", "\u2581the", "\u2581Twi", "light", "\u2581Zone", "</m>", "\u2581of", "\u2581red", "d", "it", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_281", "sentence": ["\u2581Im", "\u2581Video", "\u2581auf", "\u2581[", "\u2581world", "news", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "m", "q", "if", "7", "/", "truck", "_", "ram", "med", "_", "in", "to", "_", "ped", "est", "rian", "s", "_", "in", "_", "t", "error", "ist", "_", "attack", "/", ")", "\u2581kann", "\u2581man", "\u2581sehen", ",", "\u2581dass", "\u2581der", "\u2581nicht", "\u2581nur", "\u2581in", "\u2581die", "\u2581Menge", "\u2581", "f\u00e4hrt", ",", "\u2581", "sondern", "\u2581auch", "\u2581zur\u00fcck", "setzt", "\u2581und", "\u2581nochmal", "\u2581in", "\u2581die", "\u2581Liege", "n", "ge", "blieben", "en", "\u2581", "f\u00e4hrt", ".", ".", ".", "\u2581da", "\u2581fehlen", "\u2581mir", "\u2581die", "\u2581Wort", "e", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Im", "\u2581Video", "\u2581auf", "\u2581[", "\u2581world", "news", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "m", "q", "if", "7", "/", "truck", "_", "ram", "med", "_", "in", "to", "_", "ped", "est", "rian", "s", "_", "in", "_", "t", "error", "ist", "_", "attack", "/", ")", "\u2581kann", "\u2581man", "\u2581sehen", ",", "\u2581dass", "\u2581der", "\u2581nicht", "\u2581nur", "\u2581in", "\u2581die", "\u2581Menge", "\u2581", "f\u00e4hrt", ",", "\u2581", "sondern", "\u2581auch", "\u2581zur\u00fcck", "setzt", "\u2581und", "\u2581nochmal", "\u2581in", "\u2581die", "\u2581Liege", "n", "ge", "blieben", "en", "\u2581", "f\u00e4hrt", ".", ".", ".", "\u2581da", "\u2581fehlen", "\u2581mir", "\u2581die", "\u2581Wort", "e", ".", "</s>"], "target_sentence": ["\u2581Im", "\u2581Video", "\u2581auf", "\u2581[", "\u2581world", "news", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "com", "ments", "/5", "m", "q", "if", "7", "/", "truck", "_", "ram", "med", "_", "in", "to", "_", "ped", "est", "rian", "s", "_", "in", "_", "t", "error", "ist", "_", "attack", "/", ")", "\u2581kann", "\u2581man", "\u2581sehen", ",", "\u2581dass", "\u2581der", "\u2581nicht", "\u2581nur", "\u2581in", "\u2581die", "\u2581Menge", "\u2581", "f\u00e4hrt", ",", "\u2581", "sondern", "\u2581auch", "\u2581zur\u00fcck", "setzt", "\u2581und", "\u2581nochmal", "\u2581in", "\u2581die", "\u2581Liege", "n", "ge", "blieben", "en", "\u2581", "f\u00e4hrt", ".", ".", ".", "\u2581da", "\u2581fehlen", "\u2581mir", "\u2581die", "\u2581Wort", "e", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 29, 29, 29, 29, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 38, 39, 40], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_282", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581[", "\u2581I", "\u2581", "voted", "\u2581Bernie", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581[", "\u2581I", "\u2581", "voted", "\u2581Bernie", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581[", "\u2581I", "\u2581", "voted", "<m>", "<m>", "\u2581Bernie", "</m>", "</m>", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, -1]}, {"doc_id": "emerging.test_283", "sentence": ["\u2581[", "\u2581Brit", "\u2581clouds", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/", "61", "i", "0", "n", "u", "/", "u", "f", "o", "_", "spotted", "_", "in", "_", "ark", "low", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Brit", "\u2581clouds", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/", "61", "i", "0", "n", "u", "/", "u", "f", "o", "_", "spotted", "_", "in", "_", "ark", "low", "/", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581Brit", "\u2581clouds", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/", "61", "i", "0", "n", "u", "/", "u", "f", "o", "_", "spotted", "_", "in", "_", "ark", "low", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_284", "sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581movies", ":", "\u2581Film", "\u2581", "/", "\u2581theatre", "\u2581teacher", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581movies", ":", "\u2581Film", "\u2581", "/", "\u2581theatre", "\u2581teacher", "</s>"], "target_sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581movies", ":", "\u2581Film", "\u2581", "/", "\u2581theatre", "\u2581teacher", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_285", "sentence": ["\u2581This", "\u2581post", "\u2581has", "\u2581like", "\u258110", "\u2581comments", "\u2581and", "\u2581no", "\u2581one", "\u2581except", "\u2581the", "\u2581", "OP", "\u2581(", "\u2581who", "\u2581seems", "\u2581to", "\u2581[", "\u2581", "s", "hit", "\u2581their", "\u2581pants", "\u2581about", "\u2581the", "\u2581", "e", "s", "s", "\u2581ja", "y", "\u2581du", "b", "s", ",", "\u2581just", "\u2581like", "\u2581you", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "n", "83", "q", "t", "/", "an", "other", "_", "case", "_", "of", "_", "an", "_", "e", "mp", "loyer", "_", "under", "_", "pay", "ing", "_", "and", "/", "d", "c", "9", "s", "g", "r", "j", "/", ")", ")", "\u2581is", "\u2581talking", "\u2581about", "\u2581", "e", "-", "c", "i", "g", "s", "\u2581or", "\u2581saying", "\u2581this", "\u2581guy", "\u2581is", "\u2581", "a", "\u2581saint", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581post", "\u2581has", "\u2581like", "\u258110", "\u2581comments", "\u2581and", "\u2581no", "\u2581one", "\u2581except", "\u2581the", "\u2581", "OP", "\u2581(", "\u2581who", "\u2581seems", "\u2581to", "\u2581[", "\u2581", "s", "hit", "\u2581their", "\u2581pants", "\u2581about", "\u2581the", "\u2581", "e", "s", "s", "\u2581ja", "y", "\u2581du", "b", "s", ",", "\u2581just", "\u2581like", "\u2581you", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "n", "83", "q", "t", "/", "an", "other", "_", "case", "_", "of", "_", "an", "_", "e", "mp", "loyer", "_", "under", "_", "pay", "ing", "_", "and", "/", "d", "c", "9", "s", "g", "r", "j", "/", ")", ")", "\u2581is", "\u2581talking", "\u2581about", "\u2581", "e", "-", "c", "i", "g", "s", "\u2581or", "\u2581saying", "\u2581this", "\u2581guy", "\u2581is", "\u2581", "a", "\u2581saint", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581post", "\u2581has", "\u2581like", "\u258110", "\u2581comments", "\u2581and", "\u2581no", "\u2581one", "\u2581except", "\u2581the", "\u2581", "OP", "\u2581(", "\u2581who", "\u2581seems", "\u2581to", "\u2581[", "\u2581", "s", "hit", "\u2581their", "\u2581pants", "\u2581about", "\u2581the", "<m>", "\u2581", "e", "s", "s", "\u2581ja", "y", "</m>", "\u2581du", "b", "s", ",", "\u2581just", "\u2581like", "\u2581you", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "new", "ze", "al", "and", "/", "com", "ments", "/5", "n", "83", "q", "t", "/", "an", "other", "_", "case", "_", "of", "_", "an", "_", "e", "mp", "loyer", "_", "under", "_", "pay", "ing", "_", "and", "/", "d", "c", "9", "s", "g", "r", "j", "/", ")", ")", "\u2581is", "\u2581talking", "\u2581about", "\u2581", "e", "-", "c", "i", "g", "s", "\u2581or", "\u2581saying", "\u2581this", "\u2581guy", "\u2581is", "\u2581", "a", "\u2581saint", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 17, 17, 18, 19, 20, 21, 22, 22, 22, 22, 23, 23, 24, 24, 24, 25, 26, 27, 28, 29, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 33, 34, 35, 36, 37, 37, 37, 37, 37, 37, 37, 38, 39, 40, 41, 42, 43, 43, 44, 45, 46], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_286", "sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "\u2581\"", "\u2581", "bla", "bla", "bla", "\u2581political", "\u2581bull", "s", "hit", "\u2581Hur", "\u2581dur", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "\u2581\"", "\u2581", "bla", "bla", "bla", "\u2581political", "\u2581bull", "s", "hit", "\u2581Hur", "\u2581dur", "\u2581\"", "</s>"], "target_sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", ":", "\u2581\"", "\u2581", "bla", "bla", "bla", "\u2581political", "\u2581bull", "s", "hit", "\u2581Hur", "\u2581dur", "\u2581\"", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 8, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_287", "sentence": ["\u2581https", "://", "ce", "d", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "new", "N", "a", "h", ",", "you", "'", "re", "not", "blin", "d", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "ce", "d", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "new", "N", "a", "h", ",", "you", "'", "re", "not", "blin", "d", ".", "</s>"], "target_sentence": ["\u2581https", "://", "ce", "d", "d", "it", ".", "com", "/", "r", "/", "world", "news", "/", "new", "N", "a", "h", ",", "you", "'", "re", "not", "blin", "d", ".", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_288", "sentence": ["\u2581I", "\u2581was", "\u2581", "referencing", "\u2581", "a", "\u2581Famous", "\u2581Red", "d", "it", "\u2581Post", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581was", "\u2581", "referencing", "\u2581", "a", "\u2581Famous", "\u2581Red", "d", "it", "\u2581Post", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", "</s>"], "target_sentence": ["\u2581I", "\u2581was", "\u2581", "referencing", "\u2581", "a", "\u2581Famous", "<m>", "<m>", "\u2581Red", "d", "it", "</m>", "</m>", "\u2581Post", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "ire", "l", "and", "/", "com", "ments", "/3", "d", "p", "ux", "y", "/", "vis", "it", "ing", "_", "your", "_", "be", "au", "t", "if", "ul", "_", "country", "_", "this", "_", "week", "end", "_", "wan", "t", "/", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 5, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_289", "sentence": ["\u2581Jesus", "\u2581", "christ", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Jesus", "\u2581", "christ", ".", "</s>"], "target_sentence": ["<m>", "\u2581Jesus", "\u2581", "christ", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_290", "sentence": ["\u2581Chelsea", "\u2581lost", "\u2581yesterday", ",", "\u2581now", "\u2581I", "'", "\u2581", "m", "\u2581hiding", "\u2581from", "\u2581the", "\u2581match", "\u2581and", "\u2581post", "\u2581match", "\u2581thread", "s", "\u2581on", "\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581", "/", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Chelsea", "\u2581lost", "\u2581yesterday", ",", "\u2581now", "\u2581I", "'", "\u2581", "m", "\u2581hiding", "\u2581from", "\u2581the", "\u2581match", "\u2581and", "\u2581post", "\u2581match", "\u2581thread", "s", "\u2581on", "\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581", "/", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", ")", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Chelsea", "</m>", "</m>", "\u2581lost", "\u2581yesterday", ",", "\u2581now", "\u2581I", "'", "\u2581", "m", "\u2581hiding", "\u2581from", "\u2581the", "\u2581match", "\u2581and", "\u2581post", "\u2581match", "\u2581thread", "s", "\u2581on", "\u2581[", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581soccer", "\u2581", "/", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 18, 19, 19, 20, 20, 21, 22, 22, 23, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_291", "sentence": ["\u2581Ken", "\u2581King", "\u2581said", "\u2581it", "\u2581himself", "\u2581when", "\u2581", "he", "\u2581started", "\u2581talking", "\u2581about", "\u2581Calgary", "NE", "X", "T", "\u2581that", "\u2581", "he", "\u2581wants", "\u2581*", "\u2581less", "\u2581*", "\u2581seats", "\u2581in", "\u2581the", "\u2581new", "\u2581arena", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ken", "\u2581King", "\u2581said", "\u2581it", "\u2581himself", "\u2581when", "\u2581", "he", "\u2581started", "\u2581talking", "\u2581about", "\u2581Calgary", "NE", "X", "T", "\u2581that", "\u2581", "he", "\u2581wants", "\u2581*", "\u2581less", "\u2581*", "\u2581seats", "\u2581in", "\u2581the", "\u2581new", "\u2581arena", ".", "</s>"], "target_sentence": ["<m>", "\u2581Ken", "\u2581King", "</m>", "\u2581said", "\u2581it", "\u2581himself", "\u2581when", "\u2581", "he", "\u2581started", "\u2581talking", "\u2581about", "<m>", "<m>", "<m>", "<m>", "\u2581Calgary", "NE", "X", "T", "</m>", "</m>", "</m>", "</m>", "\u2581that", "\u2581", "he", "\u2581wants", "\u2581*", "\u2581less", "\u2581*", "\u2581seats", "\u2581in", "\u2581the", "\u2581new", "\u2581arena", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 2, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, 1, 4, -1, -1, -1, -1, 2, 3, 1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_292", "sentence": ["\u2581LOL", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581LOL", ".", "</s>"], "target_sentence": ["\u2581LOL", ".", "</s>"], "subtoken_map": [0, 1, 2], "ent_type_sequence": [-1, -1, -1], "ent_indices": [-1, -1, -1]}, {"doc_id": "emerging.test_293", "sentence": ["\u2581Writing", "\u2581", "a", "\u2581fake", "\u2581interview", "\u2581with", "\u2581Mess", "i", "\u2581is", "\u2581easy", ",", "\u2581[", "\u2581I", "\u2581even", "\u2581did", "\u2581it", "\u2581myself", "\u2581here", "\u2581", "a", "\u2581few", "\u2581years", "\u2581ago", ".", ".", ".", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/2", "i", "z", "2", "q", "9", "/", "inter", "view", "ing", "_", "le", "o", "_", "mes", "s", "i", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Writing", "\u2581", "a", "\u2581fake", "\u2581interview", "\u2581with", "\u2581Mess", "i", "\u2581is", "\u2581easy", ",", "\u2581[", "\u2581I", "\u2581even", "\u2581did", "\u2581it", "\u2581myself", "\u2581here", "\u2581", "a", "\u2581few", "\u2581years", "\u2581ago", ".", ".", ".", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/2", "i", "z", "2", "q", "9", "/", "inter", "view", "ing", "_", "le", "o", "_", "mes", "s", "i", "/", ")", "</s>"], "target_sentence": ["\u2581Writing", "\u2581", "a", "\u2581fake", "\u2581interview", "\u2581with", "<m>", "<m>", "\u2581Mess", "i", "</m>", "</m>", "\u2581is", "\u2581easy", ",", "\u2581[", "\u2581I", "\u2581even", "\u2581did", "\u2581it", "\u2581myself", "\u2581here", "\u2581", "a", "\u2581few", "\u2581years", "\u2581ago", ".", ".", ".", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/2", "i", "z", "2", "q", "9", "/", "inter", "view", "ing", "_", "le", "o", "_", "mes", "s", "i", "/", ")", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_294", "sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Ad", "e", "bay", "or", "\u2581signs", "\u2581for", "\u2581Turkish", "\u2581side", "\u2581Bas", "ak", "s", "e", "hir", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "\u2581Ad", "e", "bay", "or", "\u2581signs", "\u2581for", "\u2581Turkish", "\u2581side", "\u2581Bas", "ak", "s", "e", "hir", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581submission", "\u2581title", "\u2581*", "\u2581*", ":", "<m>", "<m>", "\u2581Ad", "e", "bay", "or", "</m>", "</m>", "\u2581signs", "\u2581for", "\u2581Turkish", "\u2581side", "<m>", "\u2581Bas", "ak", "s", "e", "hir", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1]}, {"doc_id": "emerging.test_295", "sentence": ["\u2581One", "\u2581last", "\u2581reminder", "\u2581for", "\u2581[", "\u2581Old", "ies", "\u2581Night", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "x", "l", "59", "i", "/", "old", "ies", "_", "night", "_", "18", "_", "m", "arch", "_", "2017", "_", "b", "ava", "rian", "_", "b", "ier", "_", "ca", "f", "e", "/", ")", "\u2581", "-", "\u2581still", "\u2581time", "\u2581to", "\u2581join", "\u2581in", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581One", "\u2581last", "\u2581reminder", "\u2581for", "\u2581[", "\u2581Old", "ies", "\u2581Night", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "x", "l", "59", "i", "/", "old", "ies", "_", "night", "_", "18", "_", "m", "arch", "_", "2017", "_", "b", "ava", "rian", "_", "b", "ier", "_", "ca", "f", "e", "/", ")", "\u2581", "-", "\u2581still", "\u2581time", "\u2581to", "\u2581join", "\u2581in", ".", "</s>"], "target_sentence": ["\u2581One", "\u2581last", "\u2581reminder", "\u2581for", "\u2581[", "\u2581Old", "ies", "\u2581Night", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "x", "l", "59", "i", "/", "old", "ies", "_", "night", "_", "18", "_", "m", "arch", "_", "2017", "_", "b", "ava", "rian", "_", "b", "ier", "_", "ca", "f", "e", "/", ")", "\u2581", "-", "\u2581still", "\u2581time", "\u2581to", "\u2581join", "\u2581in", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_296", "sentence": ["\u2581[", "\u2581Fa", "ke", "\u2581News", ",", "\u2581", "e", "h", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Fa", "ke", "\u2581News", ",", "\u2581", "e", "h", "?", "</s>"], "target_sentence": ["\u2581[", "\u2581Fa", "ke", "\u2581News", ",", "\u2581", "e", "h", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_297", "sentence": ["\u2581[", "\u2581Please", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581forget", "\u2581that", "\u2581liberal", "s", "\u2581and", "\u2581Democrats", "\u2581are", "\u2581Nazi", "\u2581Use", "ful", "\u2581I", "d", "i", "o", "t", "s", "\u2581who", "\u2581believe", "\u2581government", "\u2581", "/", "\u2581", "CIA", "\u2581propaganda", "\u2581and", "\u2581Fa", "ke", "\u2581News", "\u2581sites", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Please", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581forget", "\u2581that", "\u2581liberal", "s", "\u2581and", "\u2581Democrats", "\u2581are", "\u2581Nazi", "\u2581Use", "ful", "\u2581I", "d", "i", "o", "t", "s", "\u2581who", "\u2581believe", "\u2581government", "\u2581", "/", "\u2581", "CIA", "\u2581propaganda", "\u2581and", "\u2581Fa", "ke", "\u2581News", "\u2581sites", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581Please", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581forget", "\u2581that", "\u2581liberal", "s", "\u2581and", "\u2581Democrats", "\u2581are", "\u2581Nazi", "\u2581Use", "ful", "\u2581I", "d", "i", "o", "t", "s", "\u2581who", "\u2581believe", "\u2581government", "\u2581", "/", "\u2581", "CIA", "\u2581propaganda", "\u2581and", "\u2581Fa", "ke", "\u2581News", "\u2581sites", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 14, 14, 14, 14, 14, 15, 16, 17, 18, 18, 19, 19, 20, 21, 22, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_298", "sentence": ["\u2581[", "\u2581Okay", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Okay", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581Okay", ".", "</s>"], "subtoken_map": [0, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1]}, {"doc_id": "emerging.test_299", "sentence": ["\u2581Even", "\u2581though", "\u2581I", "'", "\u2581", "ve", "\u2581only", "\u2581been", "\u2581once", "\u2581through", "\u2581", "a", "\u2581reciproc", "al", "\u2581membership", ",", "\u2581I", "'", "\u2581", "ll", "\u2581nom", "inate", "\u2581Virgin", "\u2581Active", "\u2581at", "\u2581Moore", "\u2581Park", "\u2581", "/", "\u2581Ze", "t", "l", "and", "\u2581for", "\u2581you", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Even", "\u2581though", "\u2581I", "'", "\u2581", "ve", "\u2581only", "\u2581been", "\u2581once", "\u2581through", "\u2581", "a", "\u2581reciproc", "al", "\u2581membership", ",", "\u2581I", "'", "\u2581", "ll", "\u2581nom", "inate", "\u2581Virgin", "\u2581Active", "\u2581at", "\u2581Moore", "\u2581Park", "\u2581", "/", "\u2581Ze", "t", "l", "and", "\u2581for", "\u2581you", ".", "</s>"], "target_sentence": ["\u2581Even", "\u2581though", "\u2581I", "'", "\u2581", "ve", "\u2581only", "\u2581been", "\u2581once", "\u2581through", "\u2581", "a", "\u2581reciproc", "al", "\u2581membership", ",", "\u2581I", "'", "\u2581", "ll", "\u2581nom", "inate", "<m>", "<m>", "\u2581Virgin", "</m>", "\u2581Active", "</m>", "\u2581at", "<m>", "<m>", "\u2581Moore", "\u2581Park", "</m>", "</m>", "\u2581", "/", "<m>", "<m>", "\u2581Ze", "t", "l", "and", "</m>", "</m>", "\u2581for", "\u2581you", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 10, 11, 12, 13, 14, 15, 15, 16, 16, 17, 18, 19, 20, 21, 22, 22, 23, 23, 23, 23, 24, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 4, -1, -1, -1, -1, -1, 0, 2, -1, -1, -1, -1, -1, -1, -1, -1, 0, 2, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, -1, 1, -1, 3, 2, -1, -1, 3, 2, -1, -1, 5, 4, -1, -1, -1, -1, 5, 4, -1, -1, -1, -1]}, {"doc_id": "emerging.test_300", "sentence": ["\u2581[", "\u2581Answer", "e", "d", "\u2581here", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Answer", "e", "d", "\u2581here", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581Answer", "e", "d", "\u2581here", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_301", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581It", "'", "\u2581", "s", "\u2581the", "\u2581body", "\u2581of", "\u2581", "a", "\u25812", "\u2581time", "\u2581Super", "\u2581Bowl", "\u2581MVP", ",", "\u2581god", "dam", "mit", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581It", "'", "\u2581", "s", "\u2581the", "\u2581body", "\u2581of", "\u2581", "a", "\u25812", "\u2581time", "\u2581Super", "\u2581Bowl", "\u2581MVP", ",", "\u2581god", "dam", "mit", ".", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581It", "'", "\u2581", "s", "\u2581the", "\u2581body", "\u2581of", "\u2581", "a", "\u25812", "\u2581time", "<m>", "\u2581Super", "\u2581Bowl", "</m>", "\u2581MVP", ",", "\u2581god", "dam", "mit", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_302", "sentence": ["\u2581Ge", "ez", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ge", "ez", ".", "</s>"], "target_sentence": ["\u2581Ge", "ez", ".", "</s>"], "subtoken_map": [0, 0, 1, 2], "ent_type_sequence": [-1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1]}, {"doc_id": "emerging.test_303", "sentence": ["\u2581He", "'", "\u2581", "s", "\u2581", "a", "\u2581", "~", "\u2581", "~", "\u2581not", "-", "s", "o", "-", "\u2581", "~", "\u2581", "~", "\u2581silent", "\u2581guard", "i", "an", ",", "\u2581", "a", "\u2581watch", "ful", "\u2581protector", ",", "\u2581", "a", "\u2581Dark", "\u2581Knight", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581He", "'", "\u2581", "s", "\u2581", "a", "\u2581", "~", "\u2581", "~", "\u2581not", "-", "s", "o", "-", "\u2581", "~", "\u2581", "~", "\u2581silent", "\u2581guard", "i", "an", ",", "\u2581", "a", "\u2581watch", "ful", "\u2581protector", ",", "\u2581", "a", "\u2581Dark", "\u2581Knight", ".", "</s>"], "target_sentence": ["\u2581He", "'", "\u2581", "s", "\u2581", "a", "\u2581", "~", "\u2581", "~", "\u2581not", "-", "s", "o", "-", "\u2581", "~", "\u2581", "~", "\u2581silent", "\u2581guard", "i", "an", ",", "\u2581", "a", "\u2581watch", "ful", "\u2581protector", ",", "\u2581", "a", "<m>", "<m>", "\u2581Dark", "\u2581Knight", "</m>", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 10, 10, 10, 11, 12, 12, 13, 13, 14, 15, 16, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1]}, {"doc_id": "emerging.test_304", "sentence": ["\u2581", "er", "r", "\u2581you", "\u2581commented", "\u2581on", "\u2581Z", "l", "at", "an", "\u2581[", "\u2581right", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "my", "r", "5", "v", "/", "z", "l", "at", "an", "_", "i", "bra", "him", "ovic", "_", "win", "s", "_", "de", "f", "am", "ation", "_", "case", "_", "over", "/", "d", "c", "7", "m", "jon", "/", ")", "\u2581in", "\u2581", "a", "\u2581thread", "\u2581where", "\u2581the", "\u2581headline", "\u2581literally", "\u2581contains", "\u2581the", "\u2581phrase", "\u2581\"", "\u2581", "alleged", "\u2581do", "ping", "\u2581alle", "g", "ation", "\u2581\"", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "er", "r", "\u2581you", "\u2581commented", "\u2581on", "\u2581Z", "l", "at", "an", "\u2581[", "\u2581right", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "my", "r", "5", "v", "/", "z", "l", "at", "an", "_", "i", "bra", "him", "ovic", "_", "win", "s", "_", "de", "f", "am", "ation", "_", "case", "_", "over", "/", "d", "c", "7", "m", "jon", "/", ")", "\u2581in", "\u2581", "a", "\u2581thread", "\u2581where", "\u2581the", "\u2581headline", "\u2581literally", "\u2581contains", "\u2581the", "\u2581phrase", "\u2581\"", "\u2581", "alleged", "\u2581do", "ping", "\u2581alle", "g", "ation", "\u2581\"", ".", "</s>"], "target_sentence": ["\u2581", "er", "r", "\u2581you", "\u2581commented", "\u2581on", "<m>", "<m>", "<m>", "\u2581Z", "l", "at", "an", "</m>", "</m>", "</m>", "\u2581[", "\u2581right", "\u2581here", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "my", "r", "5", "v", "/", "z", "l", "at", "an", "_", "i", "bra", "him", "ovic", "_", "win", "s", "_", "de", "f", "am", "ation", "_", "case", "_", "over", "/", "d", "c", "7", "m", "jon", "/", ")", "\u2581in", "\u2581", "a", "\u2581thread", "\u2581where", "\u2581the", "\u2581headline", "\u2581literally", "\u2581contains", "\u2581the", "\u2581phrase", "\u2581\"", "\u2581", "alleged", "\u2581do", "ping", "\u2581alle", "g", "ation", "\u2581\"", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 24, 25, 25, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 2, 1, 0, -1, -1, -1, -1, 2, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_305", "sentence": ["\u2581Le", "l", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Le", "l", "</s>"], "target_sentence": ["\u2581Le", "l", "</s>"], "subtoken_map": [0, 0, 1], "ent_type_sequence": [-1, -1, -1], "ent_indices": [-1, -1, -1]}, {"doc_id": "emerging.test_306", "sentence": ["\u2581There", "'", "\u2581", "s", "\u2581no", "\u2581problem", "\u2581wanting", "\u2581to", "\u2581feed", "\u2581them", ",", "\u2581but", "\u2581please", ",", "\u2581read", "\u2581the", "\u2581guide", "\u2581from", "\u2581Zealand", "i", "a", "\u2581before", "\u2581doing", "\u2581so", ":", "\u2581[", "\u2581Fee", "d", "ing", "\u2581birds", "\u2581at", "\u2581home", "]", "\u2581(", "\u2581http", "://", "www", ".", "vis", "itz", "e", "al", "and", "i", "a", ".", "com", "/", "Port", "als", "/", "0", "/", "F", "eed", "ing", "%", "20", "B", "i", "r", "d", "s", "%", "20", "at", "%", "20", "Home", ".", "pdf", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581There", "'", "\u2581", "s", "\u2581no", "\u2581problem", "\u2581wanting", "\u2581to", "\u2581feed", "\u2581them", ",", "\u2581but", "\u2581please", ",", "\u2581read", "\u2581the", "\u2581guide", "\u2581from", "\u2581Zealand", "i", "a", "\u2581before", "\u2581doing", "\u2581so", ":", "\u2581[", "\u2581Fee", "d", "ing", "\u2581birds", "\u2581at", "\u2581home", "]", "\u2581(", "\u2581http", "://", "www", ".", "vis", "itz", "e", "al", "and", "i", "a", ".", "com", "/", "Port", "als", "/", "0", "/", "F", "eed", "ing", "%", "20", "B", "i", "r", "d", "s", "%", "20", "at", "%", "20", "Home", ".", "pdf", ")", "</s>"], "target_sentence": ["\u2581There", "'", "\u2581", "s", "\u2581no", "\u2581problem", "\u2581wanting", "\u2581to", "\u2581feed", "\u2581them", ",", "\u2581but", "\u2581please", ",", "\u2581read", "\u2581the", "\u2581guide", "\u2581from", "<m>", "\u2581Zealand", "i", "a", "</m>", "\u2581before", "\u2581doing", "\u2581so", ":", "\u2581[", "\u2581Fee", "d", "ing", "\u2581birds", "\u2581at", "\u2581home", "]", "\u2581(", "\u2581http", "://", "www", ".", "vis", "itz", "e", "al", "and", "i", "a", ".", "com", "/", "Port", "als", "/", "0", "/", "F", "eed", "ing", "%", "20", "B", "i", "r", "d", "s", "%", "20", "at", "%", "20", "Home", ".", "pdf", ")", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 18, 19, 20, 21, 22, 23, 23, 23, 24, 25, 26, 27, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_307", "sentence": ["\u2581It", "\u2581happens", "\u2581on", "\u2581United", "\u2581related", "\u2581posts", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "\u2581happens", "\u2581on", "\u2581United", "\u2581related", "\u2581posts", ".", "</s>"], "target_sentence": ["\u2581It", "\u2581happens", "\u2581on", "\u2581United", "\u2581related", "\u2581posts", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_308", "sentence": ["\u2581Tru", "d", "eau", "\u2581hanging", "\u2581out", "\u2581with", "\u2581his", "\u2581brother", ".", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Tru", "d", "eau", "\u2581hanging", "\u2581out", "\u2581with", "\u2581his", "\u2581brother", ".", ".", ".", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Tru", "d", "eau", "</m>", "</m>", "\u2581hanging", "\u2581out", "\u2581with", "\u2581his", "\u2581brother", ".", ".", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [1, 0, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_309", "sentence": ["\u2581[", "\u2581So", "\u2581that", "\u2581random", "\u2581website", "\u2581Sky", "\u2581Sports", "\u2581quoted", "\u2581was", "\u2581correct", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "r", "9", "r", "s", "3/", "sky", "_", "sport", "s", "_", "just", "_", "see", "m", "_", "to", "_", "open", "ly", "_", "not", "_", "give", "_", "a", "_", "f", "uck", "/", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581So", "\u2581that", "\u2581random", "\u2581website", "\u2581Sky", "\u2581Sports", "\u2581quoted", "\u2581was", "\u2581correct", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "r", "9", "r", "s", "3/", "sky", "_", "sport", "s", "_", "just", "_", "see", "m", "_", "to", "_", "open", "ly", "_", "not", "_", "give", "_", "a", "_", "f", "uck", "/", ")", "</s>"], "target_sentence": ["\u2581[", "\u2581So", "\u2581that", "\u2581random", "\u2581website", "<m>", "\u2581Sky", "\u2581Sports", "</m>", "\u2581quoted", "\u2581was", "\u2581correct", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "occ", "er", "/", "com", "ments", "/5", "r", "9", "r", "s", "3/", "sky", "_", "sport", "s", "_", "just", "_", "see", "m", "_", "to", "_", "open", "ly", "_", "not", "_", "give", "_", "a", "_", "f", "uck", "/", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_310", "sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581Jay", "\u2581911", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "\u2581Jay", "\u2581911", "</s>"], "target_sentence": ["\u2581*", "\u2581*", "\u2581red", "d", "it", "or", "\u2581*", "\u2581*", ":", "<m>", "\u2581Jay", "\u2581911", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1]}, {"doc_id": "emerging.test_311", "sentence": ["\u2581What", "\u2581Mont", "ans", "K", "it", "ten", "S", "igh", "s", "\u2581says", "\u2581has", "\u2581nothing", "\u2581to", "\u2581do", "\u2581with", "\u2581me", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581Mont", "ans", "K", "it", "ten", "S", "igh", "s", "\u2581says", "\u2581has", "\u2581nothing", "\u2581to", "\u2581do", "\u2581with", "\u2581me", ".", "</s>"], "target_sentence": ["\u2581What", "<m>", "\u2581Mont", "ans", "K", "it", "ten", "S", "igh", "s", "</m>", "\u2581says", "\u2581has", "\u2581nothing", "\u2581to", "\u2581do", "\u2581with", "\u2581me", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_312", "sentence": ["\u2581[", "\u2581Oh", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Oh", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581Oh", ".", "</s>"], "subtoken_map": [0, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1]}, {"doc_id": "emerging.test_313", "sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581has", "\u2581no", "\u2581problem", "\u2581with", "\u2581thread", "s", "\u2581about", "\u2581hate", "\u2581crimes", ",", "\u2581as", "\u2581long", "\u2581at", "\u2581they", "'", "\u2581", "re", "\u2581being", "\u2581", "attributed", "\u2581to", "\u2581Trump", "\u2581supporters", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581has", "\u2581no", "\u2581problem", "\u2581with", "\u2581thread", "s", "\u2581about", "\u2581hate", "\u2581crimes", ",", "\u2581as", "\u2581long", "\u2581at", "\u2581they", "'", "\u2581", "re", "\u2581being", "\u2581", "attributed", "\u2581to", "\u2581Trump", "\u2581supporters", ".", "</s>"], "target_sentence": ["\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581politics", "\u2581has", "\u2581no", "\u2581problem", "\u2581with", "\u2581thread", "s", "\u2581about", "\u2581hate", "\u2581crimes", ",", "\u2581as", "\u2581long", "\u2581at", "\u2581they", "'", "\u2581", "re", "\u2581being", "\u2581", "attributed", "\u2581to", "<m>", "<m>", "\u2581Trump", "</m>", "</m>", "\u2581supporters", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_314", "sentence": ["\u2581Looking", "\u2581at", "\u2581you", ",", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581Tru", "F", "al", "con", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Looking", "\u2581at", "\u2581you", ",", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581Tru", "F", "al", "con", ".", "</s>"], "target_sentence": ["\u2581Looking", "\u2581at", "\u2581you", ",", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581Tru", "F", "al", "con", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_315", "sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Are", "\u2581you", "\u2581hoping", "\u2581that", "\u2581someone", "\u2581in", "\u2581R", "\u2581", "/", "\u2581Calgary", "\u2581just", "\u2581happens", "\u2581to", "\u2581be", "\u2581", "a", "\u2581stock", "\u2581shelf", "er", "\u2581there", "\u2581or", "\u2581has", "\u2581an", "\u2581extremely", "\u2581intimate", "\u2581knowledge", "\u2581of", "\u2581all", "\u2581of", "\u2581their", "\u25811", "\u2581million", "\u2581items", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581Are", "\u2581you", "\u2581hoping", "\u2581that", "\u2581someone", "\u2581in", "\u2581R", "\u2581", "/", "\u2581Calgary", "\u2581just", "\u2581happens", "\u2581to", "\u2581be", "\u2581", "a", "\u2581stock", "\u2581shelf", "er", "\u2581there", "\u2581or", "\u2581has", "\u2581an", "\u2581extremely", "\u2581intimate", "\u2581knowledge", "\u2581of", "\u2581all", "\u2581of", "\u2581their", "\u25811", "\u2581million", "\u2581items", "?", "</s>"], "target_sentence": ["\u2581", "&", "\u2581", "g", "t", ";", "\u2581Are", "\u2581you", "\u2581hoping", "\u2581that", "\u2581someone", "\u2581in", "\u2581R", "\u2581", "/", "<m>", "<m>", "\u2581Calgary", "</m>", "</m>", "\u2581just", "\u2581happens", "\u2581to", "\u2581be", "\u2581", "a", "\u2581stock", "\u2581shelf", "er", "\u2581there", "\u2581or", "\u2581has", "\u2581an", "\u2581extremely", "\u2581intimate", "\u2581knowledge", "\u2581of", "\u2581all", "\u2581of", "\u2581their", "\u25811", "\u2581million", "\u2581items", "?", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_316", "sentence": ["\u2581I", "\u2581am", "\u2581not", "\u2581", "a", "\u2581huge", "\u2581support", "er", "\u2581of", "\u2581Cor", "by", "n", ",", "\u2581", "ive", "\u2581been", "\u2581rather", "\u2581critical", "\u2581of", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581his", "\u2581moves", "\u2581recently", "\u2581but", "\u2581I", "\u2581like", "\u2581the", "\u2581idea", "\u2581of", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581his", "\u2581policies", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581am", "\u2581not", "\u2581", "a", "\u2581huge", "\u2581support", "er", "\u2581of", "\u2581Cor", "by", "n", ",", "\u2581", "ive", "\u2581been", "\u2581rather", "\u2581critical", "\u2581of", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581his", "\u2581moves", "\u2581recently", "\u2581but", "\u2581I", "\u2581like", "\u2581the", "\u2581idea", "\u2581of", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581his", "\u2581policies", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581am", "\u2581not", "\u2581", "a", "\u2581huge", "\u2581support", "er", "\u2581of", "<m>", "<m>", "\u2581Cor", "by", "n", "</m>", "</m>", ",", "\u2581", "ive", "\u2581been", "\u2581rather", "\u2581critical", "\u2581of", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581his", "\u2581moves", "\u2581recently", "\u2581but", "\u2581I", "\u2581like", "\u2581the", "\u2581idea", "\u2581of", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581his", "\u2581policies", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 7, 7, 8, 9, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_317", "sentence": ["\u2581Of", "\u2581course", "\u2581there", "\u2581are", "\u2581some", "\u2581Leave", "\u2581supporters", "\u2581who", "\u2581are", "\u2581not", "\u2581against", "\u2581immigration", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Of", "\u2581course", "\u2581there", "\u2581are", "\u2581some", "\u2581Leave", "\u2581supporters", "\u2581who", "\u2581are", "\u2581not", "\u2581against", "\u2581immigration", ".", "</s>"], "target_sentence": ["\u2581Of", "\u2581course", "\u2581there", "\u2581are", "\u2581some", "<m>", "<m>", "\u2581Leave", "</m>", "</m>", "\u2581supporters", "\u2581who", "\u2581are", "\u2581not", "\u2581against", "\u2581immigration", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_318", "sentence": ["\u2581Hat", "e", "\u2581crime", "\u2581confirmed", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hat", "e", "\u2581crime", "\u2581confirmed", "</s>"], "target_sentence": ["\u2581Hat", "e", "\u2581crime", "\u2581confirmed", "</s>"], "subtoken_map": [0, 0, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_319", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581pretty", "\u2581sure", "\u2581this", "\u2581rarely", "\u2581happens", "\u2581in", "\u2581Europe", "\u2581but", "\u2581it", "'", "\u2581", "s", "\u2581still", "\u2581wrong", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581pretty", "\u2581sure", "\u2581this", "\u2581rarely", "\u2581happens", "\u2581in", "\u2581Europe", "\u2581but", "\u2581it", "'", "\u2581", "s", "\u2581still", "\u2581wrong", ".", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "m", "\u2581pretty", "\u2581sure", "\u2581this", "\u2581rarely", "\u2581happens", "\u2581in", "<m>", "<m>", "\u2581Europe", "</m>", "</m>", "\u2581but", "\u2581it", "'", "\u2581", "s", "\u2581still", "\u2581wrong", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_320", "sentence": ["\u2581", "Despite", "\u2581being", "\u2581", "a", "\u2581politically", "\u2581motivated", "\u2581hate", "\u2581crime", "\u2581this", "\u2581was", "\u2581removed", "\u2581by", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581", "luc", "a", "star", "s", "\u2581because", "\u2581of", "\u2581\"", "\u2581Off", "\u2581Topic", ".", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Despite", "\u2581being", "\u2581", "a", "\u2581politically", "\u2581motivated", "\u2581hate", "\u2581crime", "\u2581this", "\u2581was", "\u2581removed", "\u2581by", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581", "luc", "a", "star", "s", "\u2581because", "\u2581of", "\u2581\"", "\u2581Off", "\u2581Topic", ".", "\u2581\"", "</s>"], "target_sentence": ["\u2581", "Despite", "\u2581being", "\u2581", "a", "\u2581politically", "\u2581motivated", "\u2581hate", "\u2581crime", "\u2581this", "\u2581was", "\u2581removed", "\u2581by", "\u2581", "/", "\u2581", "u", "\u2581", "/", "\u2581", "luc", "a", "star", "s", "\u2581because", "\u2581of", "\u2581\"", "\u2581Off", "\u2581Topic", ".", "\u2581\"", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 13, 14, 14, 14, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_321", "sentence": ["\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "y", "v", "q", "x", "t", "/", "good", "_", "mor", "n", "ing", "_", "s", "y", "d", "ney", "_", "gam", "ers", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581", "s", "y", "d", "ney", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "y", "v", "q", "x", "t", "/", "good", "_", "mor", "n", "ing", "_", "s", "y", "d", "ney", "_", "gam", "ers", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "\u2581", "s", "y", "d", "ney", "</s>"], "target_sentence": ["\u2581[", "\u2581Source", "]", "\u2581(", "\u2581https", "://", "www", ".", "red", "d", "it", ".", "com", "/", "r", "/", "s", "y", "d", "ney", "/", "com", "ments", "/5", "y", "v", "q", "x", "t", "/", "good", "_", "mor", "n", "ing", "_", "s", "y", "d", "ney", "_", "gam", "ers", "/", ")", "\u2581at", "\u2581", "/", "\u2581", "r", "\u2581", "/", "<m>", "\u2581", "s", "y", "d", "ney", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 7, 7, 8, 8, 9, 9, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_322", "sentence": ["\u2581Fantasy", "\u2581Drama", "\u2581Movie", "\u2581about", "\u2581", "a", "\u2581Girl", "\u2581Looking", "\u2581for", "\u2581her", "\u2581Father", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Fantasy", "\u2581Drama", "\u2581Movie", "\u2581about", "\u2581", "a", "\u2581Girl", "\u2581Looking", "\u2581for", "\u2581her", "\u2581Father", "</s>"], "target_sentence": ["\u2581Fantasy", "\u2581Drama", "\u2581Movie", "\u2581about", "\u2581", "a", "\u2581Girl", "\u2581Looking", "\u2581for", "\u2581her", "\u2581Father", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_323", "sentence": ["\u2581How", "\u2581does", "\u2581this", "\u2581answer", "\u2581the", "\u2581question", "?", "\u2581This", "\u2581is", "\u2581commentary", "\u2581at", "\u2581best", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581does", "\u2581this", "\u2581answer", "\u2581the", "\u2581question", "?", "\u2581This", "\u2581is", "\u2581commentary", "\u2581at", "\u2581best", ".", "</s>"], "target_sentence": ["\u2581How", "\u2581does", "\u2581this", "\u2581answer", "\u2581the", "\u2581question", "?", "\u2581This", "\u2581is", "\u2581commentary", "\u2581at", "\u2581best", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_324", "sentence": ["\u2581Path", "\u2581integral", "\u2581measure", "\u2581in", "\u2581Coleman", "'", "\u2581", "s", "\u2581\"", "\u2581A", "spect", "s", "\u2581of", "\u2581", "symmetry", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Path", "\u2581integral", "\u2581measure", "\u2581in", "\u2581Coleman", "'", "\u2581", "s", "\u2581\"", "\u2581A", "spect", "s", "\u2581of", "\u2581", "symmetry", "\u2581\"", "</s>"], "target_sentence": ["\u2581Path", "\u2581integral", "\u2581measure", "\u2581in", "<m>", "\u2581Coleman", "</m>", "'", "\u2581", "s", "\u2581\"", "<m>", "<m>", "\u2581A", "spect", "s", "\u2581of", "\u2581", "symmetry", "</m>", "</m>", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 8, 8, 9, 10, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, 2, 1, -1, -1]}, {"doc_id": "emerging.test_325", "sentence": ["\u2581No", ".", "\u2581It", "\u2581would", "\u2581be", "\u2581", "p", "\u2581equal", "s", "\u2581some", "\u2581specified", "\u2581value", "\u2581at", "\u2581some", "\u2581", "z", "\u2581elevation", ".", "\u2581This", "\u2581has", "\u2581to", "\u2581correspond", "\u2581to", "\u2581some", "\u2581known", "\u2581pressure", "\u2581at", "\u2581some", "\u2581known", "\u2581elevation", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581No", ".", "\u2581It", "\u2581would", "\u2581be", "\u2581", "p", "\u2581equal", "s", "\u2581some", "\u2581specified", "\u2581value", "\u2581at", "\u2581some", "\u2581", "z", "\u2581elevation", ".", "\u2581This", "\u2581has", "\u2581to", "\u2581correspond", "\u2581to", "\u2581some", "\u2581known", "\u2581pressure", "\u2581at", "\u2581some", "\u2581known", "\u2581elevation", ".", "</s>"], "target_sentence": ["\u2581No", ".", "\u2581It", "\u2581would", "\u2581be", "\u2581", "p", "\u2581equal", "s", "\u2581some", "\u2581specified", "\u2581value", "\u2581at", "\u2581some", "\u2581", "z", "\u2581elevation", ".", "\u2581This", "\u2581has", "\u2581to", "\u2581correspond", "\u2581to", "\u2581some", "\u2581known", "\u2581pressure", "\u2581at", "\u2581some", "\u2581known", "\u2581elevation", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_326", "sentence": ["\u2581This", "\u2581is", "\u2581wrong", ",", "\u2581Electric", "\u2581field", "\u2581is", "\u2581non", "con", "serv", "ative", "\u2581when", "\u2581magnetic", "\u2581field", "\u2581is", "\u2581changing", "\u2581and", "\u2581you", "\u2581cannot", "\u2581apply", "\u2581Kirch", "hoff", "'", "\u2581", "s", "\u2581law", "\u2581then", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581is", "\u2581wrong", ",", "\u2581Electric", "\u2581field", "\u2581is", "\u2581non", "con", "serv", "ative", "\u2581when", "\u2581magnetic", "\u2581field", "\u2581is", "\u2581changing", "\u2581and", "\u2581you", "\u2581cannot", "\u2581apply", "\u2581Kirch", "hoff", "'", "\u2581", "s", "\u2581law", "\u2581then", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581is", "\u2581wrong", ",", "\u2581Electric", "\u2581field", "\u2581is", "\u2581non", "con", "serv", "ative", "\u2581when", "\u2581magnetic", "\u2581field", "\u2581is", "\u2581changing", "\u2581and", "\u2581you", "\u2581cannot", "\u2581apply", "<m>", "\u2581Kirch", "hoff", "</m>", "'", "\u2581", "s", "\u2581law", "\u2581then", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_327", "sentence": ["\u2581Looking", "\u2581up", "\u2581touchscreen", "\u2581history", "\u2581", "-", "\u2581found", "\u2581this", "\u25811981", "\u2581computer", "\u2581that", "\u2581used", "\u2581In", "f", "rare", "d", "\u2581to", "\u2581detect", "\u2581finger", "\u2581movement", ".", "\u2581", "Clearly", "\u2581Star", "\u2581Trek", "\u2581was", "\u2581an", "\u2581inspiration", ".", "\u2581https", "://", "en", ".", "wikipedia", ".", "org", "/", "wiki", "/", "To", "uch", "screen", "#", "/", "media", "/", "F", "ile", ":", "Plat", "o", "v", "term", "198", "1.", "jpg", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Looking", "\u2581up", "\u2581touchscreen", "\u2581history", "\u2581", "-", "\u2581found", "\u2581this", "\u25811981", "\u2581computer", "\u2581that", "\u2581used", "\u2581In", "f", "rare", "d", "\u2581to", "\u2581detect", "\u2581finger", "\u2581movement", ".", "\u2581", "Clearly", "\u2581Star", "\u2581Trek", "\u2581was", "\u2581an", "\u2581inspiration", ".", "\u2581https", "://", "en", ".", "wikipedia", ".", "org", "/", "wiki", "/", "To", "uch", "screen", "#", "/", "media", "/", "F", "ile", ":", "Plat", "o", "v", "term", "198", "1.", "jpg", "</s>"], "target_sentence": ["\u2581Looking", "\u2581up", "\u2581touchscreen", "\u2581history", "\u2581", "-", "\u2581found", "\u2581this", "\u25811981", "\u2581computer", "\u2581that", "\u2581used", "\u2581In", "f", "rare", "d", "\u2581to", "\u2581detect", "\u2581finger", "\u2581movement", ".", "\u2581", "Clearly", "<m>", "<m>", "\u2581Star", "\u2581Trek", "</m>", "</m>", "\u2581was", "\u2581an", "\u2581inspiration", ".", "\u2581https", "://", "en", ".", "wikipedia", ".", "org", "/", "wiki", "/", "To", "uch", "screen", "#", "/", "media", "/", "F", "ile", ":", "Plat", "o", "v", "term", "198", "1.", "jpg", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_328", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581", "referring", "\u2581to", "\u2581the", "\u2581ones", "\u2581newly", "\u2581introduced", "\u2581in", "\u2581R", "ogue", "\u2581One", "\u2581", "-", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581remember", "\u2581", "if", "\u2581they", "\u2581were", "\u2581given", "\u2581", "a", "\u2581specific", "\u2581name", "\u2581", "-", "\u2581I", "\u2581only", "\u2581remember", "\u2581them", "\u2581being", "\u2581", "referred", "\u2581to", "\u2581as", "'", "\u2581Imperial", "\u2581Dr", "oids", "'", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581", "referring", "\u2581to", "\u2581the", "\u2581ones", "\u2581newly", "\u2581introduced", "\u2581in", "\u2581R", "ogue", "\u2581One", "\u2581", "-", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581remember", "\u2581", "if", "\u2581they", "\u2581were", "\u2581given", "\u2581", "a", "\u2581specific", "\u2581name", "\u2581", "-", "\u2581I", "\u2581only", "\u2581remember", "\u2581them", "\u2581being", "\u2581", "referred", "\u2581to", "\u2581as", "'", "\u2581Imperial", "\u2581Dr", "oids", "'", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "m", "\u2581", "referring", "\u2581to", "\u2581the", "\u2581ones", "\u2581newly", "\u2581introduced", "\u2581in", "<m>", "\u2581R", "ogue", "\u2581One", "</m>", "\u2581", "-", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581remember", "\u2581", "if", "\u2581they", "\u2581were", "\u2581given", "\u2581", "a", "\u2581specific", "\u2581name", "\u2581", "-", "\u2581I", "\u2581only", "\u2581remember", "\u2581them", "\u2581being", "\u2581", "referred", "\u2581to", "\u2581as", "'", "<m>", "\u2581Imperial", "\u2581Dr", "oids", "</m>", "'", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 15, 16, 17, 17, 18, 19, 19, 20, 21, 22, 23, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32, 32, 33, 34, 35, 36, 37, 37, 38, 39], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_329", "sentence": ["\u2581Religious", "\u2581persecution", "\u2581is", "\u2581", "hardly", "\u2581unique", "\u2581to", "\u2581commun", "ist", "\u2581countries", ".", "\u2581It", "'", "\u2581", "s", "\u2581practically", "\u2581universal", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Religious", "\u2581persecution", "\u2581is", "\u2581", "hardly", "\u2581unique", "\u2581to", "\u2581commun", "ist", "\u2581countries", ".", "\u2581It", "'", "\u2581", "s", "\u2581practically", "\u2581universal", ".", "</s>"], "target_sentence": ["\u2581Religious", "\u2581persecution", "\u2581is", "\u2581", "hardly", "\u2581unique", "\u2581to", "\u2581commun", "ist", "\u2581countries", ".", "\u2581It", "'", "\u2581", "s", "\u2581practically", "\u2581universal", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_330", "sentence": ["\u2581How", "\u2581would", "\u2581you", "\u2581class", "ify", "\u2581the", "\u2581documentary", "\u2581Trans", "c", "enden", "t", "\u2581Man", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581would", "\u2581you", "\u2581class", "ify", "\u2581the", "\u2581documentary", "\u2581Trans", "c", "enden", "t", "\u2581Man", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581would", "\u2581you", "\u2581class", "ify", "\u2581the", "\u2581documentary", "<m>", "\u2581Trans", "c", "enden", "t", "\u2581Man", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 6, 6, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_331", "sentence": ["\u2581Which", "\u2581protocol", "\u2581should", "\u2581I", "\u2581use", "\u2581for", "\u2581secure", "\u2581message", "\u2581transfers", "\u2581between", "\u2581two", "\u2581servers", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Which", "\u2581protocol", "\u2581should", "\u2581I", "\u2581use", "\u2581for", "\u2581secure", "\u2581message", "\u2581transfers", "\u2581between", "\u2581two", "\u2581servers", "?", "</s>"], "target_sentence": ["\u2581Which", "\u2581protocol", "\u2581should", "\u2581I", "\u2581use", "\u2581for", "\u2581secure", "\u2581message", "\u2581transfers", "\u2581between", "\u2581two", "\u2581servers", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_332", "sentence": ["\u2581As", "\u2581you", "\u2581mention", ",", "\u2581it", "\u2581the", "\u2581fact", "\u2581that", "\u2581the", "\u2581first", "\u2581", "polar", "iser", "'", "\u2581convert", "s", "'", "\u2581un", "polar", "ised", "\u2581light", "\u2581to", "\u2581", "polar", "ised", "\u2581light", "\u2581that", "\u2581does", "\u2581the", "\u2581majority", "\u2581of", "\u2581the", "\u2581perceived", "\u2581at", "ten", "u", "ation", ".", "\u2581For", "\u2581an", "\u2581interesting", "\u2581test", "\u2581(", "\u2581for", "\u2581the", "\u2581", "OP", "\u2581who", "\u2581has", "\u2581the", "\u2581sheets", ".", ".", ")", ",", "\u2581take", "\u2581the", "\u2581first", "\u2581two", "\u2581sheets", "\u2581and", "\u2581arrange", "\u2581them", "\u2581as", "\u2581", "a", "\u2581crossed", "\u2581", "polar", "iser", "\u2581at", "\u2581maximum", "\u2581", "extinction", ",", "\u2581then", "\u2581insert", "\u2581", "a", "\u2581third", "\u2581", "polar", "iser", "\u2581between", "\u2581them", "\u2581at", "\u2581", "a", "\u258145", "\u2581degree", "\u2581angle", ".", "\u2581What", "\u2581happens", "\u2581and", "\u2581Why", ".", ".", ".", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581As", "\u2581you", "\u2581mention", ",", "\u2581it", "\u2581the", "\u2581fact", "\u2581that", "\u2581the", "\u2581first", "\u2581", "polar", "iser", "'", "\u2581convert", "s", "'", "\u2581un", "polar", "ised", "\u2581light", "\u2581to", "\u2581", "polar", "ised", "\u2581light", "\u2581that", "\u2581does", "\u2581the", "\u2581majority", "\u2581of", "\u2581the", "\u2581perceived", "\u2581at", "ten", "u", "ation", ".", "\u2581For", "\u2581an", "\u2581interesting", "\u2581test", "\u2581(", "\u2581for", "\u2581the", "\u2581", "OP", "\u2581who", "\u2581has", "\u2581the", "\u2581sheets", ".", ".", ")", ",", "\u2581take", "\u2581the", "\u2581first", "\u2581two", "\u2581sheets", "\u2581and", "\u2581arrange", "\u2581them", "\u2581as", "\u2581", "a", "\u2581crossed", "\u2581", "polar", "iser", "\u2581at", "\u2581maximum", "\u2581", "extinction", ",", "\u2581then", "\u2581insert", "\u2581", "a", "\u2581third", "\u2581", "polar", "iser", "\u2581between", "\u2581them", "\u2581at", "\u2581", "a", "\u258145", "\u2581degree", "\u2581angle", ".", "\u2581What", "\u2581happens", "\u2581and", "\u2581Why", ".", ".", ".", "?", "</s>"], "target_sentence": ["\u2581As", "\u2581you", "\u2581mention", ",", "\u2581it", "\u2581the", "\u2581fact", "\u2581that", "\u2581the", "\u2581first", "\u2581", "polar", "iser", "'", "\u2581convert", "s", "'", "\u2581un", "polar", "ised", "\u2581light", "\u2581to", "\u2581", "polar", "ised", "\u2581light", "\u2581that", "\u2581does", "\u2581the", "\u2581majority", "\u2581of", "\u2581the", "\u2581perceived", "\u2581at", "ten", "u", "ation", ".", "\u2581For", "\u2581an", "\u2581interesting", "\u2581test", "\u2581(", "\u2581for", "\u2581the", "\u2581", "OP", "\u2581who", "\u2581has", "\u2581the", "\u2581sheets", ".", ".", ")", ",", "\u2581take", "\u2581the", "\u2581first", "\u2581two", "\u2581sheets", "\u2581and", "\u2581arrange", "\u2581them", "\u2581as", "\u2581", "a", "\u2581crossed", "\u2581", "polar", "iser", "\u2581at", "\u2581maximum", "\u2581", "extinction", ",", "\u2581then", "\u2581insert", "\u2581", "a", "\u2581third", "\u2581", "polar", "iser", "\u2581between", "\u2581them", "\u2581at", "\u2581", "a", "\u258145", "\u2581degree", "\u2581angle", ".", "\u2581What", "\u2581happens", "\u2581and", "\u2581Why", ".", ".", ".", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 12, 13, 14, 14, 14, 15, 16, 17, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 53, 54, 55, 55, 55, 56, 57, 58, 58, 59, 60, 61, 62, 62, 63, 64, 64, 64, 65, 66, 67, 68, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_333", "sentence": ["\u2581@", "\u2581not", "store", "b", "ough", "t", "dir", "t", "\u2581", "-", "\u2581", "Probably", "\u2581not", ".", "\u2581\"", "\u2581[", "\u2581C", "]", "\u2581on", "duct", "\u2581or", "\u2581motive", "\u2581un", "worthy", "\u2581or", "\u2581unbe", "coming", "\u2581", "a", "\u2581Senator", "\u2581\"", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581cover", "\u2581anything", "\u2581related", "\u2581to", "\u2581the", "\u2581job", "\u2581they", "\u2581will", "\u2581be", "\u2581taking", "\u2581or", "\u2581specific", "\u2581facts", "\u2581or", "\u2581commentary", "\u2581on", "\u2581the", "\u2581nominee", "'", "\u2581", "s", "\u2581qualifications", ".", "\u2581It", "\u2581only", "\u2581restrict", "s", "\u2581discussing", "\u2581*", "\u2581things", "\u2581that", "\u2581were", "\u2581done", "\u2581*", "\u2581(", "\u2581conduct", ")", "\u2581or", "\u2581the", "\u2581*", "\u2581reasons", "\u2581for", "\u2581them", "\u2581*", "\u2581(", "\u2581motive", ")", ".", "\u2581So", "\u2581\"", "\u2581You", "\u2581have", "\u2581no", "\u2581experience", "\u2581with", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581is", "\u2581valid", ",", "\u2581but", "\u2581\"", "\u2581You", "\u2581took", "\u2581", "bri", "be", "s", "\u2581from", "\u2581the", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581industry", "\u2581\"", "\u2581is", "\u2581not", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581not", "store", "b", "ough", "t", "dir", "t", "\u2581", "-", "\u2581", "Probably", "\u2581not", ".", "\u2581\"", "\u2581[", "\u2581C", "]", "\u2581on", "duct", "\u2581or", "\u2581motive", "\u2581un", "worthy", "\u2581or", "\u2581unbe", "coming", "\u2581", "a", "\u2581Senator", "\u2581\"", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581cover", "\u2581anything", "\u2581related", "\u2581to", "\u2581the", "\u2581job", "\u2581they", "\u2581will", "\u2581be", "\u2581taking", "\u2581or", "\u2581specific", "\u2581facts", "\u2581or", "\u2581commentary", "\u2581on", "\u2581the", "\u2581nominee", "'", "\u2581", "s", "\u2581qualifications", ".", "\u2581It", "\u2581only", "\u2581restrict", "s", "\u2581discussing", "\u2581*", "\u2581things", "\u2581that", "\u2581were", "\u2581done", "\u2581*", "\u2581(", "\u2581conduct", ")", "\u2581or", "\u2581the", "\u2581*", "\u2581reasons", "\u2581for", "\u2581them", "\u2581*", "\u2581(", "\u2581motive", ")", ".", "\u2581So", "\u2581\"", "\u2581You", "\u2581have", "\u2581no", "\u2581experience", "\u2581with", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581is", "\u2581valid", ",", "\u2581but", "\u2581\"", "\u2581You", "\u2581took", "\u2581", "bri", "be", "s", "\u2581from", "\u2581the", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581industry", "\u2581\"", "\u2581is", "\u2581not", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581not", "store", "b", "ough", "t", "dir", "t", "\u2581", "-", "\u2581", "Probably", "\u2581not", ".", "\u2581\"", "\u2581[", "\u2581C", "]", "\u2581on", "duct", "\u2581or", "\u2581motive", "\u2581un", "worthy", "\u2581or", "\u2581unbe", "coming", "\u2581", "a", "\u2581Senator", "\u2581\"", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581cover", "\u2581anything", "\u2581related", "\u2581to", "\u2581the", "\u2581job", "\u2581they", "\u2581will", "\u2581be", "\u2581taking", "\u2581or", "\u2581specific", "\u2581facts", "\u2581or", "\u2581commentary", "\u2581on", "\u2581the", "\u2581nominee", "'", "\u2581", "s", "\u2581qualifications", ".", "\u2581It", "\u2581only", "\u2581restrict", "s", "\u2581discussing", "\u2581*", "\u2581things", "\u2581that", "\u2581were", "\u2581done", "\u2581*", "\u2581(", "\u2581conduct", ")", "\u2581or", "\u2581the", "\u2581*", "\u2581reasons", "\u2581for", "\u2581them", "\u2581*", "\u2581(", "\u2581motive", ")", ".", "\u2581So", "\u2581\"", "\u2581You", "\u2581have", "\u2581no", "\u2581experience", "\u2581with", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581is", "\u2581valid", ",", "\u2581but", "\u2581\"", "\u2581You", "\u2581took", "\u2581", "bri", "be", "s", "\u2581from", "\u2581the", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581industry", "\u2581\"", "\u2581is", "\u2581not", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 13, 14, 15, 15, 16, 16, 17, 18, 19, 20, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 42, 43, 44, 45, 46, 47, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 76, 77, 77, 78, 78, 79, 79, 80, 80, 81, 81, 82, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 91, 91, 91, 92, 93, 94, 94, 95, 95, 96, 96, 97, 97, 98, 98, 99, 100, 101, 102, 103, 104], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_334", "sentence": ["\u2581Just", "\u2581wanted", "\u2581add", ",", "\u2581anyone", "\u2581notice", "\u2581that", "\u2581in", "\u2581the", "\u2581finale", ",", "\u2581French", "\u2581is", "\u2581dressed", "\u2581in", "\u2581the", "\u2581exact", "\u2581outfit", "\u2581that", "\u2581Home", "r", "\u2581was", "\u2581in", "\u2581from", "\u2581Cuba", "\u2581on", "ward", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Just", "\u2581wanted", "\u2581add", ",", "\u2581anyone", "\u2581notice", "\u2581that", "\u2581in", "\u2581the", "\u2581finale", ",", "\u2581French", "\u2581is", "\u2581dressed", "\u2581in", "\u2581the", "\u2581exact", "\u2581outfit", "\u2581that", "\u2581Home", "r", "\u2581was", "\u2581in", "\u2581from", "\u2581Cuba", "\u2581on", "ward", "s", "?", "</s>"], "target_sentence": ["\u2581Just", "\u2581wanted", "\u2581add", ",", "\u2581anyone", "\u2581notice", "\u2581that", "\u2581in", "\u2581the", "\u2581finale", ",", "\u2581French", "\u2581is", "\u2581dressed", "\u2581in", "\u2581the", "\u2581exact", "\u2581outfit", "\u2581that", "<m>", "\u2581Home", "r", "</m>", "\u2581was", "\u2581in", "\u2581from", "<m>", "\u2581Cuba", "</m>", "\u2581on", "ward", "s", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 24, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_335", "sentence": ["\u2581@", "\u2581S", "med", "ley", "DS", "lap", ",", "\u2581that", "\u2581sounds", "\u2581suspicious", "ly", "\u2581similar", "\u2581to", "\u2581Universal", "\u2581Basic", "\u2581Income", ",", "\u2581but", "\u2581not", "\u2581as", "\u2581good", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581S", "med", "ley", "DS", "lap", ",", "\u2581that", "\u2581sounds", "\u2581suspicious", "ly", "\u2581similar", "\u2581to", "\u2581Universal", "\u2581Basic", "\u2581Income", ",", "\u2581but", "\u2581not", "\u2581as", "\u2581good", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581S", "med", "ley", "DS", "lap", ",", "\u2581that", "\u2581sounds", "\u2581suspicious", "ly", "\u2581similar", "\u2581to", "<m>", "<m>", "\u2581Universal", "</m>", "\u2581Basic", "</m>", "\u2581Income", ",", "\u2581but", "\u2581not", "\u2581as", "\u2581good", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_336", "sentence": ["\u2581Science", "\u2581fiction", "\u2581novel", "\u2581about", "\u2581an", "\u2581as", "s", "assi", "n", "'", "\u2581", "s", "\u2581guild", "\u2581that", "\u2581claims", "\u2581to", "\u2581be", "\u2581", "a", "poli", "t", "ical", "\u2581(", "\u2581while", "\u2581doing", "\u2581the", "\u2581local", "\u2581", "t", "y", "rant", "'", "\u2581", "s", "\u2581dirty", "\u2581work", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Science", "\u2581fiction", "\u2581novel", "\u2581about", "\u2581an", "\u2581as", "s", "assi", "n", "'", "\u2581", "s", "\u2581guild", "\u2581that", "\u2581claims", "\u2581to", "\u2581be", "\u2581", "a", "poli", "t", "ical", "\u2581(", "\u2581while", "\u2581doing", "\u2581the", "\u2581local", "\u2581", "t", "y", "rant", "'", "\u2581", "s", "\u2581dirty", "\u2581work", ")", "</s>"], "target_sentence": ["\u2581Science", "\u2581fiction", "\u2581novel", "\u2581about", "\u2581an", "\u2581as", "s", "assi", "n", "'", "\u2581", "s", "\u2581guild", "\u2581that", "\u2581claims", "\u2581to", "\u2581be", "\u2581", "a", "poli", "t", "ical", "\u2581(", "\u2581while", "\u2581doing", "\u2581the", "\u2581local", "\u2581", "t", "y", "rant", "'", "\u2581", "s", "<m>", "\u2581dirty", "\u2581work", "</m>", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 20, 21, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_337", "sentence": ["\u2581What", "\u2581exactly", "\u2581is", "\u2581Trump", "'", "\u2581", "s", "\u2581economic", "\u2581policy", ",", "\u2581and", "\u2581is", "\u2581it", "\u2581consistent", "\u2581with", "\u2581his", "\u2581previous", "\u2581statements", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581exactly", "\u2581is", "\u2581Trump", "'", "\u2581", "s", "\u2581economic", "\u2581policy", ",", "\u2581and", "\u2581is", "\u2581it", "\u2581consistent", "\u2581with", "\u2581his", "\u2581previous", "\u2581statements", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581exactly", "\u2581is", "<m>", "\u2581Trump", "'", "\u2581", "s", "</m>", "\u2581economic", "\u2581policy", ",", "\u2581and", "\u2581is", "\u2581it", "\u2581consistent", "\u2581with", "\u2581his", "\u2581previous", "\u2581statements", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_338", "sentence": ["\u2581@", "\u2581ale", "x", "w", "l", "chan", "\u2581", "-", "\u2581You", "'", "\u2581", "re", "\u2581right", ".", "\u2581I", "'", "\u2581", "ve", "\u2581added", "\u2581it", "\u2581to", "\u2581my", "\u2581answer", "\u2581below", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581ale", "x", "w", "l", "chan", "\u2581", "-", "\u2581You", "'", "\u2581", "re", "\u2581right", ".", "\u2581I", "'", "\u2581", "ve", "\u2581added", "\u2581it", "\u2581to", "\u2581my", "\u2581answer", "\u2581below", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581ale", "x", "w", "l", "chan", "\u2581", "-", "\u2581You", "'", "\u2581", "re", "\u2581right", ".", "\u2581I", "'", "\u2581", "ve", "\u2581added", "\u2581it", "\u2581to", "\u2581my", "\u2581answer", "\u2581below", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_339", "sentence": ["\u2581I", "\u2581vote", "\u2581to", "\u2581", "re", "open", ".", "\u2581This", "\u2581does", "\u2581show", "\u2581effort", "\u2581and", "\u2581is", "\u2581about", "\u2581", "a", "\u2581", "physics", "\u2581concept", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581vote", "\u2581to", "\u2581", "re", "open", ".", "\u2581This", "\u2581does", "\u2581show", "\u2581effort", "\u2581and", "\u2581is", "\u2581about", "\u2581", "a", "\u2581", "physics", "\u2581concept", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581vote", "\u2581to", "\u2581", "re", "open", ".", "\u2581This", "\u2581does", "\u2581show", "\u2581effort", "\u2581and", "\u2581is", "\u2581about", "\u2581", "a", "\u2581", "physics", "\u2581concept", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_340", "sentence": ["\u2581But", "\u2581keep", "\u2581in", "\u2581mind", "\u2581that", "\u2581", "tru", "mp", "\u2581expressed", "\u2581his", "\u2581hatred", "\u2581for", "\u2581snow", "den", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581But", "\u2581keep", "\u2581in", "\u2581mind", "\u2581that", "\u2581", "tru", "mp", "\u2581expressed", "\u2581his", "\u2581hatred", "\u2581for", "\u2581snow", "den", "</s>"], "target_sentence": ["\u2581But", "\u2581keep", "\u2581in", "\u2581mind", "\u2581that", "\u2581", "tru", "mp", "\u2581expressed", "\u2581his", "\u2581hatred", "\u2581for", "\u2581snow", "den", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_341", "sentence": ["\u2581", "Identify", "\u2581The", "\u2581Day", "\u2581of", "\u2581the", "\u2581Doctor", "\u2581old", "\u2581shots", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Identify", "\u2581The", "\u2581Day", "\u2581of", "\u2581the", "\u2581Doctor", "\u2581old", "\u2581shots", "</s>"], "target_sentence": ["\u2581", "Identify", "<m>", "\u2581The", "\u2581Day", "\u2581of", "\u2581the", "\u2581Doctor", "</m>", "\u2581old", "\u2581shots", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_342", "sentence": ["\u2581$", "\u2581", "SU", "\u2581(", "\u25812", ")", "\u2581", "_", "\u2581L", "\u2581$", "\u2581Gau", "ge", "\u2581theory", "\u2581and", "\u2581particle", "-", "anti", "p", "article", "\u2581", "anni", "h", "il", "ation", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581$", "\u2581", "SU", "\u2581(", "\u25812", ")", "\u2581", "_", "\u2581L", "\u2581$", "\u2581Gau", "ge", "\u2581theory", "\u2581and", "\u2581particle", "-", "anti", "p", "article", "\u2581", "anni", "h", "il", "ation", "</s>"], "target_sentence": ["\u2581$", "\u2581", "SU", "\u2581(", "\u25812", ")", "\u2581", "_", "\u2581L", "\u2581$", "\u2581Gau", "ge", "\u2581theory", "\u2581and", "\u2581particle", "-", "anti", "p", "article", "\u2581", "anni", "h", "il", "ation", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_343", "sentence": ["\u2581", "h", "mm", "n", "n", ".", ".", ".", "\u2581maybe", ".", "\u2581Sorry", ",", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581sure", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581help", "\u2581you", "\u2581but", "\u2581maybe", "\u2581would", "\u2581be", "\u2581as", "\u2581simple", "\u2581as", "\u2581\"", "\u2581give", "\u2581it", "\u2581to", "\u2581them", "\u2581", "if", "\u2581you", "\u2581trust", "\u2581them", "\u2581\"", ".", "\u2581If", "\u2581not", ",", "\u2581ask", "\u2581why", "\u2581and", "\u2581why", "\u2581and", "\u2581why", "\u2581until", "\u2581they", "\u2581give", "\u2581you", "\u2581", "a", "\u2581reasonable", "\u2581reason", "\u2581or", "\u2581", "if", "\u2581not", ",", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581give", "\u2581to", "\u2581them", "\u2581the", "\u2581documents", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "h", "mm", "n", "n", ".", ".", ".", "\u2581maybe", ".", "\u2581Sorry", ",", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581sure", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581help", "\u2581you", "\u2581but", "\u2581maybe", "\u2581would", "\u2581be", "\u2581as", "\u2581simple", "\u2581as", "\u2581\"", "\u2581give", "\u2581it", "\u2581to", "\u2581them", "\u2581", "if", "\u2581you", "\u2581trust", "\u2581them", "\u2581\"", ".", "\u2581If", "\u2581not", ",", "\u2581ask", "\u2581why", "\u2581and", "\u2581why", "\u2581and", "\u2581why", "\u2581until", "\u2581they", "\u2581give", "\u2581you", "\u2581", "a", "\u2581reasonable", "\u2581reason", "\u2581or", "\u2581", "if", "\u2581not", ",", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581give", "\u2581to", "\u2581them", "\u2581the", "\u2581documents", ".", "</s>"], "target_sentence": ["\u2581", "h", "mm", "n", "n", ".", ".", ".", "\u2581maybe", ".", "\u2581Sorry", ",", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581sure", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581help", "\u2581you", "\u2581but", "\u2581maybe", "\u2581would", "\u2581be", "\u2581as", "\u2581simple", "\u2581as", "\u2581\"", "\u2581give", "\u2581it", "\u2581to", "\u2581them", "\u2581", "if", "\u2581you", "\u2581trust", "\u2581them", "\u2581\"", ".", "\u2581If", "\u2581not", ",", "\u2581ask", "\u2581why", "\u2581and", "\u2581why", "\u2581and", "\u2581why", "\u2581until", "\u2581they", "\u2581give", "\u2581you", "\u2581", "a", "\u2581reasonable", "\u2581reason", "\u2581or", "\u2581", "if", "\u2581not", ",", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581give", "\u2581to", "\u2581them", "\u2581the", "\u2581documents", ".", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 50, 51, 52, 53, 54, 54, 55, 56, 57, 58, 58, 59, 60, 60, 61, 62, 63, 64, 65, 66, 67], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_344", "sentence": ["\u2581how", "\u2581long", "\u2581is", "\u2581\"", "\u2581", "a", "\u2581few", "\u2581years", "\u2581back", "\u2581\"", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581how", "\u2581long", "\u2581is", "\u2581\"", "\u2581", "a", "\u2581few", "\u2581years", "\u2581back", "\u2581\"", "?", "</s>"], "target_sentence": ["\u2581how", "\u2581long", "\u2581is", "\u2581\"", "\u2581", "a", "\u2581few", "\u2581years", "\u2581back", "\u2581\"", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_345", "sentence": ["\u2581@", "\u2581pe", "la", "\u2581Ok", "\u2581Thank", "u", ".", "\u2581Will", "\u2581search", "\u2581for", "\u2581it", ".", "\u2581Learn", "\u2581it", "\u2581when", "\u2581it", "\u2581calls", ".", "\u2581Thank", "u", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581pe", "la", "\u2581Ok", "\u2581Thank", "u", ".", "\u2581Will", "\u2581search", "\u2581for", "\u2581it", ".", "\u2581Learn", "\u2581it", "\u2581when", "\u2581it", "\u2581calls", ".", "\u2581Thank", "u", "</s>"], "target_sentence": ["\u2581@", "\u2581pe", "la", "\u2581Ok", "\u2581Thank", "u", ".", "\u2581Will", "\u2581search", "\u2581for", "\u2581it", ".", "\u2581Learn", "\u2581it", "\u2581when", "\u2581it", "\u2581calls", ".", "\u2581Thank", "u", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_346", "sentence": ["\u2581@", "\u2581Gall", "if", "re", "y", "an", "\u2581Give", "\u2581the", "\u2581people", "\u2581what", "\u2581they", "\u2581want", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Gall", "if", "re", "y", "an", "\u2581Give", "\u2581the", "\u2581people", "\u2581what", "\u2581they", "\u2581want", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Gall", "if", "re", "y", "an", "\u2581Give", "\u2581the", "\u2581people", "\u2581what", "\u2581they", "\u2581want", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_347", "sentence": ["\u2581When", "\u2581did", "\u2581Clay", "\u2581become", "\u2581", "a", "\u2581phone", "r", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581When", "\u2581did", "\u2581Clay", "\u2581become", "\u2581", "a", "\u2581phone", "r", "?", "</s>"], "target_sentence": ["\u2581When", "\u2581did", "<m>", "\u2581Clay", "</m>", "\u2581become", "\u2581", "a", "\u2581phone", "r", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_348", "sentence": ["\u2581In", "\u2581the", "\u2581Travel", "\u2581Ban", "\u2581Executive", "\u2581order", "\u2581", "-", "\u2581What", "\u2581is", "\u2581the", "\u2581\"", "\u2581Bio", "metric", "\u2581Entry", "-", "\u2581Ex", "it", "\u2581Track", "ing", "\u2581System", "?", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581In", "\u2581the", "\u2581Travel", "\u2581Ban", "\u2581Executive", "\u2581order", "\u2581", "-", "\u2581What", "\u2581is", "\u2581the", "\u2581\"", "\u2581Bio", "metric", "\u2581Entry", "-", "\u2581Ex", "it", "\u2581Track", "ing", "\u2581System", "?", "\u2581\"", "</s>"], "target_sentence": ["\u2581In", "\u2581the", "\u2581Travel", "\u2581Ban", "\u2581Executive", "\u2581order", "\u2581", "-", "\u2581What", "\u2581is", "\u2581the", "\u2581\"", "\u2581Bio", "metric", "\u2581Entry", "-", "\u2581Ex", "it", "\u2581Track", "ing", "\u2581System", "?", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_349", "sentence": ["\u2581Why", "\u2581were", "\u2581Olive", "\u2581and", "\u2581Emma", "'", "\u2581", "s", "\u2581powers", "\u2581changed", "\u2581in", "\u2581Miss", "\u2581Per", "e", "grin", "e", "'", "\u2581", "s", "\u2581Home", "\u2581for", "\u2581Pe", "cul", "i", "ar", "\u2581Children", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581were", "\u2581Olive", "\u2581and", "\u2581Emma", "'", "\u2581", "s", "\u2581powers", "\u2581changed", "\u2581in", "\u2581Miss", "\u2581Per", "e", "grin", "e", "'", "\u2581", "s", "\u2581Home", "\u2581for", "\u2581Pe", "cul", "i", "ar", "\u2581Children", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581were", "<m>", "\u2581Olive", "</m>", "\u2581and", "<m>", "\u2581Emma", "</m>", "'", "\u2581", "s", "\u2581powers", "\u2581changed", "\u2581in", "<m>", "<m>", "<m>", "\u2581Miss", "\u2581Per", "e", "grin", "e", "</m>", "</m>", "</m>", "'", "\u2581", "s", "<m>", "\u2581Home", "\u2581for", "\u2581Pe", "cul", "i", "ar", "\u2581Children", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 11, 11, 12, 13, 13, 14, 15, 16, 16, 16, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, 0, -1, 0, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 3, 2, 4, -1, -1, -1, -1, -1, 3, 2, 4, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1]}, {"doc_id": "emerging.test_350", "sentence": ["\u2581This", "\u2581is", "\u2581", "a", "\u2581great", "\u2581example", "\u2581of", "\u2581", "a", "\u2581scale", "\u2581error", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581is", "\u2581", "a", "\u2581great", "\u2581example", "\u2581of", "\u2581", "a", "\u2581scale", "\u2581error", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581is", "\u2581", "a", "\u2581great", "\u2581example", "\u2581of", "\u2581", "a", "\u2581scale", "\u2581error", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_351", "sentence": ["\u2581What", "\u2581", "explains", "\u2581the", "\u2581connection", "\u2581between", "\u2581the", "\u2581boat", "'", "\u2581", "s", "\u2581name", "\u2581and", "\u2581Lee", "'", "\u2581", "s", "\u2581daughter", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581", "explains", "\u2581the", "\u2581connection", "\u2581between", "\u2581the", "\u2581boat", "'", "\u2581", "s", "\u2581name", "\u2581and", "\u2581Lee", "'", "\u2581", "s", "\u2581daughter", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581", "explains", "\u2581the", "\u2581connection", "\u2581between", "\u2581the", "\u2581boat", "'", "\u2581", "s", "\u2581name", "\u2581and", "<m>", "\u2581Lee", "</m>", "'", "\u2581", "s", "\u2581daughter", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_352", "sentence": ["\u2581Why", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581", "a", "\u2581standard", "\u2581for", "\u2581encrypted", "\u2581but", "\u2581open", "\u2581WiFi", "\u2581developed", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581", "a", "\u2581standard", "\u2581for", "\u2581encrypted", "\u2581but", "\u2581open", "\u2581WiFi", "\u2581developed", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581", "a", "\u2581standard", "\u2581for", "\u2581encrypted", "\u2581but", "\u2581open", "<m>", "\u2581WiFi", "</m>", "\u2581developed", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_353", "sentence": ["\u2581Old", "\u2581novel", "\u2581of", "\u2581", "a", "\u2581hunt", "er", "\u2581on", "\u2581", "a", "\u2581man", "-", "e", "ating", "\u2581island", ";", "\u2581", "he", "\u2581has", "\u2581to", "\u2581escape", "\u2581from", "\u2581another", "\u2581hunt", "er", "\u2581who", "\u2581would", "\u2581try", "\u2581to", "\u2581kill", "\u2581him", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Old", "\u2581novel", "\u2581of", "\u2581", "a", "\u2581hunt", "er", "\u2581on", "\u2581", "a", "\u2581man", "-", "e", "ating", "\u2581island", ";", "\u2581", "he", "\u2581has", "\u2581to", "\u2581escape", "\u2581from", "\u2581another", "\u2581hunt", "er", "\u2581who", "\u2581would", "\u2581try", "\u2581to", "\u2581kill", "\u2581him", "</s>"], "target_sentence": ["\u2581Old", "\u2581novel", "\u2581of", "\u2581", "a", "\u2581hunt", "er", "\u2581on", "\u2581", "a", "\u2581man", "-", "e", "ating", "<m>", "\u2581island", "</m>", ";", "\u2581", "he", "\u2581has", "\u2581to", "\u2581escape", "\u2581from", "\u2581another", "\u2581hunt", "er", "\u2581who", "\u2581would", "\u2581try", "\u2581to", "\u2581kill", "\u2581him", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 5, 6, 6, 7, 7, 7, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_354", "sentence": ["\u2581", "s", "en", "ate", "\u2581", "democrat", "s", "\u2581eliminated", "\u2581the", "\u2581nuclear", "\u2581option", "\u2581when", "\u2581they", "\u2581had", "\u2581the", "\u2581majority", "\u2581", "a", "\u2581few", "\u2581years", "\u2581ago", ",", "\u2581over", "\u2581republic", "an", "\u2581objection", "s", ".", "\u2581the", "\u2581republic", "ans", "\u2581warned", "\u2581that", "\u2581without", "\u2581the", "\u2581nuclear", "\u2581option", ",", "\u2581the", "\u2581", "democrat", "s", "\u2581could", "\u2581lose", "\u2581", "a", "\u2581powerful", "\u2581means", "\u2581to", "\u2581stop", "\u2581the", "\u2581republic", "an", "\u2581administration", "\u2581nominee", "s", "\u2581", "if", "\u2581", "/", "\u2581when", "\u2581the", "\u2581table", "\u2581is", "\u2581turned", ".", "\u2581well", ",", "\u2581the", "\u2581", "democrat", "s", "\u2581today", "\u2581would", "\u2581have", "\u2581loved", "\u2581to", "\u2581und", "o", "\u2581what", "\u2581they", "\u2581enthusiastic", "ally", "\u2581did", "\u2581", "a", "\u2581few", "\u2581year", "\u2581back", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "s", "en", "ate", "\u2581", "democrat", "s", "\u2581eliminated", "\u2581the", "\u2581nuclear", "\u2581option", "\u2581when", "\u2581they", "\u2581had", "\u2581the", "\u2581majority", "\u2581", "a", "\u2581few", "\u2581years", "\u2581ago", ",", "\u2581over", "\u2581republic", "an", "\u2581objection", "s", ".", "\u2581the", "\u2581republic", "ans", "\u2581warned", "\u2581that", "\u2581without", "\u2581the", "\u2581nuclear", "\u2581option", ",", "\u2581the", "\u2581", "democrat", "s", "\u2581could", "\u2581lose", "\u2581", "a", "\u2581powerful", "\u2581means", "\u2581to", "\u2581stop", "\u2581the", "\u2581republic", "an", "\u2581administration", "\u2581nominee", "s", "\u2581", "if", "\u2581", "/", "\u2581when", "\u2581the", "\u2581table", "\u2581is", "\u2581turned", ".", "\u2581well", ",", "\u2581the", "\u2581", "democrat", "s", "\u2581today", "\u2581would", "\u2581have", "\u2581loved", "\u2581to", "\u2581und", "o", "\u2581what", "\u2581they", "\u2581enthusiastic", "ally", "\u2581did", "\u2581", "a", "\u2581few", "\u2581year", "\u2581back", ".", "</s>"], "target_sentence": ["\u2581", "s", "en", "ate", "\u2581", "democrat", "s", "\u2581eliminated", "\u2581the", "\u2581nuclear", "\u2581option", "\u2581when", "\u2581they", "\u2581had", "\u2581the", "\u2581majority", "\u2581", "a", "\u2581few", "\u2581years", "\u2581ago", ",", "\u2581over", "\u2581republic", "an", "\u2581objection", "s", ".", "\u2581the", "\u2581republic", "ans", "\u2581warned", "\u2581that", "\u2581without", "\u2581the", "\u2581nuclear", "\u2581option", ",", "\u2581the", "\u2581", "democrat", "s", "\u2581could", "\u2581lose", "\u2581", "a", "\u2581powerful", "\u2581means", "\u2581to", "\u2581stop", "\u2581the", "\u2581republic", "an", "\u2581administration", "\u2581nominee", "s", "\u2581", "if", "\u2581", "/", "\u2581when", "\u2581the", "\u2581table", "\u2581is", "\u2581turned", ".", "\u2581well", ",", "\u2581the", "\u2581", "democrat", "s", "\u2581today", "\u2581would", "\u2581have", "\u2581loved", "\u2581to", "\u2581und", "o", "\u2581what", "\u2581they", "\u2581enthusiastic", "ally", "\u2581did", "\u2581", "a", "\u2581few", "\u2581year", "\u2581back", ".", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 18, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 30, 31, 32, 33, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 41, 42, 42, 43, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 53, 53, 54, 55, 56, 57, 58, 59, 59, 60, 61, 62, 62, 63, 64, 64, 65, 66, 67, 68, 69], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_355", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581best", "\u2581to", "\u2581consider", "\u2581*", "\u2581Vo", "y", "ager", "\u2581*", "\u2581as", "\u2581", "a", "\u2581whole", "\u2581as", "\u2581non", "-", "can", "on", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581best", "\u2581to", "\u2581consider", "\u2581*", "\u2581Vo", "y", "ager", "\u2581*", "\u2581as", "\u2581", "a", "\u2581whole", "\u2581as", "\u2581non", "-", "can", "on", ".", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581best", "\u2581to", "\u2581consider", "\u2581*", "<m>", "\u2581Vo", "y", "ager", "</m>", "\u2581*", "\u2581as", "\u2581", "a", "\u2581whole", "\u2581as", "\u2581non", "-", "can", "on", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 7, 8, 9, 10, 10, 11, 12, 13, 13, 13, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_356", "sentence": ["\u2581Why", "\u2581was", "\u2581por", "y", "gon", "\u2581in", "\u2581this", "\u2581episode", "\u2581of", "\u2581Pok\u00e9mon", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581was", "\u2581por", "y", "gon", "\u2581in", "\u2581this", "\u2581episode", "\u2581of", "\u2581Pok\u00e9mon", "</s>"], "target_sentence": ["\u2581Why", "\u2581was", "<m>", "\u2581por", "y", "gon", "</m>", "\u2581in", "\u2581this", "\u2581episode", "\u2581of", "<m>", "<m>", "\u2581Pok\u00e9mon", "</m>", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, 1, 2, -1, 1, 2, -1]}, {"doc_id": "emerging.test_357", "sentence": ["\u2581About", "\u2581role", "\u2581of", "\u2581", "a", "\u2581minister", "\u2581in", "\u2581Parliament", "\u2581who", "\u2581is", "\u2581not", "\u2581", "a", "\u2581member", "\u2581of", "\u2581either", "\u2581house", "\u2581of", "\u2581Parliament", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581About", "\u2581role", "\u2581of", "\u2581", "a", "\u2581minister", "\u2581in", "\u2581Parliament", "\u2581who", "\u2581is", "\u2581not", "\u2581", "a", "\u2581member", "\u2581of", "\u2581either", "\u2581house", "\u2581of", "\u2581Parliament", ".", "</s>"], "target_sentence": ["\u2581About", "\u2581role", "\u2581of", "\u2581", "a", "\u2581minister", "\u2581in", "<m>", "\u2581Parliament", "</m>", "\u2581who", "\u2581is", "\u2581not", "\u2581", "a", "\u2581member", "\u2581of", "\u2581either", "\u2581house", "\u2581of", "<m>", "\u2581Parliament", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_358", "sentence": ["\u2581Server", "\u2581key", "\u2581length", "\u2581in", "\u2581Open", "S", "SH", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Server", "\u2581key", "\u2581length", "\u2581in", "\u2581Open", "S", "SH", "</s>"], "target_sentence": ["\u2581Server", "\u2581key", "\u2581length", "\u2581in", "\u2581Open", "S", "SH", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_359", "sentence": ["\u2581In", "\u2581my", "\u2581judgment", ",", "\u2581the", "\u2581goal", "\u2581is", "\u2581to", "\u2581determine", "\u2581the", "\u2581torque", "\u2581about", "\u2581the", "\u2581", "COM", ".", "\u2581This", "\u2581can", "\u2581then", "\u2581be", "\u2581set", "\u2581equal", "\u2581to", "\u2581the", "\u2581", "ang", "ular", "\u2581acceleration", "\u2581times", "\u2581the", "\u2581moment", "\u2581of", "\u2581in", "er", "tial", "\u2581about", "\u2581the", "\u2581", "COM", ".", "\u2581We", "\u2581can", "\u2581get", "\u2581this", "\u2581torque", "\u2581about", "\u2581the", "\u2581", "COM", "\u2581using", "\u2581any", "\u2581other", "\u2581point", "\u2581as", "\u2581the", "\u2581", "axi", "s", "\u2581of", "\u2581rotation", "\u2581by", "\u2581including", "\u2581the", "\u2581pseudo", "\u2581force", "\u2581through", "\u2581the", "\u2581", "COM", "\u2581and", "\u2581the", "\u2581moment", "\u2581it", "\u2581produces", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581In", "\u2581my", "\u2581judgment", ",", "\u2581the", "\u2581goal", "\u2581is", "\u2581to", "\u2581determine", "\u2581the", "\u2581torque", "\u2581about", "\u2581the", "\u2581", "COM", ".", "\u2581This", "\u2581can", "\u2581then", "\u2581be", "\u2581set", "\u2581equal", "\u2581to", "\u2581the", "\u2581", "ang", "ular", "\u2581acceleration", "\u2581times", "\u2581the", "\u2581moment", "\u2581of", "\u2581in", "er", "tial", "\u2581about", "\u2581the", "\u2581", "COM", ".", "\u2581We", "\u2581can", "\u2581get", "\u2581this", "\u2581torque", "\u2581about", "\u2581the", "\u2581", "COM", "\u2581using", "\u2581any", "\u2581other", "\u2581point", "\u2581as", "\u2581the", "\u2581", "axi", "s", "\u2581of", "\u2581rotation", "\u2581by", "\u2581including", "\u2581the", "\u2581pseudo", "\u2581force", "\u2581through", "\u2581the", "\u2581", "COM", "\u2581and", "\u2581the", "\u2581moment", "\u2581it", "\u2581produces", ".", "</s>"], "target_sentence": ["\u2581In", "\u2581my", "\u2581judgment", ",", "\u2581the", "\u2581goal", "\u2581is", "\u2581to", "\u2581determine", "\u2581the", "\u2581torque", "\u2581about", "\u2581the", "\u2581", "COM", ".", "\u2581This", "\u2581can", "\u2581then", "\u2581be", "\u2581set", "\u2581equal", "\u2581to", "\u2581the", "\u2581", "ang", "ular", "\u2581acceleration", "\u2581times", "\u2581the", "\u2581moment", "\u2581of", "\u2581in", "er", "tial", "\u2581about", "\u2581the", "\u2581", "COM", ".", "\u2581We", "\u2581can", "\u2581get", "\u2581this", "\u2581torque", "\u2581about", "\u2581the", "\u2581", "COM", "\u2581using", "\u2581any", "\u2581other", "\u2581point", "\u2581as", "\u2581the", "\u2581", "axi", "s", "\u2581of", "\u2581rotation", "\u2581by", "\u2581including", "\u2581the", "\u2581pseudo", "\u2581force", "\u2581through", "\u2581the", "\u2581", "COM", "\u2581and", "\u2581the", "\u2581moment", "\u2581it", "\u2581produces", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 24, 25, 26, 27, 28, 29, 29, 29, 30, 31, 32, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 41, 42, 43, 44, 45, 46, 47, 48, 48, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 58, 59, 60, 61, 62, 63, 64, 65], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_360", "sentence": ["\u2581And", "\u2581one", "\u2581might", "\u2581also", "\u2581ask", ".", ".", ".", "\u2581*", "\u2581what", "\u2581was", "\u2581his", "\u2581plan", "\u2581there", ",", "\u2581anyway", "?", "!", "\u2581*", "\u2581How", "\u2581on", "\u2581earth", "\u2581did", "\u2581", "he", "\u2581know", "\u2581where", "'", "\u2581", "ll", "\u2581hit", "\u2581and", "\u2581who", "'", "\u2581", "ll", "\u2581hurt", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581And", "\u2581one", "\u2581might", "\u2581also", "\u2581ask", ".", ".", ".", "\u2581*", "\u2581what", "\u2581was", "\u2581his", "\u2581plan", "\u2581there", ",", "\u2581anyway", "?", "!", "\u2581*", "\u2581How", "\u2581on", "\u2581earth", "\u2581did", "\u2581", "he", "\u2581know", "\u2581where", "'", "\u2581", "ll", "\u2581hit", "\u2581and", "\u2581who", "'", "\u2581", "ll", "\u2581hurt", "?", "</s>"], "target_sentence": ["\u2581And", "\u2581one", "\u2581might", "\u2581also", "\u2581ask", ".", ".", ".", "\u2581*", "\u2581what", "\u2581was", "\u2581his", "\u2581plan", "\u2581there", ",", "\u2581anyway", "?", "!", "\u2581*", "\u2581How", "\u2581on", "\u2581earth", "\u2581did", "\u2581", "he", "\u2581know", "\u2581where", "'", "\u2581", "ll", "\u2581hit", "\u2581and", "\u2581who", "'", "\u2581", "ll", "\u2581hurt", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 27, 28, 29, 30, 31, 32, 32, 33, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_361", "sentence": ["\u2581what", "\u2581do", "\u2581we", "\u2581mean", "\u2581by", "'", "\u2581regular", "\u2581person", "'", ".", "\u2581Has", "\u2581", "n", "'", "\u2581", "t", "\u2581Rick", "\u2581only", "\u2581ever", "\u2581explained", "\u2581what", "\u2581Dimension", "\u2581", "he", "\u2581is", "\u2581from", "\u2581to", "\u2581those", "\u2581individuals", "\u2581who", "\u2581are", "\u2581aware", "\u2581of", "\u2581multiple", "\u2581Dimension", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581what", "\u2581do", "\u2581we", "\u2581mean", "\u2581by", "'", "\u2581regular", "\u2581person", "'", ".", "\u2581Has", "\u2581", "n", "'", "\u2581", "t", "\u2581Rick", "\u2581only", "\u2581ever", "\u2581explained", "\u2581what", "\u2581Dimension", "\u2581", "he", "\u2581is", "\u2581from", "\u2581to", "\u2581those", "\u2581individuals", "\u2581who", "\u2581are", "\u2581aware", "\u2581of", "\u2581multiple", "\u2581Dimension", "s", "?", "</s>"], "target_sentence": ["\u2581what", "\u2581do", "\u2581we", "\u2581mean", "\u2581by", "'", "\u2581regular", "\u2581person", "'", ".", "\u2581Has", "\u2581", "n", "'", "\u2581", "t", "<m>", "\u2581Rick", "</m>", "\u2581only", "\u2581ever", "\u2581explained", "\u2581what", "\u2581Dimension", "\u2581", "he", "\u2581is", "\u2581from", "\u2581to", "\u2581those", "\u2581individuals", "\u2581who", "\u2581are", "\u2581aware", "\u2581of", "\u2581multiple", "\u2581Dimension", "s", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 31, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_362", "sentence": ["\u2581Ok", ",", "\u2581thanks", ".", "\u2581What", "'", "\u2581", "s", "\u2581the", "\u2581difference", "\u2581between", "\u2581ball", "istic", "\u2581gal", "van", "ometer", "\u2581and", "\u2581classic", "\u2581gal", "van", "ometer", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ok", ",", "\u2581thanks", ".", "\u2581What", "'", "\u2581", "s", "\u2581the", "\u2581difference", "\u2581between", "\u2581ball", "istic", "\u2581gal", "van", "ometer", "\u2581and", "\u2581classic", "\u2581gal", "van", "ometer", "?", "</s>"], "target_sentence": ["\u2581Ok", ",", "\u2581thanks", ".", "\u2581What", "'", "\u2581", "s", "\u2581the", "\u2581difference", "\u2581between", "<m>", "\u2581ball", "istic", "\u2581gal", "van", "ometer", "</m>", "\u2581and", "<m>", "\u2581classic", "\u2581gal", "van", "ometer", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 11, 11, 11, 12, 13, 14, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, 2, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_363", "sentence": ["\u2581Hi", "\u2581Gar", "van", "\u2581and", "\u2581welcome", "\u2581to", "\u2581the", "\u2581Physics", "\u2581SE", "!", "\u2581Please", "\u2581note", "\u2581that", "\u2581this", "\u2581is", "\u2581not", "\u2581", "a", "\u2581homework", "\u2581help", "\u2581site", ".", "\u2581Please", "\u2581see", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581on", "\u2581asking", "\u2581homework", "\u2581questions", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/7", "14", "/", "how", "-", "d", "o", "-", "i", "-", "a", "s", "k", "-", "home", "work", "-", "quest", "ions", "-", "on", "-", "physics", "-", "s", "t", "ack", "-", "ex", "change", ")", "\u2581and", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581for", "\u2581\"", "\u2581check", "\u2581my", "\u2581work", "\u2581\"", "\u2581problems", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/6", "09", "3/", "should", "-", "any", "-", "check", "-", "my", "-", "work", "-", "quest", "ions", "-", "be", "-", "made", "-", "on", "-", "topic", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hi", "\u2581Gar", "van", "\u2581and", "\u2581welcome", "\u2581to", "\u2581the", "\u2581Physics", "\u2581SE", "!", "\u2581Please", "\u2581note", "\u2581that", "\u2581this", "\u2581is", "\u2581not", "\u2581", "a", "\u2581homework", "\u2581help", "\u2581site", ".", "\u2581Please", "\u2581see", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581on", "\u2581asking", "\u2581homework", "\u2581questions", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/7", "14", "/", "how", "-", "d", "o", "-", "i", "-", "a", "s", "k", "-", "home", "work", "-", "quest", "ions", "-", "on", "-", "physics", "-", "s", "t", "ack", "-", "ex", "change", ")", "\u2581and", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581for", "\u2581\"", "\u2581check", "\u2581my", "\u2581work", "\u2581\"", "\u2581problems", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/6", "09", "3/", "should", "-", "any", "-", "check", "-", "my", "-", "work", "-", "quest", "ions", "-", "be", "-", "made", "-", "on", "-", "topic", ")", ".", "</s>"], "target_sentence": ["\u2581Hi", "<m>", "\u2581Gar", "van", "</m>", "\u2581and", "\u2581welcome", "\u2581to", "\u2581the", "\u2581Physics", "\u2581SE", "!", "\u2581Please", "\u2581note", "\u2581that", "\u2581this", "\u2581is", "\u2581not", "\u2581", "a", "\u2581homework", "\u2581help", "\u2581site", ".", "\u2581Please", "\u2581see", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581on", "\u2581asking", "\u2581homework", "\u2581questions", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/7", "14", "/", "how", "-", "d", "o", "-", "i", "-", "a", "s", "k", "-", "home", "work", "-", "quest", "ions", "-", "on", "-", "physics", "-", "s", "t", "ack", "-", "ex", "change", ")", "\u2581and", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581for", "\u2581\"", "\u2581check", "\u2581my", "\u2581work", "\u2581\"", "\u2581problems", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/6", "09", "3/", "should", "-", "any", "-", "check", "-", "my", "-", "work", "-", "quest", "ions", "-", "be", "-", "made", "-", "on", "-", "topic", ")", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 50, 51], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_364", "sentence": ["\u2581I", "s", "\u2581it", "\u2581safe", "\u2581to", "\u2581download", "\u2581internet", "\u2581files", "\u2581over", "\u2581", "TOR", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581it", "\u2581safe", "\u2581to", "\u2581download", "\u2581internet", "\u2581files", "\u2581over", "\u2581", "TOR", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581it", "\u2581safe", "\u2581to", "\u2581download", "\u2581internet", "\u2581files", "\u2581over", "<m>", "\u2581", "TOR", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1]}, {"doc_id": "emerging.test_365", "sentence": ["\u2581Java", "\u2581", "Object", "\u2581encryption", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Java", "\u2581", "Object", "\u2581encryption", "</s>"], "target_sentence": ["\u2581Java", "\u2581", "Object", "\u2581encryption", "</s>"], "subtoken_map": [0, 1, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_366", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581so", "\u2581sure", "\u2581that", "\u2581there", "\u2581is", "\u2581", "a", "\u2581significant", "\u2581anti", "-", "\u2581Eastern", "\u2581Europe", "\u2581vibe", "\u2581among", "\u2581the", "\u2581parties", "\u2581mentioned", ".", "\u2581Politic", "ians", "\u2581like", "\u2581Or", "ban", "\u2581are", "\u2581", "viewed", "\u2581as", "\u2581leaders", "\u2581acting", "\u2581in", "\u2581their", "\u2581national", "\u2581interest", ",", "\u2581which", "\u2581might", "\u2581not", "\u2581align", "\u2581with", "\u2581Western", "\u2581European", "\u2581interests", "\u2581but", "\u2581they", "\u2581are", "\u2581still", "\u2581respected", "\u2581for", "\u2581by", "\u2581other", "\u2581national", "ist", "s", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581so", "\u2581sure", "\u2581that", "\u2581there", "\u2581is", "\u2581", "a", "\u2581significant", "\u2581anti", "-", "\u2581Eastern", "\u2581Europe", "\u2581vibe", "\u2581among", "\u2581the", "\u2581parties", "\u2581mentioned", ".", "\u2581Politic", "ians", "\u2581like", "\u2581Or", "ban", "\u2581are", "\u2581", "viewed", "\u2581as", "\u2581leaders", "\u2581acting", "\u2581in", "\u2581their", "\u2581national", "\u2581interest", ",", "\u2581which", "\u2581might", "\u2581not", "\u2581align", "\u2581with", "\u2581Western", "\u2581European", "\u2581interests", "\u2581but", "\u2581they", "\u2581are", "\u2581still", "\u2581respected", "\u2581for", "\u2581by", "\u2581other", "\u2581national", "ist", "s", ".", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581so", "\u2581sure", "\u2581that", "\u2581there", "\u2581is", "\u2581", "a", "\u2581significant", "\u2581anti", "-", "<m>", "\u2581Eastern", "\u2581Europe", "</m>", "\u2581vibe", "\u2581among", "\u2581the", "\u2581parties", "\u2581mentioned", ".", "\u2581Politic", "ians", "\u2581like", "<m>", "\u2581Or", "ban", "</m>", "\u2581are", "\u2581", "viewed", "\u2581as", "\u2581leaders", "\u2581acting", "\u2581in", "\u2581their", "\u2581national", "\u2581interest", ",", "\u2581which", "\u2581might", "\u2581not", "\u2581align", "\u2581with", "<m>", "\u2581Western", "\u2581European", "</m>", "\u2581interests", "\u2581but", "\u2581they", "\u2581are", "\u2581still", "\u2581respected", "\u2581for", "\u2581by", "\u2581other", "\u2581national", "ist", "s", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 49, 49, 50, 51], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_367", "sentence": ["\u2581I", "s", "\u2581it", "\u2581OK", "\u2581to", "\u2581pass", "\u2581credentials", "\u2581to", "\u2581the", "\u2581client", "\u2581to", "\u2581allow", "\u2581it", "\u2581to", "\u2581upload", "\u2581files", "\u2581to", "\u2581Amazon", "\u2581S", "\u25813", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581it", "\u2581OK", "\u2581to", "\u2581pass", "\u2581credentials", "\u2581to", "\u2581the", "\u2581client", "\u2581to", "\u2581allow", "\u2581it", "\u2581to", "\u2581upload", "\u2581files", "\u2581to", "\u2581Amazon", "\u2581S", "\u25813", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581it", "\u2581OK", "\u2581to", "\u2581pass", "\u2581credentials", "\u2581to", "\u2581the", "\u2581client", "\u2581to", "\u2581allow", "\u2581it", "\u2581to", "\u2581upload", "\u2581files", "\u2581to", "<m>", "<m>", "\u2581Amazon", "</m>", "\u2581S", "\u25813", "</m>", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_368", "sentence": ["\u2581This", "\u2581is", "\u2581no", "\u2581joke", "\u2581my", "\u2581friend", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581is", "\u2581no", "\u2581joke", "\u2581my", "\u2581friend", "!", "</s>"], "target_sentence": ["\u2581This", "\u2581is", "\u2581no", "\u2581joke", "\u2581my", "\u2581friend", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_369", "sentence": ["\u2581the", "\u2581reason", "\u2581why", "\u2581I", "\u2581ask", "\u2581is", "\u2581because", "\u2581I", "\u2581want", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581create", "\u2581", "a", "\u2581", "java", ".", "\u2581security", ".", "\u2581Public", "Key", "\u2581object", "\u2581with", "\u2581the", "\u2581by", "tes", "\u2581and", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581how", "\u2581to", "\u2581do", "\u2581that", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581the", "\u2581reason", "\u2581why", "\u2581I", "\u2581ask", "\u2581is", "\u2581because", "\u2581I", "\u2581want", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581create", "\u2581", "a", "\u2581", "java", ".", "\u2581security", ".", "\u2581Public", "Key", "\u2581object", "\u2581with", "\u2581the", "\u2581by", "tes", "\u2581and", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581how", "\u2581to", "\u2581do", "\u2581that", ".", "</s>"], "target_sentence": ["\u2581the", "\u2581reason", "\u2581why", "\u2581I", "\u2581ask", "\u2581is", "\u2581because", "\u2581I", "\u2581want", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581create", "\u2581", "a", "<m>", "\u2581", "java", "</m>", ".", "\u2581security", ".", "<m>", "\u2581Public", "Key", "</m>", "\u2581object", "\u2581with", "\u2581the", "\u2581by", "tes", "\u2581and", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581how", "\u2581to", "\u2581do", "\u2581that", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 15, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 27, 28, 29, 29, 30, 31, 32, 33, 34, 35, 36], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_370", "sentence": ["\u2581Can", "\u2581the", "\u2581president", "\u2581", "a", "p", "point", "\u2581him", "-", "\u2581or", "\u2581herself", "\u2581to", "\u2581the", "\u2581Supreme", "\u2581Court", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Can", "\u2581the", "\u2581president", "\u2581", "a", "p", "point", "\u2581him", "-", "\u2581or", "\u2581herself", "\u2581to", "\u2581the", "\u2581Supreme", "\u2581Court", "?", "</s>"], "target_sentence": ["\u2581Can", "\u2581the", "\u2581president", "\u2581", "a", "p", "point", "\u2581him", "-", "\u2581or", "\u2581herself", "\u2581to", "\u2581the", "<m>", "\u2581Supreme", "\u2581Court", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_371", "sentence": ["\u2581\"", "\u2581A", "\u2581rather", "\u2581larger", "\u2581body", ",", "\u2581", "varying", "\u2581at", "\u2581need", ",", "\u2581was", "\u2581employed", "\u2581to", "'", "\u2581beat", "\u2581the", "\u2581bound", "s", "'", ",", "\u2581and", "\u2581to", "\u2581see", "\u2581that", "\u2581Outside", "r", "s", "\u2581of", "\u2581any", "\u2581kind", ",", "\u2581great", "\u2581or", "\u2581small", ",", "\u2581did", "\u2581not", "\u2581make", "\u2581themselves", "\u2581", "a", "\u2581nuisance", ".", "\u2581\"", "\u2581Not", "\u2581sure", "\u2581exactly", "\u2581how", "\u2581that", "\u2581needs", "\u2581to", "\u2581be", "\u2581", "interpreted", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\"", "\u2581A", "\u2581rather", "\u2581larger", "\u2581body", ",", "\u2581", "varying", "\u2581at", "\u2581need", ",", "\u2581was", "\u2581employed", "\u2581to", "'", "\u2581beat", "\u2581the", "\u2581bound", "s", "'", ",", "\u2581and", "\u2581to", "\u2581see", "\u2581that", "\u2581Outside", "r", "s", "\u2581of", "\u2581any", "\u2581kind", ",", "\u2581great", "\u2581or", "\u2581small", ",", "\u2581did", "\u2581not", "\u2581make", "\u2581themselves", "\u2581", "a", "\u2581nuisance", ".", "\u2581\"", "\u2581Not", "\u2581sure", "\u2581exactly", "\u2581how", "\u2581that", "\u2581needs", "\u2581to", "\u2581be", "\u2581", "interpreted", ".", "</s>"], "target_sentence": ["\u2581\"", "\u2581A", "\u2581rather", "\u2581larger", "\u2581body", ",", "\u2581", "varying", "\u2581at", "\u2581need", ",", "\u2581was", "\u2581employed", "\u2581to", "'", "\u2581beat", "\u2581the", "\u2581bound", "s", "'", ",", "\u2581and", "\u2581to", "\u2581see", "\u2581that", "\u2581Outside", "r", "s", "\u2581of", "\u2581any", "\u2581kind", ",", "\u2581great", "\u2581or", "\u2581small", ",", "\u2581did", "\u2581not", "\u2581make", "\u2581themselves", "\u2581", "a", "\u2581nuisance", ".", "\u2581\"", "\u2581Not", "\u2581sure", "\u2581exactly", "\u2581how", "\u2581that", "\u2581needs", "\u2581to", "\u2581be", "\u2581", "interpreted", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 48, 49, 50], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_372", "sentence": ["\u2581But", "\u2581is", "\u2581", "ry", "ll", "\u2581mine", "d", "\u2581on", "\u2581K", "essel", "?", "\u2581They", "\u2581mention", "\u2581that", "\u2581planet", "\u2581in", "\u2581A", "NH", ",", "\u2581and", "\u2581then", "\u2581never", "\u2581again", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581But", "\u2581is", "\u2581", "ry", "ll", "\u2581mine", "d", "\u2581on", "\u2581K", "essel", "?", "\u2581They", "\u2581mention", "\u2581that", "\u2581planet", "\u2581in", "\u2581A", "NH", ",", "\u2581and", "\u2581then", "\u2581never", "\u2581again", ".", "</s>"], "target_sentence": ["\u2581But", "\u2581is", "\u2581", "ry", "ll", "\u2581mine", "d", "\u2581on", "\u2581K", "essel", "?", "\u2581They", "\u2581mention", "\u2581that", "\u2581planet", "\u2581in", "<m>", "\u2581A", "NH", "</m>", ",", "\u2581and", "\u2581then", "\u2581never", "\u2581again", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_373", "sentence": ["\u2581@", "\u2581", "X", "ante", "c", ".", "\u2581You", "'", "\u2581", "re", "\u2581right", ",", "\u2581it", "\u2581is", ".", "\u2581The", "\u2581Ho", "g", "war", "t", "s", "\u2581staff", "\u2581member", "\u2581", "delivering", "\u2581the", "\u2581letter", "\u2581would", "\u2581be", "\u2581expected", "\u2581to", "\u2581mention", "\u2581Dia", "gon", "\u2581Alle", "y", "\u2581(", "\u2581as", "\u2581D", "umble", "d", "or", "e", "\u2581did", ")", ".", "\u2581Hag", "rid", "\u2581neglected", "\u2581to", "\u2581do", "\u2581this", "\u2581by", "\u2581just", "\u2581posting", "\u2581the", "\u2581letter", "\u2581through", "\u2581the", "\u2581letter", "box", ".", "\u2581So", "\u2581really", "\u2581it", "'", "\u2581", "s", "\u2581an", "\u2581oversight", "\u2581on", "\u2581the", "\u2581part", "\u2581of", "\u2581Hag", "rid", "\u2581(", "\u2581although", "\u2581obviously", "\u2581in", "\u2581reality", "\u2581", "he", "\u2581did", "\u2581take", "\u2581Harry", "\u2581to", "\u2581", "DA", "\u2581in", "\u2581person", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "X", "ante", "c", ".", "\u2581You", "'", "\u2581", "re", "\u2581right", ",", "\u2581it", "\u2581is", ".", "\u2581The", "\u2581Ho", "g", "war", "t", "s", "\u2581staff", "\u2581member", "\u2581", "delivering", "\u2581the", "\u2581letter", "\u2581would", "\u2581be", "\u2581expected", "\u2581to", "\u2581mention", "\u2581Dia", "gon", "\u2581Alle", "y", "\u2581(", "\u2581as", "\u2581D", "umble", "d", "or", "e", "\u2581did", ")", ".", "\u2581Hag", "rid", "\u2581neglected", "\u2581to", "\u2581do", "\u2581this", "\u2581by", "\u2581just", "\u2581posting", "\u2581the", "\u2581letter", "\u2581through", "\u2581the", "\u2581letter", "box", ".", "\u2581So", "\u2581really", "\u2581it", "'", "\u2581", "s", "\u2581an", "\u2581oversight", "\u2581on", "\u2581the", "\u2581part", "\u2581of", "\u2581Hag", "rid", "\u2581(", "\u2581although", "\u2581obviously", "\u2581in", "\u2581reality", "\u2581", "he", "\u2581did", "\u2581take", "\u2581Harry", "\u2581to", "\u2581", "DA", "\u2581in", "\u2581person", ")", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "X", "ante", "c", "</m>", ".", "\u2581You", "'", "\u2581", "re", "\u2581right", ",", "\u2581it", "\u2581is", ".", "\u2581The", "<m>", "\u2581Ho", "g", "war", "t", "s", "</m>", "\u2581staff", "\u2581member", "\u2581", "delivering", "\u2581the", "\u2581letter", "\u2581would", "\u2581be", "\u2581expected", "\u2581to", "\u2581mention", "\u2581Dia", "gon", "\u2581Alle", "y", "\u2581(", "\u2581as", "<m>", "\u2581D", "umble", "d", "or", "e", "</m>", "\u2581did", ")", ".", "<m>", "\u2581Hag", "rid", "</m>", "\u2581neglected", "\u2581to", "\u2581do", "\u2581this", "\u2581by", "\u2581just", "\u2581posting", "\u2581the", "\u2581letter", "\u2581through", "\u2581the", "\u2581letter", "box", ".", "\u2581So", "\u2581really", "\u2581it", "'", "\u2581", "s", "\u2581an", "\u2581oversight", "\u2581on", "\u2581the", "\u2581part", "\u2581of", "<m>", "\u2581Hag", "rid", "</m>", "\u2581(", "\u2581although", "\u2581obviously", "\u2581in", "\u2581reality", "\u2581", "he", "\u2581did", "\u2581take", "\u2581Harry", "\u2581to", "\u2581", "DA", "\u2581in", "\u2581person", ")", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 24, 25, 26, 27, 27, 27, 27, 27, 28, 29, 30, 31, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 43, 44, 45, 46, 47, 48, 49, 49, 50, 51, 52, 53, 54, 55, 56, 56, 57, 58, 59, 60, 61, 62, 62, 63, 64, 65, 66, 67, 67, 68, 69, 70, 71, 72], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, 3, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_374", "sentence": ["\u2581Good", ",", "\u2581I", "\u2581got", "\u2581it", "\u2581right", "\u2581then", ".", "\u2581Thanks", "\u2581for", "\u2581the", "\u2581answer", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Good", ",", "\u2581I", "\u2581got", "\u2581it", "\u2581right", "\u2581then", ".", "\u2581Thanks", "\u2581for", "\u2581the", "\u2581answer", "!", "</s>"], "target_sentence": ["<m>", "\u2581Good", "</m>", ",", "\u2581I", "\u2581got", "\u2581it", "\u2581right", "\u2581then", ".", "\u2581Thanks", "\u2581for", "\u2581the", "\u2581answer", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_375", "sentence": ["\u2581A", "liens", ",", "\u2581capable", "\u2581of", "\u2581inter", "s", "tell", "ar", "\u2581travel", ".", "\u2581Im", "\u2581sure", "\u2581for", "ging", "\u2581some", "\u2581documents", "\u2581are", "\u2581easy", "\u2581enough", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "liens", ",", "\u2581capable", "\u2581of", "\u2581inter", "s", "tell", "ar", "\u2581travel", ".", "\u2581Im", "\u2581sure", "\u2581for", "ging", "\u2581some", "\u2581documents", "\u2581are", "\u2581easy", "\u2581enough", ".", "</s>"], "target_sentence": ["\u2581A", "liens", ",", "\u2581capable", "\u2581of", "\u2581inter", "s", "tell", "ar", "\u2581travel", ".", "\u2581Im", "\u2581sure", "\u2581for", "ging", "\u2581some", "\u2581documents", "\u2581are", "\u2581easy", "\u2581enough", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_376", "sentence": ["\u2581How", "\u2581do", "\u2581we", "\u2581know", "\u2581the", "\u2581number", "\u2581of", "\u2581photo", "n", "s", "\u2581in", "\u2581", "a", "\u2581decay", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581do", "\u2581we", "\u2581know", "\u2581the", "\u2581number", "\u2581of", "\u2581photo", "n", "s", "\u2581in", "\u2581", "a", "\u2581decay", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581do", "\u2581we", "\u2581know", "\u2581the", "\u2581number", "\u2581of", "<m>", "\u2581photo", "n", "s", "</m>", "\u2581in", "\u2581", "a", "<m>", "\u2581decay", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 9, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, 1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_377", "sentence": ["\u2581What", "\u2581do", "\u2581you", "\u2581mean", "\u2581by", "\u2581\"", "\u2581the", "\u2581average", "\u2581force", "\u2581normal", "\u2581to", "\u2581surface", "\u2581on", "\u2581the", "\u2581ball", "\u2581cancel", "s", "\u2581(", "\u2581due", "\u2581to", "\u2581assumption", "\u2581of", "\u2581uniform", "ity", "\u2581in", "\u2581the", "\u2581field", ")", "\u2581\"", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581do", "\u2581you", "\u2581mean", "\u2581by", "\u2581\"", "\u2581the", "\u2581average", "\u2581force", "\u2581normal", "\u2581to", "\u2581surface", "\u2581on", "\u2581the", "\u2581ball", "\u2581cancel", "s", "\u2581(", "\u2581due", "\u2581to", "\u2581assumption", "\u2581of", "\u2581uniform", "ity", "\u2581in", "\u2581the", "\u2581field", ")", "\u2581\"", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581do", "\u2581you", "\u2581mean", "\u2581by", "\u2581\"", "\u2581the", "\u2581average", "\u2581force", "\u2581normal", "\u2581to", "\u2581surface", "\u2581on", "\u2581the", "\u2581ball", "\u2581cancel", "s", "\u2581(", "\u2581due", "\u2581to", "\u2581assumption", "\u2581of", "\u2581uniform", "ity", "\u2581in", "\u2581the", "\u2581field", ")", "\u2581\"", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_378", "sentence": ["\u2581Why", "\u2581do", "\u2581you", "\u2581think", "\u2581surface", "\u2581charge", "\u2581density", "\u2581should", "\u2581not", "\u2581change", "?", "\u2581\"", "\u2581By", "\u2581my", "\u2581knowledge", "\u2581\"", "\u2581is", "\u2581not", "\u2581", "a", "\u2581reason", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581do", "\u2581you", "\u2581think", "\u2581surface", "\u2581charge", "\u2581density", "\u2581should", "\u2581not", "\u2581change", "?", "\u2581\"", "\u2581By", "\u2581my", "\u2581knowledge", "\u2581\"", "\u2581is", "\u2581not", "\u2581", "a", "\u2581reason", ".", "</s>"], "target_sentence": ["\u2581Why", "\u2581do", "\u2581you", "\u2581think", "\u2581surface", "\u2581charge", "\u2581density", "\u2581should", "\u2581not", "\u2581change", "?", "\u2581\"", "\u2581By", "\u2581my", "\u2581knowledge", "\u2581\"", "\u2581is", "\u2581not", "\u2581", "a", "\u2581reason", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_379", "sentence": ["\u2581H", "mm", ",", "\u2581but", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581[", "\u2581V", "rij", "zin", "nig", "e", "\u2581Part", "i", "j", "]", "\u2581(", "\u2581https", "://", "n", "l", ".", "wikipedia", ".", "org", "/", "wiki", "/", "V", "rij", "zin", "nig", "e", "_", "Part", "i", "j", ")", "\u2581in", "\u2581parliament", "\u2581under", "\u2581the", "\u2581name", "\u2581[", "\u2581Gro", "e", "p", "\u2581Klein", "]", "\u2581(", "\u2581https", "://", "www", ".", "t", "weed", "e", "ka", "mer", ".", "n", "l", "/", "ka", "mer", "led", "en", "/", "frac", "ties", "/", "kle", "in", ")", "?", "\u2581The", "n", "\u2581why", "\u2581Nie", "u", "we", "\u2581We", "gen", "\u2581", "/", "\u2581Mon", "a", "sch", "\u2581but", "\u2581not", "\u2581V", "rij", "zin", "nig", "e", "\u2581Part", "i", "j", "\u2581", "/", "\u2581Klein", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581H", "mm", ",", "\u2581but", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581[", "\u2581V", "rij", "zin", "nig", "e", "\u2581Part", "i", "j", "]", "\u2581(", "\u2581https", "://", "n", "l", ".", "wikipedia", ".", "org", "/", "wiki", "/", "V", "rij", "zin", "nig", "e", "_", "Part", "i", "j", ")", "\u2581in", "\u2581parliament", "\u2581under", "\u2581the", "\u2581name", "\u2581[", "\u2581Gro", "e", "p", "\u2581Klein", "]", "\u2581(", "\u2581https", "://", "www", ".", "t", "weed", "e", "ka", "mer", ".", "n", "l", "/", "ka", "mer", "led", "en", "/", "frac", "ties", "/", "kle", "in", ")", "?", "\u2581The", "n", "\u2581why", "\u2581Nie", "u", "we", "\u2581We", "gen", "\u2581", "/", "\u2581Mon", "a", "sch", "\u2581but", "\u2581not", "\u2581V", "rij", "zin", "nig", "e", "\u2581Part", "i", "j", "\u2581", "/", "\u2581Klein", "?", "</s>"], "target_sentence": ["\u2581H", "mm", ",", "\u2581but", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581[", "\u2581V", "rij", "zin", "nig", "e", "\u2581Part", "i", "j", "]", "\u2581(", "\u2581https", "://", "n", "l", ".", "wikipedia", ".", "org", "/", "wiki", "/", "V", "rij", "zin", "nig", "e", "_", "Part", "i", "j", ")", "\u2581in", "\u2581parliament", "\u2581under", "\u2581the", "\u2581name", "\u2581[", "<m>", "\u2581Gro", "e", "p", "\u2581Klein", "</m>", "]", "\u2581(", "\u2581https", "://", "www", ".", "t", "weed", "e", "ka", "mer", ".", "n", "l", "/", "ka", "mer", "led", "en", "/", "frac", "ties", "/", "kle", "in", ")", "?", "\u2581The", "n", "\u2581why", "<m>", "\u2581Nie", "u", "we", "\u2581We", "gen", "</m>", "\u2581", "/", "\u2581Mon", "a", "sch", "\u2581but", "\u2581not", "\u2581V", "rij", "zin", "nig", "e", "\u2581Part", "i", "j", "\u2581", "/", "<m>", "\u2581Klein", "</m>", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 9, 9, 9, 9, 10, 10, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 22, 23, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 27, 28, 28, 29, 30, 30, 30, 31, 31, 32, 32, 33, 33, 33, 34, 35, 36, 36, 36, 36, 36, 37, 37, 37, 38, 38, 39, 40, 41], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 2, -1, -1]}, {"doc_id": "emerging.test_380", "sentence": ["\u2581Why", "\u2581not", "?", "\u2581I", "'", "\u2581", "m", "\u2581just", "\u2581accepting", "\u2581observations", ".", "\u2581If", "\u2581A", "'", "\u2581", "s", "\u2581angle", "\u2581is", "\u2581vertical", "\u2581and", "\u2581B", "'", "\u2581", "s", "\u2581angle", "\u2581is", "\u258160", "\u2581", "\u00b0", ",", "\u2581then", "\u2581B", "\u2581gives", "\u2581opposite", "\u2581spin", "s", "\u25813", "\u2581", "/", "\u25814", "\u2581of", "\u2581the", "\u2581time", ".", "\u2581That", "'", "\u2581", "s", "\u2581real", ",", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581disagree", "\u2581with", "\u2581that", ".", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581saying", "\u2581the", "\u2581inequality", "\u2581is", "\u2581wrong", ",", "\u2581as", "\u2581I", "\u2581said", "\u2581in", "\u2581the", "\u2581first", "\u2581paragraph", ",", "\u2581I", "'", "\u2581", "m", "\u2581saying", "\u2581the", "\u2581experiment", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581reproduce", "\u2581it", ".", "\u2581Check", "\u2581what", "\u2581I", "'", "\u2581", "ve", "\u2581answered", "\u2581to", "\u2581the", "\u2581other", "\u2581guy", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581not", "?", "\u2581I", "'", "\u2581", "m", "\u2581just", "\u2581accepting", "\u2581observations", ".", "\u2581If", "\u2581A", "'", "\u2581", "s", "\u2581angle", "\u2581is", "\u2581vertical", "\u2581and", "\u2581B", "'", "\u2581", "s", "\u2581angle", "\u2581is", "\u258160", "\u2581", "\u00b0", ",", "\u2581then", "\u2581B", "\u2581gives", "\u2581opposite", "\u2581spin", "s", "\u25813", "\u2581", "/", "\u25814", "\u2581of", "\u2581the", "\u2581time", ".", "\u2581That", "'", "\u2581", "s", "\u2581real", ",", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581disagree", "\u2581with", "\u2581that", ".", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581saying", "\u2581the", "\u2581inequality", "\u2581is", "\u2581wrong", ",", "\u2581as", "\u2581I", "\u2581said", "\u2581in", "\u2581the", "\u2581first", "\u2581paragraph", ",", "\u2581I", "'", "\u2581", "m", "\u2581saying", "\u2581the", "\u2581experiment", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581reproduce", "\u2581it", ".", "\u2581Check", "\u2581what", "\u2581I", "'", "\u2581", "ve", "\u2581answered", "\u2581to", "\u2581the", "\u2581other", "\u2581guy", ".", "</s>"], "target_sentence": ["\u2581Why", "\u2581not", "?", "\u2581I", "'", "\u2581", "m", "\u2581just", "\u2581accepting", "\u2581observations", ".", "\u2581If", "\u2581A", "'", "\u2581", "s", "\u2581angle", "\u2581is", "\u2581vertical", "\u2581and", "\u2581B", "'", "\u2581", "s", "\u2581angle", "\u2581is", "\u258160", "\u2581", "\u00b0", ",", "\u2581then", "\u2581B", "\u2581gives", "\u2581opposite", "\u2581spin", "s", "\u25813", "\u2581", "/", "\u25814", "\u2581of", "\u2581the", "\u2581time", ".", "\u2581That", "'", "\u2581", "s", "\u2581real", ",", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581disagree", "\u2581with", "\u2581that", ".", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581saying", "\u2581the", "\u2581inequality", "\u2581is", "\u2581wrong", ",", "\u2581as", "\u2581I", "\u2581said", "\u2581in", "\u2581the", "\u2581first", "\u2581paragraph", ",", "\u2581I", "'", "\u2581", "m", "\u2581saying", "\u2581the", "\u2581experiment", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581reproduce", "\u2581it", ".", "\u2581Check", "\u2581what", "\u2581I", "'", "\u2581", "ve", "\u2581answered", "\u2581to", "\u2581the", "\u2581other", "\u2581guy", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 32, 33, 34, 35, 36, 37, 38, 39, 40, 40, 41, 42, 43, 44, 45, 45, 46, 47, 47, 48, 49, 50, 51, 52, 53, 54, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 72, 73, 74, 75, 76, 77, 77, 78, 79, 79, 80, 81, 82, 83, 84, 85, 86, 87, 87, 88, 89, 90, 91, 92, 93, 94], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_381", "sentence": ["\u2581How", "\u2581does", "\u2581the", "\u2581state", "\u2581variables", "\u2581$", "\u2581(", "\u2581P", ",", "\u2581V", ")", "\u2581$", "\u2581remain", "\u2581constant", "\u2581for", "\u2581", "a", "\u2581system", "\u2581with", "\u2581", "adia", "b", "atic", "\u2581wall", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581does", "\u2581the", "\u2581state", "\u2581variables", "\u2581$", "\u2581(", "\u2581P", ",", "\u2581V", ")", "\u2581$", "\u2581remain", "\u2581constant", "\u2581for", "\u2581", "a", "\u2581system", "\u2581with", "\u2581", "adia", "b", "atic", "\u2581wall", "</s>"], "target_sentence": ["\u2581How", "\u2581does", "\u2581the", "\u2581state", "\u2581variables", "\u2581$", "\u2581(", "\u2581P", ",", "\u2581V", ")", "\u2581$", "\u2581remain", "\u2581constant", "\u2581for", "\u2581", "a", "\u2581system", "\u2581with", "\u2581", "adia", "b", "atic", "\u2581wall", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 18, 18, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_382", "sentence": ["\u2581[", "\u2581This", "\u2581page", "]", "\u2581(", "\u2581http", "://", "s", "f", "-", "ency", "clo", "pedia", ".", "com", "/", "ent", "ry", "/", "time", "_", "l", "oop", ")", "\u2581lists", "\u2581", "a", "\u258119", "32", "\u2581short", "\u2581story", ",", "\u2581but", "\u2581I", "'", "\u2581", "m", "\u2581certain", "\u2581the", "\u2581genre", "\u2581is", "\u2581much", "\u2581older", "\u2581than", "\u2581that", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581This", "\u2581page", "]", "\u2581(", "\u2581http", "://", "s", "f", "-", "ency", "clo", "pedia", ".", "com", "/", "ent", "ry", "/", "time", "_", "l", "oop", ")", "\u2581lists", "\u2581", "a", "\u258119", "32", "\u2581short", "\u2581story", ",", "\u2581but", "\u2581I", "'", "\u2581", "m", "\u2581certain", "\u2581the", "\u2581genre", "\u2581is", "\u2581much", "\u2581older", "\u2581than", "\u2581that", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581This", "\u2581page", "]", "\u2581(", "\u2581http", "://", "s", "f", "-", "ency", "clo", "pedia", ".", "com", "/", "ent", "ry", "/", "time", "_", "l", "oop", ")", "\u2581lists", "\u2581", "a", "\u258119", "32", "\u2581short", "\u2581story", ",", "\u2581but", "\u2581I", "'", "\u2581", "m", "\u2581certain", "\u2581the", "\u2581genre", "\u2581is", "\u2581much", "\u2581older", "\u2581than", "\u2581that", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_383", "sentence": ["\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581T", "-", "\u25811000", "\u2581terminat", "or", "\u2581shoot", "\u2581the", "\u2581eyes", "\u2581of", "\u2581the", "\u2581T", "-", "\u2581800", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581T", "-", "\u25811000", "\u2581terminat", "or", "\u2581shoot", "\u2581the", "\u2581eyes", "\u2581of", "\u2581the", "\u2581T", "-", "\u2581800", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581T", "-", "\u25811000", "\u2581terminat", "or", "\u2581shoot", "\u2581the", "\u2581eyes", "\u2581of", "\u2581the", "\u2581T", "-", "\u2581800", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_384", "sentence": ["\u2581You", "\u2581are", "\u2581right", ",", "\u2581the", "\u2581not", "ation", "\u2581is", "\u2581pretty", "\u2581awful", ",", "\u2581I", "\u2581just", "\u2581tried", "\u2581to", "\u2581follow", "\u2581that", "\u2581of", "\u2581the", "\u2581book", "\u2581though", ".", "\u2581Now", "\u2581I", "\u2581", "re", "write", "\u2581It", ",", "\u2581also", "\u2581because", "\u2581I", "\u2581think", "\u2581I", "\u2581can", "\u2581handle", "\u2581the", "\u2581first", "\u2581part", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581are", "\u2581right", ",", "\u2581the", "\u2581not", "ation", "\u2581is", "\u2581pretty", "\u2581awful", ",", "\u2581I", "\u2581just", "\u2581tried", "\u2581to", "\u2581follow", "\u2581that", "\u2581of", "\u2581the", "\u2581book", "\u2581though", ".", "\u2581Now", "\u2581I", "\u2581", "re", "write", "\u2581It", ",", "\u2581also", "\u2581because", "\u2581I", "\u2581think", "\u2581I", "\u2581can", "\u2581handle", "\u2581the", "\u2581first", "\u2581part", ".", "</s>"], "target_sentence": ["\u2581You", "\u2581are", "\u2581right", ",", "\u2581the", "\u2581not", "ation", "\u2581is", "\u2581pretty", "\u2581awful", ",", "\u2581I", "\u2581just", "\u2581tried", "\u2581to", "\u2581follow", "\u2581that", "\u2581of", "\u2581the", "\u2581book", "\u2581though", ".", "\u2581Now", "\u2581I", "\u2581", "re", "write", "\u2581It", ",", "\u2581also", "\u2581because", "\u2581I", "\u2581think", "\u2581I", "\u2581can", "\u2581handle", "\u2581the", "\u2581first", "\u2581part", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_385", "sentence": ["\u2581Image", "\u2581of", "\u2581diver", "ging", "\u2581lens", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Image", "\u2581of", "\u2581diver", "ging", "\u2581lens", "</s>"], "target_sentence": ["\u2581Image", "\u2581of", "\u2581diver", "ging", "\u2581lens", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_386", "sentence": ["\u2581@", "\u2581Ste", "even", "\u2581added", "\u2581", "a", "\u2581sketch", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Ste", "even", "\u2581added", "\u2581", "a", "\u2581sketch", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Ste", "even", "\u2581added", "\u2581", "a", "\u2581sketch", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_387", "sentence": ["\u2581Physical", "\u2581", "chemistry", "\u2581problem", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Physical", "\u2581", "chemistry", "\u2581problem", "</s>"], "target_sentence": ["\u2581Physical", "\u2581", "chemistry", "\u2581problem", "</s>"], "subtoken_map": [0, 1, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_388", "sentence": ["\u2581This", "\u2581answer", "\u2581seems", "\u2581", "spec", "ul", "ative", ",", "\u2581more", "\u2581of", "\u2581an", "\u2581opinion", "\u2581piece", ";", "\u2581but", "\u2581the", "\u2581", "OP", "\u2581is", "\u2581", "requesting", "\u2581fact", "\u2581checking", ".", "\u2581S", "up", "pos", "ing", "\u2581at", "\u2581present", "\u2581the", "\u2581facts", "\u2581are", "\u2581obscure", "d", "\u2581by", "\u2581mystery", ",", "\u2581there", "'", "\u2581", "s", "\u2581no", "\u2581harm", "\u2581in", "\u2581leaving", "\u2581it", "\u2581un", "ans", "w", "ered", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581answer", "\u2581seems", "\u2581", "spec", "ul", "ative", ",", "\u2581more", "\u2581of", "\u2581an", "\u2581opinion", "\u2581piece", ";", "\u2581but", "\u2581the", "\u2581", "OP", "\u2581is", "\u2581", "requesting", "\u2581fact", "\u2581checking", ".", "\u2581S", "up", "pos", "ing", "\u2581at", "\u2581present", "\u2581the", "\u2581facts", "\u2581are", "\u2581obscure", "d", "\u2581by", "\u2581mystery", ",", "\u2581there", "'", "\u2581", "s", "\u2581no", "\u2581harm", "\u2581in", "\u2581leaving", "\u2581it", "\u2581un", "ans", "w", "ered", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581answer", "\u2581seems", "\u2581", "spec", "ul", "ative", ",", "\u2581more", "\u2581of", "\u2581an", "\u2581opinion", "\u2581piece", ";", "\u2581but", "\u2581the", "\u2581", "OP", "\u2581is", "\u2581", "requesting", "\u2581fact", "\u2581checking", ".", "\u2581S", "up", "pos", "ing", "\u2581at", "\u2581present", "\u2581the", "\u2581facts", "\u2581are", "\u2581obscure", "d", "\u2581by", "\u2581mystery", ",", "\u2581there", "'", "\u2581", "s", "\u2581no", "\u2581harm", "\u2581in", "\u2581leaving", "\u2581it", "\u2581un", "ans", "w", "ered", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 15, 16, 17, 18, 19, 19, 19, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 31, 32, 33, 34, 35, 36, 37, 37, 37, 37, 38, 39], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_389", "sentence": ["\u2581[", "\u2581The", "\u2581version", "\u2581found", "\u2581in", "\u2581the", "\u2581Co", "S", "\u2581game", "]", "\u2581(", "\u2581http", "://", "i", ".", "im", "gur", ".", "com", "/", "L", "h", "h", "RT", "y", "G", ".", "jpg", ")", "\u2581(", "\u2581which", "\u2581has", "\u2581been", "\u2581[", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581written", "\u2581by", "\u2581Jo", "]", "\u2581(", "\u2581http", "://", "web", ".", "archiv", "e", ".", "org", "/", "web", "/20", "100", "310", "145", "70", "2/", "\u2581http", "://", "www", ".", "j", "k", "row", "ling", ".", "com", "/", "text", "only", "/", "en", "/", "f", "a", "q", "_", "view", ".", "c", "f", "m", "?", "i", "d", "=", "96", ")", ")", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581mention", "\u2581the", "\u2581Order", ".", "\u2581The", "\u2581version", "\u2581packaged", "\u2581with", "\u2581[", "\u2581the", "\u2581Has", "bro", "\u2581chocolate", "\u2581", "f", "rog", "\u2581cards", "]", "\u2581(", "\u2581https", "://", "i", ".", "im", "gur", ".", "com", "/", "F", "H", "v", "t", "OW", "0", ".", "jpg", ")", "\u2581(", "\u2581not", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581from", "\u2581Jo", ")", "\u2581did", ".", "\u2581This", "\u2581is", "\u2581correctly", "\u2581explained", "\u2581in", "\u2581[", "\u2581the", "\u2581Lex", "i", "con", "'", "\u2581", "s", "\u2581updated", "\u2581article", "]", "\u2581(", "\u2581https", "://", "www", ".", "h", "p", "-", "lexic", "on", ".", "org", "/2016", "/12", "/", "29", "/", "f", "am", "ous", "-", "w", "i", "zar", "d", "-", "card", "s", "/", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581The", "\u2581version", "\u2581found", "\u2581in", "\u2581the", "\u2581Co", "S", "\u2581game", "]", "\u2581(", "\u2581http", "://", "i", ".", "im", "gur", ".", "com", "/", "L", "h", "h", "RT", "y", "G", ".", "jpg", ")", "\u2581(", "\u2581which", "\u2581has", "\u2581been", "\u2581[", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581written", "\u2581by", "\u2581Jo", "]", "\u2581(", "\u2581http", "://", "web", ".", "archiv", "e", ".", "org", "/", "web", "/20", "100", "310", "145", "70", "2/", "\u2581http", "://", "www", ".", "j", "k", "row", "ling", ".", "com", "/", "text", "only", "/", "en", "/", "f", "a", "q", "_", "view", ".", "c", "f", "m", "?", "i", "d", "=", "96", ")", ")", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581mention", "\u2581the", "\u2581Order", ".", "\u2581The", "\u2581version", "\u2581packaged", "\u2581with", "\u2581[", "\u2581the", "\u2581Has", "bro", "\u2581chocolate", "\u2581", "f", "rog", "\u2581cards", "]", "\u2581(", "\u2581https", "://", "i", ".", "im", "gur", ".", "com", "/", "F", "H", "v", "t", "OW", "0", ".", "jpg", ")", "\u2581(", "\u2581not", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581from", "\u2581Jo", ")", "\u2581did", ".", "\u2581This", "\u2581is", "\u2581correctly", "\u2581explained", "\u2581in", "\u2581[", "\u2581the", "\u2581Lex", "i", "con", "'", "\u2581", "s", "\u2581updated", "\u2581article", "]", "\u2581(", "\u2581https", "://", "www", ".", "h", "p", "-", "lexic", "on", ".", "org", "/2016", "/12", "/", "29", "/", "f", "am", "ous", "-", "w", "i", "zar", "d", "-", "card", "s", "/", ")", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581The", "\u2581version", "\u2581found", "\u2581in", "\u2581the", "<m>", "<m>", "\u2581Co", "S", "</m>", "</m>", "\u2581game", "]", "\u2581(", "\u2581http", "://", "i", ".", "im", "gur", ".", "com", "/", "L", "h", "h", "RT", "y", "G", ".", "jpg", ")", "\u2581(", "\u2581which", "\u2581has", "\u2581been", "\u2581[", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581written", "\u2581by", "\u2581Jo", "]", "\u2581(", "\u2581http", "://", "web", ".", "archiv", "e", ".", "org", "/", "web", "/20", "100", "310", "145", "70", "2/", "\u2581http", "://", "www", ".", "j", "k", "row", "ling", ".", "com", "/", "text", "only", "/", "en", "/", "f", "a", "q", "_", "view", ".", "c", "f", "m", "?", "i", "d", "=", "96", ")", ")", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581mention", "\u2581the", "\u2581Order", ".", "\u2581The", "\u2581version", "\u2581packaged", "\u2581with", "\u2581[", "\u2581the", "<m>", "\u2581Has", "bro", "</m>", "\u2581chocolate", "\u2581", "f", "rog", "\u2581cards", "]", "\u2581(", "\u2581https", "://", "i", ".", "im", "gur", ".", "com", "/", "F", "H", "v", "t", "OW", "0", ".", "jpg", ")", "\u2581(", "\u2581not", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581from", "\u2581Jo", ")", "\u2581did", ".", "\u2581This", "\u2581is", "\u2581correctly", "\u2581explained", "\u2581in", "\u2581[", "\u2581the", "\u2581Lex", "i", "con", "'", "\u2581", "s", "\u2581updated", "\u2581article", "]", "\u2581(", "\u2581https", "://", "www", ".", "h", "p", "-", "lexic", "on", ".", "org", "/2016", "/12", "/", "29", "/", "f", "am", "ous", "-", "w", "i", "zar", "d", "-", "card", "s", "/", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 28, 29, 30, 30, 31, 32, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 43, 44, 45, 45, 45, 46, 47, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 68, 68, 69, 70, 70, 71, 72, 73, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 77, 78], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_390", "sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581electric", "\u2581potential", "\u2581at", "\u2581the", "\u2581point", "\u2581charge", ",", "\u2581at", "\u2581the", "\u2581source", "\u2581of", "\u2581field", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581is", "\u2581the", "\u2581electric", "\u2581potential", "\u2581at", "\u2581the", "\u2581point", "\u2581charge", ",", "\u2581at", "\u2581the", "\u2581source", "\u2581of", "\u2581field", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581electric", "\u2581potential", "\u2581at", "\u2581the", "\u2581point", "\u2581charge", ",", "\u2581at", "\u2581the", "\u2581source", "\u2581of", "\u2581field", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_391", "sentence": ["\u2581Can", "\u2581", "u", "\u2581please", "\u2581elaborate", "\u2581or", "\u2581suggest", "\u2581any", "\u2581online", "\u2581resource", "\u2581where", "\u2581", "i", "\u2581could", "\u2581find", "\u2581more", "\u2581about", "\u2581this", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Can", "\u2581", "u", "\u2581please", "\u2581elaborate", "\u2581or", "\u2581suggest", "\u2581any", "\u2581online", "\u2581resource", "\u2581where", "\u2581", "i", "\u2581could", "\u2581find", "\u2581more", "\u2581about", "\u2581this", "?", "</s>"], "target_sentence": ["\u2581Can", "\u2581", "u", "\u2581please", "\u2581elaborate", "\u2581or", "\u2581suggest", "\u2581any", "\u2581online", "\u2581resource", "\u2581where", "\u2581", "i", "\u2581could", "\u2581find", "\u2581more", "\u2581about", "\u2581this", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_392", "sentence": ["\u2581@", "\u2581Carpet", "s", "m", "o", "ker", ":", "\u2581That", "'", "\u2581", "s", "\u2581specifically", "\u2581against", "\u2581Eastern", "\u2581European", "s", "\u2581working", "\u2581in", "\u2581Western", "\u2581Europe", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Carpet", "s", "m", "o", "ker", ":", "\u2581That", "'", "\u2581", "s", "\u2581specifically", "\u2581against", "\u2581Eastern", "\u2581European", "s", "\u2581working", "\u2581in", "\u2581Western", "\u2581Europe", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Carpet", "s", "m", "o", "ker", ":", "\u2581That", "'", "\u2581", "s", "\u2581specifically", "\u2581against", "<m>", "\u2581Eastern", "\u2581European", "s", "</m>", "\u2581working", "\u2581in", "<m>", "\u2581Western", "\u2581Europe", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, 1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_393", "sentence": ["\u2581I", "\u2581gave", "\u2581", "a", "\u2581source", "\u2581(", "\u2581the", "\u2581link", ")", ".", "\u2581Here", "'", "\u2581", "s", "\u2581another", ":", "\u2581https", "://", "www", ".", "m", "erri", "am", "-", "web", "ster", ".", "com", "/", "diction", "ary", "/", "alia", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581gave", "\u2581", "a", "\u2581source", "\u2581(", "\u2581the", "\u2581link", ")", ".", "\u2581Here", "'", "\u2581", "s", "\u2581another", ":", "\u2581https", "://", "www", ".", "m", "erri", "am", "-", "web", "ster", ".", "com", "/", "diction", "ary", "/", "alia", "s", "</s>"], "target_sentence": ["\u2581I", "\u2581gave", "\u2581", "a", "\u2581source", "\u2581(", "\u2581the", "\u2581link", ")", ".", "\u2581Here", "'", "\u2581", "s", "\u2581another", ":", "\u2581https", "://", "www", ".", "m", "erri", "am", "-", "web", "ster", ".", "com", "/", "diction", "ary", "/", "alia", "s", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_394", "sentence": ["\u2581How", "\u2581to", "\u2581ensure", "\u2581wild", "card", "\u2581certificate", "\u2581private", "\u2581key", "\u2581security", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581to", "\u2581ensure", "\u2581wild", "card", "\u2581certificate", "\u2581private", "\u2581key", "\u2581security", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581to", "\u2581ensure", "<m>", "\u2581wild", "card", "</m>", "\u2581certificate", "\u2581private", "\u2581key", "\u2581security", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_395", "sentence": ["\u2581@", "\u2581B", "ry", "than", "\u2581", "-", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581this", "\u2581is", "\u2581", "a", "\u2581duplicate", ",", "\u2581but", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581", "a", "\u2581good", "\u2581job", "\u2581of", "\u2581", "separating", "\u2581my", "\u2581question", "\u2581from", "\u2581that", "\u2581one", ".", "\u2581", "Hopefully", "\u2581now", "\u2581it", "'", "\u2581", "s", "\u2581more", "\u2581clear", "\u2581that", "\u2581I", "\u2581am", "\u2581not", "\u2581asking", "\u2581for", "\u2581advantages", "\u2581(", "\u2581although", "\u2581some", "\u2581advantages", "\u2581may", "\u2581be", "\u2581relevant", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581B", "ry", "than", "\u2581", "-", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581this", "\u2581is", "\u2581", "a", "\u2581duplicate", ",", "\u2581but", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581", "a", "\u2581good", "\u2581job", "\u2581of", "\u2581", "separating", "\u2581my", "\u2581question", "\u2581from", "\u2581that", "\u2581one", ".", "\u2581", "Hopefully", "\u2581now", "\u2581it", "'", "\u2581", "s", "\u2581more", "\u2581clear", "\u2581that", "\u2581I", "\u2581am", "\u2581not", "\u2581asking", "\u2581for", "\u2581advantages", "\u2581(", "\u2581although", "\u2581some", "\u2581advantages", "\u2581may", "\u2581be", "\u2581relevant", ")", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581B", "ry", "than", "</m>", "\u2581", "-", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581this", "\u2581is", "\u2581", "a", "\u2581duplicate", ",", "\u2581but", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581", "a", "\u2581good", "\u2581job", "\u2581of", "\u2581", "separating", "\u2581my", "\u2581question", "\u2581from", "\u2581that", "\u2581one", ".", "\u2581", "Hopefully", "\u2581now", "\u2581it", "'", "\u2581", "s", "\u2581more", "\u2581clear", "\u2581that", "\u2581I", "\u2581am", "\u2581not", "\u2581asking", "\u2581for", "\u2581advantages", "\u2581(", "\u2581although", "\u2581some", "\u2581advantages", "\u2581may", "\u2581be", "\u2581relevant", ")", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 19, 20, 21, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 32, 33, 34, 35, 36, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_396", "sentence": ["\u2581@", "\u2581Q", "me", "chan", "ic", "\u2581yeah", ",", "\u2581I", "\u2581wa", "ffle", "d", "\u2581over", "\u2581this", ",", "\u2581but", "\u2581ultimately", "\u2581chose", "\u2581Physics", "\u2581since", "\u2581it", "\u2581seemed", "\u2581to", "\u2581have", "\u2581more", "\u2581continuu", "m", "-", "me", "chan", "ic", "s", "\u2581related", "\u2581questions", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Q", "me", "chan", "ic", "\u2581yeah", ",", "\u2581I", "\u2581wa", "ffle", "d", "\u2581over", "\u2581this", ",", "\u2581but", "\u2581ultimately", "\u2581chose", "\u2581Physics", "\u2581since", "\u2581it", "\u2581seemed", "\u2581to", "\u2581have", "\u2581more", "\u2581continuu", "m", "-", "me", "chan", "ic", "s", "\u2581related", "\u2581questions", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Q", "me", "chan", "ic", "\u2581yeah", ",", "\u2581I", "\u2581wa", "ffle", "d", "\u2581over", "\u2581this", ",", "\u2581but", "\u2581ultimately", "\u2581chose", "\u2581Physics", "\u2581since", "\u2581it", "\u2581seemed", "\u2581to", "\u2581have", "\u2581more", "\u2581continuu", "m", "-", "me", "chan", "ic", "s", "\u2581related", "\u2581questions", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_397", "sentence": ["\u2581I", "s", "\u2581redirect", "ing", "\u2581in", "\u2581", "h", "t", "access", "\u2581providing", "\u2581enough", "\u2581security", "\u2581for", "\u2581sensitive", "\u2581pages", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581redirect", "ing", "\u2581in", "\u2581", "h", "t", "access", "\u2581providing", "\u2581enough", "\u2581security", "\u2581for", "\u2581sensitive", "\u2581pages", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581redirect", "ing", "\u2581in", "\u2581", "h", "t", "access", "\u2581providing", "\u2581enough", "\u2581security", "\u2581for", "\u2581sensitive", "\u2581pages", "?", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_398", "sentence": ["\u2581@", "\u2581", "CP", "HP", "y", "th", "on", "\u2581It", "\u2581works", "\u2581when", "\u2581your", "\u2581intr", "usion", "\u2581scanner", "\u2581is", "\u2581just", "\u2581", "gre", "pping", "\u2581for", "'", "\u2581assert", "'", ".", "\u2581How", "\u2581many", "\u2581of", "\u2581them", "\u2581do", "\u2581that", ",", "\u2581I", "\u2581have", "\u2581no", "\u2581idea", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "CP", "HP", "y", "th", "on", "\u2581It", "\u2581works", "\u2581when", "\u2581your", "\u2581intr", "usion", "\u2581scanner", "\u2581is", "\u2581just", "\u2581", "gre", "pping", "\u2581for", "'", "\u2581assert", "'", ".", "\u2581How", "\u2581many", "\u2581of", "\u2581them", "\u2581do", "\u2581that", ",", "\u2581I", "\u2581have", "\u2581no", "\u2581idea", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581", "CP", "HP", "y", "th", "on", "\u2581It", "\u2581works", "\u2581when", "\u2581your", "\u2581intr", "usion", "\u2581scanner", "\u2581is", "\u2581just", "\u2581", "gre", "pping", "\u2581for", "'", "\u2581assert", "'", ".", "\u2581How", "\u2581many", "\u2581of", "\u2581them", "\u2581do", "\u2581that", ",", "\u2581I", "\u2581have", "\u2581no", "\u2581idea", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_399", "sentence": ["\u2581Difference", "\u2581between", "\u2581Executive", "\u2581Order", "s", "\u2581and", "\u2581Presidential", "\u2581Memo", "r", "and", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Difference", "\u2581between", "\u2581Executive", "\u2581Order", "s", "\u2581and", "\u2581Presidential", "\u2581Memo", "r", "and", "a", "</s>"], "target_sentence": ["\u2581Difference", "\u2581between", "\u2581Executive", "\u2581Order", "s", "\u2581and", "\u2581Presidential", "\u2581Memo", "r", "and", "a", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_400", "sentence": ["\u2581Why", "\u2581was", "\u2581Thor", "in", "\u2581so", "\u2581interested", "\u2581in", "\u2581gold", "\u2581in", "\u2581the", "\u2581film", ",", "\u2581when", "\u2581", "he", "\u2581was", "\u2581really", "\u2581just", "\u2581after", "\u2581the", "\u2581Ark", "en", "stone", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581was", "\u2581Thor", "in", "\u2581so", "\u2581interested", "\u2581in", "\u2581gold", "\u2581in", "\u2581the", "\u2581film", ",", "\u2581when", "\u2581", "he", "\u2581was", "\u2581really", "\u2581just", "\u2581after", "\u2581the", "\u2581Ark", "en", "stone", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581was", "<m>", "\u2581Thor", "in", "</m>", "\u2581so", "\u2581interested", "\u2581in", "\u2581gold", "\u2581in", "\u2581the", "\u2581film", ",", "\u2581when", "\u2581", "he", "\u2581was", "\u2581really", "\u2581just", "\u2581after", "\u2581the", "<m>", "\u2581Ark", "en", "stone", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 18, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_401", "sentence": ["\u2581Possible", "\u2581anomal", "y", "\u2581in", "\u2581Crypto", "nom", "i", "con", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Possible", "\u2581anomal", "y", "\u2581in", "\u2581Crypto", "nom", "i", "con", "</s>"], "target_sentence": ["\u2581Possible", "\u2581anomal", "y", "\u2581in", "<m>", "<m>", "\u2581Crypto", "nom", "i", "con", "</m>", "</m>", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1], "ent_indices": [-1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 0, 1, -1]}, {"doc_id": "emerging.test_402", "sentence": ["\u2581@", "\u2581Tri", "la", "rion", "\u2581Neg", "ative", ".", "\u2581Tor", "ture", "\u2581has", "\u2581been", "\u2581illegal", "\u2581for", "\u2581", "a", "\u2581while", ".", "\u2581There", "\u2581was", "\u2581never", "\u2581an", "\u2581attempt", "\u2581to", "\u2581make", "\u2581torture", "\u2581legal", ".", "\u2581", "Rather", ",", "\u2581they", "\u2581", "categorized", "\u2581the", "\u2581actions", "\u2581they", "\u2581were", "\u2581taking", "\u2581as", "\u2581\"", "\u2581not", "\u2581torture", "\u2581\"", "\u2581but", "\u2581enhanced", "\u2581inter", "rog", "ation", "\u2581techniques", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Tri", "la", "rion", "\u2581Neg", "ative", ".", "\u2581Tor", "ture", "\u2581has", "\u2581been", "\u2581illegal", "\u2581for", "\u2581", "a", "\u2581while", ".", "\u2581There", "\u2581was", "\u2581never", "\u2581an", "\u2581attempt", "\u2581to", "\u2581make", "\u2581torture", "\u2581legal", ".", "\u2581", "Rather", ",", "\u2581they", "\u2581", "categorized", "\u2581the", "\u2581actions", "\u2581they", "\u2581were", "\u2581taking", "\u2581as", "\u2581\"", "\u2581not", "\u2581torture", "\u2581\"", "\u2581but", "\u2581enhanced", "\u2581inter", "rog", "ation", "\u2581techniques", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Tri", "la", "rion", "\u2581Neg", "ative", ".", "\u2581Tor", "ture", "\u2581has", "\u2581been", "\u2581illegal", "\u2581for", "\u2581", "a", "\u2581while", ".", "\u2581There", "\u2581was", "\u2581never", "\u2581an", "\u2581attempt", "\u2581to", "\u2581make", "\u2581torture", "\u2581legal", ".", "\u2581", "Rather", ",", "\u2581they", "\u2581", "categorized", "\u2581the", "\u2581actions", "\u2581they", "\u2581were", "\u2581taking", "\u2581as", "\u2581\"", "\u2581not", "\u2581torture", "\u2581\"", "\u2581but", "\u2581enhanced", "\u2581inter", "rog", "ation", "\u2581techniques", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 38, 38, 39, 40, 41], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_403", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581voting", "\u2581to", "\u2581close", "\u2581this", "\u2581question", "\u2581as", "\u2581off", "-", "topic", "\u2581because", "\u2581this", "\u2581is", "\u2581", "a", "\u2581legal", "\u2581question", "\u2581and", "\u2581belongs", "\u2581on", "\u2581[", "\u2581Law", ".", "\u2581SE", "]", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581voting", "\u2581to", "\u2581close", "\u2581this", "\u2581question", "\u2581as", "\u2581off", "-", "topic", "\u2581because", "\u2581this", "\u2581is", "\u2581", "a", "\u2581legal", "\u2581question", "\u2581and", "\u2581belongs", "\u2581on", "\u2581[", "\u2581Law", ".", "\u2581SE", "]", ".", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "m", "\u2581voting", "\u2581to", "\u2581close", "\u2581this", "\u2581question", "\u2581as", "\u2581off", "-", "topic", "\u2581because", "\u2581this", "\u2581is", "\u2581", "a", "\u2581legal", "\u2581question", "\u2581and", "\u2581belongs", "\u2581on", "\u2581[", "\u2581Law", ".", "\u2581SE", "]", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_404", "sentence": ["\u2581This", "\u2581is", "\u2581", "a", "\u2581good", "\u2581explanation", ",", "\u2581thanks", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581is", "\u2581", "a", "\u2581good", "\u2581explanation", ",", "\u2581thanks", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581is", "\u2581", "a", "\u2581good", "\u2581explanation", ",", "\u2581thanks", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_405", "sentence": ["\u2581Welcome", "\u2581to", "\u2581Physics", "\u2581", "Stack", "\u2581Exchange", "!", "\u2581[", "\u2581This", "\u2581related", "\u2581question", "]", "\u2581(", "\u2581http", "://", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/", "53", "26", "/5", "62", "99", ")", "\u2581may", "\u2581help", "\u2581you", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Welcome", "\u2581to", "\u2581Physics", "\u2581", "Stack", "\u2581Exchange", "!", "\u2581[", "\u2581This", "\u2581related", "\u2581question", "]", "\u2581(", "\u2581http", "://", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/", "53", "26", "/5", "62", "99", ")", "\u2581may", "\u2581help", "\u2581you", ".", "</s>"], "target_sentence": ["\u2581Welcome", "\u2581to", "\u2581Physics", "\u2581", "Stack", "\u2581Exchange", "!", "\u2581[", "\u2581This", "\u2581related", "\u2581question", "]", "\u2581(", "\u2581http", "://", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/", "53", "26", "/5", "62", "99", ")", "\u2581may", "\u2581help", "\u2581you", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_406", "sentence": ["\u2581[", "\u2581Professor", "\u2581Mon", "key", "-", "\u2581For", "-", "\u2581A", "-", "He", "a", "d", "]", "\u2581(", "\u2581http", "://", "e", "arth", "worm", "j", "im", ".", "wiki", "a", ".", "com", "/", "wiki", "/", "Prof", "essor", "_", "Mon", "key", "-", "For", "-", "A", "-", "He", "a", "d", ")", "\u2581from", "\u2581", "_", "\u2581Earth", "worm", "\u2581Jim", "\u2581", "_", "\u2581precede", "d", "\u2581him", ",", "\u2581but", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581", "if", "\u2581that", "\u2581counts", ":", "\u2581", "-", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Professor", "\u2581Mon", "key", "-", "\u2581For", "-", "\u2581A", "-", "He", "a", "d", "]", "\u2581(", "\u2581http", "://", "e", "arth", "worm", "j", "im", ".", "wiki", "a", ".", "com", "/", "wiki", "/", "Prof", "essor", "_", "Mon", "key", "-", "For", "-", "A", "-", "He", "a", "d", ")", "\u2581from", "\u2581", "_", "\u2581Earth", "worm", "\u2581Jim", "\u2581", "_", "\u2581precede", "d", "\u2581him", ",", "\u2581but", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581", "if", "\u2581that", "\u2581counts", ":", "\u2581", "-", ")", "</s>"], "target_sentence": ["\u2581[", "<m>", "\u2581Professor", "\u2581Mon", "key", "-", "\u2581For", "-", "\u2581A", "-", "He", "a", "d", "</m>", "]", "\u2581(", "\u2581http", "://", "e", "arth", "worm", "j", "im", ".", "wiki", "a", ".", "com", "/", "wiki", "/", "Prof", "essor", "_", "Mon", "key", "-", "For", "-", "A", "-", "He", "a", "d", ")", "\u2581from", "\u2581", "_", "<m>", "\u2581Earth", "worm", "\u2581Jim", "</m>", "\u2581", "_", "\u2581precede", "d", "\u2581him", ",", "\u2581but", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581", "if", "\u2581that", "\u2581counts", ":", "\u2581", "-", ")", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 10, 10, 11, 11, 12, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 22, 23, 23, 24, 25, 26, 27, 27, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_407", "sentence": ["\u2581But", ",", "\u2581I", "\u2581guess", "\u2581we", "\u2581look", "\u2581at", "\u2581this", "\u2581emp", "has", "izing", "\u2581very", "\u2581different", "\u2581principles", ".", "\u2581I", "\u2581appreciate", "\u2581the", "\u2581time", "\u2581you", "\u2581put", "\u2581into", "\u2581answering", "\u2581my", "\u2581comments", ".", "\u2581Look", "s", "\u2581like", "\u2581the", "\u2581mod", "er", "ators", "\u2581think", "\u2581the", "\u2581exchange", "\u2581is", "\u2581too", "\u2581long", ",", "\u2581so", "\u2581may", "\u2581be", "\u2581we", "\u2581can", "\u2581return", "\u2581to", "\u2581this", "\u2581in", "\u2581the", "\u2581context", "\u2581of", "\u2581some", "\u2581thread", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581But", ",", "\u2581I", "\u2581guess", "\u2581we", "\u2581look", "\u2581at", "\u2581this", "\u2581emp", "has", "izing", "\u2581very", "\u2581different", "\u2581principles", ".", "\u2581I", "\u2581appreciate", "\u2581the", "\u2581time", "\u2581you", "\u2581put", "\u2581into", "\u2581answering", "\u2581my", "\u2581comments", ".", "\u2581Look", "s", "\u2581like", "\u2581the", "\u2581mod", "er", "ators", "\u2581think", "\u2581the", "\u2581exchange", "\u2581is", "\u2581too", "\u2581long", ",", "\u2581so", "\u2581may", "\u2581be", "\u2581we", "\u2581can", "\u2581return", "\u2581to", "\u2581this", "\u2581in", "\u2581the", "\u2581context", "\u2581of", "\u2581some", "\u2581thread", ".", "</s>"], "target_sentence": ["\u2581But", ",", "\u2581I", "\u2581guess", "\u2581we", "\u2581look", "\u2581at", "\u2581this", "\u2581emp", "has", "izing", "\u2581very", "\u2581different", "\u2581principles", ".", "\u2581I", "\u2581appreciate", "\u2581the", "\u2581time", "\u2581you", "\u2581put", "\u2581into", "\u2581answering", "\u2581my", "\u2581comments", ".", "\u2581Look", "s", "\u2581like", "\u2581the", "\u2581mod", "er", "ators", "\u2581think", "\u2581the", "\u2581exchange", "\u2581is", "\u2581too", "\u2581long", ",", "\u2581so", "\u2581may", "\u2581be", "\u2581we", "\u2581can", "\u2581return", "\u2581to", "\u2581this", "\u2581in", "\u2581the", "\u2581context", "\u2581of", "\u2581some", "\u2581thread", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 27, 27, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_408", "sentence": ["\u2581What", "'", "\u2581", "s", "\u2581meant", "\u2581by", "\u2581this", "\u2581bill", "\u2581(", "\u2581H", ".", "\u2581R", ".", "\u2581", "720", ")", "\u2581text", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "'", "\u2581", "s", "\u2581meant", "\u2581by", "\u2581this", "\u2581bill", "\u2581(", "\u2581H", ".", "\u2581R", ".", "\u2581", "720", ")", "\u2581text", "?", "</s>"], "target_sentence": ["\u2581What", "'", "\u2581", "s", "\u2581meant", "\u2581by", "\u2581this", "\u2581bill", "\u2581(", "<m>", "\u2581H", ".", "\u2581R", ".", "\u2581", "720", "</m>", ")", "\u2581text", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1]}, {"doc_id": "emerging.test_409", "sentence": ["\u2581What", "\u2581was", "\u2581funny", "\u2581about", "\u2581Ha", "nzo", "'", "\u2581", "s", "\u2581hand", "\u2581in", "\u2581the", "\u2581film", "\u2581Pre", "d", "ators", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581was", "\u2581funny", "\u2581about", "\u2581Ha", "nzo", "'", "\u2581", "s", "\u2581hand", "\u2581in", "\u2581the", "\u2581film", "\u2581Pre", "d", "ators", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581was", "\u2581funny", "\u2581about", "<m>", "<m>", "\u2581Ha", "nzo", "</m>", "</m>", "'", "<m>", "\u2581", "s", "\u2581hand", "</m>", "\u2581in", "\u2581the", "\u2581film", "<m>", "<m>", "\u2581Pre", "d", "ators", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, 2, -1, -1, -1, 2, -1, -1, -1, 3, 4, -1, -1, -1, 3, 4, -1, -1]}, {"doc_id": "emerging.test_410", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581uncomfortable", "\u2581with", "\u2581this", "\u2581kind", "\u2581of", "\u2581question", ".", "\u2581It", "'", "\u2581", "s", "\u2581asking", "\u2581for", "\u2581direct", "\u2581help", "\u2581in", "\u2581crack", "ing", "\u2581someone", "'", "\u2581", "s", "\u2581wifi", "\u2581network", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581uncomfortable", "\u2581with", "\u2581this", "\u2581kind", "\u2581of", "\u2581question", ".", "\u2581It", "'", "\u2581", "s", "\u2581asking", "\u2581for", "\u2581direct", "\u2581help", "\u2581in", "\u2581crack", "ing", "\u2581someone", "'", "\u2581", "s", "\u2581wifi", "\u2581network", ".", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "m", "\u2581uncomfortable", "\u2581with", "\u2581this", "\u2581kind", "\u2581of", "\u2581question", ".", "\u2581It", "'", "\u2581", "s", "\u2581asking", "\u2581for", "\u2581direct", "\u2581help", "\u2581in", "\u2581crack", "ing", "\u2581someone", "'", "\u2581", "s", "\u2581wifi", "\u2581network", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_411", "sentence": ["\u2581In", "\u2581the", "\u2581context", "\u2581of", "\u2581", "FI", "DO", "\u2581U", "\u25812", "\u2581F", ",", "\u2581when", "\u2581is", "\u2581", "a", "\u2581new", "\u2581", "e", "p", "he", "mer", "al", "\u2581key", "\u2581reuse", "d", ",", "\u2581or", "\u2581cache", "d", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581In", "\u2581the", "\u2581context", "\u2581of", "\u2581", "FI", "DO", "\u2581U", "\u25812", "\u2581F", ",", "\u2581when", "\u2581is", "\u2581", "a", "\u2581new", "\u2581", "e", "p", "he", "mer", "al", "\u2581key", "\u2581reuse", "d", ",", "\u2581or", "\u2581cache", "d", "?", "</s>"], "target_sentence": ["\u2581In", "\u2581the", "\u2581context", "\u2581of", "\u2581", "FI", "DO", "\u2581U", "\u25812", "\u2581F", ",", "\u2581when", "\u2581is", "\u2581", "a", "\u2581new", "\u2581", "e", "p", "he", "mer", "al", "\u2581key", "\u2581reuse", "d", ",", "\u2581or", "\u2581cache", "d", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 13, 13, 13, 13, 14, 15, 15, 16, 17, 18, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_412", "sentence": ["\u2581We", "re", "\u2581the", "\u2581B", "org", "\u2581Always", "\u2581intended", "\u2581to", "\u2581be", "\u2581", "a", "\u2581Delta", "\u2581Quad", "rant", "\u2581power", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581We", "re", "\u2581the", "\u2581B", "org", "\u2581Always", "\u2581intended", "\u2581to", "\u2581be", "\u2581", "a", "\u2581Delta", "\u2581Quad", "rant", "\u2581power", "?", "</s>"], "target_sentence": ["\u2581We", "re", "\u2581the", "<m>", "<m>", "\u2581B", "org", "</m>", "</m>", "\u2581Always", "\u2581intended", "\u2581to", "\u2581be", "\u2581", "a", "<m>", "<m>", "\u2581Delta", "</m>", "\u2581Quad", "rant", "</m>", "\u2581power", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 4, -1, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, 2, 3, -1, 2, -1, -1, 3, -1, -1, -1]}, {"doc_id": "emerging.test_413", "sentence": ["\u2581Amazon", "\u2581Echo", "\u2581", "/", "\u2581Do", "t", "\u2581on", "\u2581your", "\u2581network", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Amazon", "\u2581Echo", "\u2581", "/", "\u2581Do", "t", "\u2581on", "\u2581your", "\u2581network", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Amazon", "</m>", "\u2581Echo", "</m>", "\u2581", "/", "<m>", "\u2581Do", "t", "</m>", "\u2581on", "\u2581your", "\u2581network", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, 2, -1, 5, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1], "ent_indices": [0, 1, -1, 0, -1, 1, -1, -1, 2, -1, -1, 2, -1, -1, -1, -1]}, {"doc_id": "emerging.test_414", "sentence": ["\u2581Per", "cent", "\u2581difference", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581work", "\u2581for", "\u2581my", "\u2581data", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Per", "cent", "\u2581difference", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581work", "\u2581for", "\u2581my", "\u2581data", "</s>"], "target_sentence": ["\u2581Per", "cent", "\u2581difference", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581work", "\u2581for", "\u2581my", "\u2581data", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_415", "sentence": ["\u2581Which", "\u2581public", "\u2581key", "\u2581encryption", "\u2581method", "\u2581should", "\u2581I", "\u2581choose", "\u2581to", "\u2581sign", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Which", "\u2581public", "\u2581key", "\u2581encryption", "\u2581method", "\u2581should", "\u2581I", "\u2581choose", "\u2581to", "\u2581sign", "?", "</s>"], "target_sentence": ["\u2581Which", "\u2581public", "\u2581key", "\u2581encryption", "\u2581method", "\u2581should", "\u2581I", "\u2581choose", "\u2581to", "\u2581sign", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_416", "sentence": ["\u2581Your", "\u2581responses", "\u2581are", "\u2581much", "\u2581appreciated", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Your", "\u2581responses", "\u2581are", "\u2581much", "\u2581appreciated", ".", "</s>"], "target_sentence": ["\u2581Your", "\u2581responses", "\u2581are", "\u2581much", "\u2581appreciated", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_417", "sentence": ["\u2581In", "\u2581\"", "\u2581The", "\u2581Six", "\u2581That", "cher", "s", "\u2581\"", ",", "\u2581why", "\u2581does", "\u2581Watson", "\u2581blame", "\u2581Sherlock", "\u2581rather", "\u2581than", "\u2581himself", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581In", "\u2581\"", "\u2581The", "\u2581Six", "\u2581That", "cher", "s", "\u2581\"", ",", "\u2581why", "\u2581does", "\u2581Watson", "\u2581blame", "\u2581Sherlock", "\u2581rather", "\u2581than", "\u2581himself", "?", "</s>"], "target_sentence": ["\u2581In", "\u2581\"", "<m>", "<m>", "<m>", "\u2581The", "\u2581Six", "\u2581That", "cher", "s", "</m>", "</m>", "</m>", "\u2581\"", ",", "\u2581why", "\u2581does", "<m>", "\u2581Watson", "</m>", "\u2581blame", "\u2581Sherlock", "\u2581rather", "\u2581than", "\u2581himself", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, 5, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 2, 0, 1, -1, -1, -1, -1, -1, 2, 0, 1, -1, -1, -1, -1, 3, -1, 3, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_418", "sentence": ["\u2581Network", "\u2581administrator", "\u2581knowing", "\u2581all", "\u2581user", "\u2581password", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Network", "\u2581administrator", "\u2581knowing", "\u2581all", "\u2581user", "\u2581password", "s", "</s>"], "target_sentence": ["\u2581Network", "\u2581administrator", "\u2581knowing", "\u2581all", "\u2581user", "\u2581password", "s", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_419", "sentence": ["\u2581I", "\u2581recommend", "\u2581", "re", "word", "ing", "\u2581your", "\u2581question", "\u2581to", "\u2581\"", "\u2581What", "\u2581technical", "\u2581means", "\u2581are", "\u2581available", "\u2581to", "\u2581deal", "\u2581with", "\u2581state", "\u2581actors", "\u2581breaking", "\u2581T", "LS", "?", "\u2581\"", ".", "\u2581The", "\u2581question", "\u2581as", "\u2581it", "\u2581is", "\u2581currently", "\u2581", "formulated", "\u2581is", "\u2581better", "\u2581", "suited", "\u2581for", "\u2581law", ".", "\u2581SE", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581recommend", "\u2581", "re", "word", "ing", "\u2581your", "\u2581question", "\u2581to", "\u2581\"", "\u2581What", "\u2581technical", "\u2581means", "\u2581are", "\u2581available", "\u2581to", "\u2581deal", "\u2581with", "\u2581state", "\u2581actors", "\u2581breaking", "\u2581T", "LS", "?", "\u2581\"", ".", "\u2581The", "\u2581question", "\u2581as", "\u2581it", "\u2581is", "\u2581currently", "\u2581", "formulated", "\u2581is", "\u2581better", "\u2581", "suited", "\u2581for", "\u2581law", ".", "\u2581SE", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581recommend", "\u2581", "re", "word", "ing", "\u2581your", "\u2581question", "\u2581to", "\u2581\"", "\u2581What", "\u2581technical", "\u2581means", "\u2581are", "\u2581available", "\u2581to", "\u2581deal", "\u2581with", "\u2581state", "\u2581actors", "\u2581breaking", "\u2581T", "LS", "?", "\u2581\"", ".", "\u2581The", "\u2581question", "\u2581as", "\u2581it", "\u2581is", "\u2581currently", "\u2581", "formulated", "\u2581is", "\u2581better", "\u2581", "suited", "\u2581for", "\u2581law", ".", "\u2581SE", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 29, 30, 31, 31, 32, 33, 34, 35, 36, 37], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_420", "sentence": ["\u2581Are", "\u2581the", "\u2581T", "IE", "\u2581Fighter", "\u2581pilot", "s", "\u2581", "clo", "nes", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Are", "\u2581the", "\u2581T", "IE", "\u2581Fighter", "\u2581pilot", "s", "\u2581", "clo", "nes", "?", "</s>"], "target_sentence": ["\u2581Are", "\u2581the", "<m>", "\u2581T", "IE", "\u2581Fighter", "\u2581pilot", "s", "</m>", "\u2581", "clo", "nes", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_421", "sentence": ["\u2581Does", "\u2581energy", "\u2581of", "\u2581photo", "n", "\u2581change", "\u2581due", "\u2581to", "\u2581some", "\u2581external", "\u2581magnetic", "\u2581field", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Does", "\u2581energy", "\u2581of", "\u2581photo", "n", "\u2581change", "\u2581due", "\u2581to", "\u2581some", "\u2581external", "\u2581magnetic", "\u2581field", "?", "</s>"], "target_sentence": ["\u2581Does", "\u2581energy", "\u2581of", "<m>", "\u2581photo", "n", "\u2581change", "</m>", "\u2581due", "\u2581to", "\u2581some", "<m>", "\u2581external", "\u2581magnetic", "\u2581field", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_422", "sentence": ["\u2581The", "\u2581form", "\u2581\"", "\u2581Q", "\u2581\"", "\u2581takes", "\u2581is", "\u2581cosmetic", "\u2581as", "\u2581implied", "\u2581by", "\u2581the", "\u2581episode", ",", "\u2581[", "\u2581D\u00e9", "j", "\u00e0", "\u2581Q", "]", "\u2581(", "\u2581https", "://", "en", ".", "wikipedia", ".", "org", "/", "wiki", "/", "D", "%", "C", "3%", "A", "9", "j", "%", "C", "3%", "A", "0", "_", "Q", ")", "\u2581in", "\u2581which", "\u2581another", "\u2581\"", "\u2581Q", "\u2581\"", "\u2581appears", "\u2581and", "\u2581remarks", "\u2581at", "\u2581the", "\u2581bi", "ped", "al", "\u2581nature", "\u2581of", "\u2581their", "\u2581circumstance", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581form", "\u2581\"", "\u2581Q", "\u2581\"", "\u2581takes", "\u2581is", "\u2581cosmetic", "\u2581as", "\u2581implied", "\u2581by", "\u2581the", "\u2581episode", ",", "\u2581[", "\u2581D\u00e9", "j", "\u00e0", "\u2581Q", "]", "\u2581(", "\u2581https", "://", "en", ".", "wikipedia", ".", "org", "/", "wiki", "/", "D", "%", "C", "3%", "A", "9", "j", "%", "C", "3%", "A", "0", "_", "Q", ")", "\u2581in", "\u2581which", "\u2581another", "\u2581\"", "\u2581Q", "\u2581\"", "\u2581appears", "\u2581and", "\u2581remarks", "\u2581at", "\u2581the", "\u2581bi", "ped", "al", "\u2581nature", "\u2581of", "\u2581their", "\u2581circumstance", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581form", "\u2581\"", "\u2581Q", "\u2581\"", "\u2581takes", "\u2581is", "\u2581cosmetic", "\u2581as", "\u2581implied", "\u2581by", "\u2581the", "\u2581episode", ",", "\u2581[", "<m>", "\u2581D\u00e9", "j", "\u00e0", "\u2581Q", "</m>", "]", "\u2581(", "\u2581https", "://", "en", ".", "wikipedia", ".", "org", "/", "wiki", "/", "D", "%", "C", "3%", "A", "9", "j", "%", "C", "3%", "A", "0", "_", "Q", ")", "\u2581in", "\u2581which", "\u2581another", "\u2581\"", "\u2581Q", "\u2581\"", "\u2581appears", "\u2581and", "\u2581remarks", "\u2581at", "\u2581the", "\u2581bi", "ped", "al", "\u2581nature", "\u2581of", "\u2581their", "\u2581circumstance", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 15, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 32, 33, 34, 35, 36, 37, 38], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_423", "sentence": ["\u2581Why", "\u2581is", "\u2581visa", "-", "free", "\u2581travel", "\u2581such", "\u2581", "a", "\u2581big", "\u2581deal", "\u2581in", "\u2581politics", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581visa", "-", "free", "\u2581travel", "\u2581such", "\u2581", "a", "\u2581big", "\u2581deal", "\u2581in", "\u2581politics", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "<m>", "\u2581visa", "-", "free", "</m>", "\u2581travel", "\u2581such", "\u2581", "a", "\u2581big", "\u2581deal", "\u2581in", "\u2581politics", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_424", "sentence": ["\u2581buddy", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581say", "\u2581", "x", "men", "\u25813", "\u2581as", "\u2581disaster", "\u2581I", "\u2581like", "\u2581original", "\u2581trilogy", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581buddy", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581say", "\u2581", "x", "men", "\u25813", "\u2581as", "\u2581disaster", "\u2581I", "\u2581like", "\u2581original", "\u2581trilogy", ".", "</s>"], "target_sentence": ["\u2581buddy", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581say", "<m>", "<m>", "\u2581", "x", "men", "\u25813", "</m>", "</m>", "\u2581as", "\u2581disaster", "\u2581I", "\u2581like", "\u2581original", "\u2581trilogy", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_425", "sentence": ["\u2581Do", "\u2581countries", "\u2581frame", "\u2581their", "\u2581contributions", "\u2581in", "\u2581climate", "\u2581change", "\u2581neg", "o", "t", "ations", "\u2581in", "\u2581reference", "\u2581to", "\u2581others", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Do", "\u2581countries", "\u2581frame", "\u2581their", "\u2581contributions", "\u2581in", "\u2581climate", "\u2581change", "\u2581neg", "o", "t", "ations", "\u2581in", "\u2581reference", "\u2581to", "\u2581others", "?", "</s>"], "target_sentence": ["\u2581Do", "\u2581countries", "\u2581frame", "\u2581their", "\u2581contributions", "\u2581in", "\u2581climate", "\u2581change", "\u2581neg", "o", "t", "ations", "\u2581in", "\u2581reference", "\u2581to", "\u2581others", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_426", "sentence": ["\u2581I", "\u2581feel", "\u2581like", "\u2581other", "\u2581animals", "\u2581could", "\u2581kick", "\u2581", "a", "\u2581field", "\u2581goal", "\u2581given", "\u2581proper", "\u2581training", ".", "\u2581Es", "p", ".", "\u2581since", "\u2581the", "\u2581", "FG", "\u2581distance", "\u2581wasn", "t", "\u2581very", "\u2581far", "\u2581for", "\u2581Snow", "f", "lake", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581feel", "\u2581like", "\u2581other", "\u2581animals", "\u2581could", "\u2581kick", "\u2581", "a", "\u2581field", "\u2581goal", "\u2581given", "\u2581proper", "\u2581training", ".", "\u2581Es", "p", ".", "\u2581since", "\u2581the", "\u2581", "FG", "\u2581distance", "\u2581wasn", "t", "\u2581very", "\u2581far", "\u2581for", "\u2581Snow", "f", "lake", "</s>"], "target_sentence": ["\u2581I", "\u2581feel", "\u2581like", "\u2581other", "\u2581animals", "\u2581could", "\u2581kick", "\u2581", "a", "\u2581field", "\u2581goal", "\u2581given", "\u2581proper", "\u2581training", ".", "\u2581Es", "p", ".", "\u2581since", "\u2581the", "\u2581", "FG", "\u2581distance", "\u2581wasn", "t", "\u2581very", "\u2581far", "\u2581for", "\u2581Snow", "f", "lake", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 18, 19, 20, 20, 21, 22, 23, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_427", "sentence": ["\u2581I", "\u2581think", "\u2581this", "\u2581answer", "\u2581is", "\u2581wrong", "\u2581", "\u2014", "\u2581I", "\u2581certainly", "\u2581took", "\u2581it", "\u2581to", "\u2581be", "\u2581meant", "\u2581literally", ".", "\u2581The", "\u2581last", "\u2581line", "\u2581in", "\u2581your", "\u2581answer", "\u2581is", "\u2581key", ",", "\u2581but", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581entirely", "\u2581possible", "\u2581that", "\u2581the", "\u2581worth", "\u2581of", "\u2581market", "\u2581value", "\u2581of", "\u2581small", "\u2581amounts", "\u2581of", "\u2581mit", "h", "r", "il", "\u2581is", "\u2581so", "\u2581ridiculous", "ly", "\u2581high", "\u2581that", ",", "\u2581scale", "d", "\u2581to", "\u2581", "a", "\u2581whole", "\u2581arm", "our", "\u2581made", "\u2581of", "\u2581mit", "h", "r", "il", ",", "\u2581its", "\u2581value", "\u2581would", "\u2581indeed", "\u2581dwarf", "\u2581an", "\u2581un", "important", "\u2581economy", "\u2581such", "\u2581as", "\u2581the", "\u2581Shi", "re", "\u2581", "\u2019", "\u2581", "s", ",", "\u2581without", "\u2581", "requiring", "\u2581an", "\u2581exact", "\u2581calculation", ".", "\u2581This", "\u2581is", "n", "\u2581", "\u2019", "\u2581", "t", "\u2581*", "\u2581that", "\u2581*", "\u2581unrealistic", "\u2581for", "\u2581an", "\u2581item", "\u2581", "\u2019", "\u2581", "s", "\u2581value", "\u2581(", "\u2581as", "\u2581", "a", "\u2581gift", ",", "\u2581it", "\u2581kind", "\u2581of", "\u2581is", "\u2581though", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581think", "\u2581this", "\u2581answer", "\u2581is", "\u2581wrong", "\u2581", "\u2014", "\u2581I", "\u2581certainly", "\u2581took", "\u2581it", "\u2581to", "\u2581be", "\u2581meant", "\u2581literally", ".", "\u2581The", "\u2581last", "\u2581line", "\u2581in", "\u2581your", "\u2581answer", "\u2581is", "\u2581key", ",", "\u2581but", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581entirely", "\u2581possible", "\u2581that", "\u2581the", "\u2581worth", "\u2581of", "\u2581market", "\u2581value", "\u2581of", "\u2581small", "\u2581amounts", "\u2581of", "\u2581mit", "h", "r", "il", "\u2581is", "\u2581so", "\u2581ridiculous", "ly", "\u2581high", "\u2581that", ",", "\u2581scale", "d", "\u2581to", "\u2581", "a", "\u2581whole", "\u2581arm", "our", "\u2581made", "\u2581of", "\u2581mit", "h", "r", "il", ",", "\u2581its", "\u2581value", "\u2581would", "\u2581indeed", "\u2581dwarf", "\u2581an", "\u2581un", "important", "\u2581economy", "\u2581such", "\u2581as", "\u2581the", "\u2581Shi", "re", "\u2581", "\u2019", "\u2581", "s", ",", "\u2581without", "\u2581", "requiring", "\u2581an", "\u2581exact", "\u2581calculation", ".", "\u2581This", "\u2581is", "n", "\u2581", "\u2019", "\u2581", "t", "\u2581*", "\u2581that", "\u2581*", "\u2581unrealistic", "\u2581for", "\u2581an", "\u2581item", "\u2581", "\u2019", "\u2581", "s", "\u2581value", "\u2581(", "\u2581as", "\u2581", "a", "\u2581gift", ",", "\u2581it", "\u2581kind", "\u2581of", "\u2581is", "\u2581though", ")", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581think", "\u2581this", "\u2581answer", "\u2581is", "\u2581wrong", "\u2581", "\u2014", "\u2581I", "\u2581certainly", "\u2581took", "\u2581it", "\u2581to", "\u2581be", "\u2581meant", "\u2581literally", ".", "\u2581The", "\u2581last", "\u2581line", "\u2581in", "\u2581your", "\u2581answer", "\u2581is", "\u2581key", ",", "\u2581but", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581entirely", "\u2581possible", "\u2581that", "\u2581the", "\u2581worth", "\u2581of", "\u2581market", "\u2581value", "\u2581of", "\u2581small", "\u2581amounts", "\u2581of", "\u2581mit", "h", "r", "il", "\u2581is", "\u2581so", "\u2581ridiculous", "ly", "\u2581high", "\u2581that", ",", "\u2581scale", "d", "\u2581to", "\u2581", "a", "\u2581whole", "\u2581arm", "our", "\u2581made", "\u2581of", "\u2581mit", "h", "r", "il", ",", "\u2581its", "\u2581value", "\u2581would", "\u2581indeed", "\u2581dwarf", "\u2581an", "\u2581un", "important", "\u2581economy", "\u2581such", "\u2581as", "<m>", "\u2581the", "<m>", "\u2581Shi", "re", "</m>", "</m>", "\u2581", "\u2019", "\u2581", "s", ",", "\u2581without", "\u2581", "requiring", "\u2581an", "\u2581exact", "\u2581calculation", ".", "\u2581This", "\u2581is", "n", "\u2581", "\u2019", "\u2581", "t", "\u2581*", "\u2581that", "\u2581*", "\u2581unrealistic", "\u2581for", "\u2581an", "\u2581item", "\u2581", "\u2019", "\u2581", "s", "\u2581value", "\u2581(", "\u2581as", "\u2581", "a", "\u2581gift", ",", "\u2581it", "\u2581kind", "\u2581of", "\u2581is", "\u2581though", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 28, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 41, 41, 41, 42, 43, 44, 44, 45, 46, 47, 48, 48, 49, 50, 50, 51, 52, 52, 53, 54, 55, 55, 55, 55, 56, 57, 58, 59, 60, 61, 62, 63, 63, 64, 65, 66, 67, 68, 68, 69, 69, 70, 70, 71, 72, 73, 73, 74, 75, 76, 77, 78, 79, 79, 80, 80, 81, 81, 82, 83, 84, 85, 86, 87, 88, 89, 89, 90, 90, 91, 92, 93, 94, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_428", "sentence": ["\u2581Do", "\u2581politicians", "\u2581ever", "\u2581admit", "\u2581they", "\u2581made", "\u2581", "a", "\u2581bad", "\u2581decision", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Do", "\u2581politicians", "\u2581ever", "\u2581admit", "\u2581they", "\u2581made", "\u2581", "a", "\u2581bad", "\u2581decision", "?", "</s>"], "target_sentence": ["\u2581Do", "\u2581politicians", "\u2581ever", "\u2581admit", "\u2581they", "\u2581made", "\u2581", "a", "\u2581bad", "\u2581decision", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_429", "sentence": ["\u2581I", "\u2581still", "\u2581think", "\u2581that", "\u2581with", "\u2581more", "\u2581details", "\u2581from", "\u2581your", "\u2581actual", "\u2581proof", ",", "\u2581you", "\u2581might", "\u2581have", "\u2581", "a", "\u2581better", "\u2581chance", "\u2581of", "\u2581getting", "\u2581something", "\u2581which", "\u2581is", "\u2581useful", "\u2581for", "\u2581you", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581still", "\u2581think", "\u2581that", "\u2581with", "\u2581more", "\u2581details", "\u2581from", "\u2581your", "\u2581actual", "\u2581proof", ",", "\u2581you", "\u2581might", "\u2581have", "\u2581", "a", "\u2581better", "\u2581chance", "\u2581of", "\u2581getting", "\u2581something", "\u2581which", "\u2581is", "\u2581useful", "\u2581for", "\u2581you", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581still", "\u2581think", "\u2581that", "\u2581with", "\u2581more", "\u2581details", "\u2581from", "\u2581your", "\u2581actual", "\u2581proof", ",", "\u2581you", "\u2581might", "\u2581have", "\u2581", "a", "\u2581better", "\u2581chance", "\u2581of", "\u2581getting", "\u2581something", "\u2581which", "\u2581is", "\u2581useful", "\u2581for", "\u2581you", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_430", "sentence": ["\u2581Running", "\u2581", "a", "\u2581local", "\u2581server", "\u2581inside", "\u2581", "a", "\u2581virtual", "\u2581machine", "\u2581disconnected", "\u2581from", "\u2581the", "\u2581Internet", "\u2581", "-", "\u2581is", "\u2581this", "\u2581secure", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Running", "\u2581", "a", "\u2581local", "\u2581server", "\u2581inside", "\u2581", "a", "\u2581virtual", "\u2581machine", "\u2581disconnected", "\u2581from", "\u2581the", "\u2581Internet", "\u2581", "-", "\u2581is", "\u2581this", "\u2581secure", "?", "</s>"], "target_sentence": ["\u2581Running", "\u2581", "a", "\u2581local", "\u2581server", "\u2581inside", "\u2581", "a", "\u2581virtual", "\u2581machine", "\u2581disconnected", "\u2581from", "\u2581the", "\u2581Internet", "\u2581", "-", "\u2581is", "\u2581this", "\u2581secure", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_431", "sentence": ["\u2581What", "\u2581non", "-", "\u2581Star", "\u2581Trek", "\u2581movie", "\u2581used", "\u2581the", "\u2581TO", "S", "\u2581font", "\u2581for", "\u2581the", "\u2581end", "\u2581credits", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581non", "-", "\u2581Star", "\u2581Trek", "\u2581movie", "\u2581used", "\u2581the", "\u2581TO", "S", "\u2581font", "\u2581for", "\u2581the", "\u2581end", "\u2581credits", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581non", "-", "<m>", "<m>", "\u2581Star", "\u2581Trek", "</m>", "</m>", "\u2581movie", "\u2581used", "\u2581the", "\u2581TO", "S", "\u2581font", "\u2581for", "\u2581the", "\u2581end", "\u2581credits", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 0, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_432", "sentence": ["\u2581Book", "\u2581", "n", "ar", "rated", "\u2581by", "\u2581the", "\u2581de", "vil", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Book", "\u2581", "n", "ar", "rated", "\u2581by", "\u2581the", "\u2581de", "vil", "</s>"], "target_sentence": ["\u2581Book", "\u2581", "n", "ar", "rated", "\u2581by", "\u2581the", "<m>", "\u2581de", "vil", "</m>", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1]}, {"doc_id": "emerging.test_433", "sentence": ["\u2581Does", "\u2581someone", "\u2581have", "\u2581it", "\u2581out", "\u2581for", "\u2581me", ",", "\u2581or", "\u2581is", "\u2581this", "\u2581router", "\u2581\"", "\u2581features", "\u2581\"", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Does", "\u2581someone", "\u2581have", "\u2581it", "\u2581out", "\u2581for", "\u2581me", ",", "\u2581or", "\u2581is", "\u2581this", "\u2581router", "\u2581\"", "\u2581features", "\u2581\"", "?", "</s>"], "target_sentence": ["\u2581Does", "\u2581someone", "\u2581have", "\u2581it", "\u2581out", "\u2581for", "\u2581me", ",", "\u2581or", "\u2581is", "\u2581this", "\u2581router", "\u2581\"", "\u2581features", "\u2581\"", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_434", "sentence": ["\u2581Store", "\u2581SQL", "\u2581database", "\u2581credentials", "\u2581in", "\u2581", "a", "\u2581web", "server", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Store", "\u2581SQL", "\u2581database", "\u2581credentials", "\u2581in", "\u2581", "a", "\u2581web", "server", "</s>"], "target_sentence": ["\u2581Store", "\u2581SQL", "\u2581database", "\u2581credentials", "\u2581in", "\u2581", "a", "\u2581web", "server", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_435", "sentence": ["\u2581That", "'", "\u2581", "s", "\u2581not", ".", "\u2581", "p", "\u258112", "\u2581format", ".", "\u2581Just", ".", "\u2581P", "EM", "\u2581format", "\u2581with", "\u2581the", "\u2581(", "\u2581wrong", ")", ".", "\u2581", "p", "\u258112", "\u2581file", "\u2581name", "\u2581extension", ".", "\u2581Do", "\u2581you", "\u2581really", ",", "\u2581really", "\u2581need", "\u2581", "p", "\u258112", "\u2581format", "?", "\u2581(", "\u2581If", "\u2581what", "\u2581you", "\u2581did", "\u2581works", ",", "\u2581then", "\u2581you", "\u2581don", "'", "\u2581", "t", ",", "\u2581since", "\u2581it", "\u2581never", "\u2581was", "\u2581P", "\u258112", ".", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581That", "'", "\u2581", "s", "\u2581not", ".", "\u2581", "p", "\u258112", "\u2581format", ".", "\u2581Just", ".", "\u2581P", "EM", "\u2581format", "\u2581with", "\u2581the", "\u2581(", "\u2581wrong", ")", ".", "\u2581", "p", "\u258112", "\u2581file", "\u2581name", "\u2581extension", ".", "\u2581Do", "\u2581you", "\u2581really", ",", "\u2581really", "\u2581need", "\u2581", "p", "\u258112", "\u2581format", "?", "\u2581(", "\u2581If", "\u2581what", "\u2581you", "\u2581did", "\u2581works", ",", "\u2581then", "\u2581you", "\u2581don", "'", "\u2581", "t", ",", "\u2581since", "\u2581it", "\u2581never", "\u2581was", "\u2581P", "\u258112", ".", ")", "</s>"], "target_sentence": ["\u2581That", "'", "\u2581", "s", "\u2581not", ".", "\u2581", "p", "\u258112", "\u2581format", ".", "\u2581Just", ".", "\u2581P", "EM", "\u2581format", "\u2581with", "\u2581the", "\u2581(", "\u2581wrong", ")", ".", "\u2581", "p", "\u258112", "\u2581file", "\u2581name", "\u2581extension", ".", "\u2581Do", "\u2581you", "\u2581really", ",", "\u2581really", "\u2581need", "\u2581", "p", "\u258112", "\u2581format", "?", "\u2581(", "\u2581If", "\u2581what", "\u2581you", "\u2581did", "\u2581works", ",", "\u2581then", "\u2581you", "\u2581don", "'", "\u2581", "t", ",", "\u2581since", "\u2581it", "\u2581never", "\u2581was", "\u2581P", "\u258112", ".", ")", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_436", "sentence": ["\u2581[", "\u2581Related", "\u2581answer", "]", "\u2581(", "\u2581http", "://", "mov", "ies", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "a", "/3", "39", "05", "/11", "90", ")", "\u2581for", "\u2581you", "\u2581bonus", "\u2581side", "note", "\u2581with", "\u2581word", "\u2581of", "\u2581god", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581Related", "\u2581answer", "]", "\u2581(", "\u2581http", "://", "mov", "ies", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "a", "/3", "39", "05", "/11", "90", ")", "\u2581for", "\u2581you", "\u2581bonus", "\u2581side", "note", "\u2581with", "\u2581word", "\u2581of", "\u2581god", ".", "</s>"], "target_sentence": ["\u2581[", "\u2581Related", "\u2581answer", "]", "\u2581(", "\u2581http", "://", "mov", "ies", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "a", "/3", "39", "05", "/11", "90", ")", "\u2581for", "\u2581you", "\u2581bonus", "\u2581side", "note", "\u2581with", "\u2581word", "\u2581of", "\u2581god", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_437", "sentence": ["\u2581Anything", "\u2581else", "\u2581you", "\u2581can", "\u2581remember", "\u2581about", "\u2581", "th", "'", "\u2581", "s", "\u2581book", "?", "\u2581[", "\u2581This", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "s", "c", "if", "i", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "93", "35", "/", "how", "-", "to", "-", "a", "s", "k", "-", "a", "-", "good", "-", "story", "-", "i", "d", "-", "ques", "tion", ")", "\u2581could", "\u2581help", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Anything", "\u2581else", "\u2581you", "\u2581can", "\u2581remember", "\u2581about", "\u2581", "th", "'", "\u2581", "s", "\u2581book", "?", "\u2581[", "\u2581This", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "s", "c", "if", "i", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "93", "35", "/", "how", "-", "to", "-", "a", "s", "k", "-", "a", "-", "good", "-", "story", "-", "i", "d", "-", "ques", "tion", ")", "\u2581could", "\u2581help", ".", "</s>"], "target_sentence": ["\u2581Anything", "\u2581else", "\u2581you", "\u2581can", "\u2581remember", "\u2581about", "\u2581", "th", "'", "\u2581", "s", "\u2581book", "?", "\u2581[", "\u2581This", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "s", "c", "if", "i", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "93", "35", "/", "how", "-", "to", "-", "a", "s", "k", "-", "a", "-", "good", "-", "story", "-", "i", "d", "-", "ques", "tion", ")", "\u2581could", "\u2581help", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_438", "sentence": ["\u2581What", "\u2581did", "\u2581Tar", "zan", "\u2581say", "\u2581to", "\u2581Che", "e", "t", "a", "\u2581when", "\u2581Che", "e", "t", "a", "\u2581did", "\u2581", "a", "\u2581good", "\u2581job", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581did", "\u2581Tar", "zan", "\u2581say", "\u2581to", "\u2581Che", "e", "t", "a", "\u2581when", "\u2581Che", "e", "t", "a", "\u2581did", "\u2581", "a", "\u2581good", "\u2581job", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581did", "<m>", "<m>", "\u2581Tar", "zan", "</m>", "</m>", "\u2581say", "\u2581to", "<m>", "\u2581Che", "e", "t", "a", "</m>", "\u2581when", "<m>", "\u2581Che", "e", "t", "a", "</m>", "\u2581did", "\u2581", "a", "\u2581good", "\u2581job", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 5, 5, 6, 7, 7, 7, 7, 8, 9, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 1, 0, -1, -1, 1, 0, -1, -1, 2, -1, -1, -1, -1, 2, -1, 3, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_439", "sentence": ["\u2581Why", "\u2581is", "\u2581there", "\u2581", "a", "\u2581dis", "claim", "er", "\u2581about", "\u2581not", "\u2581accepting", "\u2581money", "\u2581from", "\u2581tobacco", "\u2581companies", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581movies", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581there", "\u2581", "a", "\u2581dis", "claim", "er", "\u2581about", "\u2581not", "\u2581accepting", "\u2581money", "\u2581from", "\u2581tobacco", "\u2581companies", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581movies", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "\u2581there", "\u2581", "a", "\u2581dis", "claim", "er", "\u2581about", "\u2581not", "\u2581accepting", "\u2581money", "\u2581from", "<m>", "\u2581tobacco", "\u2581companies", "</m>", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581movies", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_440", "sentence": ["\u2581How", "\u2581does", "\u2581the", "\u2581President", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581get", "\u2581", "a", "\u2581budget", "\u2581", "authorised", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581does", "\u2581the", "\u2581President", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581get", "\u2581", "a", "\u2581budget", "\u2581", "authorised", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581does", "\u2581the", "\u2581President", "\u2581of", "\u2581the", "<m>", "\u2581United", "\u2581States", "</m>", "\u2581get", "\u2581", "a", "\u2581budget", "\u2581", "authorised", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_441", "sentence": ["\u2581When", "\u2581did", "\u2581the", "\u2581practice", "\u2581of", "\u2581having", "\u2581", "a", "\u2581joke", "\u2581with", "\u2581no", "\u2581music", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581", "a", "\u2581trailer", "\u2581begin", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581When", "\u2581did", "\u2581the", "\u2581practice", "\u2581of", "\u2581having", "\u2581", "a", "\u2581joke", "\u2581with", "\u2581no", "\u2581music", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581", "a", "\u2581trailer", "\u2581begin", "?", "</s>"], "target_sentence": ["\u2581When", "\u2581did", "\u2581the", "\u2581practice", "\u2581of", "\u2581having", "\u2581", "a", "\u2581joke", "\u2581with", "\u2581no", "\u2581music", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581", "a", "\u2581trailer", "\u2581begin", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_442", "sentence": ["\u2581If", "\u2581at", "\u2581some", "\u2581point", "\u2581President", "\u2581Trump", "\u2581was", "\u2581imp", "e", "a", "ched", ",", "\u2581what", "\u2581would", "\u2581it", "\u2581take", "\u2581to", "\u2581actually", "\u2581be", "\u2581removed", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581at", "\u2581some", "\u2581point", "\u2581President", "\u2581Trump", "\u2581was", "\u2581imp", "e", "a", "ched", ",", "\u2581what", "\u2581would", "\u2581it", "\u2581take", "\u2581to", "\u2581actually", "\u2581be", "\u2581removed", "?", "</s>"], "target_sentence": ["\u2581If", "\u2581at", "\u2581some", "\u2581point", "<m>", "<m>", "\u2581President", "<m>", "\u2581Trump", "</m>", "</m>", "</m>", "\u2581was", "\u2581imp", "e", "a", "ched", ",", "\u2581what", "\u2581would", "\u2581it", "\u2581take", "\u2581to", "\u2581actually", "\u2581be", "\u2581removed", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 1, 0, -1, 2, -1, 1, 2, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_443", "sentence": ["\u2581What", "\u2581security", "\u2581consideration", "s", "\u2581are", "\u2581there", "\u2581when", "\u2581developing", "\u2581", "a", "\u2581random", "\u2581password", "\u2581generator", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581security", "\u2581consideration", "s", "\u2581are", "\u2581there", "\u2581when", "\u2581developing", "\u2581", "a", "\u2581random", "\u2581password", "\u2581generator", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581security", "\u2581consideration", "s", "\u2581are", "\u2581there", "\u2581when", "\u2581developing", "\u2581", "a", "\u2581random", "\u2581password", "\u2581generator", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_444", "sentence": ["\u2581A", "\u2581little", "\u2581update", "\u2581regarding", "\u2581this", ":", "\u2581I", "\u2581have", "\u2581not", "\u2581been", "\u2581called", "\u2581", "a", "\u2581single", "\u2581time", "\u2581by", "\u2581any", "\u2581kind", "\u2581of", "\u2581advertising", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "\u2581little", "\u2581update", "\u2581regarding", "\u2581this", ":", "\u2581I", "\u2581have", "\u2581not", "\u2581been", "\u2581called", "\u2581", "a", "\u2581single", "\u2581time", "\u2581by", "\u2581any", "\u2581kind", "\u2581of", "\u2581advertising", ".", "</s>"], "target_sentence": ["\u2581A", "\u2581little", "\u2581update", "\u2581regarding", "\u2581this", ":", "\u2581I", "\u2581have", "\u2581not", "\u2581been", "\u2581called", "\u2581", "a", "\u2581single", "\u2581time", "\u2581by", "\u2581any", "<m>", "\u2581kind", "\u2581of", "\u2581advertising", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_445", "sentence": ["\u2581Comment", "\u2581deleted", "\u2581and", "\u2581made", "\u2581into", "\u2581an", "\u2581answer", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Comment", "\u2581deleted", "\u2581and", "\u2581made", "\u2581into", "\u2581an", "\u2581answer", ".", "</s>"], "target_sentence": ["\u2581Comment", "\u2581deleted", "\u2581and", "\u2581made", "\u2581into", "\u2581an", "\u2581answer", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_446", "sentence": ["\u2581All", "\u2581right", ",", "\u2581seems", "\u2581we", "\u2581will", "\u2581remain", "\u2581with", "\u2581different", "\u2581opinions", "\u2581on", "\u2581this", ",", "\u2581as", "\u2581to", "\u2581me", ",", "\u2581TO", "S", "\u2581*", "\u2581Meta", "morph", "o", "s", "is", "\u2581*", "\u2581appears", "\u2581to", "\u2581be", "\u2581the", "\u2581one", "-", "off", "\u2581episode", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581All", "\u2581right", ",", "\u2581seems", "\u2581we", "\u2581will", "\u2581remain", "\u2581with", "\u2581different", "\u2581opinions", "\u2581on", "\u2581this", ",", "\u2581as", "\u2581to", "\u2581me", ",", "\u2581TO", "S", "\u2581*", "\u2581Meta", "morph", "o", "s", "is", "\u2581*", "\u2581appears", "\u2581to", "\u2581be", "\u2581the", "\u2581one", "-", "off", "\u2581episode", ".", "</s>"], "target_sentence": ["\u2581All", "\u2581right", ",", "\u2581seems", "\u2581we", "\u2581will", "\u2581remain", "\u2581with", "\u2581different", "\u2581opinions", "\u2581on", "\u2581this", ",", "\u2581as", "\u2581to", "\u2581me", ",", "<m>", "\u2581TO", "S", "</m>", "\u2581*", "<m>", "\u2581Meta", "morph", "o", "s", "is", "</m>", "\u2581*", "\u2581appears", "\u2581to", "\u2581be", "\u2581the", "\u2581one", "-", "off", "\u2581episode", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 19, 19, 19, 19, 20, 21, 22, 23, 24, 25, 25, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_447", "sentence": ["\u2581It", "\u2581seems", "\u2581to", "\u2581me", "\u2581this", "\u2581answer", "\u2581confirm", "s", "\u2581what", "\u2581the", "\u2581restrictions", "\u2581on", "\u2581", "a", "\u2581", "501", "\u2581(", "\u2581", "c", ")", "\u25813", "\u2581are", "\u2581", "w", ".", "\u2581", "r", ".", "\u2581", "t", "\u2581", "a", "\u2581candidate", ";", "\u2581I", "\u2581think", "\u2581the", "\u2581more", "\u2581relevant", "\u2581issue", "\u2581here", "\u2581is", "\u2581whether", "\u2581the", "\u2581filing", "\u2581makes", "\u2581Trump", "\u2581", "a", "\u2581\"", "\u2581candidate", "\u2581\"", "\u2581for", "\u2581purposes", "\u2581of", "\u2581said", "\u2581restrictions", ",", "\u2581especially", "\u2581in", "\u2581light", "\u2581of", "\u2581the", "\u2581first", "\u2581phrase", "\u2581in", "\u2581the", "\u2581filing", ",", "\u2581\"", "\u2581While", "\u2581this", "\u2581does", "\u2581not", "\u2581constitute", "\u2581", "a", "\u2581formal", "\u2581announcement", "\u2581of", "\u2581my", "\u2581candid", "acy", "\u2581for", "\u2581the", "\u25812020", "\u2581election", ".", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "\u2581seems", "\u2581to", "\u2581me", "\u2581this", "\u2581answer", "\u2581confirm", "s", "\u2581what", "\u2581the", "\u2581restrictions", "\u2581on", "\u2581", "a", "\u2581", "501", "\u2581(", "\u2581", "c", ")", "\u25813", "\u2581are", "\u2581", "w", ".", "\u2581", "r", ".", "\u2581", "t", "\u2581", "a", "\u2581candidate", ";", "\u2581I", "\u2581think", "\u2581the", "\u2581more", "\u2581relevant", "\u2581issue", "\u2581here", "\u2581is", "\u2581whether", "\u2581the", "\u2581filing", "\u2581makes", "\u2581Trump", "\u2581", "a", "\u2581\"", "\u2581candidate", "\u2581\"", "\u2581for", "\u2581purposes", "\u2581of", "\u2581said", "\u2581restrictions", ",", "\u2581especially", "\u2581in", "\u2581light", "\u2581of", "\u2581the", "\u2581first", "\u2581phrase", "\u2581in", "\u2581the", "\u2581filing", ",", "\u2581\"", "\u2581While", "\u2581this", "\u2581does", "\u2581not", "\u2581constitute", "\u2581", "a", "\u2581formal", "\u2581announcement", "\u2581of", "\u2581my", "\u2581candid", "acy", "\u2581for", "\u2581the", "\u25812020", "\u2581election", ".", "\u2581\"", "</s>"], "target_sentence": ["\u2581It", "\u2581seems", "\u2581to", "\u2581me", "\u2581this", "\u2581answer", "\u2581confirm", "s", "\u2581what", "\u2581the", "\u2581restrictions", "\u2581on", "\u2581", "a", "\u2581", "501", "\u2581(", "\u2581", "c", ")", "\u25813", "\u2581are", "\u2581", "w", ".", "\u2581", "r", ".", "\u2581", "t", "\u2581", "a", "\u2581candidate", ";", "\u2581I", "\u2581think", "\u2581the", "\u2581more", "\u2581relevant", "\u2581issue", "\u2581here", "\u2581is", "\u2581whether", "\u2581the", "\u2581filing", "\u2581makes", "<m>", "\u2581Trump", "</m>", "\u2581", "a", "\u2581\"", "\u2581candidate", "\u2581\"", "\u2581for", "\u2581purposes", "\u2581of", "\u2581said", "\u2581restrictions", ",", "\u2581especially", "\u2581in", "\u2581light", "\u2581of", "\u2581the", "\u2581first", "\u2581phrase", "\u2581in", "\u2581the", "\u2581filing", ",", "\u2581\"", "\u2581While", "\u2581this", "\u2581does", "\u2581not", "\u2581constitute", "\u2581", "a", "\u2581formal", "\u2581announcement", "\u2581of", "\u2581my", "\u2581candid", "acy", "\u2581for", "\u2581the", "\u25812020", "\u2581election", ".", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 14, 14, 15, 16, 17, 18, 18, 19, 20, 20, 21, 22, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 66, 67, 68, 69, 70, 71, 71, 72, 73, 74, 75, 76, 77, 78], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_448", "sentence": ["\u2581", "Anim", "ated", "\u2581movie", "\u2581about", "\u2581kid", "\u2581who", "\u2581lost", "\u2581his", "\u2581parents", "\u2581in", "\u2581", "a", "\u2581car", "\u2581accident", "\u2581with", "\u2581", "a", "\u2581de", "er", "\u2581(", "\u2581got", "\u2581", "reunite", "d", "\u2581via", "\u2581time", "\u2581travel", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Anim", "ated", "\u2581movie", "\u2581about", "\u2581kid", "\u2581who", "\u2581lost", "\u2581his", "\u2581parents", "\u2581in", "\u2581", "a", "\u2581car", "\u2581accident", "\u2581with", "\u2581", "a", "\u2581de", "er", "\u2581(", "\u2581got", "\u2581", "reunite", "d", "\u2581via", "\u2581time", "\u2581travel", ")", "</s>"], "target_sentence": ["\u2581", "Anim", "ated", "\u2581movie", "\u2581about", "\u2581kid", "\u2581who", "\u2581lost", "\u2581his", "\u2581parents", "\u2581in", "\u2581", "a", "\u2581car", "\u2581accident", "\u2581with", "\u2581", "a", "\u2581de", "er", "\u2581(", "\u2581got", "\u2581", "reunite", "d", "\u2581via", "\u2581time", "\u2581travel", ")", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 13, 14, 14, 15, 16, 17, 17, 17, 18, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_449", "sentence": ["\u2581Access", "\u2581Control", "\u2581Prim", "it", "ives", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Access", "\u2581Control", "\u2581Prim", "it", "ives", "</s>"], "target_sentence": ["\u2581Access", "\u2581Control", "\u2581Prim", "it", "ives", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_450", "sentence": ["\u2581unfortunately", "\u2581not", ",", "\u2581this", "\u2581is", "\u2581also", "\u2581not", "\u2581", "a", "\u2581series", "\u2581like", "\u2581I", "\u2581described", ".", "\u2581", "Arg", "h", "h", "\u2581its", "\u2581bug", "ging", "\u2581me", "\u2581ha", "ha", "\u2581I", "\u2581hope", "\u2581I", "\u2581find", "\u2581it", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581unfortunately", "\u2581not", ",", "\u2581this", "\u2581is", "\u2581also", "\u2581not", "\u2581", "a", "\u2581series", "\u2581like", "\u2581I", "\u2581described", ".", "\u2581", "Arg", "h", "h", "\u2581its", "\u2581bug", "ging", "\u2581me", "\u2581ha", "ha", "\u2581I", "\u2581hope", "\u2581I", "\u2581find", "\u2581it", "</s>"], "target_sentence": ["\u2581unfortunately", "\u2581not", ",", "\u2581this", "\u2581is", "\u2581also", "\u2581not", "\u2581", "a", "\u2581series", "\u2581like", "\u2581I", "\u2581described", ".", "\u2581", "Arg", "h", "h", "\u2581its", "\u2581bug", "ging", "\u2581me", "\u2581ha", "ha", "\u2581I", "\u2581hope", "\u2581I", "\u2581find", "\u2581it", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 14, 15, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_451", "sentence": ["\u2581Du", "plic", "ate", "\u2581of", "\u2581http", "://", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/4", "32", "93", "/", "176", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Du", "plic", "ate", "\u2581of", "\u2581http", "://", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/4", "32", "93", "/", "176", "?", "</s>"], "target_sentence": ["\u2581Du", "plic", "ate", "\u2581of", "\u2581http", "://", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/4", "32", "93", "/", "176", "?", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_452", "sentence": ["\u2581Why", "\u2581is", "\u2581", "a", "\u2581sleeping", "\u2581bag", "\u2581so", "\u2581cold", "\u2581when", "\u2581you", "\u2581first", "\u2581get", "\u2581in", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581", "a", "\u2581sleeping", "\u2581bag", "\u2581so", "\u2581cold", "\u2581when", "\u2581you", "\u2581first", "\u2581get", "\u2581in", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "\u2581", "a", "\u2581sleeping", "\u2581bag", "\u2581so", "\u2581cold", "\u2581when", "\u2581you", "\u2581first", "\u2581get", "\u2581in", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_453", "sentence": ["\u2581Which", "\u2581Sci", "-", "\u2581Fi", "\u2581work", "\u2581introduced", "\u2581the", "\u2581idea", "\u2581of", "\u2581\"", "\u2581Touch", "screen", "\u2581used", "\u2581by", "\u2581fingers", "\u2581\"", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Which", "\u2581Sci", "-", "\u2581Fi", "\u2581work", "\u2581introduced", "\u2581the", "\u2581idea", "\u2581of", "\u2581\"", "\u2581Touch", "screen", "\u2581used", "\u2581by", "\u2581fingers", "\u2581\"", "?", "</s>"], "target_sentence": ["\u2581Which", "\u2581Sci", "-", "\u2581Fi", "\u2581work", "\u2581introduced", "\u2581the", "\u2581idea", "\u2581of", "\u2581\"", "<m>", "\u2581Touch", "screen", "</m>", "\u2581used", "\u2581by", "\u2581fingers", "\u2581\"", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_454", "sentence": ["\u2581Thanks", ".", "\u2581A", "\u2581better", "\u2581question", ":", "\u2581did", "\u2581you", "\u2581recognise", "\u2581her", "\u2581as", "\u2581fishing", "\u2581before", ",", "\u2581or", "\u2581after", ",", "\u2581finding", "\u2581the", "\u2581full", "-", "sized", "\u2581photo", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Thanks", ".", "\u2581A", "\u2581better", "\u2581question", ":", "\u2581did", "\u2581you", "\u2581recognise", "\u2581her", "\u2581as", "\u2581fishing", "\u2581before", ",", "\u2581or", "\u2581after", ",", "\u2581finding", "\u2581the", "\u2581full", "-", "sized", "\u2581photo", "?", "</s>"], "target_sentence": ["\u2581Thanks", ".", "\u2581A", "\u2581better", "\u2581question", ":", "\u2581did", "\u2581you", "\u2581recognise", "\u2581her", "\u2581as", "\u2581fishing", "\u2581before", ",", "\u2581or", "\u2581after", ",", "\u2581finding", "\u2581the", "\u2581full", "-", "sized", "\u2581photo", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_455", "sentence": ["\u2581Com", "mut", "ation", "\u2581Relation", "\u2581between", "\u2581the", "\u2581Di", "rac", "\u2581Hamilton", "i", "an", "\u2581and", "\u2581Heli", "city", "\u2581operator", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Com", "mut", "ation", "\u2581Relation", "\u2581between", "\u2581the", "\u2581Di", "rac", "\u2581Hamilton", "i", "an", "\u2581and", "\u2581Heli", "city", "\u2581operator", "</s>"], "target_sentence": ["\u2581Com", "mut", "ation", "\u2581Relation", "\u2581between", "\u2581the", "<m>", "<m>", "<m>", "<m>", "\u2581Di", "rac", "\u2581Hamilton", "i", "an", "</m>", "</m>", "</m>", "</m>", "\u2581and", "<m>", "<m>", "<m>", "<m>", "\u2581Heli", "city", "</m>", "</m>", "</m>", "</m>", "\u2581operator", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 4, 5, 5, 5, 6, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, 1, 2, 4, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 3, 1, 0, 2, -1, -1, -1, -1, -1, 3, 1, 0, 2, -1, 7, 6, 4, 5, -1, -1, 7, 6, 4, 5, -1, -1]}, {"doc_id": "emerging.test_456", "sentence": ["\u2581What", "\u2581about", "\u2581the", "\u2581other", "\u2581AG", "RA", "\u2581drives", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581about", "\u2581the", "\u2581other", "\u2581AG", "RA", "\u2581drives", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581about", "\u2581the", "\u2581other", "<m>", "<m>", "<m>", "\u2581AG", "RA", "</m>", "</m>", "\u2581drives", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 2, -1, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, 1, 0, 2, -1, -1, 1, 0, -1, 2, -1, -1]}, {"doc_id": "emerging.test_457", "sentence": ["\u2581Does", "\u2581that", "\u2581", "imply", "\u2581president", "s", "\u2581sometimes", "\u2581push", "\u2581agenda", "s", "\u2581that", "\u2581are", "\u2581", "n", "'", "\u2581", "t", "\u2581meaningful", "\u2581to", "\u2581them", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Does", "\u2581that", "\u2581", "imply", "\u2581president", "s", "\u2581sometimes", "\u2581push", "\u2581agenda", "s", "\u2581that", "\u2581are", "\u2581", "n", "'", "\u2581", "t", "\u2581meaningful", "\u2581to", "\u2581them", "?", "</s>"], "target_sentence": ["\u2581Does", "\u2581that", "\u2581", "imply", "\u2581president", "s", "\u2581sometimes", "\u2581push", "\u2581agenda", "s", "\u2581that", "\u2581are", "\u2581", "n", "'", "\u2581", "t", "\u2581meaningful", "\u2581to", "\u2581them", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 6, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_458", "sentence": ["\u2581Interesting", "\u2581question", ",", "\u2581and", "\u2581I", "\u2581agree", "\u2581with", "\u2581you", "\u2581that", "\u2581it", "\u2581deserves", "\u2581", "a", "\u2581separate", "\u2581question", ".", "\u2581Please", "\u2581do", ",", "\u2581I", "\u2581will", "\u2581reply", "\u2581in", "\u2581this", "\u2581separate", "\u2581post", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Interesting", "\u2581question", ",", "\u2581and", "\u2581I", "\u2581agree", "\u2581with", "\u2581you", "\u2581that", "\u2581it", "\u2581deserves", "\u2581", "a", "\u2581separate", "\u2581question", ".", "\u2581Please", "\u2581do", ",", "\u2581I", "\u2581will", "\u2581reply", "\u2581in", "\u2581this", "\u2581separate", "\u2581post", ".", "</s>"], "target_sentence": ["\u2581Interesting", "\u2581question", ",", "\u2581and", "\u2581I", "\u2581agree", "\u2581with", "\u2581you", "\u2581that", "\u2581it", "\u2581deserves", "\u2581", "a", "\u2581separate", "\u2581question", ".", "\u2581Please", "\u2581do", ",", "\u2581I", "\u2581will", "\u2581reply", "\u2581in", "\u2581this", "\u2581separate", "\u2581post", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_459", "sentence": ["\u2581Why", "\u2581do", "\u2581so", "\u2581many", "\u2581kids", "\u2581in", "\u2581Digi", "mon", "\u2581wear", "\u2581gloves", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581do", "\u2581so", "\u2581many", "\u2581kids", "\u2581in", "\u2581Digi", "mon", "\u2581wear", "\u2581gloves", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581do", "\u2581so", "\u2581many", "\u2581kids", "\u2581in", "<m>", "<m>", "\u2581Digi", "mon", "</m>", "</m>", "\u2581wear", "\u2581gloves", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_460", "sentence": ["\u2581", "Firstly", "\u2581R", "\u2581", "&", "\u2581R", "\u2581signifie", "s", "\u2581Rest", "\u2581and", "\u2581Recreation", ".", "\u2581So", "\u2581the", "\u2581recreation", "\u2581part", "\u2581takes", "\u2581care", "\u2581of", "\u2581the", "\u2581radio", "\u2581programs", "\u2581part", "\u2581of", "\u2581the", "\u2581question", ".", "\u2581", "Secondly", ",", "\u2581as", "\u2581you", "\u2581can", "\u2581see", "\u2581my", "\u2581last", "\u2581quoted", "\u2581question", ",", "\u2581the", "\u2581user", "\u2581asked", "\u2581why", "\u2581radio", "\u2581programs", "\u2581were", "\u2581being", "\u2581run", "\u2581at", "\u2581Vietnam", "\u2581and", "\u2581not", "\u2581why", "\u2581the", "\u2581army", "\u2581has", "\u2581its", "\u2581own", "\u2581program", ".", "\u2581Please", "\u2581correct", "\u2581me", "\u2581", "if", "\u2581I", "\u2581understood", "\u2581the", "\u2581question", "\u2581wrong", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Firstly", "\u2581R", "\u2581", "&", "\u2581R", "\u2581signifie", "s", "\u2581Rest", "\u2581and", "\u2581Recreation", ".", "\u2581So", "\u2581the", "\u2581recreation", "\u2581part", "\u2581takes", "\u2581care", "\u2581of", "\u2581the", "\u2581radio", "\u2581programs", "\u2581part", "\u2581of", "\u2581the", "\u2581question", ".", "\u2581", "Secondly", ",", "\u2581as", "\u2581you", "\u2581can", "\u2581see", "\u2581my", "\u2581last", "\u2581quoted", "\u2581question", ",", "\u2581the", "\u2581user", "\u2581asked", "\u2581why", "\u2581radio", "\u2581programs", "\u2581were", "\u2581being", "\u2581run", "\u2581at", "\u2581Vietnam", "\u2581and", "\u2581not", "\u2581why", "\u2581the", "\u2581army", "\u2581has", "\u2581its", "\u2581own", "\u2581program", ".", "\u2581Please", "\u2581correct", "\u2581me", "\u2581", "if", "\u2581I", "\u2581understood", "\u2581the", "\u2581question", "\u2581wrong", ".", "</s>"], "target_sentence": ["\u2581", "Firstly", "\u2581R", "\u2581", "&", "\u2581R", "\u2581signifie", "s", "\u2581Rest", "\u2581and", "\u2581Recreation", ".", "\u2581So", "\u2581the", "\u2581recreation", "\u2581part", "\u2581takes", "\u2581care", "\u2581of", "\u2581the", "\u2581radio", "\u2581programs", "\u2581part", "\u2581of", "\u2581the", "\u2581question", ".", "\u2581", "Secondly", ",", "\u2581as", "\u2581you", "\u2581can", "\u2581see", "\u2581my", "\u2581last", "\u2581quoted", "\u2581question", ",", "\u2581the", "\u2581user", "\u2581asked", "\u2581why", "\u2581radio", "\u2581programs", "\u2581were", "\u2581being", "\u2581run", "\u2581at", "<m>", "\u2581Vietnam", "</m>", "\u2581and", "\u2581not", "\u2581why", "\u2581the", "\u2581army", "\u2581has", "\u2581its", "\u2581own", "\u2581program", ".", "\u2581Please", "\u2581correct", "\u2581me", "\u2581", "if", "\u2581I", "\u2581understood", "\u2581the", "\u2581question", "\u2581wrong", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 59, 60, 61, 62, 63, 64, 65, 66], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_461", "sentence": ["\u2581How", "\u2581did", "\u2581my", "\u2581professor", "\u2581sniff", "\u2581my", "\u2581G", "mail", "\u2581password", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581did", "\u2581my", "\u2581professor", "\u2581sniff", "\u2581my", "\u2581G", "mail", "\u2581password", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581did", "\u2581my", "\u2581professor", "\u2581sniff", "\u2581my", "\u2581G", "mail", "\u2581password", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_462", "sentence": ["\u2581Ghost", "\u2581from", "\u2581their", "\u2581", "kinder", "gard", "en", "\u2581will", "\u2581follow", "\u2581them", "\u2581in", "\u2581their", "\u2581dreams", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ghost", "\u2581from", "\u2581their", "\u2581", "kinder", "gard", "en", "\u2581will", "\u2581follow", "\u2581them", "\u2581in", "\u2581their", "\u2581dreams", "</s>"], "target_sentence": ["<m>", "\u2581Ghost", "</m>", "\u2581from", "\u2581their", "\u2581", "kinder", "gard", "en", "\u2581will", "\u2581follow", "\u2581them", "\u2581in", "\u2581their", "\u2581dreams", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_463", "sentence": ["\u2581Do", "\u2581we", "\u2581know", "\u2581the", "\u2581timeline", "\u2581on", "\u2581the", "\u2581Sci", "-", "\u2581Fi", "\u2581names", "\u2581in", "\u2581the", "\u2581question", "?", "\u2581I", "\u2581would", "\u2581guess", "\u2581that", "\u2581early", "\u2581ones", "\u2581were", "\u2581doctors", ",", "\u2581and", "\u2581later", "\u2581ones", "\u2581could", "\u2581have", "\u2581just", "\u2581as", "\u2581easily", "\u2581been", "\u2581inspired", "\u2581by", "\u2581the", "\u2581early", "\u2581ones", "\u2581as", "\u2581by", "\u2581the", "\u2581actual", "\u2581doctor", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Do", "\u2581we", "\u2581know", "\u2581the", "\u2581timeline", "\u2581on", "\u2581the", "\u2581Sci", "-", "\u2581Fi", "\u2581names", "\u2581in", "\u2581the", "\u2581question", "?", "\u2581I", "\u2581would", "\u2581guess", "\u2581that", "\u2581early", "\u2581ones", "\u2581were", "\u2581doctors", ",", "\u2581and", "\u2581later", "\u2581ones", "\u2581could", "\u2581have", "\u2581just", "\u2581as", "\u2581easily", "\u2581been", "\u2581inspired", "\u2581by", "\u2581the", "\u2581early", "\u2581ones", "\u2581as", "\u2581by", "\u2581the", "\u2581actual", "\u2581doctor", ".", "</s>"], "target_sentence": ["\u2581Do", "\u2581we", "\u2581know", "\u2581the", "\u2581timeline", "\u2581on", "\u2581the", "<m>", "\u2581Sci", "-", "\u2581Fi", "</m>", "\u2581names", "\u2581in", "\u2581the", "\u2581question", "?", "\u2581I", "\u2581would", "\u2581guess", "\u2581that", "\u2581early", "\u2581ones", "\u2581were", "\u2581doctors", ",", "\u2581and", "\u2581later", "\u2581ones", "\u2581could", "\u2581have", "\u2581just", "\u2581as", "\u2581easily", "\u2581been", "\u2581inspired", "\u2581by", "\u2581the", "\u2581early", "\u2581ones", "\u2581as", "\u2581by", "\u2581the", "\u2581actual", "\u2581doctor", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_464", "sentence": ["\u2581I", "\u2581have", "\u2581worked", "\u2581with", "\u2581multiple", "\u2581framework", "s", ",", "\u2581but", "\u2581still", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581see", "\u2581what", "\u2581your", "\u2581question", "\u2581is", ".", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581have", "\u2581worked", "\u2581with", "\u2581multiple", "\u2581framework", "s", ",", "\u2581but", "\u2581still", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581see", "\u2581what", "\u2581your", "\u2581question", "\u2581is", ".", ".", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581have", "\u2581worked", "\u2581with", "\u2581multiple", "\u2581framework", "s", ",", "\u2581but", "\u2581still", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581see", "\u2581what", "\u2581your", "\u2581question", "\u2581is", ".", ".", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_465", "sentence": ["\u2581@", "\u2581Paul", "\u2581leave", "\u2581the", "\u2581actors", "\u2581enough", "\u2581time", "\u2581in", "\u2581the", "\u2581snow", "\u2581and", "\u2581you", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581to", "\u2581pay", "\u2581them", "\u2581anymore", "!", ":", "\u2581", "-", "\u2581D", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Paul", "\u2581leave", "\u2581the", "\u2581actors", "\u2581enough", "\u2581time", "\u2581in", "\u2581the", "\u2581snow", "\u2581and", "\u2581you", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581to", "\u2581pay", "\u2581them", "\u2581anymore", "!", ":", "\u2581", "-", "\u2581D", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Paul", "</m>", "\u2581leave", "\u2581the", "\u2581actors", "\u2581enough", "\u2581time", "\u2581in", "\u2581the", "\u2581snow", "\u2581and", "\u2581you", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581to", "\u2581pay", "\u2581them", "\u2581anymore", "!", ":", "\u2581", "-", "\u2581D", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_466", "sentence": ["\u2581How", "\u2581to", "\u2581protect", "\u2581an", "\u2581offline", "\u2581proprietary", "\u2581software", "\u2581from", "\u2581being", "\u2581stolen", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581to", "\u2581protect", "\u2581an", "\u2581offline", "\u2581proprietary", "\u2581software", "\u2581from", "\u2581being", "\u2581stolen", "</s>"], "target_sentence": ["\u2581How", "\u2581to", "\u2581protect", "\u2581an", "\u2581offline", "\u2581proprietary", "\u2581software", "\u2581from", "\u2581being", "\u2581stolen", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_467", "sentence": ["\u2581@", "\u2581poisson", "\u2581I", "\u2581see", ".", "\u2581That", "\u2581type", "\u2581of", "\u2581", "symmetry", "\u2581breaking", "\u2581is", "\u2581not", "\u2581what", "\u2581you", "\u2581asked", "\u2581about", "\u2581in", "\u2581your", "\u2581question", ",", "\u2581which", "\u2581is", "\u2581why", "\u2581my", "\u2581answer", "\u2581discusse", "s", "\u2581", "a", "\u2581different", "\u2581type", "\u2581of", "\u2581", "symmetry", "\u2581breaking", ".", "\u2581But", "\u2581your", "\u2581comment", "\u2581here", "\u2581certainly", "\u2581implies", "\u2581", "a", "\u2581fair", "\u2581additional", "\u2581question", ".", "\u2581The", "\u2581answer", "\u2581is", "\u2581complicated", "\u2581enough", "\u2581that", "\u2581I", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581room", "\u2581for", "\u2581it", "\u2581in", "\u2581this", "\u2581comment", ",", "\u2581so", "'", "\u2581", "ll", "\u2581add", "\u2581another", "\u2581section", "\u2581to", "\u2581my", "\u2581answer", "\u2581headed", "\u2581\"", "\u2581Buck", "ling", ",", "\u2581Cr", "umbling", ",", "\u2581and", "\u2581Top", "p", "ling", "\u2581\"", ".", "\u2581But", ".", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581poisson", "\u2581I", "\u2581see", ".", "\u2581That", "\u2581type", "\u2581of", "\u2581", "symmetry", "\u2581breaking", "\u2581is", "\u2581not", "\u2581what", "\u2581you", "\u2581asked", "\u2581about", "\u2581in", "\u2581your", "\u2581question", ",", "\u2581which", "\u2581is", "\u2581why", "\u2581my", "\u2581answer", "\u2581discusse", "s", "\u2581", "a", "\u2581different", "\u2581type", "\u2581of", "\u2581", "symmetry", "\u2581breaking", ".", "\u2581But", "\u2581your", "\u2581comment", "\u2581here", "\u2581certainly", "\u2581implies", "\u2581", "a", "\u2581fair", "\u2581additional", "\u2581question", ".", "\u2581The", "\u2581answer", "\u2581is", "\u2581complicated", "\u2581enough", "\u2581that", "\u2581I", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581room", "\u2581for", "\u2581it", "\u2581in", "\u2581this", "\u2581comment", ",", "\u2581so", "'", "\u2581", "ll", "\u2581add", "\u2581another", "\u2581section", "\u2581to", "\u2581my", "\u2581answer", "\u2581headed", "\u2581\"", "\u2581Buck", "ling", ",", "\u2581Cr", "umbling", ",", "\u2581and", "\u2581Top", "p", "ling", "\u2581\"", ".", "\u2581But", ".", ".", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581poisson", "\u2581I", "\u2581see", ".", "\u2581That", "\u2581type", "\u2581of", "\u2581", "symmetry", "\u2581breaking", "\u2581is", "\u2581not", "\u2581what", "\u2581you", "\u2581asked", "\u2581about", "\u2581in", "\u2581your", "\u2581question", ",", "\u2581which", "\u2581is", "\u2581why", "\u2581my", "\u2581answer", "\u2581discusse", "s", "\u2581", "a", "\u2581different", "\u2581type", "\u2581of", "\u2581", "symmetry", "\u2581breaking", ".", "\u2581But", "\u2581your", "\u2581comment", "\u2581here", "\u2581certainly", "\u2581implies", "\u2581", "a", "\u2581fair", "\u2581additional", "\u2581question", ".", "\u2581The", "\u2581answer", "\u2581is", "\u2581complicated", "\u2581enough", "\u2581that", "\u2581I", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581room", "\u2581for", "\u2581it", "\u2581in", "\u2581this", "\u2581comment", ",", "\u2581so", "'", "\u2581", "ll", "\u2581add", "\u2581another", "\u2581section", "\u2581to", "\u2581my", "\u2581answer", "\u2581headed", "\u2581\"", "\u2581Buck", "ling", ",", "\u2581Cr", "umbling", ",", "\u2581and", "\u2581Top", "p", "ling", "\u2581\"", ".", "\u2581But", ".", ".", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 26, 27, 28, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 52, 53, 54, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 74, 75, 76, 76, 77, 78, 79, 79, 79, 80, 81, 82, 83, 84, 85, 86], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_468", "sentence": ["\u2581They", "\u2581also", "\u2581used", "'", "\u2581magic", "'", "\u2581to", "\u2581accomplish", "\u2581their", "\u2581works", ".", "\u2581Min", "a", "s", "\u2581Ti", "rith", "\u2581(", "\u2581The", "\u2581First", "\u2581Age", "\u2581one", ")", "\u2581had", "\u2581", "a", "\u2581spell", "\u2581bound", "ing", "\u2581stone", "\u2581to", "\u2581stone", ",", "\u2581and", "\u2581it", "\u2581collapse", "d", "\u2581after", "\u2581L", "\u00fa", "thi", "en", "\u2581had", "\u2581broken", "\u2581it", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581They", "\u2581also", "\u2581used", "'", "\u2581magic", "'", "\u2581to", "\u2581accomplish", "\u2581their", "\u2581works", ".", "\u2581Min", "a", "s", "\u2581Ti", "rith", "\u2581(", "\u2581The", "\u2581First", "\u2581Age", "\u2581one", ")", "\u2581had", "\u2581", "a", "\u2581spell", "\u2581bound", "ing", "\u2581stone", "\u2581to", "\u2581stone", ",", "\u2581and", "\u2581it", "\u2581collapse", "d", "\u2581after", "\u2581L", "\u00fa", "thi", "en", "\u2581had", "\u2581broken", "\u2581it", ".", "</s>"], "target_sentence": ["\u2581They", "\u2581also", "\u2581used", "'", "\u2581magic", "'", "\u2581to", "\u2581accomplish", "\u2581their", "\u2581works", ".", "<m>", "\u2581Min", "a", "s", "\u2581Ti", "rith", "</m>", "\u2581(", "\u2581The", "<m>", "\u2581First", "\u2581Age", "</m>", "\u2581one", ")", "\u2581had", "\u2581", "a", "\u2581spell", "\u2581bound", "ing", "\u2581stone", "\u2581to", "\u2581stone", ",", "\u2581and", "\u2581it", "\u2581collapse", "d", "\u2581after", "<m>", "\u2581L", "\u00fa", "thi", "en", "</m>", "\u2581had", "\u2581broken", "\u2581it", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 29, 30, 31, 31, 31, 31, 32, 33, 34, 35, 36], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_469", "sentence": ["\u2581Visual", "izing", "\u2581the", "\u2581$", "\u2581H", "\u2581$", "\u2581field", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Visual", "izing", "\u2581the", "\u2581$", "\u2581H", "\u2581$", "\u2581field", "</s>"], "target_sentence": ["\u2581Visual", "izing", "\u2581the", "\u2581$", "\u2581H", "\u2581$", "\u2581field", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_470", "sentence": ["\u2581How", "\u2581steady", "\u2581is", "\u2581your", "\u2581hand", "?", "\u2581But", "\u2581seriously", ",", "\u2581this", "\u2581question", "\u2581is", "\u2581entirely", "\u2581wrong", "-", "headed", "\u2581", "if", "\u2581you", "\u2581are", "\u2581concerned", "\u2581about", "\u2581safety", ".", "\u2581If", "\u2581anything", "\u2581is", "\u2581going", "\u2581to", "\u2581get", "\u2581close", "\u2581to", "\u2581an", "\u2581electrical", "\u2581contact", ",", "\u2581it", "\u2581must", "\u2581be", "\u2581de", "-", "powered", ".", "\u2581No", "\u2581exception", "s", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581steady", "\u2581is", "\u2581your", "\u2581hand", "?", "\u2581But", "\u2581seriously", ",", "\u2581this", "\u2581question", "\u2581is", "\u2581entirely", "\u2581wrong", "-", "headed", "\u2581", "if", "\u2581you", "\u2581are", "\u2581concerned", "\u2581about", "\u2581safety", ".", "\u2581If", "\u2581anything", "\u2581is", "\u2581going", "\u2581to", "\u2581get", "\u2581close", "\u2581to", "\u2581an", "\u2581electrical", "\u2581contact", ",", "\u2581it", "\u2581must", "\u2581be", "\u2581de", "-", "powered", ".", "\u2581No", "\u2581exception", "s", "!", "</s>"], "target_sentence": ["\u2581How", "\u2581steady", "\u2581is", "\u2581your", "\u2581hand", "?", "\u2581But", "\u2581seriously", ",", "\u2581this", "\u2581question", "\u2581is", "\u2581entirely", "\u2581wrong", "-", "headed", "\u2581", "if", "\u2581you", "\u2581are", "\u2581concerned", "\u2581about", "\u2581safety", ".", "\u2581If", "\u2581anything", "\u2581is", "\u2581going", "\u2581to", "\u2581get", "\u2581close", "\u2581to", "\u2581an", "\u2581electrical", "\u2581contact", ",", "\u2581it", "\u2581must", "\u2581be", "\u2581de", "-", "powered", ".", "\u2581No", "\u2581exception", "s", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 36, 36, 37, 38, 39, 39, 40, 41], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_471", "sentence": ["\u2581\"", "\u2581*", "\u2581It", "'", "\u2581", "s", "\u2581all", "\u2581down", "\u2581to", "\u2581Ne", "ville", ".", "\u2581He", "\u2581really", "\u2581gets", "\u2581this", "\u2581room", ".", "\u2581You", "'", "\u2581", "ve", "\u2581got", "\u2581to", "\u2581ask", "\u2581it", "\u2581for", "\u2581exactly", "\u2581what", "\u2581you", "\u2581need", "\u2581", "-", "\u2581like", ",", "'", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581want", "\u2581any", "\u2581C", "arrow", "\u2581supporters", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581get", "\u2581in", "'", "\u2581", "-", "\u2581and", "'", "\u2581", "ll", "\u2581do", "\u2581it", "\u2581for", "\u2581you", "!", "\u2581You", "'", "\u2581", "ve", "\u2581just", "\u2581got", "\u2581to", "\u2581make", "\u2581sure", "\u2581you", "\u2581close", "\u2581the", "\u2581loop", "hole", "s", "!", "\u2581Ne", "ville", "'", "\u2581", "s", "\u2581the", "\u2581man", "!", "\u2581*", "\u2581\"", "\u2581", "-", "\u2581Sea", "mus", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\"", "\u2581*", "\u2581It", "'", "\u2581", "s", "\u2581all", "\u2581down", "\u2581to", "\u2581Ne", "ville", ".", "\u2581He", "\u2581really", "\u2581gets", "\u2581this", "\u2581room", ".", "\u2581You", "'", "\u2581", "ve", "\u2581got", "\u2581to", "\u2581ask", "\u2581it", "\u2581for", "\u2581exactly", "\u2581what", "\u2581you", "\u2581need", "\u2581", "-", "\u2581like", ",", "'", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581want", "\u2581any", "\u2581C", "arrow", "\u2581supporters", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581get", "\u2581in", "'", "\u2581", "-", "\u2581and", "'", "\u2581", "ll", "\u2581do", "\u2581it", "\u2581for", "\u2581you", "!", "\u2581You", "'", "\u2581", "ve", "\u2581just", "\u2581got", "\u2581to", "\u2581make", "\u2581sure", "\u2581you", "\u2581close", "\u2581the", "\u2581loop", "hole", "s", "!", "\u2581Ne", "ville", "'", "\u2581", "s", "\u2581the", "\u2581man", "!", "\u2581*", "\u2581\"", "\u2581", "-", "\u2581Sea", "mus", "</s>"], "target_sentence": ["\u2581\"", "\u2581*", "\u2581It", "'", "\u2581", "s", "\u2581all", "\u2581down", "\u2581to", "<m>", "<m>", "\u2581Ne", "ville", "</m>", "</m>", ".", "\u2581He", "\u2581really", "\u2581gets", "\u2581this", "\u2581room", ".", "\u2581You", "'", "\u2581", "ve", "\u2581got", "\u2581to", "\u2581ask", "\u2581it", "\u2581for", "\u2581exactly", "\u2581what", "\u2581you", "\u2581need", "\u2581", "-", "\u2581like", ",", "'", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581want", "\u2581any", "<m>", "\u2581C", "arrow", "</m>", "\u2581supporters", "\u2581to", "\u2581be", "\u2581", "able", "\u2581to", "\u2581get", "\u2581in", "'", "\u2581", "-", "\u2581and", "'", "\u2581", "ll", "\u2581do", "\u2581it", "\u2581for", "\u2581you", "!", "\u2581You", "'", "\u2581", "ve", "\u2581just", "\u2581got", "\u2581to", "\u2581make", "\u2581sure", "\u2581you", "\u2581close", "\u2581the", "\u2581loop", "hole", "s", "!", "<m>", "\u2581Ne", "ville", "</m>", "'", "\u2581", "s", "\u2581the", "\u2581man", "!", "\u2581*", "\u2581\"", "\u2581", "-", "<m>", "\u2581Sea", "mus", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 29, 30, 31, 32, 33, 34, 34, 35, 36, 36, 37, 38, 39, 39, 40, 41, 42, 43, 43, 44, 45, 46, 47, 48, 48, 49, 50, 51, 51, 52, 53, 54, 55, 56, 57, 58, 59, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 68, 68, 69, 70, 70, 71, 72, 72, 73, 74, 75, 76, 77, 78, 78, 79, 79, 80], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, 4, -1]}, {"doc_id": "emerging.test_472", "sentence": ["\u2581Why", "\u2581is", "\u2581the", "\u2581Labour", "\u2581Party", "\u2581in", "\u2581such", "\u2581significant", "\u2581decline", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581the", "\u2581Labour", "\u2581Party", "\u2581in", "\u2581such", "\u2581significant", "\u2581decline", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "\u2581the", "<m>", "<m>", "\u2581Labour", "\u2581Party", "</m>", "</m>", "\u2581in", "\u2581such", "\u2581significant", "\u2581decline", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_473", "sentence": ["\u2581The", "\u2581spin", "-", "or", "bit", "\u2581interaction", "\u2581for", "\u2581", "a", "\u2581classical", "\u2581magnetic", "\u2581di", "pole", "\u2581moving", "\u2581in", "\u2581an", "\u2581electric", "\u2581field", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581spin", "-", "or", "bit", "\u2581interaction", "\u2581for", "\u2581", "a", "\u2581classical", "\u2581magnetic", "\u2581di", "pole", "\u2581moving", "\u2581in", "\u2581an", "\u2581electric", "\u2581field", "</s>"], "target_sentence": ["\u2581The", "\u2581spin", "-", "or", "bit", "\u2581interaction", "\u2581for", "\u2581", "a", "\u2581classical", "\u2581magnetic", "\u2581di", "pole", "\u2581moving", "\u2581in", "\u2581an", "\u2581electric", "\u2581field", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_474", "sentence": ["\u2581Because", "\u2581light", "\u2581", "s", "a", "ber", "s", "\u2581glow", "\u2581in", "\u2581the", "\u2581dark", ".", "\u2581Search", "\u2581TV", "\u2581Trop", "e", "s", "\u2581for", "\u2581\"", "\u2581Rule", "\u2581of", "\u2581Cool", ".", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Because", "\u2581light", "\u2581", "s", "a", "ber", "s", "\u2581glow", "\u2581in", "\u2581the", "\u2581dark", ".", "\u2581Search", "\u2581TV", "\u2581Trop", "e", "s", "\u2581for", "\u2581\"", "\u2581Rule", "\u2581of", "\u2581Cool", ".", "\u2581\"", "</s>"], "target_sentence": ["\u2581Because", "\u2581light", "\u2581", "s", "a", "ber", "s", "\u2581glow", "\u2581in", "\u2581the", "\u2581dark", ".", "\u2581Search", "\u2581TV", "\u2581Trop", "e", "s", "\u2581for", "\u2581\"", "<m>", "\u2581Rule", "\u2581of", "\u2581Cool", "</m>", ".", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_475", "sentence": ["\u2581What", "\u2581exactly", "\u2581did", "\u2581the", "\u2581federal", "\u2581judge", "\u2581do", "\u2581to", "\u2581Trump", "'", "\u2581", "s", "\u2581executive", "\u2581order", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581exactly", "\u2581did", "\u2581the", "\u2581federal", "\u2581judge", "\u2581do", "\u2581to", "\u2581Trump", "'", "\u2581", "s", "\u2581executive", "\u2581order", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581exactly", "\u2581did", "\u2581the", "\u2581federal", "\u2581judge", "\u2581do", "\u2581to", "<m>", "\u2581Trump", "</m>", "'", "\u2581", "s", "\u2581executive", "\u2581order", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_476", "sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581edited", "\u2581the", "\u2581question", "\u2581with", "\u2581some", "\u2581links", "\u2581and", "\u2581", "re", "phra", "s", "ing", "\u2581to", "\u2581try", "\u2581to", "\u2581clarify", ";", "\u2581feel", "\u2581free", "\u2581to", "\u2581", "re", "vert", "\u2581", "if", "\u2581you", "\u2581disagree", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "ve", "\u2581edited", "\u2581the", "\u2581question", "\u2581with", "\u2581some", "\u2581links", "\u2581and", "\u2581", "re", "phra", "s", "ing", "\u2581to", "\u2581try", "\u2581to", "\u2581clarify", ";", "\u2581feel", "\u2581free", "\u2581to", "\u2581", "re", "vert", "\u2581", "if", "\u2581you", "\u2581disagree", ".", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581edited", "\u2581the", "\u2581question", "\u2581with", "\u2581some", "\u2581links", "\u2581and", "\u2581", "re", "phra", "s", "ing", "\u2581to", "\u2581try", "\u2581to", "\u2581clarify", ";", "\u2581feel", "\u2581free", "\u2581to", "\u2581", "re", "vert", "\u2581", "if", "\u2581you", "\u2581disagree", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 20, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_477", "sentence": ["\u2581Ag", "re", "e", "d", ".", "\u2581Nothing", "\u2581I", "'", "\u2581", "ve", "\u2581read", "\u2581has", "\u2581reference", "d", "\u2581", "a", "\u2581prior", "\u2581similar", "\u2581event", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ag", "re", "e", "d", ".", "\u2581Nothing", "\u2581I", "'", "\u2581", "ve", "\u2581read", "\u2581has", "\u2581reference", "d", "\u2581", "a", "\u2581prior", "\u2581similar", "\u2581event", ".", "</s>"], "target_sentence": ["\u2581Ag", "re", "e", "d", ".", "\u2581Nothing", "\u2581I", "'", "\u2581", "ve", "\u2581read", "\u2581has", "\u2581reference", "d", "\u2581", "a", "\u2581prior", "\u2581similar", "\u2581event", ".", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_478", "sentence": ["\u2581We", "\u2581differ", "\u2581politically", "\u2581but", "\u2581this", "\u2581is", "\u2581", "a", "\u2581great", "\u2581and", "\u2581concise", "\u2581answer", ".", "\u2581+", "\u25811", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581We", "\u2581differ", "\u2581politically", "\u2581but", "\u2581this", "\u2581is", "\u2581", "a", "\u2581great", "\u2581and", "\u2581concise", "\u2581answer", ".", "\u2581+", "\u25811", "</s>"], "target_sentence": ["\u2581We", "\u2581differ", "\u2581politically", "\u2581but", "\u2581this", "\u2581is", "\u2581", "a", "\u2581great", "\u2581and", "\u2581concise", "\u2581answer", ".", "\u2581+", "\u25811", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_479", "sentence": ["\u2581Why", "\u2581do", "\u2581", "fusion", "\u2581cross", "\u2581sections", "\u2581drop", "\u2581after", "\u2581", "a", "\u2581certain", "\u2581temperature", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581do", "\u2581", "fusion", "\u2581cross", "\u2581sections", "\u2581drop", "\u2581after", "\u2581", "a", "\u2581certain", "\u2581temperature", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581do", "\u2581", "fusion", "\u2581cross", "\u2581sections", "\u2581drop", "\u2581after", "\u2581", "a", "\u2581certain", "\u2581temperature", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_480", "sentence": ["\u2581could", "\u2581you", "\u2581try", "'", "\u2581", "/", "\u2581", "/", "\u2581", "\\", "\u2581", "n", "a", "ler", "t", "\u2581(", "\u25811", ")", ";", "\u2581window", ".", "\u2581history", ".", "\u2581back", "\u2581(", ")", "?", ".", "\u2581", "if", "\u2581that", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581work", ",", "\u2581it", "\u2581might", "\u2581be", "\u2581", "a", "\u2581500", "\u2581error", "\u2581with", "\u2581", "a", "\u2581redirect", "\u2581to", "\u2581root", "\u2581as", "\u2581default", "\u2581behaviour", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581could", "\u2581you", "\u2581try", "'", "\u2581", "/", "\u2581", "/", "\u2581", "\\", "\u2581", "n", "a", "ler", "t", "\u2581(", "\u25811", ")", ";", "\u2581window", ".", "\u2581history", ".", "\u2581back", "\u2581(", ")", "?", ".", "\u2581", "if", "\u2581that", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581work", ",", "\u2581it", "\u2581might", "\u2581be", "\u2581", "a", "\u2581500", "\u2581error", "\u2581with", "\u2581", "a", "\u2581redirect", "\u2581to", "\u2581root", "\u2581as", "\u2581default", "\u2581behaviour", "</s>"], "target_sentence": ["\u2581could", "\u2581you", "\u2581try", "'", "\u2581", "/", "\u2581", "/", "\u2581", "\\", "\u2581", "n", "a", "ler", "t", "\u2581(", "\u25811", ")", ";", "\u2581window", ".", "\u2581history", ".", "\u2581back", "\u2581(", ")", "?", ".", "\u2581", "if", "\u2581that", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581work", ",", "\u2581it", "\u2581might", "\u2581be", "\u2581", "a", "\u2581500", "\u2581error", "\u2581with", "\u2581", "a", "\u2581redirect", "\u2581to", "\u2581root", "\u2581as", "\u2581default", "\u2581behaviour", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 22, 23, 24, 24, 25, 26, 26, 27, 28, 29, 30, 31, 32, 32, 33, 34, 35, 36, 36, 37, 38, 39, 40, 41, 42, 43], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_481", "sentence": ["\u2581Spo", "o", "ky", "\u2581behaviour", "\u2581with", "\u2581", "Auth", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Spo", "o", "ky", "\u2581behaviour", "\u2581with", "\u2581", "Auth", "y", "</s>"], "target_sentence": ["\u2581Spo", "o", "ky", "\u2581behaviour", "\u2581with", "<m>", "<m>", "\u2581", "Auth", "y", "</m>", "</m>", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 1, 0, -1]}, {"doc_id": "emerging.test_482", "sentence": ["\u2581Thank", "\u2581you", "\u2581for", "\u2581the", "\u2581quick", "\u2581reply", ".", "\u2581Just", "\u2581wanted", "\u2581to", "\u2581confirm", "\u2581one", "\u2581more", "\u2581thing", ".", "\u2581How", "\u2581do", "\u2581you", "\u2581mitigate", "\u2581this", "\u2581issue", "?", "\u2581I", "s", "\u2581it", "\u2581done", "\u2581by", "\u2581mandat", "ing", "\u2581au", "th", "\u2581for", "\u2581all", "\u2581the", "\u2581mail", "\u2581sending", "\u2581actions", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Thank", "\u2581you", "\u2581for", "\u2581the", "\u2581quick", "\u2581reply", ".", "\u2581Just", "\u2581wanted", "\u2581to", "\u2581confirm", "\u2581one", "\u2581more", "\u2581thing", ".", "\u2581How", "\u2581do", "\u2581you", "\u2581mitigate", "\u2581this", "\u2581issue", "?", "\u2581I", "s", "\u2581it", "\u2581done", "\u2581by", "\u2581mandat", "ing", "\u2581au", "th", "\u2581for", "\u2581all", "\u2581the", "\u2581mail", "\u2581sending", "\u2581actions", "?", "</s>"], "target_sentence": ["\u2581Thank", "\u2581you", "\u2581for", "\u2581the", "\u2581quick", "\u2581reply", ".", "\u2581Just", "\u2581wanted", "\u2581to", "\u2581confirm", "\u2581one", "\u2581more", "\u2581thing", ".", "\u2581How", "\u2581do", "\u2581you", "\u2581mitigate", "\u2581this", "\u2581issue", "?", "\u2581I", "s", "\u2581it", "\u2581done", "\u2581by", "\u2581mandat", "ing", "\u2581au", "th", "\u2581for", "\u2581all", "\u2581the", "\u2581mail", "\u2581sending", "\u2581actions", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 26, 27, 27, 28, 29, 30, 31, 32, 33, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_483", "sentence": ["\u2581Positive", "\u2581charge", "\u2581has", "\u2581high", "\u2581potential", "\u2581why", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Positive", "\u2581charge", "\u2581has", "\u2581high", "\u2581potential", "\u2581why", "?", "</s>"], "target_sentence": ["\u2581Positive", "\u2581charge", "\u2581has", "\u2581high", "\u2581potential", "\u2581why", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_484", "sentence": ["\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581Snap", "e", "\u2581just", "\u2581kill", "\u2581Vol", "dem", "or", "t", "\u2581to", "\u2581buy", "\u2581more", "\u2581time", "\u2581while", "\u2581the", "\u2581latter", "\u2581was", "\u2581recuper", "ating", "\u2581as", "\u2581", "a", "\u2581Hor", "cru", "x", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581Snap", "e", "\u2581just", "\u2581kill", "\u2581Vol", "dem", "or", "t", "\u2581to", "\u2581buy", "\u2581more", "\u2581time", "\u2581while", "\u2581the", "\u2581latter", "\u2581was", "\u2581recuper", "ating", "\u2581as", "\u2581", "a", "\u2581Hor", "cru", "x", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "<m>", "\u2581Snap", "e", "</m>", "\u2581just", "\u2581kill", "<m>", "\u2581Vol", "dem", "or", "t", "</m>", "\u2581to", "\u2581buy", "\u2581more", "\u2581time", "\u2581while", "\u2581the", "\u2581latter", "\u2581was", "\u2581recuper", "ating", "\u2581as", "\u2581", "a", "\u2581Hor", "cru", "x", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 5, 6, 7, 8, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 19, 20, 20, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_485", "sentence": ["\u2581I", "\u2581hate", "\u2581your", "\u2581answer", ",", "\u2581but", "\u2581it", "\u2581is", "\u2581correct", ".", "\u2581I", ",", "\u2581", "n", "a", "ively", ",", "\u2581had", "\u2581", "a", "\u2581different", "\u2581reaction", "\u2581upon", "\u2581reading", "\u2581that", "\u2581part", ".", "\u2581Name", "ly", ":", "\u2581\"", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581wait", "\u2581to", "\u2581see", "\u2581that", "\u2581in", "\u2581film", "\u2581\"", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581hate", "\u2581your", "\u2581answer", ",", "\u2581but", "\u2581it", "\u2581is", "\u2581correct", ".", "\u2581I", ",", "\u2581", "n", "a", "ively", ",", "\u2581had", "\u2581", "a", "\u2581different", "\u2581reaction", "\u2581upon", "\u2581reading", "\u2581that", "\u2581part", ".", "\u2581Name", "ly", ":", "\u2581\"", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581wait", "\u2581to", "\u2581see", "\u2581that", "\u2581in", "\u2581film", "\u2581\"", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581hate", "\u2581your", "\u2581answer", ",", "\u2581but", "\u2581it", "\u2581is", "\u2581correct", ".", "\u2581I", ",", "\u2581", "n", "a", "ively", ",", "\u2581had", "\u2581", "a", "\u2581different", "\u2581reaction", "\u2581upon", "\u2581reading", "\u2581that", "\u2581part", ".", "\u2581Name", "ly", ":", "\u2581\"", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581wait", "\u2581to", "\u2581see", "\u2581that", "\u2581in", "\u2581film", "\u2581\"", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 28, 28, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_486", "sentence": ["\u2581@", "\u2581Snow", "man", "\u2581\"", "\u2581They", "\u2581mostly", "\u2581come", "\u2581at", "\u2581night", ".", "\u2581", "Mostly", ".", "\u2581\"", "\u2581Excellent", "\u2581reference", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Snow", "man", "\u2581\"", "\u2581They", "\u2581mostly", "\u2581come", "\u2581at", "\u2581night", ".", "\u2581", "Mostly", ".", "\u2581\"", "\u2581Excellent", "\u2581reference", "!", "</s>"], "target_sentence": ["\u2581@", "\u2581Snow", "man", "\u2581\"", "<m>", "\u2581They", "\u2581mostly", "\u2581come", "\u2581at", "\u2581night", "</m>", ".", "<m>", "\u2581", "Mostly", "</m>", ".", "\u2581\"", "\u2581Excellent", "\u2581reference", "!", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_487", "sentence": ["\u2581Su", "g", "gestion", "s", "\u2581on", "\u2581how", "\u2581I", "\u2581would", "\u2581detect", "\u2581that", ",", "\u2581or", "\u2581rather", ";", "\u2581or", "\u2581whether", "\u2581there", "\u2581would", "\u2581be", "\u2581", "a", "\u2581Windows", "\u2581Event", "\u2581log", "\u2581", "confirming", "\u2581this", "?", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Su", "g", "gestion", "s", "\u2581on", "\u2581how", "\u2581I", "\u2581would", "\u2581detect", "\u2581that", ",", "\u2581or", "\u2581rather", ";", "\u2581or", "\u2581whether", "\u2581there", "\u2581would", "\u2581be", "\u2581", "a", "\u2581Windows", "\u2581Event", "\u2581log", "\u2581", "confirming", "\u2581this", "?", "?", "</s>"], "target_sentence": ["\u2581Su", "g", "gestion", "s", "\u2581on", "\u2581how", "\u2581I", "\u2581would", "\u2581detect", "\u2581that", ",", "\u2581or", "\u2581rather", ";", "\u2581or", "\u2581whether", "\u2581there", "\u2581would", "\u2581be", "\u2581", "a", "<m>", "\u2581Windows", "</m>", "\u2581Event", "\u2581log", "\u2581", "confirming", "\u2581this", "?", "?", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_488", "sentence": ["\u2581Where", "\u2581was", "\u2581the", "\u2581planet", "\u2581", "inhabited", "\u2581by", "\u2581\"", "\u2581the", "\u2581Gi", "ants", "\u2581\"", "\u2581located", "\u2581relative", "\u2581to", "\u2581Earth", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Where", "\u2581was", "\u2581the", "\u2581planet", "\u2581", "inhabited", "\u2581by", "\u2581\"", "\u2581the", "\u2581Gi", "ants", "\u2581\"", "\u2581located", "\u2581relative", "\u2581to", "\u2581Earth", "?", "</s>"], "target_sentence": ["\u2581Where", "\u2581was", "\u2581the", "\u2581planet", "\u2581", "inhabited", "\u2581by", "\u2581\"", "<m>", "\u2581the", "\u2581Gi", "ants", "</m>", "\u2581\"", "\u2581located", "\u2581relative", "\u2581to", "<m>", "\u2581Earth", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_489", "sentence": ["\u2581Why", "\u2581is", "\u2581the", "\u2581per", "pen", "dic", "ular", "\u2581part", "\u2581", "a", "\u2581", "s", "cal", "ar", "\u2581in", "\u2581the", "\u2581electro", "dynamic", "\u2581boundary", "\u2581conditions", "\u2581at", "\u2581surfaces", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581the", "\u2581per", "pen", "dic", "ular", "\u2581part", "\u2581", "a", "\u2581", "s", "cal", "ar", "\u2581in", "\u2581the", "\u2581electro", "dynamic", "\u2581boundary", "\u2581conditions", "\u2581at", "\u2581surfaces", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "\u2581the", "\u2581per", "pen", "dic", "ular", "\u2581part", "\u2581", "a", "\u2581", "s", "cal", "ar", "\u2581in", "\u2581the", "\u2581electro", "dynamic", "\u2581boundary", "\u2581conditions", "\u2581at", "\u2581surfaces", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 4, 5, 5, 6, 6, 6, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_490", "sentence": ["\u2581", "Anim", "ated", "\u2581TV", "\u2581series", "\u2581with", "\u2581King", "\u2581Arthur", "\u2581", "/", "\u2581S", "word", "\u2581in", "\u2581Stone", "\u2581theme", ";", "'", "\u2581Ex", "cali", "bur", "'", "\u2581replaced", "\u2581by", "\u2581AI", "\u2581robot", "\u2581", "s", "cept", "er", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Anim", "ated", "\u2581TV", "\u2581series", "\u2581with", "\u2581King", "\u2581Arthur", "\u2581", "/", "\u2581S", "word", "\u2581in", "\u2581Stone", "\u2581theme", ";", "'", "\u2581Ex", "cali", "bur", "'", "\u2581replaced", "\u2581by", "\u2581AI", "\u2581robot", "\u2581", "s", "cept", "er", "</s>"], "target_sentence": ["\u2581", "Anim", "ated", "\u2581TV", "\u2581series", "\u2581with", "<m>", "<m>", "\u2581King", "\u2581Arthur", "</m>", "\u2581", "/", "\u2581S", "word", "\u2581in", "\u2581Stone", "</m>", "\u2581theme", ";", "'", "<m>", "\u2581Ex", "cali", "bur", "</m>", "'", "\u2581replaced", "\u2581by", "\u2581AI", "\u2581robot", "\u2581", "s", "cept", "er", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_491", "sentence": ["\u2581I", "s", "\u2581the", "\u2581story", "\u2581plot", "line", "\u2581or", "\u2581", "arc", "\u2581for", "\u2581the", "\u2581Star", "\u2581Wars", "\u2581series", "\u2581going", "\u2581to", "\u2581be", "\u2581overhaul", "e", "d", "\u2581with", "\u2581Car", "rie", "\u2581Fisher", "'", "\u2581", "s", "\u2581death", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581the", "\u2581story", "\u2581plot", "line", "\u2581or", "\u2581", "arc", "\u2581for", "\u2581the", "\u2581Star", "\u2581Wars", "\u2581series", "\u2581going", "\u2581to", "\u2581be", "\u2581overhaul", "e", "d", "\u2581with", "\u2581Car", "rie", "\u2581Fisher", "'", "\u2581", "s", "\u2581death", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581the", "\u2581story", "\u2581plot", "line", "\u2581or", "\u2581", "arc", "\u2581for", "\u2581the", "<m>", "<m>", "<m>", "\u2581Star", "\u2581Wars", "</m>", "</m>", "</m>", "\u2581series", "\u2581going", "\u2581to", "\u2581be", "\u2581overhaul", "e", "d", "\u2581with", "<m>", "\u2581Car", "rie", "\u2581Fisher", "</m>", "'", "\u2581", "s", "\u2581death", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 15, 16, 16, 17, 18, 19, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 0, 1, -1, -1, 2, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_492", "sentence": ["\u2581What", "\u25811980", "'", "\u2581", "s", "\u2581kids", "\u2581book", "\u2581series", "\u2581about", "\u2581boy", "\u2581learning", "\u2581magic", "\u2581spell", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u25811980", "'", "\u2581", "s", "\u2581kids", "\u2581book", "\u2581series", "\u2581about", "\u2581boy", "\u2581learning", "\u2581magic", "\u2581spell", "s", "?", "</s>"], "target_sentence": ["\u2581What", "\u25811980", "'", "\u2581", "s", "\u2581kids", "\u2581book", "\u2581series", "\u2581about", "\u2581boy", "\u2581learning", "\u2581magic", "\u2581spell", "s", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_493", "sentence": ["\u2581Why", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581line", "\u2581of", "\u2581succession", "\u2581for", "\u2581cabinet", "\u2581members", "\u2581followed", "\u2581after", "\u2581they", "\u2581died", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581line", "\u2581of", "\u2581succession", "\u2581for", "\u2581cabinet", "\u2581members", "\u2581followed", "\u2581after", "\u2581they", "\u2581died", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581line", "\u2581of", "\u2581succession", "\u2581for", "\u2581cabinet", "\u2581members", "\u2581followed", "\u2581after", "\u2581they", "\u2581died", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_494", "sentence": ["\u2581can", "\u2581", "a", "\u2581nation", "\u2581", "encompassing", "\u2581", "a", "\u2581di", "a", "spor", "a", "\u2581with", "\u2581no", "\u2581geographical", "\u2581de", "line", "ation", "\u2581also", "\u2581be", "\u2581or", "\u2581have", "\u2581its", "\u2581own", "\u2581state", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581can", "\u2581", "a", "\u2581nation", "\u2581", "encompassing", "\u2581", "a", "\u2581di", "a", "spor", "a", "\u2581with", "\u2581no", "\u2581geographical", "\u2581de", "line", "ation", "\u2581also", "\u2581be", "\u2581or", "\u2581have", "\u2581its", "\u2581own", "\u2581state", "</s>"], "target_sentence": ["\u2581can", "\u2581", "a", "\u2581nation", "\u2581", "encompassing", "\u2581", "a", "\u2581di", "a", "spor", "a", "\u2581with", "\u2581no", "\u2581geographical", "\u2581de", "line", "ation", "\u2581also", "\u2581be", "\u2581or", "\u2581have", "\u2581its", "\u2581own", "\u2581state", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 4, 5, 5, 5, 5, 6, 7, 8, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_495", "sentence": ["\u2581H", "m", ",", "\u2581pest", "\u2581should", "\u2581not", "\u2581be", "\u2581", "a", "\u2581problem", "\u2581for", "\u2581witch", "ers", ",", "\u2581as", "\u2581their", "\u2581mutation", "\u2581makes", "\u2581them", "\u2581immune", "\u2581to", "\u2581diseases", ".", "\u2581However", ",", "\u2581there", "\u2581is", "\u2581another", "\u2581reason", "\u2581to", "\u2581avoid", "\u2581cities", "\u2581or", "\u2581even", "\u2581villages", ":", "\u2581Most", "\u2581people", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581like", "\u2581witch", "ers", "\u2581and", "\u2581highly", "\u2581distrus", "t", "\u2581them", "\u2581(", "\u2581yeah", ",", "\u2581they", "\u2581might", "\u2581be", "\u2581useful", "\u2581to", "\u2581get", "\u2581rid", "\u2581of", "\u2581most", "ers", ",", "\u2581but", "\u2581they", "\u2581are", "\u2581somehow", "\u2581monster", "s", "\u2581themselves", "\u2581and", "\u2581may", "\u2581", "rob", "\u2581your", "\u2581children", "\u2581", "if", "\u2581you", "'", "\u2581", "re", "\u2581not", "\u2581careful", ")", ".", "\u2581So", "\u2581it", "\u2581is", "\u2581safer", "\u2581for", "\u2581witch", "ers", "\u2581to", "\u2581stay", "\u2581among", "\u2581themselves", ",", "\u2581far", "\u2581away", "\u2581from", "\u2581other", "\u2581people", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581H", "m", ",", "\u2581pest", "\u2581should", "\u2581not", "\u2581be", "\u2581", "a", "\u2581problem", "\u2581for", "\u2581witch", "ers", ",", "\u2581as", "\u2581their", "\u2581mutation", "\u2581makes", "\u2581them", "\u2581immune", "\u2581to", "\u2581diseases", ".", "\u2581However", ",", "\u2581there", "\u2581is", "\u2581another", "\u2581reason", "\u2581to", "\u2581avoid", "\u2581cities", "\u2581or", "\u2581even", "\u2581villages", ":", "\u2581Most", "\u2581people", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581like", "\u2581witch", "ers", "\u2581and", "\u2581highly", "\u2581distrus", "t", "\u2581them", "\u2581(", "\u2581yeah", ",", "\u2581they", "\u2581might", "\u2581be", "\u2581useful", "\u2581to", "\u2581get", "\u2581rid", "\u2581of", "\u2581most", "ers", ",", "\u2581but", "\u2581they", "\u2581are", "\u2581somehow", "\u2581monster", "s", "\u2581themselves", "\u2581and", "\u2581may", "\u2581", "rob", "\u2581your", "\u2581children", "\u2581", "if", "\u2581you", "'", "\u2581", "re", "\u2581not", "\u2581careful", ")", ".", "\u2581So", "\u2581it", "\u2581is", "\u2581safer", "\u2581for", "\u2581witch", "ers", "\u2581to", "\u2581stay", "\u2581among", "\u2581themselves", ",", "\u2581far", "\u2581away", "\u2581from", "\u2581other", "\u2581people", ".", "</s>"], "target_sentence": ["\u2581H", "m", ",", "\u2581pest", "\u2581should", "\u2581not", "\u2581be", "\u2581", "a", "\u2581problem", "\u2581for", "\u2581witch", "ers", ",", "\u2581as", "\u2581their", "\u2581mutation", "\u2581makes", "\u2581them", "\u2581immune", "\u2581to", "\u2581diseases", ".", "\u2581However", ",", "\u2581there", "\u2581is", "\u2581another", "\u2581reason", "\u2581to", "\u2581avoid", "\u2581cities", "\u2581or", "\u2581even", "\u2581villages", ":", "\u2581Most", "\u2581people", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581like", "\u2581witch", "ers", "\u2581and", "\u2581highly", "\u2581distrus", "t", "\u2581them", "\u2581(", "\u2581yeah", ",", "\u2581they", "\u2581might", "\u2581be", "\u2581useful", "\u2581to", "\u2581get", "\u2581rid", "\u2581of", "\u2581most", "ers", ",", "\u2581but", "\u2581they", "\u2581are", "\u2581somehow", "\u2581monster", "s", "\u2581themselves", "\u2581and", "\u2581may", "\u2581", "rob", "\u2581your", "\u2581children", "\u2581", "if", "\u2581you", "'", "\u2581", "re", "\u2581not", "\u2581careful", ")", ".", "\u2581So", "\u2581it", "\u2581is", "\u2581safer", "\u2581for", "\u2581witch", "ers", "\u2581to", "\u2581stay", "\u2581among", "\u2581themselves", ",", "\u2581far", "\u2581away", "\u2581from", "\u2581other", "\u2581people", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 36, 37, 38, 38, 39, 40, 40, 41, 42, 43, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 56, 57, 58, 59, 60, 61, 62, 62, 63, 64, 65, 66, 66, 67, 68, 69, 69, 70, 71, 72, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_496", "sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581meaning", "\u2581", "if", "\u2581all", "\u2581I", "o", "T", "\u2581", "h", "acked", "\u2581by", "\u2581Mir", "a", "i", "\u2581all", "\u2581over", "\u2581the", "\u2581world", "\u2581identify", "\u2581themselves", "\u2581on", "\u2581my", "\u2581server", "\u2581since", "\u258115", "\u2581days", "\u2581in", "\u2581the", "\u2581rhythm", "\u2581of", "\u2581180", "\u2581unique", "\u2581I", "o", "T", "\u2581", "/", "\u2581", "h", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581is", "\u2581the", "\u2581meaning", "\u2581", "if", "\u2581all", "\u2581I", "o", "T", "\u2581", "h", "acked", "\u2581by", "\u2581Mir", "a", "i", "\u2581all", "\u2581over", "\u2581the", "\u2581world", "\u2581identify", "\u2581themselves", "\u2581on", "\u2581my", "\u2581server", "\u2581since", "\u258115", "\u2581days", "\u2581in", "\u2581the", "\u2581rhythm", "\u2581of", "\u2581180", "\u2581unique", "\u2581I", "o", "T", "\u2581", "/", "\u2581", "h", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581meaning", "\u2581", "if", "\u2581all", "\u2581I", "o", "T", "\u2581", "h", "acked", "\u2581by", "<m>", "\u2581Mir", "a", "i", "</m>", "\u2581all", "\u2581over", "\u2581the", "\u2581world", "\u2581identify", "\u2581themselves", "\u2581on", "\u2581my", "\u2581server", "\u2581since", "\u258115", "\u2581days", "\u2581in", "\u2581the", "\u2581rhythm", "\u2581of", "\u2581180", "\u2581unique", "\u2581I", "o", "T", "\u2581", "/", "\u2581", "h", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 6, 6, 7, 7, 7, 8, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 28, 29, 29, 30, 30, 31, 32], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_497", "sentence": ["\u2581@", "\u2581MP", "S", "\u2581Ye", "p", ",", "\u2581that", "'", "\u2581", "s", "\u2581the", "\u2581one", "\u2581(", "\u2581for", "\u2581Ubuntu", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581MP", "S", "\u2581Ye", "p", ",", "\u2581that", "'", "\u2581", "s", "\u2581the", "\u2581one", "\u2581(", "\u2581for", "\u2581Ubuntu", ")", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581MP", "S", "\u2581Ye", "p", ",", "\u2581that", "'", "\u2581", "s", "\u2581the", "\u2581one", "\u2581(", "\u2581for", "\u2581Ubuntu", ")", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_498", "sentence": ["\u2581", "Usually", "\u2581clouds", "\u2581move", "\u2581across", "\u2581the", "\u2581sky", ",", "\u2581sometimes", "\u2581very", "\u2581fast", ",", "\u2581sometimes", "\u2581slow", ".", "\u2581A", "\u2581stationary", "\u2581cloud", "\u2581is", "\u2581not", "\u2581common", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Usually", "\u2581clouds", "\u2581move", "\u2581across", "\u2581the", "\u2581sky", ",", "\u2581sometimes", "\u2581very", "\u2581fast", ",", "\u2581sometimes", "\u2581slow", ".", "\u2581A", "\u2581stationary", "\u2581cloud", "\u2581is", "\u2581not", "\u2581common", ".", "</s>"], "target_sentence": ["\u2581", "Usually", "\u2581clouds", "\u2581move", "\u2581across", "\u2581the", "\u2581sky", ",", "\u2581sometimes", "\u2581very", "\u2581fast", ",", "\u2581sometimes", "\u2581slow", ".", "\u2581A", "\u2581stationary", "\u2581cloud", "\u2581is", "\u2581not", "\u2581common", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_499", "sentence": ["\u2581Do", "\u2581le", "k", "ku", "\u2581grow", "\u2581with", "\u2581age", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Do", "\u2581le", "k", "ku", "\u2581grow", "\u2581with", "\u2581age", "?", "</s>"], "target_sentence": ["\u2581Do", "\u2581le", "k", "ku", "\u2581grow", "\u2581with", "\u2581age", "?", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_500", "sentence": ["\u2581I", "s", "\u2581the", "\u2581soft", "\u2581iron", "\u2581core", "\u2581inside", "\u2581", "a", "\u2581sole", "noi", "d", "\u2581moved", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581the", "\u2581soft", "\u2581iron", "\u2581core", "\u2581inside", "\u2581", "a", "\u2581sole", "noi", "d", "\u2581moved", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581the", "\u2581soft", "\u2581iron", "\u2581core", "\u2581inside", "\u2581", "a", "\u2581sole", "noi", "d", "\u2581moved", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_501", "sentence": ["\u2581", "<", "\u2581more", "\u2581prayers", "\u2581or", "\u2581religious", "\u2581speeches", "\u2581happened", ",", "\u2581and", "\u2581one", "\u2581of", "\u2581them", "\u2581was", "\u2581by", "\u2581", "a", "\u2581Rabbi", ".", "\u2581this", "\u2581goes", "\u2581to", "\u2581the", "\u2581point", "\u2581I", "\u2581made", "\u2581below", "\u2581", "-", "\u2581there", "\u2581are", "\u2581many", "\u2581different", "\u2581flavors", "\u2581of", "\u2581\"", "\u2581secular", "\u2581\"", ",", "\u2581just", "\u2581as", "\u2581there", "\u2581are", "\u2581many", "\u2581different", "\u2581flavors", "\u2581of", "\u2581\"", "\u2581at", "he", "ist", "\u2581\"", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "<", "\u2581more", "\u2581prayers", "\u2581or", "\u2581religious", "\u2581speeches", "\u2581happened", ",", "\u2581and", "\u2581one", "\u2581of", "\u2581them", "\u2581was", "\u2581by", "\u2581", "a", "\u2581Rabbi", ".", "\u2581this", "\u2581goes", "\u2581to", "\u2581the", "\u2581point", "\u2581I", "\u2581made", "\u2581below", "\u2581", "-", "\u2581there", "\u2581are", "\u2581many", "\u2581different", "\u2581flavors", "\u2581of", "\u2581\"", "\u2581secular", "\u2581\"", ",", "\u2581just", "\u2581as", "\u2581there", "\u2581are", "\u2581many", "\u2581different", "\u2581flavors", "\u2581of", "\u2581\"", "\u2581at", "he", "ist", "\u2581\"", ".", "</s>"], "target_sentence": ["\u2581", "<", "\u2581more", "\u2581prayers", "\u2581or", "\u2581religious", "\u2581speeches", "\u2581happened", ",", "\u2581and", "\u2581one", "\u2581of", "\u2581them", "\u2581was", "\u2581by", "\u2581", "a", "<m>", "\u2581Rabbi", "</m>", ".", "\u2581this", "\u2581goes", "\u2581to", "\u2581the", "\u2581point", "\u2581I", "\u2581made", "\u2581below", "\u2581", "-", "\u2581there", "\u2581are", "\u2581many", "\u2581different", "\u2581flavors", "\u2581of", "\u2581\"", "\u2581secular", "\u2581\"", ",", "\u2581just", "\u2581as", "\u2581there", "\u2581are", "\u2581many", "\u2581different", "\u2581flavors", "\u2581of", "\u2581\"", "\u2581at", "he", "ist", "\u2581\"", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 45, 45, 46, 47, 48], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_502", "sentence": ["\u2581How", "\u2581did", "\u2581the", "\u2581media", "\u2581know", "\u2581the", "\u2581method", "\u2581Batman", "\u2581used", "\u2581to", "\u2581catch", "\u2581the", "\u2581Jo", "ker", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581did", "\u2581the", "\u2581media", "\u2581know", "\u2581the", "\u2581method", "\u2581Batman", "\u2581used", "\u2581to", "\u2581catch", "\u2581the", "\u2581Jo", "ker", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581did", "\u2581the", "\u2581media", "\u2581know", "\u2581the", "\u2581method", "<m>", "<m>", "\u2581Batman", "</m>", "</m>", "\u2581used", "\u2581to", "\u2581catch", "\u2581the", "<m>", "<m>", "\u2581Jo", "ker", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, -1, -1, -1, 3, 2, -1, -1, 3, 2, -1, -1]}, {"doc_id": "emerging.test_503", "sentence": ["\u2581Cartoon", "\u2581in", "\u2581which", "\u2581Donald", "\u2581Duck", "\u2581", "tries", "\u2581to", "\u2581stop", "\u2581another", "\u2581duck", "\u2581from", "\u2581", "committing", "\u2581suicide", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Cartoon", "\u2581in", "\u2581which", "\u2581Donald", "\u2581Duck", "\u2581", "tries", "\u2581to", "\u2581stop", "\u2581another", "\u2581duck", "\u2581from", "\u2581", "committing", "\u2581suicide", "</s>"], "target_sentence": ["\u2581Cartoon", "\u2581in", "\u2581which", "<m>", "<m>", "<m>", "\u2581Donald", "\u2581Duck", "</m>", "</m>", "</m>", "\u2581", "tries", "\u2581to", "\u2581stop", "\u2581another", "\u2581duck", "\u2581from", "\u2581", "committing", "\u2581suicide", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, 2, -1, -1, 1, 0, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_504", "sentence": ["\u2581Standard", "ized", "\u2581Data", "\u2581Format", "s", "\u2581for", "\u2581specify", "ing", "\u2581band", "structure", "\u2581and", "\u2581Fer", "m", "i", "\u2581surfaces", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Standard", "ized", "\u2581Data", "\u2581Format", "s", "\u2581for", "\u2581specify", "ing", "\u2581band", "structure", "\u2581and", "\u2581Fer", "m", "i", "\u2581surfaces", "</s>"], "target_sentence": ["\u2581Standard", "ized", "\u2581Data", "\u2581Format", "s", "\u2581for", "\u2581specify", "ing", "\u2581band", "structure", "\u2581and", "\u2581Fer", "m", "i", "\u2581surfaces", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 4, 5, 5, 6, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_505", "sentence": ["\u2581We", "\u2581do", ".", "\u2581That", "'", "\u2581", "s", "\u2581how", "\u2581dam", "s", "\u2581work", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581We", "\u2581do", ".", "\u2581That", "'", "\u2581", "s", "\u2581how", "\u2581dam", "s", "\u2581work", ".", "</s>"], "target_sentence": ["\u2581We", "\u2581do", ".", "\u2581That", "'", "\u2581", "s", "\u2581how", "\u2581dam", "s", "\u2581work", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_506", "sentence": ["\u2581I", "s", "\u2581password", "\u2581crack", "ing", "\u2581noisy", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581password", "\u2581crack", "ing", "\u2581noisy", "?", "</s>"], "target_sentence": ["\u2581I", "s", "<m>", "\u2581password", "\u2581crack", "ing", "</m>", "\u2581noisy", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 4, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_507", "sentence": ["\u2581The", "\u2581short", "\u2581answer", "\u2581is", "\u2581*", "\u2581No", ",", "\u2581adding", "\u2581effort", "\u2581to", "\u2581solve", "\u2581the", "\u2581problem", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581help", "\u2581", "re", "open", "\u2581the", "\u2581question", "\u2581*", ".", "\u2581See", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581on", "\u2581asking", "\u2581homework", "\u2581questions", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/7", "14", "/", ")", "\u2581and", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581for", "\u2581\"", "\u2581check", "\u2581my", "\u2581work", "\u2581\"", "\u2581problems", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/6", "09", "3/", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581short", "\u2581answer", "\u2581is", "\u2581*", "\u2581No", ",", "\u2581adding", "\u2581effort", "\u2581to", "\u2581solve", "\u2581the", "\u2581problem", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581help", "\u2581", "re", "open", "\u2581the", "\u2581question", "\u2581*", ".", "\u2581See", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581on", "\u2581asking", "\u2581homework", "\u2581questions", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/7", "14", "/", ")", "\u2581and", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581for", "\u2581\"", "\u2581check", "\u2581my", "\u2581work", "\u2581\"", "\u2581problems", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/6", "09", "3/", ")", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581short", "\u2581answer", "\u2581is", "\u2581*", "\u2581No", ",", "\u2581adding", "\u2581effort", "\u2581to", "\u2581solve", "\u2581the", "\u2581problem", "\u2581wo", "\u2581", "n", "'", "\u2581", "t", "\u2581help", "\u2581", "re", "open", "\u2581the", "\u2581question", "\u2581*", ".", "\u2581See", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581on", "\u2581asking", "\u2581homework", "\u2581questions", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/7", "14", "/", ")", "\u2581and", "\u2581[", "\u2581this", "\u2581Meta", "\u2581post", "\u2581for", "\u2581\"", "\u2581check", "\u2581my", "\u2581work", "\u2581\"", "\u2581problems", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "physics", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "q", "/6", "09", "3/", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 52, 53], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_508", "sentence": ["\u2581If", "\u2581someone", "\u2581transfers", "\u2581money", "\u2581from", "\u2581", "a", "\u2581bank", "\u2581account", "\u2581to", "\u2581", "a", "\u2581", "prepaid", "\u2581master", "\u2581card", ",", "\u2581can", "\u2581", "he", "\u2581trace", "\u2581the", "\u2581master", "\u2581card", "\u2581back", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581someone", "\u2581transfers", "\u2581money", "\u2581from", "\u2581", "a", "\u2581bank", "\u2581account", "\u2581to", "\u2581", "a", "\u2581", "prepaid", "\u2581master", "\u2581card", ",", "\u2581can", "\u2581", "he", "\u2581trace", "\u2581the", "\u2581master", "\u2581card", "\u2581back", "</s>"], "target_sentence": ["\u2581If", "\u2581someone", "\u2581transfers", "\u2581money", "\u2581from", "\u2581", "a", "\u2581bank", "\u2581account", "\u2581to", "\u2581", "a", "\u2581", "prepaid", "<m>", "<m>", "\u2581master", "\u2581card", "</m>", "</m>", ",", "\u2581can", "\u2581", "he", "\u2581trace", "\u2581the", "<m>", "<m>", "\u2581master", "</m>", "\u2581card", "</m>", "\u2581back", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 10, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, 2, 3, -1, 2, -1, 3, -1, -1]}, {"doc_id": "emerging.test_509", "sentence": ["\u2581H", "mm", "?", "\u2581Please", "\u2581flesh", "\u2581out", "\u2581your", "\u2581question", "\u2581*", "\u2581before", "\u2581*", "\u2581posting", "\u2581it", "\u2581", "-", "\u2581that", "'", "\u2581", "s", "\u2581also", "\u2581in", "\u2581your", "\u2581own", "\u2581interest", ",", "\u2581since", "\u2581people", "\u2581will", "\u2581vote", "\u2581on", "\u2581the", "\u2581version", "\u2581they", "\u2581currently", "\u2581see", ",", "\u2581and", "\u2581will", "\u2581not", "\u2581necessarily", "\u2581return", "\u2581once", "\u2581you", "\u2581have", "\u2581final", "ized", "\u2581it", "\u2581to", "\u2581correct", "\u2581their", "\u2581vote", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581H", "mm", "?", "\u2581Please", "\u2581flesh", "\u2581out", "\u2581your", "\u2581question", "\u2581*", "\u2581before", "\u2581*", "\u2581posting", "\u2581it", "\u2581", "-", "\u2581that", "'", "\u2581", "s", "\u2581also", "\u2581in", "\u2581your", "\u2581own", "\u2581interest", ",", "\u2581since", "\u2581people", "\u2581will", "\u2581vote", "\u2581on", "\u2581the", "\u2581version", "\u2581they", "\u2581currently", "\u2581see", ",", "\u2581and", "\u2581will", "\u2581not", "\u2581necessarily", "\u2581return", "\u2581once", "\u2581you", "\u2581have", "\u2581final", "ized", "\u2581it", "\u2581to", "\u2581correct", "\u2581their", "\u2581vote", ".", "</s>"], "target_sentence": ["\u2581H", "mm", "?", "\u2581Please", "\u2581flesh", "\u2581out", "\u2581your", "\u2581question", "\u2581*", "\u2581before", "\u2581*", "\u2581posting", "\u2581it", "\u2581", "-", "\u2581that", "'", "\u2581", "s", "\u2581also", "\u2581in", "\u2581your", "\u2581own", "\u2581interest", ",", "\u2581since", "\u2581people", "\u2581will", "\u2581vote", "\u2581on", "\u2581the", "\u2581version", "\u2581they", "\u2581currently", "\u2581see", ",", "\u2581and", "\u2581will", "\u2581not", "\u2581necessarily", "\u2581return", "\u2581once", "\u2581you", "\u2581have", "\u2581final", "ized", "\u2581it", "\u2581to", "\u2581correct", "\u2581their", "\u2581vote", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 41, 42, 43, 44, 45, 46, 47, 48], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_510", "sentence": ["\u2581As", "\u2581soon", "\u2581as", "\u2581I", "\u2581saw", "\u2581your", "\u2581answer", "\u2581I", "\u2581", "jumped", "\u2581out", "\u2581of", "\u2581bed", "\u2581to", "\u2581look", "\u2581for", "\u2581this", "\u2581movie", ".", "\u2581I", "\u2581could", "\u2581", "n", "'", "\u2581", "t", "\u2581possibly", "\u2581thank", "\u2581you", "\u2581enough", ",", "\u2581you", "\u2581have", "\u2581no", "\u2581idea", "\u2581of", "\u2581the", "\u2581service", "\u2581you", "\u2581have", "\u2581done", "\u2581me", ",", "\u2581I", "'", "\u2581", "ve", "\u2581been", "\u2581looking", "\u2581for", "\u2581this", "\u2581movie", "\u2581ever", "\u2581since", "\u2581it", "\u2581came", "\u2581out", ",", "\u2581and", "\u2581you", "\u2581gave", "\u2581me", "\u2581the", "\u2581answer", "\u2581in", "\u2581less", "\u2581than", "\u25812", "\u2581hours", ".", "\u2581Best", "\u2581of", "\u2581luck", "\u2581to", "\u2581you", ",", "\u2581glad", "\u2581to", "\u2581be", "\u2581", "a", "\u2581member", "\u2581of", "\u2581this", "\u2581community", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581As", "\u2581soon", "\u2581as", "\u2581I", "\u2581saw", "\u2581your", "\u2581answer", "\u2581I", "\u2581", "jumped", "\u2581out", "\u2581of", "\u2581bed", "\u2581to", "\u2581look", "\u2581for", "\u2581this", "\u2581movie", ".", "\u2581I", "\u2581could", "\u2581", "n", "'", "\u2581", "t", "\u2581possibly", "\u2581thank", "\u2581you", "\u2581enough", ",", "\u2581you", "\u2581have", "\u2581no", "\u2581idea", "\u2581of", "\u2581the", "\u2581service", "\u2581you", "\u2581have", "\u2581done", "\u2581me", ",", "\u2581I", "'", "\u2581", "ve", "\u2581been", "\u2581looking", "\u2581for", "\u2581this", "\u2581movie", "\u2581ever", "\u2581since", "\u2581it", "\u2581came", "\u2581out", ",", "\u2581and", "\u2581you", "\u2581gave", "\u2581me", "\u2581the", "\u2581answer", "\u2581in", "\u2581less", "\u2581than", "\u25812", "\u2581hours", ".", "\u2581Best", "\u2581of", "\u2581luck", "\u2581to", "\u2581you", ",", "\u2581glad", "\u2581to", "\u2581be", "\u2581", "a", "\u2581member", "\u2581of", "\u2581this", "\u2581community", ".", "</s>"], "target_sentence": ["\u2581As", "\u2581soon", "\u2581as", "\u2581I", "\u2581saw", "\u2581your", "\u2581answer", "\u2581I", "\u2581", "jumped", "\u2581out", "\u2581of", "\u2581bed", "\u2581to", "\u2581look", "\u2581for", "\u2581this", "\u2581movie", ".", "\u2581I", "\u2581could", "\u2581", "n", "'", "\u2581", "t", "\u2581possibly", "\u2581thank", "\u2581you", "\u2581enough", ",", "\u2581you", "\u2581have", "\u2581no", "\u2581idea", "\u2581of", "\u2581the", "\u2581service", "\u2581you", "\u2581have", "\u2581done", "\u2581me", ",", "\u2581I", "'", "\u2581", "ve", "\u2581been", "\u2581looking", "\u2581for", "\u2581this", "\u2581movie", "\u2581ever", "\u2581since", "\u2581it", "\u2581came", "\u2581out", ",", "\u2581and", "\u2581you", "\u2581gave", "\u2581me", "\u2581the", "\u2581answer", "\u2581in", "\u2581less", "\u2581than", "\u25812", "\u2581hours", ".", "\u2581Best", "\u2581of", "\u2581luck", "\u2581to", "\u2581you", ",", "\u2581glad", "\u2581to", "\u2581be", "\u2581", "a", "\u2581member", "\u2581of", "\u2581this", "\u2581community", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 75, 76, 77, 78, 79, 80, 81], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_511", "sentence": ["\u2581@", "\u2581", "sko", "o", "b", "a", "\u2581your", "\u2581are", "\u2581gloss", "ing", "\u2581over", "\u2581all", "\u2581of", "\u2581the", "\u2581", "complexities", ".", "\u2581Because", "\u2581something", "\u2581is", "\u2581easy", "\u2581for", "\u2581you", "\u2581does", "\u2581not", "\u2581mean", "\u2581it", "\u2581is", "\u2581for", "\u2581everyone", "\u2581else", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "sko", "o", "b", "a", "\u2581your", "\u2581are", "\u2581gloss", "ing", "\u2581over", "\u2581all", "\u2581of", "\u2581the", "\u2581", "complexities", ".", "\u2581Because", "\u2581something", "\u2581is", "\u2581easy", "\u2581for", "\u2581you", "\u2581does", "\u2581not", "\u2581mean", "\u2581it", "\u2581is", "\u2581for", "\u2581everyone", "\u2581else", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "sko", "o", "b", "a", "</m>", "\u2581your", "\u2581are", "\u2581gloss", "ing", "\u2581over", "\u2581all", "\u2581of", "\u2581the", "\u2581", "complexities", ".", "\u2581Because", "\u2581something", "\u2581is", "\u2581easy", "\u2581for", "\u2581you", "\u2581does", "\u2581not", "\u2581mean", "\u2581it", "\u2581is", "\u2581for", "\u2581everyone", "\u2581else", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_512", "sentence": ["\u2581What", "'", "\u2581", "s", "\u2581different", "\u2581between", "\u2581two", "\u2581formula", "s", "\u2581in", "\u2581my", "\u2581problem", ".", "\u2581Which", "\u2581one", "\u2581shall", "\u2581I", "\u2581use", ".", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "'", "\u2581", "s", "\u2581different", "\u2581between", "\u2581two", "\u2581formula", "s", "\u2581in", "\u2581my", "\u2581problem", ".", "\u2581Which", "\u2581one", "\u2581shall", "\u2581I", "\u2581use", ".", "?", "</s>"], "target_sentence": ["\u2581What", "'", "\u2581", "s", "\u2581different", "\u2581between", "\u2581two", "\u2581formula", "s", "\u2581in", "\u2581my", "\u2581problem", ".", "\u2581Which", "\u2581one", "\u2581shall", "\u2581I", "\u2581use", ".", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_513", "sentence": ["\u2581@", "\u2581the", "gues", "t", "\u2581It", "'", "\u2581", "s", "\u2581an", "\u2581exchange", "\u2581specifically", "\u2581for", "\u2581science", "\u2581fiction", ".", "\u2581I", "\u2581was", "\u2581trying", "\u2581to", "\u2581be", "\u2581helpful", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581the", "gues", "t", "\u2581It", "'", "\u2581", "s", "\u2581an", "\u2581exchange", "\u2581specifically", "\u2581for", "\u2581science", "\u2581fiction", ".", "\u2581I", "\u2581was", "\u2581trying", "\u2581to", "\u2581be", "\u2581helpful", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581the", "gues", "t", "\u2581It", "'", "\u2581", "s", "\u2581an", "\u2581exchange", "\u2581specifically", "\u2581for", "\u2581science", "\u2581fiction", ".", "\u2581I", "\u2581was", "\u2581trying", "\u2581to", "\u2581be", "\u2581helpful", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_514", "sentence": ["'", "\u2581", "ll", "\u2581certainly", "\u2581check", "\u2581it", "\u2581out", ".", "\u2581But", "\u2581superior", "?", "\u2581As", "\u2581", "a", "\u2581native", "\u2581", "ki", "w", "i", "\u2581that", "\u2581will", "\u2581be", "\u2581my", "\u2581judgement", "\u2581to", "\u2581make", ":", "\u2581", "-", "\u2581P", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "'", "\u2581", "ll", "\u2581certainly", "\u2581check", "\u2581it", "\u2581out", ".", "\u2581But", "\u2581superior", "?", "\u2581As", "\u2581", "a", "\u2581native", "\u2581", "ki", "w", "i", "\u2581that", "\u2581will", "\u2581be", "\u2581my", "\u2581judgement", "\u2581to", "\u2581make", ":", "\u2581", "-", "\u2581P", "</s>"], "target_sentence": ["'", "\u2581", "ll", "\u2581certainly", "\u2581check", "\u2581it", "\u2581out", ".", "\u2581But", "\u2581superior", "?", "\u2581As", "\u2581", "a", "\u2581native", "\u2581", "ki", "w", "i", "\u2581that", "\u2581will", "\u2581be", "\u2581my", "\u2581judgement", "\u2581to", "\u2581make", ":", "\u2581", "-", "\u2581P", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_515", "sentence": ["\u2581probably", "\u2581not", "\u2581the", "\u2581original", "\u2581reference", ":", "\u2581https", "://", "www", ".", "th", "r", "ill", "ist", ".", "com", "/", "ent", "er", "t", "a", "in", "ment", "/", "n", "ation", "/", "ar", "rival", "-", "chi", "nes", "e", "-", "line", "-", "ending", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581probably", "\u2581not", "\u2581the", "\u2581original", "\u2581reference", ":", "\u2581https", "://", "www", ".", "th", "r", "ill", "ist", ".", "com", "/", "ent", "er", "t", "a", "in", "ment", "/", "n", "ation", "/", "ar", "rival", "-", "chi", "nes", "e", "-", "line", "-", "ending", "</s>"], "target_sentence": ["\u2581probably", "\u2581not", "\u2581the", "\u2581original", "\u2581reference", ":", "\u2581https", "://", "www", ".", "th", "r", "ill", "ist", ".", "com", "/", "ent", "er", "t", "a", "in", "ment", "/", "n", "ation", "/", "ar", "rival", "-", "chi", "nes", "e", "-", "line", "-", "ending", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_516", "sentence": ["\u2581If", "\u2581it", "\u2581is", "\u2581called", "\u2581Manda", "lor", "i", "an", ",", "\u2581I", "\u2581would", "\u2581think", "\u2581that", "\u2581the", "\u2581Manda", "lor", "ians", "\u2581designed", "\u2581it", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581it", "\u2581is", "\u2581called", "\u2581Manda", "lor", "i", "an", ",", "\u2581I", "\u2581would", "\u2581think", "\u2581that", "\u2581the", "\u2581Manda", "lor", "ians", "\u2581designed", "\u2581it", ".", "</s>"], "target_sentence": ["\u2581If", "\u2581it", "\u2581is", "\u2581called", "\u2581Manda", "lor", "i", "an", ",", "\u2581I", "\u2581would", "\u2581think", "\u2581that", "\u2581the", "\u2581Manda", "lor", "ians", "\u2581designed", "\u2581it", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_517", "sentence": ["\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581what", "\u2581is", "\u2581the", "\u2581area", "\u2581element", "\u2581", "i", "\u2581must", "\u2581use", "\u2581in", "\u2581", "s", "p", "her", "ical", "\u2581or", "\u2581cylindrical", "\u2581ones", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581what", "\u2581is", "\u2581the", "\u2581area", "\u2581element", "\u2581", "i", "\u2581must", "\u2581use", "\u2581in", "\u2581", "s", "p", "her", "ical", "\u2581or", "\u2581cylindrical", "\u2581ones", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581what", "\u2581is", "\u2581the", "\u2581area", "\u2581element", "\u2581", "i", "\u2581must", "\u2581use", "\u2581in", "\u2581", "s", "p", "her", "ical", "\u2581or", "\u2581cylindrical", "\u2581ones", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 15, 15, 15, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_518", "sentence": ["\u2581Thanks", "\u2581", "a", "\u2581lot", ",", "\u2581but", "\u2581can", "\u2581you", "\u2581give", "\u2581me", "\u2581", "a", "\u2581link", "\u2581for", "\u2581the", "\u2581first", "\u2581site", ",", "\u2581Ghost", "S", "e", "c", "'", "\u2581", "s", "\u2581pen", "test", "\u2581lab", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Thanks", "\u2581", "a", "\u2581lot", ",", "\u2581but", "\u2581can", "\u2581you", "\u2581give", "\u2581me", "\u2581", "a", "\u2581link", "\u2581for", "\u2581the", "\u2581first", "\u2581site", ",", "\u2581Ghost", "S", "e", "c", "'", "\u2581", "s", "\u2581pen", "test", "\u2581lab", "s", "?", "</s>"], "target_sentence": ["\u2581Thanks", "\u2581", "a", "\u2581lot", ",", "\u2581but", "\u2581can", "\u2581you", "\u2581give", "\u2581me", "\u2581", "a", "\u2581link", "\u2581for", "\u2581the", "\u2581first", "\u2581site", ",", "\u2581Ghost", "S", "e", "c", "'", "\u2581", "s", "\u2581pen", "test", "\u2581lab", "s", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 17, 18, 18, 19, 19, 20, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_519", "sentence": ["\u2581Please", "\u2581provide", "\u2581as", "\u2581much", "\u2581information", "\u2581as", "\u2581possible", ".", "\u2581When", "\u2581and", "\u2581where", "\u2581you", "\u2581watched", "\u2581it", ",", "\u2581language", ",", "\u2581color", "\u2581or", "\u2581black", "\u2581", "&", "\u2581white", "\u2581etc", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Please", "\u2581provide", "\u2581as", "\u2581much", "\u2581information", "\u2581as", "\u2581possible", ".", "\u2581When", "\u2581and", "\u2581where", "\u2581you", "\u2581watched", "\u2581it", ",", "\u2581language", ",", "\u2581color", "\u2581or", "\u2581black", "\u2581", "&", "\u2581white", "\u2581etc", "</s>"], "target_sentence": ["\u2581Please", "\u2581provide", "\u2581as", "\u2581much", "\u2581information", "\u2581as", "\u2581possible", ".", "\u2581When", "\u2581and", "\u2581where", "\u2581you", "\u2581watched", "\u2581it", ",", "\u2581language", ",", "\u2581color", "\u2581or", "\u2581black", "\u2581", "&", "\u2581white", "\u2581etc", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_520", "sentence": ["\u2581On", "\u2581", "a", "\u2581mo", "le", "cular", "\u2581level", ",", "\u2581what", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581", "a", "\u2581liquid", "\u2581and", "\u2581", "a", "\u2581powder", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581On", "\u2581", "a", "\u2581mo", "le", "cular", "\u2581level", ",", "\u2581what", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581", "a", "\u2581liquid", "\u2581and", "\u2581", "a", "\u2581powder", "?", "</s>"], "target_sentence": ["\u2581On", "\u2581", "a", "\u2581mo", "le", "cular", "\u2581level", ",", "\u2581what", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581", "a", "\u2581liquid", "\u2581and", "\u2581", "a", "\u2581powder", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_521", "sentence": ["\u2581The", "\u2581Mat", "r", "ix", ":", "\u2581How", "\u2581did", "\u2581the", "\u2581Ne", "buch", "a", "d", "nez", "zar", "\u2581know", "\u2581where", "\u2581to", "\u2581find", "\u2581Neo", "\u2581in", "\u2581the", "\u2581real", "\u2581world", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581Mat", "r", "ix", ":", "\u2581How", "\u2581did", "\u2581the", "\u2581Ne", "buch", "a", "d", "nez", "zar", "\u2581know", "\u2581where", "\u2581to", "\u2581find", "\u2581Neo", "\u2581in", "\u2581the", "\u2581real", "\u2581world", "?", "</s>"], "target_sentence": ["<m>", "\u2581The", "\u2581Mat", "r", "ix", "</m>", ":", "\u2581How", "\u2581did", "\u2581the", "<m>", "\u2581Ne", "buch", "a", "d", "nez", "zar", "</m>", "\u2581know", "\u2581where", "\u2581to", "\u2581find", "<m>", "\u2581Neo", "</m>", "\u2581in", "\u2581the", "\u2581real", "\u2581world", "?", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_522", "sentence": ["\u2581and", "\u2581I", "'", "\u2581", "d", "\u2581disagree", "\u2581", "w", "\u2581", "/", "\u2581@", "\u2581Ed", "lot", "h", "i", "a", "d", "'", "\u2581", "s", "\u2581response", "\u2581", "-", "\u2581it", "\u2581is", "\u2581absolutely", "\u2581", "based", "\u2581more", "\u2581on", "\u2581myth", "\u2581than", "\u2581sci", "-", "f", "i", "\u2581concepts", "\u2581", "-", "\u2581but", ",", "\u2581ultimately", ",", "\u2581that", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581matter", "\u2581since", "\u2581Val", "or", "um", "\u2581is", "\u2581correct", ":", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581and", "\u2581I", "'", "\u2581", "d", "\u2581disagree", "\u2581", "w", "\u2581", "/", "\u2581@", "\u2581Ed", "lot", "h", "i", "a", "d", "'", "\u2581", "s", "\u2581response", "\u2581", "-", "\u2581it", "\u2581is", "\u2581absolutely", "\u2581", "based", "\u2581more", "\u2581on", "\u2581myth", "\u2581than", "\u2581sci", "-", "f", "i", "\u2581concepts", "\u2581", "-", "\u2581but", ",", "\u2581ultimately", ",", "\u2581that", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581matter", "\u2581since", "\u2581Val", "or", "um", "\u2581is", "\u2581correct", ":", ")", "</s>"], "target_sentence": ["\u2581and", "\u2581I", "'", "\u2581", "d", "\u2581disagree", "\u2581", "w", "\u2581", "/", "\u2581@", "\u2581Ed", "lot", "h", "i", "a", "d", "'", "\u2581", "s", "\u2581response", "\u2581", "-", "\u2581it", "\u2581is", "\u2581absolutely", "\u2581", "based", "\u2581more", "\u2581on", "\u2581myth", "\u2581than", "\u2581sci", "-", "f", "i", "\u2581concepts", "\u2581", "-", "\u2581but", ",", "\u2581ultimately", ",", "\u2581that", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581matter", "\u2581since", "<m>", "\u2581Val", "or", "um", "</m>", "\u2581is", "\u2581correct", ":", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 6, 7, 8, 8, 8, 8, 8, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 21, 21, 21, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 32, 33, 34, 35, 35, 35, 36, 37, 38, 39, 40], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_523", "sentence": ["\u2581important", "\u2581addition", "\u2581", "\u2014", "\u2581", "if", "\u2581anyone", "\u2581touches", "\u2581your", "\u2581un", "en", "crypt", "e", "d", "\u2581installation", ",", "\u2581consider", "\u2581it", "\u2581tro", "jan", "e", "d", "\u2581", "\u2014", "\u2581wipe", "\u2581drive", "\u2581completely", "\u2581and", "\u2581install", "\u2581fresh", "\u2581OS", "\u2581afterwards", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581important", "\u2581addition", "\u2581", "\u2014", "\u2581", "if", "\u2581anyone", "\u2581touches", "\u2581your", "\u2581un", "en", "crypt", "e", "d", "\u2581installation", ",", "\u2581consider", "\u2581it", "\u2581tro", "jan", "e", "d", "\u2581", "\u2014", "\u2581wipe", "\u2581drive", "\u2581completely", "\u2581and", "\u2581install", "\u2581fresh", "\u2581OS", "\u2581afterwards", "</s>"], "target_sentence": ["\u2581important", "\u2581addition", "\u2581", "\u2014", "\u2581", "if", "\u2581anyone", "\u2581touches", "\u2581your", "\u2581un", "en", "crypt", "e", "d", "\u2581installation", ",", "\u2581consider", "\u2581it", "\u2581tro", "jan", "e", "d", "\u2581", "\u2014", "\u2581wipe", "\u2581drive", "\u2581completely", "\u2581and", "\u2581install", "\u2581fresh", "\u2581OS", "\u2581afterwards", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 6, 7, 7, 7, 7, 7, 8, 9, 10, 11, 12, 12, 12, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_524", "sentence": ["\u2581Distribution", "\u2581of", "\u2581keys", "\u2581for", "\u2581", "a", "\u2581", "p", "y", "th", "on", "\u2581messaging", "\u2581application", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Distribution", "\u2581of", "\u2581keys", "\u2581for", "\u2581", "a", "\u2581", "p", "y", "th", "on", "\u2581messaging", "\u2581application", "</s>"], "target_sentence": ["<m>", "\u2581Distribution", "\u2581of", "\u2581keys", "</m>", "\u2581for", "\u2581", "a", "\u2581", "p", "y", "th", "on", "\u2581messaging", "\u2581application", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 5, 5, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_525", "sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581always", "\u2581thought", "\u2581that", "\u2581this", "\u2581is", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581occasions", "\u2581where", "\u2581you", "\u2581need", "\u2581to", "\u2581read", "\u2581the", "\u2581book", "\u2581to", "\u2581fully", "\u2581understand", "\u2581the", "\u2581film", ".", ".", "\u2581though", "\u2581you", "\u2581also", "\u2581need", "\u2581to", "\u2581see", "\u2581the", "\u2581film", "\u2581to", "\u2581fully", "\u2581understand", "\u2581the", "\u2581book", ".", "\u2581You", "'", "\u2581", "ve", "\u2581got", "\u2581to", "\u2581vi", "ddy", "\u2581to", "\u2581", "kop", "at", ",", "\u2581that", "'", "\u2581", "s", "\u2581my", "\u2581so", "vie", "t", ",", "\u2581my", "\u2581old", "\u2581", "d", "r", "o", "o", "g", "s", ";", ")", "\u2581[", "\u2581You", "\u2581also", "\u2581need", "\u2581one", "\u2581finger", "\u2581in", "\u2581the", "\u2581gloss", "ary", ",", "\u2581right", "\u2581the", "\u2581way", "\u2581through", "]", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "ve", "\u2581always", "\u2581thought", "\u2581that", "\u2581this", "\u2581is", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581occasions", "\u2581where", "\u2581you", "\u2581need", "\u2581to", "\u2581read", "\u2581the", "\u2581book", "\u2581to", "\u2581fully", "\u2581understand", "\u2581the", "\u2581film", ".", ".", "\u2581though", "\u2581you", "\u2581also", "\u2581need", "\u2581to", "\u2581see", "\u2581the", "\u2581film", "\u2581to", "\u2581fully", "\u2581understand", "\u2581the", "\u2581book", ".", "\u2581You", "'", "\u2581", "ve", "\u2581got", "\u2581to", "\u2581vi", "ddy", "\u2581to", "\u2581", "kop", "at", ",", "\u2581that", "'", "\u2581", "s", "\u2581my", "\u2581so", "vie", "t", ",", "\u2581my", "\u2581old", "\u2581", "d", "r", "o", "o", "g", "s", ";", ")", "\u2581[", "\u2581You", "\u2581also", "\u2581need", "\u2581one", "\u2581finger", "\u2581in", "\u2581the", "\u2581gloss", "ary", ",", "\u2581right", "\u2581the", "\u2581way", "\u2581through", "]", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581always", "\u2581thought", "\u2581that", "\u2581this", "\u2581is", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581occasions", "\u2581where", "\u2581you", "\u2581need", "\u2581to", "\u2581read", "\u2581the", "\u2581book", "\u2581to", "\u2581fully", "\u2581understand", "\u2581the", "\u2581film", ".", ".", "\u2581though", "\u2581you", "\u2581also", "\u2581need", "\u2581to", "\u2581see", "\u2581the", "\u2581film", "\u2581to", "\u2581fully", "\u2581understand", "\u2581the", "\u2581book", ".", "\u2581You", "'", "\u2581", "ve", "\u2581got", "\u2581to", "\u2581vi", "ddy", "\u2581to", "\u2581", "kop", "at", ",", "\u2581that", "'", "\u2581", "s", "\u2581my", "\u2581so", "vie", "t", ",", "\u2581my", "\u2581old", "\u2581", "d", "r", "o", "o", "g", "s", ";", ")", "\u2581[", "\u2581You", "\u2581also", "\u2581need", "\u2581one", "\u2581finger", "\u2581in", "\u2581the", "\u2581gloss", "ary", ",", "\u2581right", "\u2581the", "\u2581way", "\u2581through", "]", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 43, 44, 45, 46, 46, 47, 48, 48, 48, 49, 50, 51, 52, 52, 53, 54, 54, 54, 55, 56, 57, 58, 58, 58, 58, 58, 58, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 69, 70, 71, 72, 73, 74, 75, 76], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_526", "sentence": ["\u2581I", "s", "\u2581mankind", "\u2581still", "\u2581do", "o", "med", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581\"", "\u2581Ob", "l", "ivi", "on", "\u2581\"", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581mankind", "\u2581still", "\u2581do", "o", "med", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581\"", "\u2581Ob", "l", "ivi", "on", "\u2581\"", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581mankind", "\u2581still", "\u2581do", "o", "med", "\u2581at", "\u2581the", "\u2581end", "\u2581of", "\u2581\"", "<m>", "<m>", "\u2581Ob", "l", "ivi", "on", "</m>", "</m>", "\u2581\"", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, 1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_527", "sentence": ["\u2581And", "\u2581what", "\u2581is", "\u2581not", "\u2581useful", "\u2581with", "\u2581this", "\u2581answer", "?", "\u2581Down", "vo", "tes", "\u2581with", "\u2581no", "\u2581explanation", "\u2581are", "\u2581not", "\u2581useful", "\u2581to", "\u2581anyone", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581And", "\u2581what", "\u2581is", "\u2581not", "\u2581useful", "\u2581with", "\u2581this", "\u2581answer", "?", "\u2581Down", "vo", "tes", "\u2581with", "\u2581no", "\u2581explanation", "\u2581are", "\u2581not", "\u2581useful", "\u2581to", "\u2581anyone", ".", "</s>"], "target_sentence": ["\u2581And", "\u2581what", "\u2581is", "\u2581not", "\u2581useful", "\u2581with", "\u2581this", "\u2581answer", "?", "\u2581Down", "vo", "tes", "\u2581with", "\u2581no", "\u2581explanation", "\u2581are", "\u2581not", "\u2581useful", "\u2581to", "\u2581anyone", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_528", "sentence": ["\u2581What", "\u2581does", "\u2581the", "\u2581ending", "\u2581scene", "\u2581of", "\u2581The", "\u2581So", "pra", "nos", "\u2581mean", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581does", "\u2581the", "\u2581ending", "\u2581scene", "\u2581of", "\u2581The", "\u2581So", "pra", "nos", "\u2581mean", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581does", "\u2581the", "\u2581ending", "\u2581scene", "\u2581of", "<m>", "\u2581The", "\u2581So", "pra", "nos", "</m>", "\u2581mean", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_529", "sentence": ["\u2581@", "\u2581de", "f", "alt", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581", "OP", "\u2581was", "\u2581asking", "\u2581about", "\u2581the", "\u2581VPN", "\u2581server", "'", "\u2581", "s", "\u2581port", "\u2581(", "\u2581which", "\u2581I", "\u2581addressed", ",", "\u2581too", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581de", "f", "alt", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581", "OP", "\u2581was", "\u2581asking", "\u2581about", "\u2581the", "\u2581VPN", "\u2581server", "'", "\u2581", "s", "\u2581port", "\u2581(", "\u2581which", "\u2581I", "\u2581addressed", ",", "\u2581too", ")", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581de", "f", "alt", "\u2581I", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581think", "\u2581", "OP", "\u2581was", "\u2581asking", "\u2581about", "\u2581the", "<m>", "\u2581VPN", "\u2581server", "</m>", "'", "<m>", "\u2581", "s", "\u2581port", "</m>", "\u2581(", "\u2581which", "\u2581I", "\u2581addressed", ",", "\u2581too", ")", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_530", "sentence": ["\u2581Under", "s", "to", "o", "d", ".", "\u2581I", "'", "\u2581", "m", "\u2581looking", "\u2581more", "\u2581at", "\u2581knowledge", "\u2581management", "\u2581and", "\u2581consumption", "\u2581for", "\u2581people", ".", "\u2581C", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Under", "s", "to", "o", "d", ".", "\u2581I", "'", "\u2581", "m", "\u2581looking", "\u2581more", "\u2581at", "\u2581knowledge", "\u2581management", "\u2581and", "\u2581consumption", "\u2581for", "\u2581people", ".", "\u2581C", "</s>"], "target_sentence": ["\u2581Under", "s", "to", "o", "d", ".", "\u2581I", "'", "\u2581", "m", "\u2581looking", "\u2581more", "\u2581at", "\u2581knowledge", "\u2581management", "\u2581and", "\u2581consumption", "\u2581for", "\u2581people", ".", "\u2581C", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_531", "sentence": ["\u2581How", "\u2581replace", "able", "\u2581are", "\u2581\"", "\u2581career", "\u2581\"", "\u2581bureau", "cra", "t", "s", "\u2581by", "\u2581new", "\u2581administration", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581replace", "able", "\u2581are", "\u2581\"", "\u2581career", "\u2581\"", "\u2581bureau", "cra", "t", "s", "\u2581by", "\u2581new", "\u2581administration", "s", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581replace", "able", "\u2581are", "\u2581\"", "\u2581career", "\u2581\"", "\u2581bureau", "cra", "t", "s", "\u2581by", "\u2581new", "\u2581administration", "s", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 9, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_532", "sentence": ["\u2581Ah", ",", "\u2581good", "\u2581catch", ".", "\u2581The", "\u2581last", "\u2581one", "\u2581looks", "\u2581suspicious", "ly", "\u2581familiar", ",", "\u2581too", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ah", ",", "\u2581good", "\u2581catch", ".", "\u2581The", "\u2581last", "\u2581one", "\u2581looks", "\u2581suspicious", "ly", "\u2581familiar", ",", "\u2581too", ".", "</s>"], "target_sentence": ["\u2581Ah", ",", "\u2581good", "\u2581catch", ".", "\u2581The", "\u2581last", "\u2581one", "\u2581looks", "\u2581suspicious", "ly", "\u2581familiar", ",", "\u2581too", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_533", "sentence": ["\u2581I", "s", "\u2581it", "\u2581secure", "\u2581to", "\u2581login", "\u2581to", "\u2581your", "\u2581online", "\u2581banking", "\u2581through", "\u2581", "a", "\u2581third", "\u2581party", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581it", "\u2581secure", "\u2581to", "\u2581login", "\u2581to", "\u2581your", "\u2581online", "\u2581banking", "\u2581through", "\u2581", "a", "\u2581third", "\u2581party", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581it", "\u2581secure", "\u2581to", "\u2581login", "\u2581to", "\u2581your", "\u2581online", "\u2581banking", "\u2581through", "\u2581", "a", "\u2581third", "\u2581party", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_534", "sentence": ["\u2581Hi", ",", "\u2581welcome", "\u2581to", "\u2581the", "\u2581site", ".", "\u2581You", "\u2581say", "\u2581the", "\u2581H", "ul", "k", "\u2581saw", "'", "\u2581something", "\u2581", "messe", "d", "\u2581up", "'", "\u2581", "-", "\u2581do", "\u2581you", "\u2581have", "\u2581any", "\u2581quotes", "\u2581or", "\u2581information", "\u2581from", "\u2581the", "\u2581film", "\u2581that", "\u2581would", "\u2581help", "\u2581explain", "\u2581what", "\u2581is", "\u2581was", "\u2581", "he", "\u2581actually", "\u2581saw", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hi", ",", "\u2581welcome", "\u2581to", "\u2581the", "\u2581site", ".", "\u2581You", "\u2581say", "\u2581the", "\u2581H", "ul", "k", "\u2581saw", "'", "\u2581something", "\u2581", "messe", "d", "\u2581up", "'", "\u2581", "-", "\u2581do", "\u2581you", "\u2581have", "\u2581any", "\u2581quotes", "\u2581or", "\u2581information", "\u2581from", "\u2581the", "\u2581film", "\u2581that", "\u2581would", "\u2581help", "\u2581explain", "\u2581what", "\u2581is", "\u2581was", "\u2581", "he", "\u2581actually", "\u2581saw", "?", "</s>"], "target_sentence": ["\u2581Hi", ",", "\u2581welcome", "\u2581to", "\u2581the", "\u2581site", ".", "\u2581You", "\u2581say", "\u2581the", "\u2581H", "ul", "k", "\u2581saw", "'", "\u2581something", "\u2581", "messe", "d", "\u2581up", "'", "\u2581", "-", "\u2581do", "\u2581you", "\u2581have", "\u2581any", "\u2581quotes", "\u2581or", "\u2581information", "\u2581from", "\u2581the", "\u2581film", "\u2581that", "\u2581would", "\u2581help", "\u2581explain", "\u2581what", "\u2581is", "\u2581was", "\u2581", "he", "\u2581actually", "\u2581saw", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 14, 14, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 36, 37, 38, 39], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_535", "sentence": ["\u2581I", "\u2581wish", "\u2581they", "'", "\u2581", "d", "\u2581spend", "\u2581research", "\u2581efforts", "\u2581on", "\u2581how", "\u2581to", "\u2581get", "\u2581more", "\u2581voters", "\u2581to", "\u2581act", "\u2581rational", "ly", ".", ":", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581wish", "\u2581they", "'", "\u2581", "d", "\u2581spend", "\u2581research", "\u2581efforts", "\u2581on", "\u2581how", "\u2581to", "\u2581get", "\u2581more", "\u2581voters", "\u2581to", "\u2581act", "\u2581rational", "ly", ".", ":", ")", "</s>"], "target_sentence": ["\u2581I", "\u2581wish", "\u2581they", "'", "\u2581", "d", "\u2581spend", "\u2581research", "\u2581efforts", "\u2581on", "\u2581how", "\u2581to", "\u2581get", "\u2581more", "\u2581voters", "\u2581to", "\u2581act", "\u2581rational", "ly", ".", ":", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_536", "sentence": ["\u2581I", "s", "\u2581there", "\u2581any", "\u2581evolutionary", "\u2581advantage", "\u2581to", "\u2581the", "\u2581position", "\u2581of", "\u2581the", "\u2581V", "ul", "can", "\u2581heart", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581there", "\u2581any", "\u2581evolutionary", "\u2581advantage", "\u2581to", "\u2581the", "\u2581position", "\u2581of", "\u2581the", "\u2581V", "ul", "can", "\u2581heart", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581there", "\u2581any", "\u2581evolutionary", "\u2581advantage", "\u2581to", "\u2581the", "\u2581position", "\u2581of", "\u2581the", "<m>", "\u2581V", "ul", "can", "</m>", "\u2581heart", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_537", "sentence": ["\u2581What", "\u2581was", "\u2581the", "\u2581Donna", "ger", "'", "\u2581", "s", "\u2581", "esc", "or", "t", "\u2581doing", "\u2581during", "\u2581the", "\u2581battle", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581was", "\u2581the", "\u2581Donna", "ger", "'", "\u2581", "s", "\u2581", "esc", "or", "t", "\u2581doing", "\u2581during", "\u2581the", "\u2581battle", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581was", "\u2581the", "\u2581Donna", "ger", "'", "\u2581", "s", "\u2581", "esc", "or", "t", "\u2581doing", "\u2581during", "\u2581the", "\u2581battle", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 6, 6, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_538", "sentence": ["\u2581What", "\u2581does", "\u2581this", "\u2581mean", "\u2581\"", "\u2581up", "ending", "\u2581standard", "\u2581committee", "\u2581rules", "\u2581\"", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581does", "\u2581this", "\u2581mean", "\u2581\"", "\u2581up", "ending", "\u2581standard", "\u2581committee", "\u2581rules", "\u2581\"", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581does", "\u2581this", "\u2581mean", "\u2581\"", "\u2581up", "ending", "\u2581standard", "\u2581committee", "\u2581rules", "\u2581\"", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_539", "sentence": ["\u2581How", "\u2581much", "\u2581information", "\u2581is", "\u2581stored", "\u2581in", "\u2581", "a", "\u2581genome", "\u2581and", "\u2581how", "\u2581much", "\u2581in", "\u2581the", "\u2581distribution", "\u2581of", "\u2581genome", "s", "\u2581in", "\u2581", "a", "\u2581species", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581much", "\u2581information", "\u2581is", "\u2581stored", "\u2581in", "\u2581", "a", "\u2581genome", "\u2581and", "\u2581how", "\u2581much", "\u2581in", "\u2581the", "\u2581distribution", "\u2581of", "\u2581genome", "s", "\u2581in", "\u2581", "a", "\u2581species", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581much", "\u2581information", "\u2581is", "\u2581stored", "\u2581in", "\u2581", "a", "\u2581genome", "\u2581and", "\u2581how", "\u2581much", "\u2581in", "\u2581the", "\u2581distribution", "\u2581of", "\u2581genome", "s", "\u2581in", "\u2581", "a", "\u2581species", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_540", "sentence": ["\u2581What", "'", "\u2581", "s", "\u2581the", "\u2581most", "\u2581accurate", "\u2581account", "\u2581of", "\u2581the", "\u2581current", "\u2581President", "'", "\u2581", "s", "\u2581", "monetary", "\u2581debt", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "'", "\u2581", "s", "\u2581the", "\u2581most", "\u2581accurate", "\u2581account", "\u2581of", "\u2581the", "\u2581current", "\u2581President", "'", "\u2581", "s", "\u2581", "monetary", "\u2581debt", "s", "?", "</s>"], "target_sentence": ["\u2581What", "'", "\u2581", "s", "\u2581the", "\u2581most", "\u2581accurate", "\u2581account", "\u2581of", "\u2581the", "\u2581current", "\u2581President", "'", "\u2581", "s", "\u2581", "monetary", "\u2581debt", "s", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_541", "sentence": ["\u2581How", "\u2581did", "\u2581the", "\u2581doctor", "\u2581know", "\u2581the", "\u2581cause", "\u2581of", "\u2581death", "\u2581just", "\u2581by", "\u2581", "putting", "\u2581his", "\u2581", "ear", "\u2581on", "\u2581the", "\u2581dead", "\u2581body", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581did", "\u2581the", "\u2581doctor", "\u2581know", "\u2581the", "\u2581cause", "\u2581of", "\u2581death", "\u2581just", "\u2581by", "\u2581", "putting", "\u2581his", "\u2581", "ear", "\u2581on", "\u2581the", "\u2581dead", "\u2581body", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581did", "\u2581the", "\u2581doctor", "\u2581know", "\u2581the", "\u2581cause", "\u2581of", "\u2581death", "\u2581just", "\u2581by", "\u2581", "putting", "\u2581his", "\u2581", "ear", "\u2581on", "\u2581the", "\u2581dead", "\u2581body", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_542", "sentence": ["\u2581@", "\u2581Val", "or", "um", ":", "\u2581Do", "\u2581you", "\u2581want", "\u2581to", "\u2581grab", "\u2581any", "\u2581or", "\u2581all", "\u2581of", "\u2581my", "\u2581memory", "\u2581", "era", "sure", "\u2581bit", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Val", "or", "um", ":", "\u2581Do", "\u2581you", "\u2581want", "\u2581to", "\u2581grab", "\u2581any", "\u2581or", "\u2581all", "\u2581of", "\u2581my", "\u2581memory", "\u2581", "era", "sure", "\u2581bit", "?", "</s>"], "target_sentence": ["\u2581@", "\u2581Val", "or", "um", ":", "\u2581Do", "\u2581you", "\u2581want", "\u2581to", "\u2581grab", "\u2581any", "\u2581or", "\u2581all", "\u2581of", "\u2581my", "\u2581memory", "\u2581", "era", "sure", "\u2581bit", "?", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_543", "sentence": ["\u2581Why", "\u2581do", "\u2581all", "\u2581Potter", "watch", "\u2581contributor", "s", "'", "\u2581code", "name", "s", "\u2581start", "\u2581with", "\u2581\"", "\u2581R", "\u2581\"", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581do", "\u2581all", "\u2581Potter", "watch", "\u2581contributor", "s", "'", "\u2581code", "name", "s", "\u2581start", "\u2581with", "\u2581\"", "\u2581R", "\u2581\"", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581do", "\u2581all", "<m>", "\u2581Potter", "watch", "</m>", "\u2581contributor", "s", "'", "\u2581code", "name", "s", "\u2581start", "\u2581with", "\u2581\"", "\u2581R", "\u2581\"", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_544", "sentence": ["\u2581Bu", "ffer", "\u2581over", "flow", "\u2581attack", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Bu", "ffer", "\u2581over", "flow", "\u2581attack", "</s>"], "target_sentence": ["\u2581Bu", "ffer", "\u2581over", "flow", "\u2581attack", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_545", "sentence": ["\u2581Why", "\u2581was", "\u2581Ho", "g", "war", "t", "s", "\u2581so", "\u2581", "a", "dam", "ant", "\u2581about", "\u2581having", "\u2581Harry", "\u2581go", "\u2581there", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581was", "\u2581Ho", "g", "war", "t", "s", "\u2581so", "\u2581", "a", "dam", "ant", "\u2581about", "\u2581having", "\u2581Harry", "\u2581go", "\u2581there", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581was", "<m>", "\u2581Ho", "g", "war", "t", "s", "</m>", "\u2581so", "\u2581", "a", "dam", "ant", "\u2581about", "\u2581having", "<m>", "\u2581Harry", "</m>", "\u2581go", "\u2581there", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_546", "sentence": ["\u2581If", "\u2581you", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581", "a", "\u2581specific", "\u2581question", "\u2581then", "\u2581why", "'", "\u2581", "re", "\u2581you", "\u2581posting", "\u2581here", "?", "\u2581What", "\u2581do", "\u2581you", "\u2581expect", "\u2581the", "\u2581community", "\u2581to", "\u2581help", "\u2581you", "\u2581with", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581you", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581", "a", "\u2581specific", "\u2581question", "\u2581then", "\u2581why", "'", "\u2581", "re", "\u2581you", "\u2581posting", "\u2581here", "?", "\u2581What", "\u2581do", "\u2581you", "\u2581expect", "\u2581the", "\u2581community", "\u2581to", "\u2581help", "\u2581you", "\u2581with", "?", "</s>"], "target_sentence": ["\u2581If", "\u2581you", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581have", "\u2581", "a", "\u2581specific", "\u2581question", "\u2581then", "\u2581why", "'", "\u2581", "re", "\u2581you", "\u2581posting", "\u2581here", "?", "\u2581What", "\u2581do", "\u2581you", "\u2581expect", "\u2581the", "\u2581community", "\u2581to", "\u2581help", "\u2581you", "\u2581with", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_547", "sentence": ["\u2581Well", "\u2581this", "\u2581should", "\u2581be", "\u2581some", "\u2581coefficient", "\u2581or", "\u2581", "a", "\u2581number", "\u2581that", "\u2581I", "\u2581could", "\u2581use", "\u2581to", "\u2581solve", "\u2581the", "\u2581second", "\u2581part", "\u2581of", "\u2581my", "\u2581\"", "\u2581problem", "\u2581\"", ".", "\u2581I", "\u2581have", "\u2581added", "\u2581the", "\u2581volume", "\u2581figure", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Well", "\u2581this", "\u2581should", "\u2581be", "\u2581some", "\u2581coefficient", "\u2581or", "\u2581", "a", "\u2581number", "\u2581that", "\u2581I", "\u2581could", "\u2581use", "\u2581to", "\u2581solve", "\u2581the", "\u2581second", "\u2581part", "\u2581of", "\u2581my", "\u2581\"", "\u2581problem", "\u2581\"", ".", "\u2581I", "\u2581have", "\u2581added", "\u2581the", "\u2581volume", "\u2581figure", ".", "</s>"], "target_sentence": ["\u2581Well", "\u2581this", "\u2581should", "\u2581be", "\u2581some", "\u2581coefficient", "\u2581or", "\u2581", "a", "\u2581number", "\u2581that", "\u2581I", "\u2581could", "\u2581use", "\u2581to", "\u2581solve", "\u2581the", "\u2581second", "\u2581part", "\u2581of", "\u2581my", "\u2581\"", "\u2581problem", "\u2581\"", ".", "\u2581I", "\u2581have", "\u2581added", "\u2581the", "\u2581volume", "\u2581figure", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_548", "sentence": ["\u2581The", "\u2581blue", "\u2581shifting", "\u2581could", "\u2581even", "\u2581get", "\u2581to", "\u2581the", "\u2581point", "\u2581that", "\u2581the", "\u2581microwave", "\u2581background", "\u2581is", "\u2581visible", ",", "\u2581I", "\u2581really", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", ".", "\u2581I", "\u2581think", "\u2581as", "\u2581far", "\u2581as", "\u2581the", "\u2581more", "\u2581extremely", "\u2581war", "ped", "\u2581paths", "\u2581of", "\u2581light", "\u2581coming", "\u2581up", "\u2581from", "\u2581near", "\u2581the", "\u2581black", "\u2581hole", ",", "\u2581you", "\u2581might", "\u2581look", "\u2581at", "\u2581the", "\u2581black", "\u2581hole", "\u2581from", "\u2581inter", "s", "tell", "ar", ".", "\u2581They", "\u2581", "modeled", "\u2581all", "\u2581of", "\u2581the", "\u2581light", "\u2581really", "\u2581well", ".", "\u2581However", ",", "\u2581I", "\u2581think", "\u2581you", "\u2581have", "\u2581some", "\u2581creative", "\u2581le", "e", "way", "\u2581here", "\u2581given", "\u2581just", "\u2581how", "\u2581complex", "\u2581the", "\u2581paths", "\u2581of", "\u2581", "ray", "s", "\u2581near", "\u2581", "a", "\u2581black", "\u2581hole", "\u2581can", "\u2581be", ".", "\u2581Best", "\u2581of", "\u2581luck", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581blue", "\u2581shifting", "\u2581could", "\u2581even", "\u2581get", "\u2581to", "\u2581the", "\u2581point", "\u2581that", "\u2581the", "\u2581microwave", "\u2581background", "\u2581is", "\u2581visible", ",", "\u2581I", "\u2581really", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", ".", "\u2581I", "\u2581think", "\u2581as", "\u2581far", "\u2581as", "\u2581the", "\u2581more", "\u2581extremely", "\u2581war", "ped", "\u2581paths", "\u2581of", "\u2581light", "\u2581coming", "\u2581up", "\u2581from", "\u2581near", "\u2581the", "\u2581black", "\u2581hole", ",", "\u2581you", "\u2581might", "\u2581look", "\u2581at", "\u2581the", "\u2581black", "\u2581hole", "\u2581from", "\u2581inter", "s", "tell", "ar", ".", "\u2581They", "\u2581", "modeled", "\u2581all", "\u2581of", "\u2581the", "\u2581light", "\u2581really", "\u2581well", ".", "\u2581However", ",", "\u2581I", "\u2581think", "\u2581you", "\u2581have", "\u2581some", "\u2581creative", "\u2581le", "e", "way", "\u2581here", "\u2581given", "\u2581just", "\u2581how", "\u2581complex", "\u2581the", "\u2581paths", "\u2581of", "\u2581", "ray", "s", "\u2581near", "\u2581", "a", "\u2581black", "\u2581hole", "\u2581can", "\u2581be", ".", "\u2581Best", "\u2581of", "\u2581luck", "</s>"], "target_sentence": ["\u2581The", "\u2581blue", "\u2581shifting", "\u2581could", "\u2581even", "\u2581get", "\u2581to", "\u2581the", "\u2581point", "\u2581that", "\u2581the", "\u2581microwave", "\u2581background", "\u2581is", "\u2581visible", ",", "\u2581I", "\u2581really", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581know", ".", "\u2581I", "\u2581think", "\u2581as", "\u2581far", "\u2581as", "\u2581the", "\u2581more", "\u2581extremely", "\u2581war", "ped", "\u2581paths", "\u2581of", "\u2581light", "\u2581coming", "\u2581up", "\u2581from", "\u2581near", "\u2581the", "\u2581black", "\u2581hole", ",", "\u2581you", "\u2581might", "\u2581look", "\u2581at", "\u2581the", "\u2581black", "\u2581hole", "\u2581from", "\u2581inter", "s", "tell", "ar", ".", "\u2581They", "\u2581", "modeled", "\u2581all", "\u2581of", "\u2581the", "\u2581light", "\u2581really", "\u2581well", ".", "\u2581However", ",", "\u2581I", "\u2581think", "\u2581you", "\u2581have", "\u2581some", "\u2581creative", "\u2581le", "e", "way", "\u2581here", "\u2581given", "\u2581just", "\u2581how", "\u2581complex", "\u2581the", "\u2581paths", "\u2581of", "\u2581", "ray", "s", "\u2581near", "\u2581", "a", "\u2581black", "\u2581hole", "\u2581can", "\u2581be", ".", "\u2581Best", "\u2581of", "\u2581luck", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 52, 52, 52, 53, 54, 55, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 71, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 80, 80, 81, 82, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_549", "sentence": ["\u2581A", "\u2581futur", "istic", "\u2581book", "\u2581I", "\u2581am", "\u2581sure", "\u2581was", "\u2581", "titled", "\u2581\"", "\u2581Grand", "father", "\u2581Bank", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "\u2581futur", "istic", "\u2581book", "\u2581I", "\u2581am", "\u2581sure", "\u2581was", "\u2581", "titled", "\u2581\"", "\u2581Grand", "father", "\u2581Bank", "\u2581\"", "</s>"], "target_sentence": ["\u2581A", "\u2581futur", "istic", "\u2581book", "\u2581I", "\u2581am", "\u2581sure", "\u2581was", "\u2581", "titled", "\u2581\"", "<m>", "<m>", "<m>", "\u2581Grand", "father", "\u2581Bank", "</m>", "</m>", "</m>", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 0, 1, -1, -1, -1, 2, 0, 1, -1, -1]}, {"doc_id": "emerging.test_550", "sentence": ["\u2581Please", "\u2581use", "\u2581math", "ja", "x", "\u2581to", "\u2581format", "\u2581mathematical", "\u2581expression", "s", ".", "\u2581To", "\u2581learn", "\u2581more", "\u2581about", "\u2581math", "ja", "x", ",", "\u2581please", "\u2581read", "\u2581[", "\u2581Math", "J", "a", "x", "\u2581basic", "\u2581tutorial", "\u2581and", "\u2581quick", "\u2581reference", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "mat", "h", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "50", "20", "/", "mat", "h", "ja", "x", "-", "bas", "ic", "-", "t", "u", "t", "orial", "-", "and", "-", "qui", "ck", "-", "re", "ference", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Please", "\u2581use", "\u2581math", "ja", "x", "\u2581to", "\u2581format", "\u2581mathematical", "\u2581expression", "s", ".", "\u2581To", "\u2581learn", "\u2581more", "\u2581about", "\u2581math", "ja", "x", ",", "\u2581please", "\u2581read", "\u2581[", "\u2581Math", "J", "a", "x", "\u2581basic", "\u2581tutorial", "\u2581and", "\u2581quick", "\u2581reference", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "mat", "h", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "50", "20", "/", "mat", "h", "ja", "x", "-", "bas", "ic", "-", "t", "u", "t", "orial", "-", "and", "-", "qui", "ck", "-", "re", "ference", ")", ".", "</s>"], "target_sentence": ["\u2581Please", "\u2581use", "<m>", "<m>", "\u2581math", "ja", "x", "</m>", "</m>", "\u2581to", "\u2581format", "\u2581mathematical", "\u2581expression", "s", ".", "\u2581To", "\u2581learn", "\u2581more", "\u2581about", "<m>", "\u2581math", "ja", "x", "</m>", ",", "\u2581please", "\u2581read", "\u2581[", "<m>", "\u2581Math", "J", "a", "x", "</m>", "\u2581basic", "\u2581tutorial", "\u2581and", "\u2581quick", "\u2581reference", "]", "\u2581(", "\u2581http", "://", "met", "a", ".", "mat", "h", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "50", "20", "/", "mat", "h", "ja", "x", "-", "bas", "ic", "-", "t", "u", "t", "orial", "-", "and", "-", "qui", "ck", "-", "re", "ference", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 12, 13, 14, 15, 16, 17, 17, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, -1, 3, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_551", "sentence": ["\u2581You", "\u2581do", "\u2581know", "\u2581what", "\u2581Bor", "king", "\u2581means", ",", "\u2581right", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581do", "\u2581know", "\u2581what", "\u2581Bor", "king", "\u2581means", ",", "\u2581right", "?", "</s>"], "target_sentence": ["\u2581You", "\u2581do", "\u2581know", "\u2581what", "\u2581Bor", "king", "\u2581means", ",", "\u2581right", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_552", "sentence": ["\u2581I", "\u2581believe", "\u2581in", "\u2581that", "\u2581world", "\u2581I", "'", "\u2581", "d", "\u2581say", "\u2581\"", "\u2581I", "'", "\u2581", "m", "\u2581Neg", "an", ",", "\u2581\"", "\u2581wander", "\u2581", "a", "\u2581while", "\u2581and", "\u2581then", "\u2581try", "\u2581to", "\u2581kill", "\u2581him", ".", "\u2581But", "\u2581definitely", "\u2581not", "\u2581after", "\u2581", "he", "\u2581caught", "\u2581", "a", "\u2581bullet", "\u2581with", "\u2581", "a", "\u2581bat", ",", "\u2581after", "\u2581that", "\u2581I", "'", "\u2581", "d", "\u2581probably", "\u2581decide", "\u2581not", "\u2581to", "\u2581mess", "\u2581with", "\u2581him", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581believe", "\u2581in", "\u2581that", "\u2581world", "\u2581I", "'", "\u2581", "d", "\u2581say", "\u2581\"", "\u2581I", "'", "\u2581", "m", "\u2581Neg", "an", ",", "\u2581\"", "\u2581wander", "\u2581", "a", "\u2581while", "\u2581and", "\u2581then", "\u2581try", "\u2581to", "\u2581kill", "\u2581him", ".", "\u2581But", "\u2581definitely", "\u2581not", "\u2581after", "\u2581", "he", "\u2581caught", "\u2581", "a", "\u2581bullet", "\u2581with", "\u2581", "a", "\u2581bat", ",", "\u2581after", "\u2581that", "\u2581I", "'", "\u2581", "d", "\u2581probably", "\u2581decide", "\u2581not", "\u2581to", "\u2581mess", "\u2581with", "\u2581him", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581believe", "\u2581in", "\u2581that", "\u2581world", "\u2581I", "'", "\u2581", "d", "\u2581say", "\u2581\"", "\u2581I", "'", "\u2581", "m", "<m>", "\u2581Neg", "an", "</m>", ",", "\u2581\"", "\u2581wander", "\u2581", "a", "\u2581while", "\u2581and", "\u2581then", "\u2581try", "\u2581to", "\u2581kill", "\u2581him", ".", "\u2581But", "\u2581definitely", "\u2581not", "\u2581after", "\u2581", "he", "\u2581caught", "\u2581", "a", "\u2581bullet", "\u2581with", "\u2581", "a", "\u2581bat", ",", "\u2581after", "\u2581that", "\u2581I", "'", "\u2581", "d", "\u2581probably", "\u2581decide", "\u2581not", "\u2581to", "\u2581mess", "\u2581with", "\u2581him", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 32, 33, 34, 35, 35, 36, 37, 38, 39, 40, 41, 42, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_553", "sentence": ["\u2581De", "fine", "\u2581democracy", ".", "\u2581The", "\u2581majority", "\u2581rules", ",", "\u2581but", "\u2581are", "\u2581\"", "\u2581representatives", "\u2581\"", "\u2581OK", "\u2581to", "\u2581the", "\u2581very", "\u2581notion", "\u2581of", "\u2581democracy", "?", "\u2581If", "\u2581so", ",", "\u2581are", "\u2581the", "\u2581types", "\u2581operating", "\u2581today", "\u2581", "-", "\u2581legislator", "s", ",", "\u2581governor", "s", "\u2581etc", "\u2581OK", "?", "\u2581Also", ",", "\u2581should", "\u2581we", "\u2581include", "\u2581full", "\u2581transparency", "\u2581of", "\u2581such", "\u2581", "a", "\u2581state", "\u2581in", "\u2581its", "\u2581definition", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581De", "fine", "\u2581democracy", ".", "\u2581The", "\u2581majority", "\u2581rules", ",", "\u2581but", "\u2581are", "\u2581\"", "\u2581representatives", "\u2581\"", "\u2581OK", "\u2581to", "\u2581the", "\u2581very", "\u2581notion", "\u2581of", "\u2581democracy", "?", "\u2581If", "\u2581so", ",", "\u2581are", "\u2581the", "\u2581types", "\u2581operating", "\u2581today", "\u2581", "-", "\u2581legislator", "s", ",", "\u2581governor", "s", "\u2581etc", "\u2581OK", "?", "\u2581Also", ",", "\u2581should", "\u2581we", "\u2581include", "\u2581full", "\u2581transparency", "\u2581of", "\u2581such", "\u2581", "a", "\u2581state", "\u2581in", "\u2581its", "\u2581definition", "?", "</s>"], "target_sentence": ["\u2581De", "fine", "\u2581democracy", ".", "\u2581The", "\u2581majority", "\u2581rules", ",", "\u2581but", "\u2581are", "\u2581\"", "\u2581representatives", "\u2581\"", "\u2581OK", "\u2581to", "\u2581the", "\u2581very", "\u2581notion", "\u2581of", "\u2581democracy", "?", "\u2581If", "\u2581so", ",", "\u2581are", "\u2581the", "\u2581types", "\u2581operating", "\u2581today", "\u2581", "-", "\u2581legislator", "s", ",", "\u2581governor", "s", "\u2581etc", "\u2581OK", "?", "\u2581Also", ",", "\u2581should", "\u2581we", "\u2581include", "\u2581full", "\u2581transparency", "\u2581of", "\u2581such", "\u2581", "a", "\u2581state", "\u2581in", "\u2581its", "\u2581definition", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 29, 29, 30, 31, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 44, 45, 46, 47, 48, 49, 50], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_554", "sentence": ["\u2581Why", "\u2581is", "\u2581$", "\u2581C", "\u2581", "_", "\u2581V", "\u2581$", "\u2581used", "\u2581in", "\u2581", "adia", "b", "atic", "\u2581work", "\u2581by", "\u2581an", "\u2581ideal", "\u2581gas", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581$", "\u2581C", "\u2581", "_", "\u2581V", "\u2581$", "\u2581used", "\u2581in", "\u2581", "adia", "b", "atic", "\u2581work", "\u2581by", "\u2581an", "\u2581ideal", "\u2581gas", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "\u2581$", "\u2581C", "\u2581", "_", "\u2581V", "\u2581$", "\u2581used", "\u2581in", "<m>", "\u2581", "adia", "b", "atic", "\u2581work", "</m>", "\u2581by", "\u2581an", "\u2581ideal", "\u2581gas", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_555", "sentence": ["\u2581Great", "!", "\u2581Please", "\u2581also", "\u2581mark", "\u2581my", "\u2581answer", "\u2581as", "\u2581the", "\u2581correct", "\u2581answer", ",", "\u2581there", "\u2581is", "\u2581an", "\u2581option", "\u2581for", "\u2581that", ".", "\u2581Thanks", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Great", "!", "\u2581Please", "\u2581also", "\u2581mark", "\u2581my", "\u2581answer", "\u2581as", "\u2581the", "\u2581correct", "\u2581answer", ",", "\u2581there", "\u2581is", "\u2581an", "\u2581option", "\u2581for", "\u2581that", ".", "\u2581Thanks", ".", "</s>"], "target_sentence": ["\u2581Great", "!", "\u2581Please", "\u2581also", "\u2581mark", "\u2581my", "\u2581answer", "\u2581as", "\u2581the", "\u2581correct", "\u2581answer", ",", "\u2581there", "\u2581is", "\u2581an", "\u2581option", "\u2581for", "\u2581that", ".", "\u2581Thanks", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_556", "sentence": ["\u2581Ca", "\u2581", "n", "'", "\u2581", "t", "\u2581upload", "\u2581pay", "load", "\u2581to", "\u2581my", "\u2581apa", "che", "\u25812", "\u2581server", ".", "\u2581Pen", "test", "ing", "\u2581exercise", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ca", "\u2581", "n", "'", "\u2581", "t", "\u2581upload", "\u2581pay", "load", "\u2581to", "\u2581my", "\u2581apa", "che", "\u25812", "\u2581server", ".", "\u2581Pen", "test", "ing", "\u2581exercise", "</s>"], "target_sentence": ["\u2581Ca", "\u2581", "n", "'", "\u2581", "t", "\u2581upload", "\u2581pay", "load", "\u2581to", "\u2581my", "<m>", "\u2581apa", "che", "\u25812", "</m>", "\u2581server", ".", "\u2581Pen", "test", "ing", "\u2581exercise", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_557", "sentence": ["\u2581The", "\u2581affair", "\u2581Season", "\u25813", "\u2581Episode", "\u258110", "\u2581Noah", "\u2581half", "\u2581", "-", "\u2581French", "\u2581translation", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581affair", "\u2581Season", "\u25813", "\u2581Episode", "\u258110", "\u2581Noah", "\u2581half", "\u2581", "-", "\u2581French", "\u2581translation", "</s>"], "target_sentence": ["<m>", "\u2581The", "\u2581affair", "</m>", "\u2581Season", "\u25813", "\u2581Episode", "\u258110", "\u2581Noah", "\u2581half", "\u2581", "-", "\u2581French", "\u2581translation", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_558", "sentence": ["\u2581E", "\u2581@", "\u2581user", "\u258156", "84", "58", "\u2581Unfortunately", ",", "\u2581my", "\u2581impression", "\u2581of", "\u2581him", "\u2581on", "\u2581the", "\u2581show", "\u2581was", "\u2581similar", "\u2581to", "\u2581the", "\u2581second", ",", "\u2581less", "\u2581masculin", "e", "\u2581Da", "ario", "\u2581(", "\u2581", "i", ".", "\u2581", "e", ".", "\u2581bland", "\u2581as", "\u2581opposed", "\u2581to", "\u2581the", "\u2581hyper", "-", "mas", "cu", "line", "\u2581", "d", "and", "y", "\u2581in", "\u2581the", "\u2581books", ".", ")", "\u2581Euro", "n", "\u2581is", "\u2581", "incredibly", "\u2581", "s", "poo", "ky", ",", "\u2581dark", "\u2581and", "\u2581cruel", ",", "\u2581", "possessed", "\u2581of", "\u2581strange", "\u2581magic", "\u2581and", "\u2581", "re", "lic", "s", ".", "\u2581His", "\u2581portray", "al", "\u2581on", "\u2581the", "\u2581show", "\u2581as", "\u2581is", "\u2581fairly", "\u2581be", "wild", "er", "ing", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581E", "\u2581@", "\u2581user", "\u258156", "84", "58", "\u2581Unfortunately", ",", "\u2581my", "\u2581impression", "\u2581of", "\u2581him", "\u2581on", "\u2581the", "\u2581show", "\u2581was", "\u2581similar", "\u2581to", "\u2581the", "\u2581second", ",", "\u2581less", "\u2581masculin", "e", "\u2581Da", "ario", "\u2581(", "\u2581", "i", ".", "\u2581", "e", ".", "\u2581bland", "\u2581as", "\u2581opposed", "\u2581to", "\u2581the", "\u2581hyper", "-", "mas", "cu", "line", "\u2581", "d", "and", "y", "\u2581in", "\u2581the", "\u2581books", ".", ")", "\u2581Euro", "n", "\u2581is", "\u2581", "incredibly", "\u2581", "s", "poo", "ky", ",", "\u2581dark", "\u2581and", "\u2581cruel", ",", "\u2581", "possessed", "\u2581of", "\u2581strange", "\u2581magic", "\u2581and", "\u2581", "re", "lic", "s", ".", "\u2581His", "\u2581portray", "al", "\u2581on", "\u2581the", "\u2581show", "\u2581as", "\u2581is", "\u2581fairly", "\u2581be", "wild", "er", "ing", ".", "</s>"], "target_sentence": ["\u2581E", "\u2581@", "\u2581user", "\u258156", "84", "58", "\u2581Unfortunately", ",", "\u2581my", "\u2581impression", "\u2581of", "\u2581him", "\u2581on", "\u2581the", "\u2581show", "\u2581was", "\u2581similar", "\u2581to", "\u2581the", "\u2581second", ",", "\u2581less", "\u2581masculin", "e", "<m>", "\u2581Da", "ario", "</m>", "\u2581(", "\u2581", "i", ".", "\u2581", "e", ".", "\u2581bland", "\u2581as", "\u2581opposed", "\u2581to", "\u2581the", "\u2581hyper", "-", "mas", "cu", "line", "\u2581", "d", "and", "y", "\u2581in", "\u2581the", "\u2581books", ".", ")", "<m>", "\u2581Euro", "n", "</m>", "\u2581is", "\u2581", "incredibly", "\u2581", "s", "poo", "ky", ",", "\u2581dark", "\u2581and", "\u2581cruel", ",", "\u2581", "possessed", "\u2581of", "\u2581strange", "\u2581magic", "\u2581and", "\u2581", "re", "lic", "s", ".", "\u2581His", "\u2581portray", "al", "\u2581on", "\u2581the", "\u2581show", "\u2581as", "\u2581is", "\u2581fairly", "\u2581be", "wild", "er", "ing", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21, 22, 23, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 32, 32, 32, 32, 33, 33, 33, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 41, 42, 42, 42, 42, 43, 44, 45, 46, 47, 48, 48, 49, 50, 51, 52, 53, 53, 53, 53, 54, 55, 56, 56, 57, 58, 59, 60, 61, 62, 63, 63, 63, 63, 64, 65], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_559", "sentence": ["\u2581Could", "\u2581", "a", "\u2581President", "\u2581withdraw", "\u2581no", "min", "ated", "\u2581Supreme", "\u2581Court", "\u2581judge", "\u2581before", "\u2581confirmation", "\u2581by", "\u2581the", "\u2581", "s", "en", "ate", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Could", "\u2581", "a", "\u2581President", "\u2581withdraw", "\u2581no", "min", "ated", "\u2581Supreme", "\u2581Court", "\u2581judge", "\u2581before", "\u2581confirmation", "\u2581by", "\u2581the", "\u2581", "s", "en", "ate", "?", "</s>"], "target_sentence": ["\u2581Could", "\u2581", "a", "\u2581President", "\u2581withdraw", "\u2581no", "min", "ated", "\u2581Supreme", "\u2581Court", "\u2581judge", "\u2581before", "\u2581confirmation", "\u2581by", "\u2581the", "\u2581", "s", "en", "ate", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_560", "sentence": ["\u2581", "d", "m", "cke", "e", ",", "\u2581I", "\u2581think", "\u2581you", "\u2581should", "\u2581post", "\u2581your", "\u2581comment", "\u2581as", "\u2581an", "\u2581answer", "\u2581so", "\u2581I", "\u2581can", "\u2581mark", "\u2581it", "\u2581accordingly", ".", "\u2581What", "\u2581you", "\u2581mentioned", "\u2581makes", "\u2581sense", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "d", "m", "cke", "e", ",", "\u2581I", "\u2581think", "\u2581you", "\u2581should", "\u2581post", "\u2581your", "\u2581comment", "\u2581as", "\u2581an", "\u2581answer", "\u2581so", "\u2581I", "\u2581can", "\u2581mark", "\u2581it", "\u2581accordingly", ".", "\u2581What", "\u2581you", "\u2581mentioned", "\u2581makes", "\u2581sense", ".", "</s>"], "target_sentence": ["\u2581", "d", "m", "cke", "e", ",", "\u2581I", "\u2581think", "\u2581you", "\u2581should", "\u2581post", "\u2581your", "\u2581comment", "\u2581as", "\u2581an", "\u2581answer", "\u2581so", "\u2581I", "\u2581can", "\u2581mark", "\u2581it", "\u2581accordingly", ".", "\u2581What", "\u2581you", "\u2581mentioned", "\u2581makes", "\u2581sense", ".", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_561", "sentence": ["\u2581In", "\u2581the", "\u2581Rot", "S", "\u2581scene", "\u2581where", "\u2581Ob", "i", "-", "\u2581Wa", "n", "\u2581and", "\u2581Ana", "kin", "\u2581are", "\u2581stupid", "\u2581enough", "\u2581to", "\u2581walk", "\u2581back", "ward", "s", "\u2581into", "\u2581the", "\u2581elevator", ",", "\u2581the", "\u2581", "d", "roid", "s", "\u2581could", "\u2581have", "\u2581just", "\u2581shot", "\u2581them", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581In", "\u2581the", "\u2581Rot", "S", "\u2581scene", "\u2581where", "\u2581Ob", "i", "-", "\u2581Wa", "n", "\u2581and", "\u2581Ana", "kin", "\u2581are", "\u2581stupid", "\u2581enough", "\u2581to", "\u2581walk", "\u2581back", "ward", "s", "\u2581into", "\u2581the", "\u2581elevator", ",", "\u2581the", "\u2581", "d", "roid", "s", "\u2581could", "\u2581have", "\u2581just", "\u2581shot", "\u2581them", ".", "</s>"], "target_sentence": ["\u2581In", "\u2581the", "<m>", "<m>", "\u2581Rot", "S", "</m>", "</m>", "\u2581scene", "\u2581where", "<m>", "\u2581Ob", "i", "-", "\u2581Wa", "n", "</m>", "\u2581and", "<m>", "\u2581Ana", "kin", "</m>", "\u2581are", "\u2581stupid", "\u2581enough", "\u2581to", "\u2581walk", "\u2581back", "ward", "s", "\u2581into", "\u2581the", "\u2581elevator", ",", "\u2581the", "<m>", "\u2581", "d", "roid", "s", "</m>", "\u2581could", "\u2581have", "\u2581just", "\u2581shot", "\u2581them", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 14, 15, 16, 17, 18, 19, 20, 20, 20, 20, 21, 22, 23, 24, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 1, 0, -1, -1, 1, 0, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1, 3, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_562", "sentence": ["\u2581Turkish", "\u2581military", "\u2581presence", "\u2581in", "\u2581other", "\u2581countries", "\u2581soil", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Turkish", "\u2581military", "\u2581presence", "\u2581in", "\u2581other", "\u2581countries", "\u2581soil", "</s>"], "target_sentence": ["<m>", "\u2581Turkish", "\u2581military", "</m>", "\u2581presence", "\u2581in", "\u2581other", "\u2581countries", "\u2581soil", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, 1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_563", "sentence": ["\u2581Avoid", "e", "d", "\u2581Cross", "ing", "\u2581in", "\u2581Q", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Avoid", "e", "d", "\u2581Cross", "ing", "\u2581in", "\u2581Q", "M", "</s>"], "target_sentence": ["\u2581Avoid", "e", "d", "\u2581Cross", "ing", "\u2581in", "\u2581Q", "M", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 2, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_564", "sentence": ["\u2581I", "\u2581am", "\u2581", "unable", "\u2581to", "\u2581get", "\u2581rid", "\u2581of", "\u2581extra", "\u2581", "cha", "rect", "ers", "\u2581with", "\u2581comments", "\u2581in", "\u2581SQL", "\u2581injection", "\u2581pay", "load", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581am", "\u2581", "unable", "\u2581to", "\u2581get", "\u2581rid", "\u2581of", "\u2581extra", "\u2581", "cha", "rect", "ers", "\u2581with", "\u2581comments", "\u2581in", "\u2581SQL", "\u2581injection", "\u2581pay", "load", "</s>"], "target_sentence": ["\u2581I", "\u2581am", "\u2581", "unable", "\u2581to", "\u2581get", "\u2581rid", "\u2581of", "\u2581extra", "\u2581", "cha", "rect", "ers", "\u2581with", "\u2581comments", "\u2581in", "\u2581SQL", "\u2581injection", "\u2581pay", "load", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_565", "sentence": ["\u2581Why", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581cities", "\u2581plant", "\u2581more", "\u2581fruit", "\u2581trees", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581cities", "\u2581plant", "\u2581more", "\u2581fruit", "\u2581trees", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581cities", "\u2581plant", "\u2581more", "\u2581fruit", "\u2581trees", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_566", "sentence": ["\u2581Help", "\u2581identify", "\u2581", "a", "\u2581collection", "\u2581of", "\u2581short", "\u2581stories", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Help", "\u2581identify", "\u2581", "a", "\u2581collection", "\u2581of", "\u2581short", "\u2581stories", "</s>"], "target_sentence": ["\u2581Help", "\u2581identify", "\u2581", "a", "\u2581collection", "\u2581of", "\u2581short", "\u2581stories", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_567", "sentence": ["\u2581@", "\u2581Be", "b", "s", "\u2581That", "'", "\u2581", "s", "\u2581possible", "\u2581too", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Be", "b", "s", "\u2581That", "'", "\u2581", "s", "\u2581possible", "\u2581too", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Be", "b", "s", "\u2581That", "'", "\u2581", "s", "\u2581possible", "\u2581too", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_568", "sentence": ["\u2581Why", "\u2581is", "\u2581", "imposing", "\u2581vaccination", "\u2581", "/", "\u2581im", "m", "un", "ization", "\u2581so", "\u2581hard", "\u2581to", "\u2581achieve", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581", "imposing", "\u2581vaccination", "\u2581", "/", "\u2581im", "m", "un", "ization", "\u2581so", "\u2581hard", "\u2581to", "\u2581achieve", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "\u2581", "imposing", "\u2581vaccination", "\u2581", "/", "\u2581im", "m", "un", "ization", "\u2581so", "\u2581hard", "\u2581to", "\u2581achieve", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 5, 5, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_569", "sentence": ["\u2581Few", "\u2581Questions", "\u2581About", "\u2581Tor", "\u2581Hidden", "\u2581Services", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Few", "\u2581Questions", "\u2581About", "\u2581Tor", "\u2581Hidden", "\u2581Services", "</s>"], "target_sentence": ["\u2581Few", "\u2581Questions", "\u2581About", "<m>", "\u2581Tor", "</m>", "<m>", "\u2581Hidden", "\u2581Services", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, 2, -1, -1, -1, 1, -1], "ent_indices": [-1, -1, -1, 0, -1, 0, 1, -1, -1, 1, -1]}, {"doc_id": "emerging.test_570", "sentence": ["\u2581It", "\u2581cannot", "\u2581be", "\u2581", "migrated", "\u2581with", "\u2581an", "\u2581open", "\u2581bounty", ",", "\u2581but", "\u2581yes", ",", "\u2581that", "\u2581would", "\u2581have", "\u2581made", "\u2581sense", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "\u2581cannot", "\u2581be", "\u2581", "migrated", "\u2581with", "\u2581an", "\u2581open", "\u2581bounty", ",", "\u2581but", "\u2581yes", ",", "\u2581that", "\u2581would", "\u2581have", "\u2581made", "\u2581sense", "</s>"], "target_sentence": ["\u2581It", "\u2581cannot", "\u2581be", "\u2581", "migrated", "\u2581with", "\u2581an", "\u2581open", "\u2581bounty", ",", "\u2581but", "\u2581yes", ",", "\u2581that", "\u2581would", "\u2581have", "\u2581made", "\u2581sense", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_571", "sentence": ["\u2581@", "\u2581", "c", "de", "\u2581should", "\u2581you", "\u2581want", "\u2581to", "\u2581defend", "\u2581your", "\u2581down", "vo", "t", "e", ",", "\u2581here", "\u2581http", "://", "met", "a", ".", "mov", "ies", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "26", "66", "/", "are", "-", "spo", "il", "ers", "-", "a", "-", "rea", "son", "-", "to", "-", "get", "-", "down", "vo", "tes", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "c", "de", "\u2581should", "\u2581you", "\u2581want", "\u2581to", "\u2581defend", "\u2581your", "\u2581down", "vo", "t", "e", ",", "\u2581here", "\u2581http", "://", "met", "a", ".", "mov", "ies", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "26", "66", "/", "are", "-", "spo", "il", "ers", "-", "a", "-", "rea", "son", "-", "to", "-", "get", "-", "down", "vo", "tes", "</s>"], "target_sentence": ["\u2581@", "\u2581", "c", "de", "\u2581should", "\u2581you", "\u2581want", "\u2581to", "\u2581defend", "\u2581your", "\u2581down", "vo", "t", "e", ",", "\u2581here", "\u2581http", "://", "met", "a", ".", "mov", "ies", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "26", "66", "/", "are", "-", "spo", "il", "ers", "-", "a", "-", "rea", "son", "-", "to", "-", "get", "-", "down", "vo", "tes", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_572", "sentence": ["\u2581So", ",", "\u2581this", "\u2581is", "\u2581", "a", "\u2581picture", "\u2581from", "\u2581the", "\u2581actual", "\u2581show", "?", ".", ".", ".", "\u2581Er", ",", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581it", "\u2581say", "\u2581on", "\u2581the", "\u2581page", "\u2581where", "\u2581it", "\u2581was", "\u2581from", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581So", ",", "\u2581this", "\u2581is", "\u2581", "a", "\u2581picture", "\u2581from", "\u2581the", "\u2581actual", "\u2581show", "?", ".", ".", ".", "\u2581Er", ",", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581it", "\u2581say", "\u2581on", "\u2581the", "\u2581page", "\u2581where", "\u2581it", "\u2581was", "\u2581from", "?", "</s>"], "target_sentence": ["\u2581So", ",", "\u2581this", "\u2581is", "\u2581", "a", "\u2581picture", "\u2581from", "\u2581the", "\u2581actual", "\u2581show", "?", ".", ".", ".", "\u2581Er", ",", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581it", "\u2581say", "\u2581on", "\u2581the", "\u2581page", "\u2581where", "\u2581it", "\u2581was", "\u2581from", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_573", "sentence": ["\u2581Looking", "\u2581for", "\u2581", "a", "\u2581movie", "\u2581where", "\u2581there", "\u2581is", "\u2581", "a", "\u2581Power", "ful", "\u2581Board", "\u2581Game", "\u2581played", "\u2581by", "\u2581two", "\u2581brothers", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Looking", "\u2581for", "\u2581", "a", "\u2581movie", "\u2581where", "\u2581there", "\u2581is", "\u2581", "a", "\u2581Power", "ful", "\u2581Board", "\u2581Game", "\u2581played", "\u2581by", "\u2581two", "\u2581brothers", "?", "</s>"], "target_sentence": ["\u2581Looking", "\u2581for", "\u2581", "a", "\u2581movie", "\u2581where", "\u2581there", "\u2581is", "\u2581", "a", "<m>", "\u2581Power", "ful", "\u2581Board", "\u2581Game", "</m>", "\u2581played", "\u2581by", "\u2581two", "\u2581brothers", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_574", "sentence": ["\u2581my", "\u2581concern", "\u2581is", "\u2581about", "\u2581", "s", "ecuring", "\u2581the", "\u2581content", "\u2581of", "\u2581the", "\u2581output", "\u2581of", "\u2581the", "\u2581", "api", ".", ".", "\u2581request", "\u2581to", "\u2581read", "\u2581the", "\u2581question", "\u2581and", "\u2581the", "\u2581details", "\u2581again", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581my", "\u2581concern", "\u2581is", "\u2581about", "\u2581", "s", "ecuring", "\u2581the", "\u2581content", "\u2581of", "\u2581the", "\u2581output", "\u2581of", "\u2581the", "\u2581", "api", ".", ".", "\u2581request", "\u2581to", "\u2581read", "\u2581the", "\u2581question", "\u2581and", "\u2581the", "\u2581details", "\u2581again", "</s>"], "target_sentence": ["\u2581my", "\u2581concern", "\u2581is", "\u2581about", "\u2581", "s", "ecuring", "\u2581the", "\u2581content", "\u2581of", "\u2581the", "\u2581output", "\u2581of", "\u2581the", "\u2581", "api", ".", ".", "\u2581request", "\u2581to", "\u2581read", "\u2581the", "\u2581question", "\u2581and", "\u2581the", "\u2581details", "\u2581again", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_575", "sentence": ["\u2581Please", "\u2581keep", "\u2581it", "\u2581class", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Please", "\u2581keep", "\u2581it", "\u2581class", "y", "</s>"], "target_sentence": ["\u2581Please", "\u2581keep", "\u2581it", "\u2581class", "y", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_576", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581voting", "\u2581to", "\u2581close", "\u2581this", "\u2581question", "\u2581as", "\u2581off", "-", "topic", "\u2581because", "\u2581it", "\u2581is", "\u2581better", "\u2581", "suited", "\u2581for", "\u2581world", "building", ".", "\u2581se", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581voting", "\u2581to", "\u2581close", "\u2581this", "\u2581question", "\u2581as", "\u2581off", "-", "topic", "\u2581because", "\u2581it", "\u2581is", "\u2581better", "\u2581", "suited", "\u2581for", "\u2581world", "building", ".", "\u2581se", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "m", "\u2581voting", "\u2581to", "\u2581close", "\u2581this", "\u2581question", "\u2581as", "\u2581off", "-", "topic", "\u2581because", "\u2581it", "\u2581is", "\u2581better", "\u2581", "suited", "\u2581for", "\u2581world", "building", ".", "\u2581se", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_577", "sentence": ["\u2581is", "\u2581it", "\u2581because", ",", ".", "\u2581As", "\u2581vis", "co", "s", "ity", "\u2581is", "\u2581zero", "\u2581no", "\u2581vis", "cou", "s", "\u2581force", "\u2581will", "\u2581be", "\u2581there", ".", "\u2581And", "\u2581vis", "cou", "s", "\u2581force", "\u2581is", "\u2581the", "\u2581reason", "\u2581for", "\u2581pressure", "\u2581drop", "\u2581in", "\u2581tube", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581is", "\u2581it", "\u2581because", ",", ".", "\u2581As", "\u2581vis", "co", "s", "ity", "\u2581is", "\u2581zero", "\u2581no", "\u2581vis", "cou", "s", "\u2581force", "\u2581will", "\u2581be", "\u2581there", ".", "\u2581And", "\u2581vis", "cou", "s", "\u2581force", "\u2581is", "\u2581the", "\u2581reason", "\u2581for", "\u2581pressure", "\u2581drop", "\u2581in", "\u2581tube", ".", "</s>"], "target_sentence": ["\u2581is", "\u2581it", "\u2581because", ",", ".", "\u2581As", "\u2581vis", "co", "s", "ity", "\u2581is", "\u2581zero", "\u2581no", "\u2581vis", "cou", "s", "\u2581force", "\u2581will", "\u2581be", "\u2581there", ".", "\u2581And", "\u2581vis", "cou", "s", "\u2581force", "\u2581is", "\u2581the", "\u2581reason", "\u2581for", "\u2581pressure", "\u2581drop", "\u2581in", "\u2581tube", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_578", "sentence": ["\u2581Who", "\u2581is", "\u2581driving", "\u2581Thomas", "\u2581Jane", "'", "\u2581", "s", "\u2581hair", "\u2581and", "\u2581wardrobe", "\u2581on", "\u2581the", "\u2581Ex", "pan", "s", "e", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Who", "\u2581is", "\u2581driving", "\u2581Thomas", "\u2581Jane", "'", "\u2581", "s", "\u2581hair", "\u2581and", "\u2581wardrobe", "\u2581on", "\u2581the", "\u2581Ex", "pan", "s", "e", "?", "</s>"], "target_sentence": ["\u2581Who", "\u2581is", "\u2581driving", "<m>", "<m>", "\u2581Thomas", "\u2581Jane", "</m>", "</m>", "'", "\u2581", "s", "\u2581hair", "\u2581and", "\u2581wardrobe", "\u2581on", "<m>", "\u2581the", "<m>", "\u2581Ex", "pan", "s", "e", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 4, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 2, -1, 3, -1, -1, -1, -1, 3, 2, -1, -1]}, {"doc_id": "emerging.test_579", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581afraid", "\u2581this", "\u2581is", "\u2581", "a", "\u2581deliberate", "\u2581stylist", "ic", "\u2581choice", ".", "\u2581Also", "\u2581seen", "\u2581in", "\u2581Coll", "ide", "\u2581(", "\u25812016", ")", "\u2581and", "\u2581others", ".", "\u2581", "Hopefully", "\u2581it", "'", "\u2581", "s", "\u2581one", "\u2581that", "\u2581will", "\u2581go", "\u2581away", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581afraid", "\u2581this", "\u2581is", "\u2581", "a", "\u2581deliberate", "\u2581stylist", "ic", "\u2581choice", ".", "\u2581Also", "\u2581seen", "\u2581in", "\u2581Coll", "ide", "\u2581(", "\u25812016", ")", "\u2581and", "\u2581others", ".", "\u2581", "Hopefully", "\u2581it", "'", "\u2581", "s", "\u2581one", "\u2581that", "\u2581will", "\u2581go", "\u2581away", ".", "</s>"], "target_sentence": ["<m>", "\u2581I", "'", "\u2581", "m", "</m>", "\u2581afraid", "\u2581this", "\u2581is", "\u2581", "a", "\u2581deliberate", "\u2581stylist", "ic", "\u2581choice", ".", "\u2581Also", "\u2581seen", "\u2581in", "<m>", "<m>", "\u2581Coll", "ide", "</m>", "</m>", "\u2581(", "\u25812016", ")", "\u2581and", "\u2581others", ".", "\u2581", "Hopefully", "\u2581it", "'", "\u2581", "s", "\u2581one", "\u2581that", "\u2581will", "\u2581go", "\u2581away", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 21, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 1, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_580", "sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581momentum", "\u2581between", "\u2581", "a", "\u2581light", "\u2581and", "\u2581heavy", "\u2581object", "\u2581in", "\u2581motion", "\u2581when", "\u2581the", "\u2581force", "\u2581applied", "\u2581is", "\u2581equal", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581is", "\u2581the", "\u2581momentum", "\u2581between", "\u2581", "a", "\u2581light", "\u2581and", "\u2581heavy", "\u2581object", "\u2581in", "\u2581motion", "\u2581when", "\u2581the", "\u2581force", "\u2581applied", "\u2581is", "\u2581equal", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581momentum", "\u2581between", "\u2581", "a", "\u2581light", "\u2581and", "\u2581heavy", "\u2581object", "\u2581in", "\u2581motion", "\u2581when", "\u2581the", "\u2581force", "\u2581applied", "\u2581is", "\u2581equal", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_581", "sentence": ["\u2581Can", "\u2581the", "\u2581vice", "\u2581president", "\u2581be", "\u2581fired", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Can", "\u2581the", "\u2581vice", "\u2581president", "\u2581be", "\u2581fired", "?", "</s>"], "target_sentence": ["\u2581Can", "\u2581the", "\u2581vice", "\u2581president", "\u2581be", "\u2581fired", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_582", "sentence": ["\u2581@", "\u2581", "pho", "o", "g", "\u2581Parliament", "\u2581can", "\u2581do", "\u2581anything", "\u2581it", "\u2581like", "s", ".", "\u2581It", "\u2581is", "\u2581sometimes", "\u2581said", ",", "\u2581by", "\u2581way", "\u2581of", "\u2581emphasis", "\u2581that", "\u2581\"", "\u2581it", "\u2581can", "\u2581make", "\u2581women", "\u2581men", ",", "\u2581and", "\u2581men", "\u2581women", ",", "\u2581", "if", "\u2581it", "\u2581wants", "\u2581\"", ".", "\u2581The", "\u2581only", "\u2581thing", "\u2581it", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581is", "\u2581to", "\u2581pass", "\u2581legislation", "\u2581which", "\u2581", "bind", "s", "\u2581successor", "\u2581parliament", "\u2581in", "\u2581any", "\u2581way", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "pho", "o", "g", "\u2581Parliament", "\u2581can", "\u2581do", "\u2581anything", "\u2581it", "\u2581like", "s", ".", "\u2581It", "\u2581is", "\u2581sometimes", "\u2581said", ",", "\u2581by", "\u2581way", "\u2581of", "\u2581emphasis", "\u2581that", "\u2581\"", "\u2581it", "\u2581can", "\u2581make", "\u2581women", "\u2581men", ",", "\u2581and", "\u2581men", "\u2581women", ",", "\u2581", "if", "\u2581it", "\u2581wants", "\u2581\"", ".", "\u2581The", "\u2581only", "\u2581thing", "\u2581it", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581is", "\u2581to", "\u2581pass", "\u2581legislation", "\u2581which", "\u2581", "bind", "s", "\u2581successor", "\u2581parliament", "\u2581in", "\u2581any", "\u2581way", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581", "pho", "o", "g", "<m>", "\u2581Parliament", "</m>", "\u2581can", "\u2581do", "\u2581anything", "\u2581it", "\u2581like", "s", ".", "\u2581It", "\u2581is", "\u2581sometimes", "\u2581said", ",", "\u2581by", "\u2581way", "\u2581of", "\u2581emphasis", "\u2581that", "\u2581\"", "\u2581it", "\u2581can", "\u2581make", "\u2581women", "\u2581men", ",", "\u2581and", "\u2581men", "\u2581women", ",", "\u2581", "if", "\u2581it", "\u2581wants", "\u2581\"", ".", "\u2581The", "\u2581only", "\u2581thing", "\u2581it", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581is", "\u2581to", "\u2581pass", "\u2581legislation", "\u2581which", "\u2581", "bind", "s", "\u2581successor", "\u2581parliament", "\u2581in", "\u2581any", "\u2581way", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 40, 41, 42, 42, 43, 44, 45, 46, 47, 48, 49, 49, 49, 50, 51, 52, 53, 54, 55, 56], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_583", "sentence": ["\u2581What", "\u2581are", "\u2581the", "\u2581state", "-", "of", "-", "the", "\u2581art", "\u2581techniques", "\u2581for", "\u2581crowd", "\u2581size", "\u2581estimation", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581are", "\u2581the", "\u2581state", "-", "of", "-", "the", "\u2581art", "\u2581techniques", "\u2581for", "\u2581crowd", "\u2581size", "\u2581estimation", "s", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581are", "\u2581the", "\u2581state", "-", "of", "-", "the", "\u2581art", "\u2581techniques", "\u2581for", "\u2581crowd", "\u2581size", "\u2581estimation", "s", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_584", "sentence": ["\u2581\"", "\u2581Large", "\u2581\"", "\u2581gauge", "\u2581transformation", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581act", "\u2581as", "\u2581do", "-", "n", "o", "thing", "\u2581transformation", "\u2581in", "\u2581Q", "FT", ":", "\u2581looking", "\u2581for", "\u2581classical", "\u2581analog", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\"", "\u2581Large", "\u2581\"", "\u2581gauge", "\u2581transformation", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581act", "\u2581as", "\u2581do", "-", "n", "o", "thing", "\u2581transformation", "\u2581in", "\u2581Q", "FT", ":", "\u2581looking", "\u2581for", "\u2581classical", "\u2581analog", "</s>"], "target_sentence": ["\u2581\"", "\u2581Large", "\u2581\"", "\u2581gauge", "\u2581transformation", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581act", "\u2581as", "\u2581do", "-", "n", "o", "thing", "\u2581transformation", "\u2581in", "\u2581Q", "FT", ":", "\u2581looking", "\u2581for", "\u2581classical", "\u2581analog", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 11, 11, 11, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_585", "sentence": ["\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581Beast", "\u2581kill", "\u2581Julia", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581Beast", "\u2581kill", "\u2581Julia", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581Beast", "\u2581kill", "<m>", "\u2581Julia", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1]}, {"doc_id": "emerging.test_586", "sentence": ["\u2581How", "\u2581to", "\u2581der", "ive", "\u2581the", "\u2581equation", "\u2581of", "\u2581motion", "\u2581of", "\u2581Born", "-", "\u2581In", "feld", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581to", "\u2581der", "ive", "\u2581the", "\u2581equation", "\u2581of", "\u2581motion", "\u2581of", "\u2581Born", "-", "\u2581In", "feld", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581to", "\u2581der", "ive", "\u2581the", "\u2581equation", "\u2581of", "\u2581motion", "\u2581of", "<m>", "\u2581Born", "-", "\u2581In", "feld", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_587", "sentence": ["\u2581What", "\u2581are", "\u2581the", "\u2581advantages", "\u2581of", "\u2581the", "\u2581French", "\u2581two", "-", "round", "\u2581voting", "\u2581system", "\u2581against", "\u2581", "a", "\u2581one", "\u2581round", "\u2581alternative", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581are", "\u2581the", "\u2581advantages", "\u2581of", "\u2581the", "\u2581French", "\u2581two", "-", "round", "\u2581voting", "\u2581system", "\u2581against", "\u2581", "a", "\u2581one", "\u2581round", "\u2581alternative", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581are", "\u2581the", "<m>", "\u2581advantages", "\u2581of", "\u2581the", "\u2581French", "</m>", "\u2581two", "-", "round", "\u2581voting", "\u2581system", "\u2581against", "\u2581", "a", "\u2581one", "\u2581round", "\u2581alternative", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_588", "sentence": ["\u2581A", "symmetry", "\u2581definition", "s", "\u2581electric", "\u2581$", "\u2581", "\\", "\u2581", "chi", "\u2581", "_", "\u2581", "e", "\u2581$", "\u2581and", "\u2581magnetic", "\u2581sus", "cept", "ibility", "\u2581$", "\u2581", "\\", "\u2581", "chi", "\u2581", "_", "\u2581", "m", "\u2581$", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "symmetry", "\u2581definition", "s", "\u2581electric", "\u2581$", "\u2581", "\\", "\u2581", "chi", "\u2581", "_", "\u2581", "e", "\u2581$", "\u2581and", "\u2581magnetic", "\u2581sus", "cept", "ibility", "\u2581$", "\u2581", "\\", "\u2581", "chi", "\u2581", "_", "\u2581", "m", "\u2581$", "</s>"], "target_sentence": ["\u2581A", "symmetry", "\u2581definition", "s", "\u2581electric", "\u2581$", "\u2581", "\\", "\u2581", "chi", "\u2581", "_", "\u2581", "e", "\u2581$", "\u2581and", "\u2581magnetic", "\u2581sus", "cept", "ibility", "\u2581$", "\u2581", "\\", "\u2581", "chi", "\u2581", "_", "\u2581", "m", "\u2581$", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_589", "sentence": ["\u2581How", "\u2581many", "\u2581people", "\u2581are", "\u2581the", "\u2581three", "\u2581billion", "\u2581watching", "\u2581Za", "pho", "d", "\u2581Bee", "ble", "bro", "x", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581many", "\u2581people", "\u2581are", "\u2581the", "\u2581three", "\u2581billion", "\u2581watching", "\u2581Za", "pho", "d", "\u2581Bee", "ble", "bro", "x", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581many", "\u2581people", "\u2581are", "\u2581the", "\u2581three", "\u2581billion", "\u2581watching", "<m>", "<m>", "\u2581Za", "pho", "d", "\u2581Bee", "ble", "bro", "x", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 9, 9, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1]}, {"doc_id": "emerging.test_590", "sentence": ["\u2581Does", "\u2581the", "\u2581\"", "\u2581mo", "le", "\u2581\"", "\u2581like", "\u2581device", "\u2581access", "\u2581Isabel", "la", "'", "\u2581", "s", "\u2581facial", "\u2581expression", "s", "\u2581in", "\u2581Her", "\u2581(", "\u25812013", ")", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Does", "\u2581the", "\u2581\"", "\u2581mo", "le", "\u2581\"", "\u2581like", "\u2581device", "\u2581access", "\u2581Isabel", "la", "'", "\u2581", "s", "\u2581facial", "\u2581expression", "s", "\u2581in", "\u2581Her", "\u2581(", "\u25812013", ")", "?", "</s>"], "target_sentence": ["\u2581Does", "\u2581the", "\u2581\"", "\u2581mo", "le", "\u2581\"", "\u2581like", "\u2581device", "\u2581access", "<m>", "\u2581Isabel", "la", "</m>", "'", "\u2581", "s", "\u2581facial", "\u2581expression", "s", "\u2581in", "\u2581Her", "\u2581(", "\u25812013", ")", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_591", "sentence": ["\u2581I", "\u2581think", "\u2581that", "\u2581at", "\u2581begin", "ing", "\u2581they", "\u2581were", "\u25814", "\u2581", "\u2013", "\u25815", ".", "\u2581And", "\u2581in", "\u2581that", "\u2581ma", "ze", "\u2581was", "\u2581one", "\u2581guy", "\u2581(", "\u2581killer", ")", ".", "\u2581At", "\u2581the", "\u2581end", "\u2581of", "\u2581the", "\u2581movie", "\u2581left", "\u2581only", "\u2581", "a", "\u2581girl", "\u2581and", "\u2581guy", "\u2581with", "\u2581glasses", ".", "\u2581That", "\u2581killer", "\u2581kid", "d", "naps", "\u2581that", "\u2581girl", ",", "\u2581", "c", "uff", "s", "\u2581her", "\u2581on", "\u2581the", "\u2581table", "\u2581and", "\u2581", "he", "\u2581", "tries", "\u2581to", "\u2581kill", ".", "\u2581That", "\u2581guy", "\u2581with", "\u2581glasses", "\u2581save", "s", "\u2581her", "\u2581and", "\u2581they", "\u2581finds", "\u2581way", "\u2581out", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581think", "\u2581that", "\u2581at", "\u2581begin", "ing", "\u2581they", "\u2581were", "\u25814", "\u2581", "\u2013", "\u25815", ".", "\u2581And", "\u2581in", "\u2581that", "\u2581ma", "ze", "\u2581was", "\u2581one", "\u2581guy", "\u2581(", "\u2581killer", ")", ".", "\u2581At", "\u2581the", "\u2581end", "\u2581of", "\u2581the", "\u2581movie", "\u2581left", "\u2581only", "\u2581", "a", "\u2581girl", "\u2581and", "\u2581guy", "\u2581with", "\u2581glasses", ".", "\u2581That", "\u2581killer", "\u2581kid", "d", "naps", "\u2581that", "\u2581girl", ",", "\u2581", "c", "uff", "s", "\u2581her", "\u2581on", "\u2581the", "\u2581table", "\u2581and", "\u2581", "he", "\u2581", "tries", "\u2581to", "\u2581kill", ".", "\u2581That", "\u2581guy", "\u2581with", "\u2581glasses", "\u2581save", "s", "\u2581her", "\u2581and", "\u2581they", "\u2581finds", "\u2581way", "\u2581out", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581think", "\u2581that", "\u2581at", "\u2581begin", "ing", "\u2581they", "\u2581were", "\u25814", "\u2581", "\u2013", "\u25815", ".", "\u2581And", "\u2581in", "\u2581that", "\u2581ma", "ze", "\u2581was", "\u2581one", "<m>", "\u2581guy", "</m>", "\u2581(", "\u2581killer", ")", ".", "\u2581At", "\u2581the", "\u2581end", "\u2581of", "\u2581the", "\u2581movie", "\u2581left", "\u2581only", "\u2581", "a", "<m>", "\u2581girl", "</m>", "\u2581and", "<m>", "\u2581guy", "</m>", "\u2581with", "\u2581glasses", ".", "\u2581That", "\u2581killer", "\u2581kid", "d", "naps", "\u2581that", "<m>", "\u2581girl", "</m>", ",", "\u2581", "c", "uff", "s", "\u2581her", "\u2581on", "\u2581the", "\u2581table", "\u2581and", "\u2581", "he", "\u2581", "tries", "\u2581to", "\u2581kill", ".", "\u2581That", "<m>", "\u2581guy", "</m>", "\u2581with", "\u2581glasses", "\u2581save", "s", "\u2581her", "\u2581and", "\u2581they", "\u2581finds", "\u2581way", "\u2581out", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 39, 40, 41, 42, 43, 43, 43, 43, 44, 45, 46, 47, 48, 49, 49, 50, 50, 51, 52, 53, 54, 55, 56, 57, 58, 58, 59, 60, 61, 62, 63, 64, 65, 66], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_592", "sentence": ["\u2581How", "\u2581did", "\u2581Mon", "-", "\u2581El", "\u2581know", "\u2581English", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581did", "\u2581Mon", "-", "\u2581El", "\u2581know", "\u2581English", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581did", "<m>", "\u2581Mon", "-", "\u2581El", "</m>", "\u2581know", "\u2581English", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1]}, {"doc_id": "emerging.test_593", "sentence": ["\u2581I", "s", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581network", "\u2581called", "\u2581Movie", "s", "\u2581", "&", "\u2581TV", "?", "\u2581(", "\u2581It", "\u2581clearly", "\u2581is", "\u2581TV", ",", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581it", "?", "\u2581And", "\u2581why", "\u2581would", "\u2581there", "\u2581be", "\u2581an", "\u2581\"", "\u2581academy", "-", "a", "ward", "\u2581\"", "\u2581tag", ",", "\u2581", "if", "\u2581it", "'", "\u2581", "s", "\u2581off", "\u2581topic", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581network", "\u2581called", "\u2581Movie", "s", "\u2581", "&", "\u2581TV", "?", "\u2581(", "\u2581It", "\u2581clearly", "\u2581is", "\u2581TV", ",", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581it", "?", "\u2581And", "\u2581why", "\u2581would", "\u2581there", "\u2581be", "\u2581an", "\u2581\"", "\u2581academy", "-", "a", "ward", "\u2581\"", "\u2581tag", ",", "\u2581", "if", "\u2581it", "'", "\u2581", "s", "\u2581off", "\u2581topic", "?", "</s>"], "target_sentence": ["\u2581I", "s", "\u2581", "n", "'", "\u2581", "t", "\u2581the", "\u2581network", "\u2581called", "\u2581Movie", "s", "\u2581", "&", "\u2581TV", "?", "\u2581(", "\u2581It", "\u2581clearly", "\u2581is", "\u2581TV", ",", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581it", "?", "\u2581And", "\u2581why", "\u2581would", "\u2581there", "\u2581be", "\u2581an", "\u2581\"", "\u2581academy", "-", "a", "ward", "\u2581\"", "\u2581tag", ",", "\u2581", "if", "\u2581it", "'", "\u2581", "s", "\u2581off", "\u2581topic", "?", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 3, 4, 5, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 30, 30, 31, 32, 33, 34, 34, 35, 36, 37, 37, 38, 39, 40, 41], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_594", "sentence": ["\u2581Who", "\u2581legi", "s", "late", "s", "\u2581military", "\u2581law", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Who", "\u2581legi", "s", "late", "s", "\u2581military", "\u2581law", "?", "</s>"], "target_sentence": ["\u2581Who", "\u2581legi", "s", "late", "s", "\u2581military", "\u2581law", "?", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_595", "sentence": ["\u2581What", "\u2581was", "\u2581the", "\u2581tall", "est", "\u2581structure", "\u2581built", "\u2581in", "\u2581Middle", "-", "e", "arth", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581was", "\u2581the", "\u2581tall", "est", "\u2581structure", "\u2581built", "\u2581in", "\u2581Middle", "-", "e", "arth", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581was", "\u2581the", "\u2581tall", "est", "\u2581structure", "\u2581built", "\u2581in", "<m>", "\u2581Middle", "-", "e", "arth", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_596", "sentence": ["\u2581There", "\u2581you", "\u2581go", ",", "\u2581answered", "\u2581in", "\u2581the", "\u2581", "OP", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581There", "\u2581you", "\u2581go", ",", "\u2581answered", "\u2581in", "\u2581the", "\u2581", "OP", ".", "</s>"], "target_sentence": ["\u2581There", "\u2581you", "\u2581go", ",", "\u2581answered", "\u2581in", "\u2581the", "\u2581", "OP", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_597", "sentence": ["\u2581@", "\u2581Dem", "i", ":", "\u2581I", "\u2581was", "\u2581saying", "\u2581that", "\u2581because", "\u2581I", "\u2581was", "\u2581need", "ing", "\u2581", "p", "y", "th", "on", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Dem", "i", ":", "\u2581I", "\u2581was", "\u2581saying", "\u2581that", "\u2581because", "\u2581I", "\u2581was", "\u2581need", "ing", "\u2581", "p", "y", "th", "on", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Dem", "i", "</m>", ":", "\u2581I", "\u2581was", "\u2581saying", "\u2581that", "\u2581because", "\u2581I", "\u2581was", "\u2581need", "ing", "\u2581", "p", "y", "th", "on", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 11, 11, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_598", "sentence": ["\u2581I", "\u2581used", "\u2581it", "\u2581in", "\u2581", "NL", "\u2581for", "\u25818", "\u2581years", "\u2581or", "\u2581so", "\u2581and", "\u2581never", "\u2581had", "\u2581any", "\u2581problems", ".", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581used", "\u2581it", "\u2581in", "\u2581", "NL", "\u2581for", "\u25818", "\u2581years", "\u2581or", "\u2581so", "\u2581and", "\u2581never", "\u2581had", "\u2581any", "\u2581problems", ".", ".", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581used", "\u2581it", "\u2581in", "\u2581", "NL", "\u2581for", "\u25818", "\u2581years", "\u2581or", "\u2581so", "\u2581and", "\u2581never", "\u2581had", "\u2581any", "\u2581problems", ".", ".", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_599", "sentence": ["\u2581@", "\u2581Gordon", "\u2581Not", "\u2581all", ",", "\u2581for", "\u2581example", "\u2581", "glu", "on", "s", "\u2581and", "\u2581photo", "n", "s", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581interact", "\u2581with", "\u2581the", "\u2581Hi", "gg", "s", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Gordon", "\u2581Not", "\u2581all", ",", "\u2581for", "\u2581example", "\u2581", "glu", "on", "s", "\u2581and", "\u2581photo", "n", "s", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581interact", "\u2581with", "\u2581the", "\u2581Hi", "gg", "s", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Gordon", "</m>", "\u2581Not", "\u2581all", ",", "\u2581for", "\u2581example", "\u2581", "glu", "on", "s", "\u2581and", "\u2581photo", "n", "s", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581interact", "\u2581with", "\u2581the", "\u2581Hi", "gg", "s", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9, 9, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 17, 17, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_600", "sentence": ["\u2581An", "\u2581old", "\u2581TV", "\u2581show", "\u2581with", "\u2581", "a", "\u2581man", "\u2581driving", "\u2581around", "\u2581in", "\u2581his", "\u2581ca", "d", "il", "lac", "\u2581solving", "\u2581problems", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581An", "\u2581old", "\u2581TV", "\u2581show", "\u2581with", "\u2581", "a", "\u2581man", "\u2581driving", "\u2581around", "\u2581in", "\u2581his", "\u2581ca", "d", "il", "lac", "\u2581solving", "\u2581problems", "</s>"], "target_sentence": ["\u2581An", "\u2581old", "\u2581TV", "\u2581show", "\u2581with", "\u2581", "a", "\u2581man", "\u2581driving", "\u2581around", "\u2581in", "\u2581his", "<m>", "<m>", "\u2581ca", "d", "il", "lac", "</m>", "</m>", "\u2581solving", "\u2581problems", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1]}, {"doc_id": "emerging.test_601", "sentence": ["\u2581Not", "\u2581sure", "\u2581about", "\u2581this", "\u2581answer", ".", "\u2581For", "\u2581me", "\u2581the", "\u2581chapter", "\u258121", "\u2581quote", "\u2581included", "\u2581here", "in", "\u2581conflicts", "\u2581with", "\u2581the", "\u2581\"", "\u2581probably", "\u2581using", "\u2581", "a", "\u2581Dem", "i", "gui", "s", "e", "\u2581\"", "\u2581", "s", "up", "position", "\u2581(", "\u2581which", "\u2581is", "\u2581bold", "e", "d", "\u2581at", "\u2581the", "\u2581top", ")", ".", "\u2581\u201c", "\u2581Ah", ",", "\u2581but", "\u2581the", "\u2581Third", "\u2581Hall", "ow", "\u2581is", "\u2581", "a", "\u2581true", "\u2581Clo", "ak", "\u2581of", "\u2581In", "vis", "ibility", ",", "\u2581Miss", "\u2581Gran", "ger", "!", "\u2581I", "\u2581mean", "\u2581to", "\u2581say", ",", "\u2581it", "\u2581is", "\u2581not", ".", ".", ".", "\u2581", "woven", "\u2581from", "\u2581Dem", "i", "gui", "s", "e", "\u2581hair", "\u2581\"", ".", "\u2581I", "\u2581think", "\u2581your", "\u2581second", "\u2581last", "\u2581paragraph", "\u2581gets", "\u2581to", "\u2581the", "\u2581real", "\u2581cru", "x", "\u2581of", "\u2581the", "\u2581matter", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Not", "\u2581sure", "\u2581about", "\u2581this", "\u2581answer", ".", "\u2581For", "\u2581me", "\u2581the", "\u2581chapter", "\u258121", "\u2581quote", "\u2581included", "\u2581here", "in", "\u2581conflicts", "\u2581with", "\u2581the", "\u2581\"", "\u2581probably", "\u2581using", "\u2581", "a", "\u2581Dem", "i", "gui", "s", "e", "\u2581\"", "\u2581", "s", "up", "position", "\u2581(", "\u2581which", "\u2581is", "\u2581bold", "e", "d", "\u2581at", "\u2581the", "\u2581top", ")", ".", "\u2581\u201c", "\u2581Ah", ",", "\u2581but", "\u2581the", "\u2581Third", "\u2581Hall", "ow", "\u2581is", "\u2581", "a", "\u2581true", "\u2581Clo", "ak", "\u2581of", "\u2581In", "vis", "ibility", ",", "\u2581Miss", "\u2581Gran", "ger", "!", "\u2581I", "\u2581mean", "\u2581to", "\u2581say", ",", "\u2581it", "\u2581is", "\u2581not", ".", ".", ".", "\u2581", "woven", "\u2581from", "\u2581Dem", "i", "gui", "s", "e", "\u2581hair", "\u2581\"", ".", "\u2581I", "\u2581think", "\u2581your", "\u2581second", "\u2581last", "\u2581paragraph", "\u2581gets", "\u2581to", "\u2581the", "\u2581real", "\u2581cru", "x", "\u2581of", "\u2581the", "\u2581matter", ".", "</s>"], "target_sentence": ["\u2581Not", "\u2581sure", "\u2581about", "\u2581this", "\u2581answer", ".", "\u2581For", "\u2581me", "\u2581the", "\u2581chapter", "\u258121", "\u2581quote", "\u2581included", "\u2581here", "in", "\u2581conflicts", "\u2581with", "\u2581the", "\u2581\"", "\u2581probably", "\u2581using", "\u2581", "a", "\u2581Dem", "i", "gui", "s", "e", "\u2581\"", "\u2581", "s", "up", "position", "\u2581(", "\u2581which", "\u2581is", "\u2581bold", "e", "d", "\u2581at", "\u2581the", "\u2581top", ")", ".", "\u2581\u201c", "\u2581Ah", ",", "\u2581but", "\u2581the", "\u2581Third", "\u2581Hall", "ow", "\u2581is", "\u2581", "a", "\u2581true", "\u2581Clo", "ak", "\u2581of", "\u2581In", "vis", "ibility", ",", "<m>", "\u2581Miss", "\u2581Gran", "ger", "</m>", "!", "\u2581I", "\u2581mean", "\u2581to", "\u2581say", ",", "\u2581it", "\u2581is", "\u2581not", ".", ".", ".", "\u2581", "woven", "\u2581from", "\u2581Dem", "i", "gui", "s", "e", "\u2581hair", "\u2581\"", ".", "\u2581I", "\u2581think", "\u2581your", "\u2581second", "\u2581last", "\u2581paragraph", "\u2581gets", "\u2581to", "\u2581the", "\u2581real", "\u2581cru", "x", "\u2581of", "\u2581the", "\u2581matter", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21, 21, 21, 21, 22, 23, 23, 23, 23, 24, 25, 26, 27, 27, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 41, 42, 43, 43, 44, 45, 45, 45, 46, 47, 48, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 61, 62, 63, 63, 63, 63, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 77, 78, 79, 80, 81, 82], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_602", "sentence": ["\u2581S", "SO", "\u2581against", "\u2581many", "\u2581identity", "\u2581providers", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581S", "SO", "\u2581against", "\u2581many", "\u2581identity", "\u2581providers", "</s>"], "target_sentence": ["\u2581S", "SO", "\u2581against", "\u2581many", "\u2581identity", "\u2581providers", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_603", "sentence": ["\u2581during", "\u2581", "s", "s", "h", "\u2581hands", "hak", "ing", "\u2581server", "\u2581introduce", "\u2581itself", "\u2581", "-", "\u2581does", "\u2581it", "\u2581improve", "\u2581security", "\u2581to", "\u2581change", "\u2581self", "\u2581presentation", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581during", "\u2581", "s", "s", "h", "\u2581hands", "hak", "ing", "\u2581server", "\u2581introduce", "\u2581itself", "\u2581", "-", "\u2581does", "\u2581it", "\u2581improve", "\u2581security", "\u2581to", "\u2581change", "\u2581self", "\u2581presentation", "?", "</s>"], "target_sentence": ["\u2581during", "\u2581", "s", "s", "h", "\u2581hands", "hak", "ing", "\u2581server", "\u2581introduce", "\u2581itself", "\u2581", "-", "\u2581does", "\u2581it", "\u2581improve", "\u2581security", "\u2581to", "\u2581change", "\u2581self", "\u2581presentation", "?", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_604", "sentence": ["\u2581Are", "\u2581there", "\u2581other", "\u2581M", "j", "\u00f6l", "n", "i", "r", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Are", "\u2581there", "\u2581other", "\u2581M", "j", "\u00f6l", "n", "i", "r", "s", "?", "</s>"], "target_sentence": ["\u2581Are", "\u2581there", "\u2581other", "<m>", "<m>", "\u2581M", "j", "\u00f6l", "n", "i", "r", "s", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1]}, {"doc_id": "emerging.test_605", "sentence": ["\u2581In", "\u2581order", "\u2581to", "\u2581calculate", "\u2581anything", ",", "\u2581more", "\u2581input", "\u2581data", "\u2581is", "\u2581required", ";", "\u2581such", "\u2581as", ":", "\u2581\"", "\u2581From", "\u2581where", "\u2581do", "\u2581you", "\u2581hit", "\u2581the", "\u2581ball", "\u2581and", "\u2581at", "\u2581what", "\u2581angle", "?", "\u2581Do", "\u2581you", "\u2581want", "\u2581to", "\u2581take", "\u2581into", "\u2581account", "\u2581effects", "\u2581due", "\u2581to", "\u2581the", "\u2581spin", "\u2581of", "\u2581the", "\u2581ball", "?", "\u2581Should", "\u2581friction", "\u2581be", "\u2581included", "?", "\u2581\"", "\u2581", "Generally", "\u2581(", "\u2581", "if", "\u2581you", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581put", "\u2581any", "\u2581restrictions", "\u2581on", "\u2581how", "\u2581you", "\u2581can", "\u2581hit", "\u2581it", ")", "\u2581there", "\u2581is", "\u2581no", "\u2581reason", "\u2581that", "\u2581you", "\u2581could", "\u2581not", "\u2581make", "\u2581the", "\u2581ball", "\u2581return", "\u2581(", "\u2581", "unless", "\u2581you", "'", "\u2581", "d", "\u2581have", "\u2581to", "\u2581hit", "\u2581it", "\u2581so", "\u2581hard", "\u2581that", "\u2581the", "\u2581ball", "\u2581breaks", "\u2581(", "\u2581which", "\u2581I", "\u2581doubt", "\u2581would", "\u2581be", "\u2581the", "\u2581case", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581In", "\u2581order", "\u2581to", "\u2581calculate", "\u2581anything", ",", "\u2581more", "\u2581input", "\u2581data", "\u2581is", "\u2581required", ";", "\u2581such", "\u2581as", ":", "\u2581\"", "\u2581From", "\u2581where", "\u2581do", "\u2581you", "\u2581hit", "\u2581the", "\u2581ball", "\u2581and", "\u2581at", "\u2581what", "\u2581angle", "?", "\u2581Do", "\u2581you", "\u2581want", "\u2581to", "\u2581take", "\u2581into", "\u2581account", "\u2581effects", "\u2581due", "\u2581to", "\u2581the", "\u2581spin", "\u2581of", "\u2581the", "\u2581ball", "?", "\u2581Should", "\u2581friction", "\u2581be", "\u2581included", "?", "\u2581\"", "\u2581", "Generally", "\u2581(", "\u2581", "if", "\u2581you", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581put", "\u2581any", "\u2581restrictions", "\u2581on", "\u2581how", "\u2581you", "\u2581can", "\u2581hit", "\u2581it", ")", "\u2581there", "\u2581is", "\u2581no", "\u2581reason", "\u2581that", "\u2581you", "\u2581could", "\u2581not", "\u2581make", "\u2581the", "\u2581ball", "\u2581return", "\u2581(", "\u2581", "unless", "\u2581you", "'", "\u2581", "d", "\u2581have", "\u2581to", "\u2581hit", "\u2581it", "\u2581so", "\u2581hard", "\u2581that", "\u2581the", "\u2581ball", "\u2581breaks", "\u2581(", "\u2581which", "\u2581I", "\u2581doubt", "\u2581would", "\u2581be", "\u2581the", "\u2581case", ")", ".", "</s>"], "target_sentence": ["\u2581In", "\u2581order", "\u2581to", "\u2581calculate", "\u2581anything", ",", "\u2581more", "\u2581input", "\u2581data", "\u2581is", "\u2581required", ";", "\u2581such", "\u2581as", ":", "\u2581\"", "\u2581From", "\u2581where", "\u2581do", "\u2581you", "\u2581hit", "\u2581the", "\u2581ball", "\u2581and", "\u2581at", "\u2581what", "\u2581angle", "?", "\u2581Do", "\u2581you", "\u2581want", "\u2581to", "\u2581take", "\u2581into", "\u2581account", "\u2581effects", "\u2581due", "\u2581to", "\u2581the", "\u2581spin", "\u2581of", "\u2581the", "\u2581ball", "?", "\u2581Should", "\u2581friction", "\u2581be", "\u2581included", "?", "\u2581\"", "\u2581", "Generally", "\u2581(", "\u2581", "if", "\u2581you", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581put", "\u2581any", "\u2581restrictions", "\u2581on", "\u2581how", "\u2581you", "\u2581can", "\u2581hit", "\u2581it", ")", "\u2581there", "\u2581is", "\u2581no", "\u2581reason", "\u2581that", "\u2581you", "\u2581could", "\u2581not", "\u2581make", "\u2581the", "\u2581ball", "\u2581return", "\u2581(", "\u2581", "unless", "\u2581you", "'", "\u2581", "d", "\u2581have", "\u2581to", "\u2581hit", "\u2581it", "\u2581so", "\u2581hard", "\u2581that", "\u2581the", "\u2581ball", "\u2581breaks", "\u2581(", "\u2581which", "\u2581I", "\u2581doubt", "\u2581would", "\u2581be", "\u2581the", "\u2581case", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 50, 51, 52, 52, 53, 54, 55, 55, 56, 57, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 81, 82, 83, 84, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_606", "sentence": ["\u2581Why", "\u2581did", "\u2581Clinton", "\u2581wear", "\u2581in", "\u2581all", "\u2581red", "\u2581for", "\u2581an", "\u2581Award", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581did", "\u2581Clinton", "\u2581wear", "\u2581in", "\u2581all", "\u2581red", "\u2581for", "\u2581an", "\u2581Award", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581did", "<m>", "\u2581Clinton", "</m>", "\u2581wear", "\u2581in", "\u2581all", "\u2581red", "\u2581for", "\u2581an", "<m>", "\u2581Award", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_607", "sentence": ["\u2581Would", "\u2581the", "\u2581down", "vo", "ter", "\u2581care", "\u2581to", "\u2581comment", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Would", "\u2581the", "\u2581down", "vo", "ter", "\u2581care", "\u2581to", "\u2581comment", "?", "</s>"], "target_sentence": ["\u2581Would", "\u2581the", "\u2581down", "vo", "ter", "\u2581care", "\u2581to", "\u2581comment", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_608", "sentence": ["\u2581I", "s", "\u2581Trump", "\u2581tweet", "ing", "\u2581himself", "\u2581on", "\u2581real", "Don", "al", "d", "Tru", "mp", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "s", "\u2581Trump", "\u2581tweet", "ing", "\u2581himself", "\u2581on", "\u2581real", "Don", "al", "d", "Tru", "mp", "?", "</s>"], "target_sentence": ["\u2581I", "s", "<m>", "\u2581Trump", "</m>", "\u2581tweet", "ing", "\u2581himself", "\u2581on", "<m>", "\u2581real", "Don", "al", "d", "Tru", "mp", "</m>", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, 0, -1, 0, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_609", "sentence": ["\u2581@", "\u2581Don", "at", "ello", "S", "wan", "s", "in", "o", "\u2581That", "'", "\u2581", "s", "\u2581good", "\u2581information", ".", "\u2581You", "\u2581should", "\u2581add", "\u2581it", "\u2581as", "\u2581an", "\u2581answer", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Don", "at", "ello", "S", "wan", "s", "in", "o", "\u2581That", "'", "\u2581", "s", "\u2581good", "\u2581information", ".", "\u2581You", "\u2581should", "\u2581add", "\u2581it", "\u2581as", "\u2581an", "\u2581answer", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Don", "at", "ello", "S", "wan", "s", "in", "o", "</m>", "\u2581That", "'", "\u2581", "s", "\u2581good", "\u2581information", ".", "\u2581You", "\u2581should", "\u2581add", "\u2581it", "\u2581as", "\u2581an", "\u2581answer", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_610", "sentence": ["\u2581Tang", "o", "\u2581", "-", "\u2581In", "\u2581the", "\u2581section", "\u2581about", "\u2581the", "\u2581fictional", "\u2581enterprise", "\u2581and", "\u2581the", "\u2581fictional", "\u2581working", "s", "\u2581of", "\u2581the", "\u2581Star", "\u2581Trek", "\u2581universe", "\u2581there", "\u2581is", "\u2581", "a", "\u2581section", "\u2581of", "\u2581bi", "ographie", "s", "\u2581of", "\u2581the", "\u2581Star", "\u2581Trek", "\u2581characters", ",", "\u2581including", "\u2581Kirk", ".", "\u2581My", "\u2581copy", "\u2581of", "\u2581the", "\u2581Making", "\u2581of", "\u2581Star", "\u2581Trek", "\u25811968", "\u2581edition", "\u2581is", "\u2581packed", "\u2581away", "\u2581and", "\u2581un", "re", "ach", "able", "\u2581as", "\u2581is", "\u2581any", "\u2581copy", "\u2581of", "\u2581the", "\u2581writers", "\u2581guide", "\u2581I", "\u2581may", "\u2581own", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Tang", "o", "\u2581", "-", "\u2581In", "\u2581the", "\u2581section", "\u2581about", "\u2581the", "\u2581fictional", "\u2581enterprise", "\u2581and", "\u2581the", "\u2581fictional", "\u2581working", "s", "\u2581of", "\u2581the", "\u2581Star", "\u2581Trek", "\u2581universe", "\u2581there", "\u2581is", "\u2581", "a", "\u2581section", "\u2581of", "\u2581bi", "ographie", "s", "\u2581of", "\u2581the", "\u2581Star", "\u2581Trek", "\u2581characters", ",", "\u2581including", "\u2581Kirk", ".", "\u2581My", "\u2581copy", "\u2581of", "\u2581the", "\u2581Making", "\u2581of", "\u2581Star", "\u2581Trek", "\u25811968", "\u2581edition", "\u2581is", "\u2581packed", "\u2581away", "\u2581and", "\u2581un", "re", "ach", "able", "\u2581as", "\u2581is", "\u2581any", "\u2581copy", "\u2581of", "\u2581the", "\u2581writers", "\u2581guide", "\u2581I", "\u2581may", "\u2581own", ".", "</s>"], "target_sentence": ["\u2581Tang", "o", "\u2581", "-", "\u2581In", "\u2581the", "\u2581section", "\u2581about", "\u2581the", "\u2581fictional", "\u2581enterprise", "\u2581and", "\u2581the", "\u2581fictional", "\u2581working", "s", "\u2581of", "\u2581the", "<m>", "\u2581Star", "\u2581Trek", "</m>", "\u2581universe", "\u2581there", "\u2581is", "\u2581", "a", "\u2581section", "\u2581of", "\u2581bi", "ographie", "s", "\u2581of", "\u2581the", "<m>", "\u2581Star", "\u2581Trek", "</m>", "\u2581characters", ",", "\u2581including", "<m>", "\u2581Kirk", "</m>", ".", "\u2581My", "\u2581copy", "\u2581of", "\u2581the", "<m>", "\u2581Making", "\u2581of", "<m>", "\u2581Star", "\u2581Trek", "\u25811968", "</m>", "\u2581edition", "</m>", "\u2581is", "\u2581packed", "\u2581away", "\u2581and", "\u2581un", "re", "ach", "able", "\u2581as", "\u2581is", "\u2581any", "\u2581copy", "\u2581of", "\u2581the", "\u2581writers", "\u2581guide", "\u2581I", "\u2581may", "\u2581own", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 47, 47, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, 3, -1, -1, 4, -1, -1, -1, 3, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_611", "sentence": ["\u2581What", "\u2581encryption", "\u2581type", "\u2581does", "\u2581Windows", "\u2581Hello", "\u2581use", "\u2581for", "\u2581fingerprint", "\u2581information", "\u2581on", "\u2581Windows", "\u258110", "\u2581latest", "\u2581build", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581encryption", "\u2581type", "\u2581does", "\u2581Windows", "\u2581Hello", "\u2581use", "\u2581for", "\u2581fingerprint", "\u2581information", "\u2581on", "\u2581Windows", "\u258110", "\u2581latest", "\u2581build", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581encryption", "\u2581type", "\u2581does", "<m>", "\u2581Windows", "\u2581Hello", "</m>", "\u2581use", "\u2581for", "\u2581fingerprint", "\u2581information", "\u2581on", "<m>", "\u2581Windows", "\u258110", "</m>", "\u2581latest", "\u2581build", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_612", "sentence": ["\u2581", "Despite", "\u2581never", "\u2581having", "\u2581seen", "\u2581the", "\u2581movie", ",", "\u2581im", "\u2581guess", "ing", "\u2581its", "\u2581because", "\u2581they", "\u2581were", "\u2581the", "\u2581four", "\u2581main", "\u2581characters", "\u2581and", "\u2581", "deserved", "\u2581to", "\u2581be", "\u2581apart", "\u2581from", "\u2581the", "\u2581secondary", "\u2581characters", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Despite", "\u2581never", "\u2581having", "\u2581seen", "\u2581the", "\u2581movie", ",", "\u2581im", "\u2581guess", "ing", "\u2581its", "\u2581because", "\u2581they", "\u2581were", "\u2581the", "\u2581four", "\u2581main", "\u2581characters", "\u2581and", "\u2581", "deserved", "\u2581to", "\u2581be", "\u2581apart", "\u2581from", "\u2581the", "\u2581secondary", "\u2581characters", "</s>"], "target_sentence": ["\u2581", "Despite", "\u2581never", "\u2581having", "\u2581seen", "\u2581the", "\u2581movie", ",", "\u2581im", "\u2581guess", "ing", "\u2581its", "\u2581because", "\u2581they", "\u2581were", "\u2581the", "\u2581four", "\u2581main", "\u2581characters", "\u2581and", "\u2581", "deserved", "\u2581to", "\u2581be", "\u2581apart", "\u2581from", "\u2581the", "\u2581secondary", "\u2581characters", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_613", "sentence": ["\u2581Are", "\u2581the", "\u2581Mart", "ians", "\u2581saying", "\u2581\"", "\u2581U", "t", "\u2581\"", "\u2581or", "\u2581\"", "\u2581A", "ck", "\u2581\"", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Are", "\u2581the", "\u2581Mart", "ians", "\u2581saying", "\u2581\"", "\u2581U", "t", "\u2581\"", "\u2581or", "\u2581\"", "\u2581A", "ck", "\u2581\"", "?", "</s>"], "target_sentence": ["\u2581Are", "\u2581the", "\u2581Mart", "ians", "\u2581saying", "\u2581\"", "\u2581U", "t", "\u2581\"", "\u2581or", "\u2581\"", "\u2581A", "ck", "\u2581\"", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_614", "sentence": ["\u2581I", "\u2581actually", "\u2581think", "\u2581that", "\u2581\"", "\u2581Did", "\u2581the", "\u2581Democrats", "\u2581suffer", "\u2581consequences", "\u2581for", "\u2581in", "vo", "king", "\u2581it", "?", "\u2581\"", "\u2581is", "\u2581", "a", "\u2581better", "\u2581question", "\u2581than", "\u2581the", "\u2581one", "\u2581asked", ".", "\u2581I", "\u2581think", "\u2581", "if", "\u2581you", "\u2581ask", "\u2581that", ".", "\u2581The", "n", "\u2581after", "\u2581it", "\u2581gets", "\u2581answered", "\u2581you", "co", "ul", "d", "\u2581ask", "\u2581each", "\u2581one", "\u2581of", "\u2581your", "\u2581other", "\u2581questions", "\u2581", "assuming", "\u2581you", "\u2581still", "\u2581dont", "\u2581understand", "\u2581how", "\u2581it", "\u2581works", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581actually", "\u2581think", "\u2581that", "\u2581\"", "\u2581Did", "\u2581the", "\u2581Democrats", "\u2581suffer", "\u2581consequences", "\u2581for", "\u2581in", "vo", "king", "\u2581it", "?", "\u2581\"", "\u2581is", "\u2581", "a", "\u2581better", "\u2581question", "\u2581than", "\u2581the", "\u2581one", "\u2581asked", ".", "\u2581I", "\u2581think", "\u2581", "if", "\u2581you", "\u2581ask", "\u2581that", ".", "\u2581The", "n", "\u2581after", "\u2581it", "\u2581gets", "\u2581answered", "\u2581you", "co", "ul", "d", "\u2581ask", "\u2581each", "\u2581one", "\u2581of", "\u2581your", "\u2581other", "\u2581questions", "\u2581", "assuming", "\u2581you", "\u2581still", "\u2581dont", "\u2581understand", "\u2581how", "\u2581it", "\u2581works", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581actually", "\u2581think", "\u2581that", "\u2581\"", "\u2581Did", "\u2581the", "<m>", "\u2581Democrats", "</m>", "\u2581suffer", "\u2581consequences", "\u2581for", "\u2581in", "vo", "king", "\u2581it", "?", "\u2581\"", "\u2581is", "\u2581", "a", "\u2581better", "\u2581question", "\u2581than", "\u2581the", "\u2581one", "\u2581asked", ".", "\u2581I", "\u2581think", "\u2581", "if", "\u2581you", "\u2581ask", "\u2581that", ".", "\u2581The", "n", "\u2581after", "\u2581it", "\u2581gets", "\u2581answered", "\u2581you", "co", "ul", "d", "\u2581ask", "\u2581each", "\u2581one", "\u2581of", "\u2581your", "\u2581other", "\u2581questions", "\u2581", "assuming", "\u2581you", "\u2581still", "\u2581dont", "\u2581understand", "\u2581how", "\u2581it", "\u2581works", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 31, 32, 33, 34, 35, 36, 36, 36, 36, 37, 38, 39, 40, 41, 42, 43, 44, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_615", "sentence": ["\u2581In", "\u2581the", "\u2581article", "\u2581linked", "\u2581by", "\u2581Le", "l", "o", "uch", "\u2581in", "\u2581his", "\u2581answer", "\u2581below", ",", "\u2581there", "\u2581is", "\u2581", "a", "\u2581key", "\u2581point", "\u2581\"", "\u2581The", "\u2581result", "\u2581applies", "\u2581to", "\u2581isolated", "\u2581mechanical", "\u2581systems", "\u2581subject", "\u2581to", "\u2581some", "\u2581constraints", ",", "\u2581", "e", ".", "\u2581", "g", ".", ",", "\u2581all", "\u2581particles", "\u2581must", "\u2581be", "\u2581bound", "\u2581to", "\u2581", "a", "\u2581fi", "nite", "\u2581volume", "\u2581\"", ".", "\u2581We", "\u2581do", "\u2581not", "\u2581know", "\u2581", "if", "\u2581the", "\u2581Universe", "\u2581", "complie", "s", "\u2581to", "\u2581such", "\u2581an", "\u2581assumption", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581In", "\u2581the", "\u2581article", "\u2581linked", "\u2581by", "\u2581Le", "l", "o", "uch", "\u2581in", "\u2581his", "\u2581answer", "\u2581below", ",", "\u2581there", "\u2581is", "\u2581", "a", "\u2581key", "\u2581point", "\u2581\"", "\u2581The", "\u2581result", "\u2581applies", "\u2581to", "\u2581isolated", "\u2581mechanical", "\u2581systems", "\u2581subject", "\u2581to", "\u2581some", "\u2581constraints", ",", "\u2581", "e", ".", "\u2581", "g", ".", ",", "\u2581all", "\u2581particles", "\u2581must", "\u2581be", "\u2581bound", "\u2581to", "\u2581", "a", "\u2581fi", "nite", "\u2581volume", "\u2581\"", ".", "\u2581We", "\u2581do", "\u2581not", "\u2581know", "\u2581", "if", "\u2581the", "\u2581Universe", "\u2581", "complie", "s", "\u2581to", "\u2581such", "\u2581an", "\u2581assumption", ".", "</s>"], "target_sentence": ["\u2581In", "\u2581the", "\u2581article", "\u2581linked", "\u2581by", "<m>", "\u2581Le", "l", "o", "uch", "</m>", "\u2581in", "\u2581his", "\u2581answer", "\u2581below", ",", "\u2581there", "\u2581is", "\u2581", "a", "\u2581key", "\u2581point", "\u2581\"", "\u2581The", "\u2581result", "\u2581applies", "\u2581to", "\u2581isolated", "\u2581mechanical", "\u2581systems", "\u2581subject", "\u2581to", "\u2581some", "\u2581constraints", ",", "\u2581", "e", ".", "\u2581", "g", ".", ",", "\u2581all", "\u2581particles", "\u2581must", "\u2581be", "\u2581bound", "\u2581to", "\u2581", "a", "\u2581fi", "nite", "\u2581volume", "\u2581\"", ".", "\u2581We", "\u2581do", "\u2581not", "\u2581know", "\u2581", "if", "\u2581the", "<m>", "\u2581Universe", "</m>", "\u2581", "complie", "s", "\u2581to", "\u2581such", "\u2581an", "\u2581assumption", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 29, 30, 31, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 40, 41, 41, 42, 43, 44, 45, 46, 47, 48, 49, 49, 50, 51, 52, 52, 52, 53, 54, 55, 56, 57, 58], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_616", "sentence": ["\u2581How", "\u2581much", "\u2581official", "\u2581communication", "\u2581was", "\u2581there", "\u2581between", "\u2581the", "\u2581Senate", "\u2581and", "\u2581the", "\u2581Jedi", "\u2581Council", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581much", "\u2581official", "\u2581communication", "\u2581was", "\u2581there", "\u2581between", "\u2581the", "\u2581Senate", "\u2581and", "\u2581the", "\u2581Jedi", "\u2581Council", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581much", "\u2581official", "\u2581communication", "\u2581was", "\u2581there", "\u2581between", "\u2581the", "<m>", "<m>", "\u2581Senate", "</m>", "</m>", "\u2581and", "\u2581the", "<m>", "<m>", "\u2581Jedi", "\u2581Council", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, -1, 3, 2, -1, -1, 3, 2, -1, -1]}, {"doc_id": "emerging.test_617", "sentence": ["\u2581What", "\u2581old", "\u2581", "teen", "\u2581movie", "\u2581is", "\u2581this", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581old", "\u2581", "teen", "\u2581movie", "\u2581is", "\u2581this", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581old", "\u2581", "teen", "\u2581movie", "\u2581is", "\u2581this", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_618", "sentence": ["\u2581Black", "\u2581Swan", "\u2581is", "\u2581nowhere", "\u2581near", "\u2581being", "\u2581", "a", "\u2581horror", "\u2581movie", ".", "\u2581Some", "\u2581psycho", "\u2581elements", "\u2581", "-", "\u2581yes", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Black", "\u2581Swan", "\u2581is", "\u2581nowhere", "\u2581near", "\u2581being", "\u2581", "a", "\u2581horror", "\u2581movie", ".", "\u2581Some", "\u2581psycho", "\u2581elements", "\u2581", "-", "\u2581yes", ".", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Black", "\u2581Swan", "</m>", "</m>", "\u2581is", "\u2581nowhere", "\u2581near", "\u2581being", "\u2581", "a", "\u2581horror", "\u2581movie", ".", "\u2581Some", "\u2581psycho", "\u2581elements", "\u2581", "-", "\u2581yes", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_619", "sentence": ["\u2581Are", "\u2581we", "\u2581currently", "\u2581seeing", "\u2581another", "\u2581ideological", "\u2581real", "ign", "ment", "\u2581happening", "\u2581in", "\u2581today", "'", "\u2581", "s", "\u2581unstable", "\u2581political", "\u2581climate", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Are", "\u2581we", "\u2581currently", "\u2581seeing", "\u2581another", "\u2581ideological", "\u2581real", "ign", "ment", "\u2581happening", "\u2581in", "\u2581today", "'", "\u2581", "s", "\u2581unstable", "\u2581political", "\u2581climate", "?", "</s>"], "target_sentence": ["\u2581Are", "\u2581we", "\u2581currently", "\u2581seeing", "\u2581another", "\u2581ideological", "\u2581real", "ign", "ment", "\u2581happening", "\u2581in", "\u2581today", "'", "\u2581", "s", "\u2581unstable", "\u2581political", "\u2581climate", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_620", "sentence": ["\u2581Are", "\u2581the", "\u2581Legal", "ity", "\u2581of", "\u2581Vo", "tes", "\u2581Cast", "\u2581by", "\u2581Non", "-", "\u2581Citizens", "\u2581Check", "e", "d", "\u2581After", "\u2581They", "\u2581Have", "\u2581Be", "en", "\u2581Cast", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Are", "\u2581the", "\u2581Legal", "ity", "\u2581of", "\u2581Vo", "tes", "\u2581Cast", "\u2581by", "\u2581Non", "-", "\u2581Citizens", "\u2581Check", "e", "d", "\u2581After", "\u2581They", "\u2581Have", "\u2581Be", "en", "\u2581Cast", "?", "</s>"], "target_sentence": ["\u2581Are", "\u2581the", "\u2581Legal", "ity", "\u2581of", "\u2581Vo", "tes", "\u2581Cast", "\u2581by", "\u2581Non", "-", "\u2581Citizens", "\u2581Check", "e", "d", "\u2581After", "\u2581They", "\u2581Have", "\u2581Be", "en", "\u2581Cast", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 9, 9, 10, 11, 12, 13, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_621", "sentence": ["\u2581I", "\u2581Period", "ically", "\u2581", "s", "have", "\u2581my", "\u2581head", ".", "\u2581I", "\u2581can", "\u2581confirm", "\u2581it", "\u2581does", "\u2581hold", "\u2581fuzzy", "\u2581", "hat", "s", "\u2581well", ".", "\u2581Actually", ",", "\u2581keeping", "\u2581your", "\u2581head", "\u2581completely", "\u2581smooth", "\u2581is", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581work", ",", "\u2581you", "\u2581have", "\u2581to", "\u2581", "s", "have", "\u2581with", "\u2581", "a", "\u2581real", "\u2581razor", "\u2581(", "\u2581not", "\u2581an", "\u2581electric", "\u2581one", ")", "\u2581daily", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581Period", "ically", "\u2581", "s", "have", "\u2581my", "\u2581head", ".", "\u2581I", "\u2581can", "\u2581confirm", "\u2581it", "\u2581does", "\u2581hold", "\u2581fuzzy", "\u2581", "hat", "s", "\u2581well", ".", "\u2581Actually", ",", "\u2581keeping", "\u2581your", "\u2581head", "\u2581completely", "\u2581smooth", "\u2581is", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581work", ",", "\u2581you", "\u2581have", "\u2581to", "\u2581", "s", "have", "\u2581with", "\u2581", "a", "\u2581real", "\u2581razor", "\u2581(", "\u2581not", "\u2581an", "\u2581electric", "\u2581one", ")", "\u2581daily", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581Period", "ically", "\u2581", "s", "have", "\u2581my", "\u2581head", ".", "\u2581I", "\u2581can", "\u2581confirm", "\u2581it", "\u2581does", "\u2581hold", "\u2581fuzzy", "\u2581", "hat", "s", "\u2581well", ".", "\u2581Actually", ",", "\u2581keeping", "\u2581your", "\u2581head", "\u2581completely", "\u2581smooth", "\u2581is", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581work", ",", "\u2581you", "\u2581have", "\u2581to", "\u2581", "s", "have", "\u2581with", "\u2581", "a", "\u2581real", "<m>", "\u2581razor", "</m>", "\u2581(", "\u2581not", "\u2581an", "\u2581electric", "\u2581one", ")", "\u2581daily", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 32, 33, 34, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_622", "sentence": ["\u2581Good", "\u2581idea", ",", "\u2581especially", "\u2581for", "\u2581someone", "\u2581who", "\u2581needs", "\u2581this", "\u2581routine", "ly", "\u2581for", "\u2581professional", "\u2581reasons", "\u2581it", "\u2581might", "\u2581be", "\u2581worth", "\u2581buying", "\u2581cheap", "\u2581hardware", ".", "\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581add", "\u2581two", "\u2581things", ":", "\u25811", ")", "\u2581\"", "\u2581disable", "\u2581wifi", "\u2581physically", "\u2581\"", "\u2581is", "\u2581often", "\u2581", "n", "igh", "\u2581impossible", ".", "\u2581I", "'", "\u2581", "d", "\u2581suggest", "\u2581to", "\u2581use", "\u2581", "a", "\u2581cable", ",", "\u2581so", "\u2581you", "\u2581never", "\u2581need", "\u2581to", "\u2581connect", "\u2581to", "\u2581", "a", "\u2581wifi", "\u2581network", "\u2581(", "\u2581then", "\u2581the", "\u2581device", "\u2581never", "\u2581contains", "\u2581its", "\u2581password", ")", ",", "\u2581or", "\u2581perhaps", "\u2581even", "\u2581remove", "\u2581the", "\u2581wifi", "\u2581chip", "\u2581(", "\u2581often", "\u2581fairly", "\u2581easy", ")", ".", "\u2581And", "\u25812", ")", "\u2581I", "'", "\u2581", "d", "\u2581over", "write", "\u2581the", "\u2581stick", "\u2581or", "\u2581", "s", "d", "\u2581card", "\u2581after", "\u2581use", ",", "\u2581not", "\u2581terminate", "\u2581processes", "\u2581or", "\u2581reboot", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Good", "\u2581idea", ",", "\u2581especially", "\u2581for", "\u2581someone", "\u2581who", "\u2581needs", "\u2581this", "\u2581routine", "ly", "\u2581for", "\u2581professional", "\u2581reasons", "\u2581it", "\u2581might", "\u2581be", "\u2581worth", "\u2581buying", "\u2581cheap", "\u2581hardware", ".", "\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581add", "\u2581two", "\u2581things", ":", "\u25811", ")", "\u2581\"", "\u2581disable", "\u2581wifi", "\u2581physically", "\u2581\"", "\u2581is", "\u2581often", "\u2581", "n", "igh", "\u2581impossible", ".", "\u2581I", "'", "\u2581", "d", "\u2581suggest", "\u2581to", "\u2581use", "\u2581", "a", "\u2581cable", ",", "\u2581so", "\u2581you", "\u2581never", "\u2581need", "\u2581to", "\u2581connect", "\u2581to", "\u2581", "a", "\u2581wifi", "\u2581network", "\u2581(", "\u2581then", "\u2581the", "\u2581device", "\u2581never", "\u2581contains", "\u2581its", "\u2581password", ")", ",", "\u2581or", "\u2581perhaps", "\u2581even", "\u2581remove", "\u2581the", "\u2581wifi", "\u2581chip", "\u2581(", "\u2581often", "\u2581fairly", "\u2581easy", ")", ".", "\u2581And", "\u25812", ")", "\u2581I", "'", "\u2581", "d", "\u2581over", "write", "\u2581the", "\u2581stick", "\u2581or", "\u2581", "s", "d", "\u2581card", "\u2581after", "\u2581use", ",", "\u2581not", "\u2581terminate", "\u2581processes", "\u2581or", "\u2581reboot", ".", "</s>"], "target_sentence": ["\u2581Good", "\u2581idea", ",", "\u2581especially", "\u2581for", "\u2581someone", "\u2581who", "\u2581needs", "\u2581this", "\u2581routine", "ly", "\u2581for", "\u2581professional", "\u2581reasons", "\u2581it", "\u2581might", "\u2581be", "\u2581worth", "\u2581buying", "\u2581cheap", "\u2581hardware", ".", "\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581add", "\u2581two", "\u2581things", ":", "\u25811", ")", "\u2581\"", "\u2581disable", "\u2581wifi", "\u2581physically", "\u2581\"", "\u2581is", "\u2581often", "\u2581", "n", "igh", "\u2581impossible", ".", "\u2581I", "'", "\u2581", "d", "\u2581suggest", "\u2581to", "\u2581use", "\u2581", "a", "\u2581cable", ",", "\u2581so", "\u2581you", "\u2581never", "\u2581need", "\u2581to", "\u2581connect", "\u2581to", "\u2581", "a", "\u2581wifi", "\u2581network", "\u2581(", "\u2581then", "\u2581the", "\u2581device", "\u2581never", "\u2581contains", "\u2581its", "\u2581password", ")", ",", "\u2581or", "\u2581perhaps", "\u2581even", "\u2581remove", "\u2581the", "\u2581wifi", "\u2581chip", "\u2581(", "\u2581often", "\u2581fairly", "\u2581easy", ")", ".", "\u2581And", "\u25812", ")", "\u2581I", "'", "\u2581", "d", "\u2581over", "write", "\u2581the", "\u2581stick", "\u2581or", "\u2581", "s", "d", "\u2581card", "\u2581after", "\u2581use", ",", "\u2581not", "\u2581terminate", "\u2581processes", "\u2581or", "\u2581reboot", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 39, 40, 41, 42, 43, 44, 44, 45, 46, 47, 48, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 89, 90, 90, 91, 92, 93, 94, 94, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_623", "sentence": ["\u2581Does", "\u2581using", "\u2581O", "au", "th", "\u2581behind", "\u2581firewall", "\u2581", "/", "\u2581closed", "\u2581ports", "\u2581requires", "\u2581proxy", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Does", "\u2581using", "\u2581O", "au", "th", "\u2581behind", "\u2581firewall", "\u2581", "/", "\u2581closed", "\u2581ports", "\u2581requires", "\u2581proxy", "</s>"], "target_sentence": ["\u2581Does", "\u2581using", "<m>", "\u2581O", "au", "th", "</m>", "\u2581behind", "\u2581firewall", "\u2581", "/", "\u2581closed", "\u2581ports", "\u2581requires", "\u2581proxy", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_624", "sentence": ["\u2581How", "\u2581can", "\u2581", "a", "\u2581country", "\u2581(", "\u2581UN", "\u2581or", "\u2581non", "-", "\u2581UN", "\u2581member", ")", "\u2581become", "\u2581", "a", "\u2581member", "\u2581of", "\u2581World", "\u2581Bank", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581can", "\u2581", "a", "\u2581country", "\u2581(", "\u2581UN", "\u2581or", "\u2581non", "-", "\u2581UN", "\u2581member", ")", "\u2581become", "\u2581", "a", "\u2581member", "\u2581of", "\u2581World", "\u2581Bank", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581can", "\u2581", "a", "<m>", "\u2581country", "</m>", "\u2581(", "<m>", "\u2581UN", "</m>", "\u2581or", "\u2581non", "-", "\u2581UN", "\u2581member", ")", "\u2581become", "\u2581", "a", "\u2581member", "\u2581of", "<m>", "\u2581World", "\u2581Bank", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, 0, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 2, -1, -1]}, {"doc_id": "emerging.test_625", "sentence": ["\u2581Ja", "vier", ".", ".", "\u2581So", "\u2581the", "\u2581net", "\u2581force", "\u2581remains", "\u2581but", "\u2581now", "\u2581involves", "\u2581my", "\u2581hands", "\u2581as", "\u2581well", ".", "\u2581That", "\u2581makes", "\u2581sense", "!", "\u2581", "o", "o", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ja", "vier", ".", ".", "\u2581So", "\u2581the", "\u2581net", "\u2581force", "\u2581remains", "\u2581but", "\u2581now", "\u2581involves", "\u2581my", "\u2581hands", "\u2581as", "\u2581well", ".", "\u2581That", "\u2581makes", "\u2581sense", "!", "\u2581", "o", "o", "</s>"], "target_sentence": ["\u2581Ja", "vier", ".", ".", "\u2581So", "\u2581the", "\u2581net", "\u2581force", "\u2581remains", "\u2581but", "\u2581now", "\u2581involves", "\u2581my", "\u2581hands", "\u2581as", "\u2581well", ".", "\u2581That", "\u2581makes", "\u2581sense", "!", "\u2581", "o", "o", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_626", "sentence": ["\u2581What", "\u2581building", "\u2581in", "\u2581the", "\u2581final", "\u2581scene", "\u2581of", "\u2581", "Assassin", "s", "\u2581Cre", "e", "d", "?", "\u2581(", "\u2581spoil", "er", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581building", "\u2581in", "\u2581the", "\u2581final", "\u2581scene", "\u2581of", "\u2581", "Assassin", "s", "\u2581Cre", "e", "d", "?", "\u2581(", "\u2581spoil", "er", ")", "</s>"], "target_sentence": ["\u2581What", "\u2581building", "\u2581in", "\u2581the", "\u2581final", "\u2581scene", "\u2581of", "<m>", "<m>", "\u2581", "Assassin", "s", "\u2581Cre", "e", "d", "</m>", "</m>", "?", "\u2581(", "\u2581spoil", "er", ")", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 8, 8, 9, 10, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_627", "sentence": ["\u2581", "Probably", "\u2581its", "\u2581the", "\u2581second", "\u2581time", "\u2581coming", "\u2581back", "\u2581from", "\u2581the", "\u2581dead", ",", "\u2581not", "\u2581just", "\u2581being", "\u2581in", "\u2581the", "\u2581world", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Probably", "\u2581its", "\u2581the", "\u2581second", "\u2581time", "\u2581coming", "\u2581back", "\u2581from", "\u2581the", "\u2581dead", ",", "\u2581not", "\u2581just", "\u2581being", "\u2581in", "\u2581the", "\u2581world", ".", "</s>"], "target_sentence": ["\u2581", "Probably", "\u2581its", "\u2581the", "\u2581second", "\u2581time", "\u2581coming", "\u2581back", "\u2581from", "\u2581the", "\u2581dead", ",", "\u2581not", "\u2581just", "\u2581being", "\u2581in", "\u2581the", "\u2581world", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_628", "sentence": ["\u2581@", "\u2581Cand", "ied", "O", "range", "\u2581I", "\u2581see", "\u2581", "a", "\u2581difference", "\u2581here", ".", "\u2581While", "\u2581", "explo", "d", "ing", "\u2581bomb", "s", "\u2581or", "\u2581freezing", "\u2581molecules", "\u2581always", "\u2581follow", "\u2581certain", "\u2581chemical", "\u2581and", "\u2581physical", "\u2581laws", ",", "\u2581human", "\u2581history", "\u2581has", "\u2581witnessed", "\u2581events", "\u2581where", "\u2581perceived", "\u2581equilibrium", "\u2581are", "\u2581broken", "\u2581time", "\u2581after", "\u2581time", ".", "\u2581Just", "\u2581look", "\u2581at", "\u2581our", "\u2581population", "\u2581and", "\u2581think", "\u2581about", "\u2581what", "\u2581the", "\u2581equilibrium", "\u2581would", "\u2581have", "\u2581been", "\u2581", "if", "\u2581we", "\u2581were", "\u2581still", "\u2581living", "\u2581in", "\u2581wood", "\u2581and", "\u2581stone", "\u2581age", ".", "\u2581Or", "\u2581better", "\u2581yet", ",", "\u2581see", "\u2581how", "\u2581Mal", "th", "us", "i", "a", "nism", "\u2581checks", "\u2581out", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Cand", "ied", "O", "range", "\u2581I", "\u2581see", "\u2581", "a", "\u2581difference", "\u2581here", ".", "\u2581While", "\u2581", "explo", "d", "ing", "\u2581bomb", "s", "\u2581or", "\u2581freezing", "\u2581molecules", "\u2581always", "\u2581follow", "\u2581certain", "\u2581chemical", "\u2581and", "\u2581physical", "\u2581laws", ",", "\u2581human", "\u2581history", "\u2581has", "\u2581witnessed", "\u2581events", "\u2581where", "\u2581perceived", "\u2581equilibrium", "\u2581are", "\u2581broken", "\u2581time", "\u2581after", "\u2581time", ".", "\u2581Just", "\u2581look", "\u2581at", "\u2581our", "\u2581population", "\u2581and", "\u2581think", "\u2581about", "\u2581what", "\u2581the", "\u2581equilibrium", "\u2581would", "\u2581have", "\u2581been", "\u2581", "if", "\u2581we", "\u2581were", "\u2581still", "\u2581living", "\u2581in", "\u2581wood", "\u2581and", "\u2581stone", "\u2581age", ".", "\u2581Or", "\u2581better", "\u2581yet", ",", "\u2581see", "\u2581how", "\u2581Mal", "th", "us", "i", "a", "nism", "\u2581checks", "\u2581out", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Cand", "ied", "O", "range", "</m>", "\u2581I", "\u2581see", "\u2581", "a", "\u2581difference", "\u2581here", ".", "\u2581While", "\u2581", "explo", "d", "ing", "\u2581bomb", "s", "\u2581or", "\u2581freezing", "\u2581molecules", "\u2581always", "\u2581follow", "\u2581certain", "\u2581chemical", "\u2581and", "\u2581physical", "\u2581laws", ",", "\u2581human", "\u2581history", "\u2581has", "\u2581witnessed", "\u2581events", "\u2581where", "\u2581perceived", "\u2581equilibrium", "\u2581are", "\u2581broken", "\u2581time", "\u2581after", "\u2581time", ".", "\u2581Just", "\u2581look", "\u2581at", "\u2581our", "\u2581population", "\u2581and", "\u2581think", "\u2581about", "\u2581what", "\u2581the", "\u2581equilibrium", "\u2581would", "\u2581have", "\u2581been", "\u2581", "if", "\u2581we", "\u2581were", "\u2581still", "\u2581living", "\u2581in", "\u2581wood", "\u2581and", "\u2581stone", "\u2581age", ".", "\u2581Or", "\u2581better", "\u2581yet", ",", "\u2581see", "\u2581how", "\u2581Mal", "th", "us", "i", "a", "nism", "\u2581checks", "\u2581out", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 9, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 67, 67, 67, 67, 67, 68, 69, 70, 71], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_629", "sentence": ["\u2581Difference", "\u2581between", "\u2581\"", "\u2581C", "-", "\u2581violation", "\u2581without", "\u2581", "CP", "-", "viol", "ation", "\u2581\"", "\u2581and", "\u2581\"", "\u2581C", "-", "\u2581violation", "\u2581with", "\u2581", "CP", "\u2581", "-", "\u2581violation", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Difference", "\u2581between", "\u2581\"", "\u2581C", "-", "\u2581violation", "\u2581without", "\u2581", "CP", "-", "viol", "ation", "\u2581\"", "\u2581and", "\u2581\"", "\u2581C", "-", "\u2581violation", "\u2581with", "\u2581", "CP", "\u2581", "-", "\u2581violation", "\u2581\"", "</s>"], "target_sentence": ["\u2581Difference", "\u2581between", "\u2581\"", "\u2581C", "-", "\u2581violation", "\u2581without", "\u2581", "CP", "-", "viol", "ation", "\u2581\"", "\u2581and", "\u2581\"", "\u2581C", "-", "\u2581violation", "\u2581with", "\u2581", "CP", "\u2581", "-", "\u2581violation", "\u2581\"", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 6, 6, 6, 6, 7, 8, 9, 10, 10, 11, 12, 13, 13, 14, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_630", "sentence": ["\u2581Comments", "\u2581are", "\u2581not", "\u2581for", "\u2581extended", "\u2581discussion", ";", "\u2581this", "\u2581conversation", "\u2581has", "\u2581been", "\u2581[", "\u2581moved", "\u2581to", "\u2581chat", "]", "\u2581(", "\u2581http", "://", "chat", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "room", "s", "/5", "24", "66", "/", "d", "iscus", "sion", "-", "on", "-", "ques", "tion", "-", "by", "-", "ank", "it", "-", "why", "-", "is", "-", "christ", "i", "an", "-", "bal", "e", "-", "not", "-", "in", "-", "the", "-", "upcoming", "-", "mov", "i", "e", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Comments", "\u2581are", "\u2581not", "\u2581for", "\u2581extended", "\u2581discussion", ";", "\u2581this", "\u2581conversation", "\u2581has", "\u2581been", "\u2581[", "\u2581moved", "\u2581to", "\u2581chat", "]", "\u2581(", "\u2581http", "://", "chat", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "room", "s", "/5", "24", "66", "/", "d", "iscus", "sion", "-", "on", "-", "ques", "tion", "-", "by", "-", "ank", "it", "-", "why", "-", "is", "-", "christ", "i", "an", "-", "bal", "e", "-", "not", "-", "in", "-", "the", "-", "upcoming", "-", "mov", "i", "e", ")", ".", "</s>"], "target_sentence": ["\u2581Comments", "\u2581are", "\u2581not", "\u2581for", "\u2581extended", "\u2581discussion", ";", "\u2581this", "\u2581conversation", "\u2581has", "\u2581been", "\u2581[", "\u2581moved", "\u2581to", "\u2581chat", "]", "\u2581(", "\u2581http", "://", "chat", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "room", "s", "/5", "24", "66", "/", "d", "iscus", "sion", "-", "on", "-", "ques", "tion", "-", "by", "-", "ank", "it", "-", "why", "-", "is", "-", "christ", "i", "an", "-", "bal", "e", "-", "not", "-", "in", "-", "the", "-", "upcoming", "-", "mov", "i", "e", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_631", "sentence": ["\u2581short", "\u2581story", "\u2581about", "\u2581seed", "ing", "\u2581", "a", "\u2581planet", "\u2581with", "\u2581humans", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581short", "\u2581story", "\u2581about", "\u2581seed", "ing", "\u2581", "a", "\u2581planet", "\u2581with", "\u2581humans", "</s>"], "target_sentence": ["\u2581short", "\u2581story", "\u2581about", "\u2581seed", "ing", "\u2581", "a", "<m>", "\u2581planet", "</m>", "\u2581with", "\u2581humans", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_632", "sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581Qu", "a", "s", "i", "\u2581static", "\u2581and", "\u2581Dyna", "mic", "\u2581simulation", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581Qu", "a", "s", "i", "\u2581static", "\u2581and", "\u2581Dyna", "mic", "\u2581simulation", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "<m>", "\u2581Qu", "a", "s", "i", "\u2581static", "</m>", "\u2581and", "\u2581Dyna", "mic", "\u2581simulation", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 6, 7, 8, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_633", "sentence": ["\u2581How", "\u2581does", "\u2581one", "\u2581leave", "\u2581", "a", "\u2581pen", "sie", "ve", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581does", "\u2581one", "\u2581leave", "\u2581", "a", "\u2581pen", "sie", "ve", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581does", "\u2581one", "\u2581leave", "\u2581", "a", "\u2581pen", "sie", "ve", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_634", "sentence": ["\u2581Many", "\u2581actors", "\u2581or", "\u2581actress", "e", "s", "\u2581with", "\u2581", "a", "version", "\u2581to", "\u2581showing", "\u2581skin", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581approve", "\u2581of", "\u2581body", "\u2581double", "s", ".", "\u2581The", "\u2581general", "\u2581public", "\u2581will", "\u2581still", "\u2581think", "\u2581they", "\u2581did", "\u2581it", "\u2581themselves", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Many", "\u2581actors", "\u2581or", "\u2581actress", "e", "s", "\u2581with", "\u2581", "a", "version", "\u2581to", "\u2581showing", "\u2581skin", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581approve", "\u2581of", "\u2581body", "\u2581double", "s", ".", "\u2581The", "\u2581general", "\u2581public", "\u2581will", "\u2581still", "\u2581think", "\u2581they", "\u2581did", "\u2581it", "\u2581themselves", ".", "</s>"], "target_sentence": ["\u2581Many", "\u2581actors", "\u2581or", "\u2581actress", "e", "s", "\u2581with", "\u2581", "a", "version", "\u2581to", "\u2581showing", "\u2581skin", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581approve", "\u2581of", "\u2581body", "\u2581double", "s", ".", "\u2581The", "\u2581general", "\u2581public", "\u2581will", "\u2581still", "\u2581think", "\u2581they", "\u2581did", "\u2581it", "\u2581themselves", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_635", "sentence": ["\u2581@", "\u2581", "X", "i", "ong", "Ch", "i", "ami", "o", "v", "\u2581While", "\u2581I", "\u2581can", "\u2581not", "\u2581", "formally", "\u2581prove", "\u2581it", ",", "\u2581I", "\u2581find", "\u2581it", "\u2581very", "\u2581hard", "\u2581to", "\u2581believe", "\u2581that", "\u2581feeding", "\u2581", "SHA", "\u25811", "\u2581with", "\u2581unpredictable", "\u2581input", "\u2581would", "\u2581produce", "\u2581predictable", "\u2581output", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "X", "i", "ong", "Ch", "i", "ami", "o", "v", "\u2581While", "\u2581I", "\u2581can", "\u2581not", "\u2581", "formally", "\u2581prove", "\u2581it", ",", "\u2581I", "\u2581find", "\u2581it", "\u2581very", "\u2581hard", "\u2581to", "\u2581believe", "\u2581that", "\u2581feeding", "\u2581", "SHA", "\u25811", "\u2581with", "\u2581unpredictable", "\u2581input", "\u2581would", "\u2581produce", "\u2581predictable", "\u2581output", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "X", "i", "ong", "Ch", "i", "ami", "o", "v", "</m>", "\u2581While", "\u2581I", "\u2581can", "\u2581not", "\u2581", "formally", "\u2581prove", "\u2581it", ",", "\u2581I", "\u2581find", "\u2581it", "\u2581very", "\u2581hard", "\u2581to", "\u2581believe", "\u2581that", "\u2581feeding", "\u2581", "SHA", "\u25811", "\u2581with", "\u2581unpredictable", "\u2581input", "\u2581would", "\u2581produce", "\u2581predictable", "\u2581output", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_636", "sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581significance", "\u2581of", "\u2581the", "\u2581to", "r", "n", "\u2581off", "\u2581button", "\u2581scene", "\u2581in", "\u2581The", "\u2581Next", "\u2581Three", "\u2581Days", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581is", "\u2581the", "\u2581significance", "\u2581of", "\u2581the", "\u2581to", "r", "n", "\u2581off", "\u2581button", "\u2581scene", "\u2581in", "\u2581The", "\u2581Next", "\u2581Three", "\u2581Days", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581significance", "\u2581of", "\u2581the", "\u2581to", "r", "n", "\u2581off", "\u2581button", "\u2581scene", "\u2581in", "<m>", "\u2581The", "\u2581Next", "\u2581Three", "\u2581Days", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_637", "sentence": ["\u2581Hi", "gg", "s", "\u2581bo", "son", "\u2581and", "\u2581electro", "we", "ak", "\u2581gauge", "\u2581bo", "son", "\u2581transformation", "s", "\u2581under", "\u2581", "CP", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hi", "gg", "s", "\u2581bo", "son", "\u2581and", "\u2581electro", "we", "ak", "\u2581gauge", "\u2581bo", "son", "\u2581transformation", "s", "\u2581under", "\u2581", "CP", "</s>"], "target_sentence": ["<m>", "\u2581Hi", "gg", "s", "</m>", "\u2581bo", "son", "\u2581and", "\u2581electro", "we", "ak", "\u2581gauge", "\u2581bo", "son", "\u2581transformation", "s", "\u2581under", "\u2581", "CP", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 2, 3, 3, 3, 4, 5, 5, 6, 6, 7, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_638", "sentence": ["\u2581Re", "l", "ative", "\u2581world", "\u2581carbon", "\u2581footprint", "s", "\u2581by", "\u2581nation", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Re", "l", "ative", "\u2581world", "\u2581carbon", "\u2581footprint", "s", "\u2581by", "\u2581nation", "?", "</s>"], "target_sentence": ["\u2581Re", "l", "ative", "\u2581world", "\u2581carbon", "\u2581footprint", "s", "\u2581by", "<m>", "\u2581nation", "</m>", "?", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1]}, {"doc_id": "emerging.test_639", "sentence": ["\u2581After", "\u2581seeing", "\u2581this", "\u2581[", "\u2581article", "]", "\u2581(", "\u2581https", "://", "ar", "x", "i", "v", ".", "org", "/", "abs", "/", "07", "04.", "31", "16", ")", ",", "\u2581I", "\u2581am", "\u2581convinced", "\u2581of", "\u2581the", "\u2581method", "\u2581you", "\u2581give", "\u2581in", "\u2581your", "\u2581answer", ".", "\u2581However", ",", "\u2581I", "\u2581have", "\u2581", "n", "'", "\u2581", "t", "\u2581still", "\u2581been", "\u2581", "able", "\u2581to", "\u2581der", "ive", "\u2581the", "\u2581V", "EV", "\u2581shown", "\u2581in", "\u2581the", "\u2581question", ".", "\u2581Could", "\u2581you", "\u2581give", "\u2581details", "?", "\u2581Also", ",", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581sure", "\u2581why", "\u2581the", "\u2581vacuum", "\u2581", "ket", "\u2581$", "\u2581", "\\", "\u2581", "vert", "\u2581", "0", "\u2581", "\\", "\u2581", "r", "angle", "\u2581$", "\u2581maps", "\u2581to", "\u25811", "\u2581and", "\u2581why", "\u2581$", "\u2581", "\\", "\u2581", "vert", "\u2581", "n", "\u2581", "\\", "\u2581", "r", "angle", "\u2581$", "\u2581maps", "\u2581to", "\u2581$", "\u2581", "\\", "\u2581sq", "r", "t", "\u2581", "{", "\u2581", "n", "!", "}", "\u2581", "\\", "\u2581", "x", "i", "\u2581", "^", "\u2581", "n", "\u2581$", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581After", "\u2581seeing", "\u2581this", "\u2581[", "\u2581article", "]", "\u2581(", "\u2581https", "://", "ar", "x", "i", "v", ".", "org", "/", "abs", "/", "07", "04.", "31", "16", ")", ",", "\u2581I", "\u2581am", "\u2581convinced", "\u2581of", "\u2581the", "\u2581method", "\u2581you", "\u2581give", "\u2581in", "\u2581your", "\u2581answer", ".", "\u2581However", ",", "\u2581I", "\u2581have", "\u2581", "n", "'", "\u2581", "t", "\u2581still", "\u2581been", "\u2581", "able", "\u2581to", "\u2581der", "ive", "\u2581the", "\u2581V", "EV", "\u2581shown", "\u2581in", "\u2581the", "\u2581question", ".", "\u2581Could", "\u2581you", "\u2581give", "\u2581details", "?", "\u2581Also", ",", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581sure", "\u2581why", "\u2581the", "\u2581vacuum", "\u2581", "ket", "\u2581$", "\u2581", "\\", "\u2581", "vert", "\u2581", "0", "\u2581", "\\", "\u2581", "r", "angle", "\u2581$", "\u2581maps", "\u2581to", "\u25811", "\u2581and", "\u2581why", "\u2581$", "\u2581", "\\", "\u2581", "vert", "\u2581", "n", "\u2581", "\\", "\u2581", "r", "angle", "\u2581$", "\u2581maps", "\u2581to", "\u2581$", "\u2581", "\\", "\u2581sq", "r", "t", "\u2581", "{", "\u2581", "n", "!", "}", "\u2581", "\\", "\u2581", "x", "i", "\u2581", "^", "\u2581", "n", "\u2581$", ".", "</s>"], "target_sentence": ["\u2581After", "\u2581seeing", "\u2581this", "\u2581[", "\u2581article", "]", "\u2581(", "\u2581https", "://", "ar", "x", "i", "v", ".", "org", "/", "abs", "/", "07", "04.", "31", "16", ")", ",", "\u2581I", "\u2581am", "\u2581convinced", "\u2581of", "\u2581the", "\u2581method", "\u2581you", "\u2581give", "\u2581in", "\u2581your", "\u2581answer", ".", "\u2581However", ",", "\u2581I", "\u2581have", "\u2581", "n", "'", "\u2581", "t", "\u2581still", "\u2581been", "\u2581", "able", "\u2581to", "\u2581der", "ive", "\u2581the", "\u2581V", "EV", "\u2581shown", "\u2581in", "\u2581the", "\u2581question", ".", "\u2581Could", "\u2581you", "\u2581give", "\u2581details", "?", "\u2581Also", ",", "\u2581I", "'", "\u2581", "m", "\u2581not", "\u2581sure", "\u2581why", "\u2581the", "\u2581vacuum", "\u2581", "ket", "\u2581$", "\u2581", "\\", "\u2581", "vert", "\u2581", "0", "\u2581", "\\", "\u2581", "r", "angle", "\u2581$", "\u2581maps", "\u2581to", "\u25811", "\u2581and", "\u2581why", "\u2581$", "\u2581", "\\", "\u2581", "vert", "\u2581", "n", "\u2581", "\\", "\u2581", "r", "angle", "\u2581$", "\u2581maps", "\u2581to", "\u2581$", "\u2581", "\\", "\u2581sq", "r", "t", "\u2581", "{", "\u2581", "n", "!", "}", "\u2581", "\\", "\u2581", "x", "i", "\u2581", "^", "\u2581", "n", "\u2581$", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 28, 29, 30, 31, 31, 32, 33, 33, 34, 35, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 50, 51, 52, 53, 54, 55, 56, 56, 57, 58, 58, 59, 59, 60, 60, 61, 61, 62, 62, 62, 63, 64, 65, 66, 67, 68, 69, 70, 70, 71, 71, 72, 72, 73, 73, 74, 74, 74, 75, 76, 77, 78, 79, 79, 80, 80, 80, 81, 81, 82, 82, 83, 84, 85, 85, 86, 86, 86, 87, 87, 88, 88, 89, 90, 91], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_640", "sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581Ya", "u", "t", "ja", "\u2581and", "\u2581Super", "\u2581Ya", "u", "t", "ja", "\u2581in", "\u2581Pre", "d", "ators", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581Ya", "u", "t", "ja", "\u2581and", "\u2581Super", "\u2581Ya", "u", "t", "ja", "\u2581in", "\u2581Pre", "d", "ators", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "<m>", "\u2581Ya", "u", "t", "ja", "</m>", "\u2581and", "<m>", "\u2581Super", "\u2581Ya", "u", "t", "ja", "</m>", "\u2581in", "<m>", "\u2581Pre", "d", "ators", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 6, 7, 8, 8, 8, 8, 9, 10, 10, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, 2, -1, -1, -1, 2, -1, -1]}, {"doc_id": "emerging.test_641", "sentence": ["\u2581What", "\u2581Star", "\u2581Trek", "\u2581TO", "S", "\u2581characters", "\u2581have", "\u2581been", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581appearing", "\u2581in", "\u2581Discovery", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581Star", "\u2581Trek", "\u2581TO", "S", "\u2581characters", "\u2581have", "\u2581been", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581appearing", "\u2581in", "\u2581Discovery", "?", "</s>"], "target_sentence": ["\u2581What", "<m>", "\u2581Star", "\u2581Trek", "\u2581TO", "S", "</m>", "\u2581characters", "\u2581have", "\u2581been", "\u2581confirmed", "\u2581to", "\u2581be", "\u2581appearing", "\u2581in", "<m>", "<m>", "\u2581Discovery", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 2, 1, -1, 2, 1, -1, -1]}, {"doc_id": "emerging.test_642", "sentence": ["\u2581There", "'", "\u2581", "s", "\u2581nothing", "\u2581in", "\u2581law", "\u2581that", "\u2581says", "\u2581", "a", "\u2581politician", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581switch", "\u2581parties", ",", "\u2581but", "\u2581the", "\u2581few", "\u2581times", "\u2581it", "'", "\u2581", "s", "\u2581happened", "\u2581in", "\u2581history", ",", "\u2581the", "\u2581politician", "\u2581has", "\u2581been", "\u2581black", "listed", "\u2581by", "\u2581their", "\u2581previous", "\u2581party", ",", "\u2581and", "\u2581then", "\u2581not", "\u2581exactly", "\u2581welcomed", "\u2581by", "\u2581the", "\u2581new", "\u2581party", "\u2581because", "\u2581they", "\u2581are", "\u2581", "a", "\u2581turn", "coat", ",", "\u2581and", "\u2581could", "\u2581do", "\u2581it", "\u2581again", ".", "\u2581It", "\u2581is", "\u2581", "a", "kin", "\u2581to", "\u2581political", "\u2581suicide", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581There", "'", "\u2581", "s", "\u2581nothing", "\u2581in", "\u2581law", "\u2581that", "\u2581says", "\u2581", "a", "\u2581politician", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581switch", "\u2581parties", ",", "\u2581but", "\u2581the", "\u2581few", "\u2581times", "\u2581it", "'", "\u2581", "s", "\u2581happened", "\u2581in", "\u2581history", ",", "\u2581the", "\u2581politician", "\u2581has", "\u2581been", "\u2581black", "listed", "\u2581by", "\u2581their", "\u2581previous", "\u2581party", ",", "\u2581and", "\u2581then", "\u2581not", "\u2581exactly", "\u2581welcomed", "\u2581by", "\u2581the", "\u2581new", "\u2581party", "\u2581because", "\u2581they", "\u2581are", "\u2581", "a", "\u2581turn", "coat", ",", "\u2581and", "\u2581could", "\u2581do", "\u2581it", "\u2581again", ".", "\u2581It", "\u2581is", "\u2581", "a", "kin", "\u2581to", "\u2581political", "\u2581suicide", ".", "</s>"], "target_sentence": ["\u2581There", "'", "\u2581", "s", "\u2581nothing", "\u2581in", "\u2581law", "\u2581that", "\u2581says", "\u2581", "a", "\u2581politician", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581switch", "\u2581parties", ",", "\u2581but", "\u2581the", "\u2581few", "\u2581times", "\u2581it", "'", "\u2581", "s", "\u2581happened", "\u2581in", "\u2581history", ",", "\u2581the", "\u2581politician", "\u2581has", "\u2581been", "\u2581black", "listed", "\u2581by", "\u2581their", "\u2581previous", "\u2581party", ",", "\u2581and", "\u2581then", "\u2581not", "\u2581exactly", "\u2581welcomed", "\u2581by", "\u2581the", "\u2581new", "\u2581party", "\u2581because", "\u2581they", "\u2581are", "\u2581", "a", "\u2581turn", "coat", ",", "\u2581and", "\u2581could", "\u2581do", "\u2581it", "\u2581again", ".", "\u2581It", "\u2581is", "\u2581", "a", "kin", "\u2581to", "\u2581political", "\u2581suicide", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 50, 51, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 61, 61, 62, 63, 64, 65, 66], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_643", "sentence": ["\u2581No", "pe", "s", ",", "\u2581full", "\u2581story", "\u2581was", "\u2581presented", "\u2581in", "\u2581parts", ",", "\u2581I", "\u2581think", "\u25813", "\u2581parts", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581No", "pe", "s", ",", "\u2581full", "\u2581story", "\u2581was", "\u2581presented", "\u2581in", "\u2581parts", ",", "\u2581I", "\u2581think", "\u25813", "\u2581parts", ".", "</s>"], "target_sentence": ["\u2581No", "pe", "s", ",", "\u2581full", "\u2581story", "\u2581was", "\u2581presented", "\u2581in", "<m>", "\u2581parts", "</m>", ",", "\u2581I", "\u2581think", "\u25813", "\u2581parts", ".", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_644", "sentence": ["\u2581magnetic", "\u2581potential", "\u2581", "v", "s", ".", "\u2581solid", "\u2581angle", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581magnetic", "\u2581potential", "\u2581", "v", "s", ".", "\u2581solid", "\u2581angle", "</s>"], "target_sentence": ["\u2581magnetic", "\u2581potential", "\u2581", "v", "s", ".", "\u2581solid", "\u2581angle", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_645", "sentence": ["\u2581Why", "\u2581is", "\u2581it", "\u2581necessary", "\u2581to", "\u2581minimize", "\u2581red", "und", "ancy", "\u2581in", "\u2581the", "\u2581", "cip", "her", "text", "\u2581of", "\u2581", "a", "\u2581stream", "\u2581", "cip", "her", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581is", "\u2581it", "\u2581necessary", "\u2581to", "\u2581minimize", "\u2581red", "und", "ancy", "\u2581in", "\u2581the", "\u2581", "cip", "her", "text", "\u2581of", "\u2581", "a", "\u2581stream", "\u2581", "cip", "her", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581is", "\u2581it", "\u2581necessary", "\u2581to", "\u2581minimize", "\u2581red", "und", "ancy", "\u2581in", "\u2581the", "\u2581", "cip", "her", "text", "\u2581of", "\u2581", "a", "\u2581stream", "\u2581", "cip", "her", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 9, 9, 9, 10, 11, 11, 12, 13, 13, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_646", "sentence": ["\u2581", "Identify", "\u2581this", "\u2581post", "\u2581", "a", "poc", "a", "ly", "p", "tic", "\u2581movie", "\u2581with", "\u2581rival", "\u2581can", "n", "i", "bal", "\u2581car", "\u2581", "gang", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Identify", "\u2581this", "\u2581post", "\u2581", "a", "poc", "a", "ly", "p", "tic", "\u2581movie", "\u2581with", "\u2581rival", "\u2581can", "n", "i", "bal", "\u2581car", "\u2581", "gang", "s", "</s>"], "target_sentence": ["\u2581", "Identify", "\u2581this", "\u2581post", "\u2581", "a", "poc", "a", "ly", "p", "tic", "\u2581movie", "\u2581with", "<m>", "\u2581rival", "\u2581can", "n", "i", "bal", "\u2581car", "\u2581", "gang", "s", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_647", "sentence": ["\u2581Are", "\u2581Ho", "g", "war", "t", "s", "\u2581students", "\u2581allowed", "\u2581to", "\u2581go", "\u2581to", "\u2581other", "\u2581houses", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Are", "\u2581Ho", "g", "war", "t", "s", "\u2581students", "\u2581allowed", "\u2581to", "\u2581go", "\u2581to", "\u2581other", "\u2581houses", "?", "</s>"], "target_sentence": ["\u2581Are", "<m>", "<m>", "\u2581Ho", "g", "war", "t", "s", "</m>", "</m>", "\u2581students", "\u2581allowed", "\u2581to", "\u2581go", "\u2581to", "<m>", "\u2581other", "\u2581houses", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [-1, 0, 1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 2, -1, -1, 2, -1, -1]}, {"doc_id": "emerging.test_648", "sentence": ["\u2581You", "\u2581can", "\u2581add", "\u2581to", "r", "sion", "\u2581", "if", "\u2581you", "\u2581want", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581can", "\u2581add", "\u2581to", "r", "sion", "\u2581", "if", "\u2581you", "\u2581want", "</s>"], "target_sentence": ["\u2581You", "\u2581can", "\u2581add", "<m>", "\u2581to", "r", "sion", "</m>", "\u2581", "if", "\u2581you", "\u2581want", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_649", "sentence": ["\u2581I", "\u2581think", "\u2581$", "\u2581", "\\", "\u2581delta", "\u2581", "\\", "\u2581omega", "\u2581$", "\u2581cannot", "\u2581move", "\u2581freely", "\u2581to", "\u2581the", "\u2581right", ".", "\u2581It", "'", "\u2581", "s", "\u2581", "a", "\u2581", "cliff", "or", "d", "\u2581algebra", "\u2581", "vul", "u", "e", "d", "\u2581in", "\u2581this", "\u2581case", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581think", "\u2581$", "\u2581", "\\", "\u2581delta", "\u2581", "\\", "\u2581omega", "\u2581$", "\u2581cannot", "\u2581move", "\u2581freely", "\u2581to", "\u2581the", "\u2581right", ".", "\u2581It", "'", "\u2581", "s", "\u2581", "a", "\u2581", "cliff", "or", "d", "\u2581algebra", "\u2581", "vul", "u", "e", "d", "\u2581in", "\u2581this", "\u2581case", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581think", "\u2581$", "\u2581", "\\", "\u2581delta", "\u2581", "\\", "<m>", "\u2581omega", "</m>", "\u2581$", "\u2581cannot", "\u2581move", "\u2581freely", "\u2581to", "\u2581the", "\u2581right", ".", "\u2581It", "'", "\u2581", "s", "\u2581", "a", "\u2581", "cliff", "or", "d", "<m>", "\u2581algebra", "</m>", "\u2581", "vul", "u", "e", "d", "\u2581in", "\u2581this", "\u2581case", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 18, 19, 19, 19, 19, 20, 21, 21, 21, 21, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_650", "sentence": ["\u2581ID", "\u2581movie", ":", "\u2581High", "school", "\u2581boy", "\u2581is", "\u2581bull", "ied", "\u2581into", "\u2581", "a", "\u2581", "com", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581ID", "\u2581movie", ":", "\u2581High", "school", "\u2581boy", "\u2581is", "\u2581bull", "ied", "\u2581into", "\u2581", "a", "\u2581", "com", "a", "</s>"], "target_sentence": ["\u2581ID", "\u2581movie", ":", "\u2581High", "school", "\u2581boy", "\u2581is", "\u2581bull", "ied", "\u2581into", "\u2581", "a", "\u2581", "com", "a", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 6, 7, 8, 8, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_651", "sentence": ["\u2581Oh", "\u2581my", "\u2581god", ",", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581the", "\u2581differential", "\u2581was", "\u2581", "a", "\u2581thing", ".", ".", ".", "\u2581That", "\u2581helps", "\u2581so", "\u2581much", ",", "\u2581thanks", "!", ".", "\u2581And", "\u2581@", "\u2581Fed", "x", "a", ",", "\u2581", "if", "\u2581that", "'", "\u2581", "s", "\u2581so", ",", "\u2581then", "\u2581I", "'", "\u2581", "m", "\u2581really", "\u2581confused", ".", "\u2581I", "\u2581just", "\u2581put", "\u2581", "a", "\u2581screenshot", "\u2581of", "\u2581the", "\u2581example", "\u2581where", "\u2581I", "'", "\u2581", "m", "\u2581getting", "\u2581that", "\u2581conclusion", "\u2581from", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Oh", "\u2581my", "\u2581god", ",", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581the", "\u2581differential", "\u2581was", "\u2581", "a", "\u2581thing", ".", ".", ".", "\u2581That", "\u2581helps", "\u2581so", "\u2581much", ",", "\u2581thanks", "!", ".", "\u2581And", "\u2581@", "\u2581Fed", "x", "a", ",", "\u2581", "if", "\u2581that", "'", "\u2581", "s", "\u2581so", ",", "\u2581then", "\u2581I", "'", "\u2581", "m", "\u2581really", "\u2581confused", ".", "\u2581I", "\u2581just", "\u2581put", "\u2581", "a", "\u2581screenshot", "\u2581of", "\u2581the", "\u2581example", "\u2581where", "\u2581I", "'", "\u2581", "m", "\u2581getting", "\u2581that", "\u2581conclusion", "\u2581from", ".", "</s>"], "target_sentence": ["\u2581Oh", "\u2581my", "\u2581god", ",", "\u2581I", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581know", "\u2581the", "\u2581differential", "\u2581was", "\u2581", "a", "\u2581thing", ".", ".", ".", "\u2581That", "\u2581helps", "\u2581so", "\u2581much", ",", "\u2581thanks", "!", ".", "\u2581And", "\u2581@", "<m>", "\u2581Fed", "x", "a", "</m>", ",", "\u2581", "if", "\u2581that", "'", "\u2581", "s", "\u2581so", ",", "\u2581then", "\u2581I", "'", "\u2581", "m", "\u2581really", "\u2581confused", ".", "\u2581I", "\u2581just", "\u2581put", "\u2581", "a", "\u2581screenshot", "\u2581of", "\u2581the", "\u2581example", "\u2581where", "\u2581I", "'", "\u2581", "m", "\u2581getting", "\u2581that", "\u2581conclusion", "\u2581from", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 28, 29, 30, 30, 31, 32, 33, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 42, 43, 44, 45, 46, 46, 47, 48, 49, 50, 51, 52, 53, 54, 54, 55, 56, 57, 58, 59, 60], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_652", "sentence": ["\u2581Does", "\u2581R", "ogue", "\u2581One", "\u2581create", "\u2581", "a", "\u2581plot", "\u2581hole", "\u2581in", "\u2581Return", "\u2581of", "\u2581the", "\u2581Jedi", "\u2581", "re", "\u2581Hyper", "space", "\u2581Radio", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Does", "\u2581R", "ogue", "\u2581One", "\u2581create", "\u2581", "a", "\u2581plot", "\u2581hole", "\u2581in", "\u2581Return", "\u2581of", "\u2581the", "\u2581Jedi", "\u2581", "re", "\u2581Hyper", "space", "\u2581Radio", "?", "</s>"], "target_sentence": ["\u2581Does", "\u2581R", "ogue", "\u2581One", "\u2581create", "\u2581", "a", "\u2581plot", "\u2581hole", "\u2581in", "<m>", "\u2581Return", "\u2581of", "\u2581the", "\u2581Jedi", "</m>", "\u2581", "re", "\u2581Hyper", "space", "\u2581Radio", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_653", "sentence": ["\u2581Books", "\u2581are", "\u2581never", "\u2581peer", "\u2581reviewed", ".", "\u2581I", "\u2581can", "\u2581add", "\u2581some", "\u2581journal", "\u2581references", ",", "\u2581but", "\u2581they", "\u2581will", "\u2581almost", "\u2581definitely", "\u2581be", "\u2581behind", "\u2581", "a", "\u2581pay", "wall", ".", "\u2581I", "\u2581would", "\u2581call", "\u2581it", "\u2581non", "partisan", "\u2581in", "\u2581the", "\u2581sense", "\u2581that", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581an", "\u2581attempt", "\u2581to", "\u2581support", "\u2581any", "\u2581party", "\u2581or", "\u2581candidates", ",", "\u2581but", "\u2581any", "\u2581analysis", "\u2581of", "\u2581parties", "\u2581is", "\u2581going", "\u2581to", "\u2581vin", "dic", "ate", "\u2581someone", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Books", "\u2581are", "\u2581never", "\u2581peer", "\u2581reviewed", ".", "\u2581I", "\u2581can", "\u2581add", "\u2581some", "\u2581journal", "\u2581references", ",", "\u2581but", "\u2581they", "\u2581will", "\u2581almost", "\u2581definitely", "\u2581be", "\u2581behind", "\u2581", "a", "\u2581pay", "wall", ".", "\u2581I", "\u2581would", "\u2581call", "\u2581it", "\u2581non", "partisan", "\u2581in", "\u2581the", "\u2581sense", "\u2581that", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581an", "\u2581attempt", "\u2581to", "\u2581support", "\u2581any", "\u2581party", "\u2581or", "\u2581candidates", ",", "\u2581but", "\u2581any", "\u2581analysis", "\u2581of", "\u2581parties", "\u2581is", "\u2581going", "\u2581to", "\u2581vin", "dic", "ate", "\u2581someone", ".", "</s>"], "target_sentence": ["\u2581Books", "\u2581are", "\u2581never", "\u2581peer", "\u2581reviewed", ".", "\u2581I", "\u2581can", "\u2581add", "\u2581some", "\u2581journal", "\u2581references", ",", "\u2581but", "\u2581they", "\u2581will", "\u2581almost", "\u2581definitely", "\u2581be", "\u2581behind", "\u2581", "a", "\u2581pay", "wall", ".", "\u2581I", "\u2581would", "\u2581call", "\u2581it", "\u2581non", "partisan", "\u2581in", "\u2581the", "\u2581sense", "\u2581that", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581an", "\u2581attempt", "\u2581to", "\u2581support", "\u2581any", "\u2581party", "\u2581or", "\u2581candidates", ",", "\u2581but", "\u2581any", "\u2581analysis", "\u2581of", "\u2581parties", "\u2581is", "\u2581going", "\u2581to", "\u2581vin", "dic", "ate", "\u2581someone", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21, 22, 23, 24, 25, 26, 27, 27, 28, 29, 30, 31, 32, 33, 33, 34, 35, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 53, 53, 54, 55, 56], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_654", "sentence": ["\u2581@", "\u2581it", "p", "a", "stor", "n", "\u2581yes", ",", "\u2581but", "\u2581I", "\u2581think", "\u2581you", "\u2581can", "\u2581also", "\u2581take", "\u2581the", "\u2581ones", "\u2581that", "\u2581are", "\u2581described", "\u2581as", "\u2581evidence", "\u2581that", "\u2581there", "\u2581generally", "\u2581*", "\u2581are", "\u2581*", "\u2581holidays", ",", "\u2581probably", "\u2581many", "\u2581different", "\u2581ones", "\u2581in", "\u2581many", "\u2581different", "\u2581communities", ",", "\u2581and", "\u2581we", "\u2581just", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581get", "\u2581to", "\u2581hear", "\u2581about", "\u2581them", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581it", "p", "a", "stor", "n", "\u2581yes", ",", "\u2581but", "\u2581I", "\u2581think", "\u2581you", "\u2581can", "\u2581also", "\u2581take", "\u2581the", "\u2581ones", "\u2581that", "\u2581are", "\u2581described", "\u2581as", "\u2581evidence", "\u2581that", "\u2581there", "\u2581generally", "\u2581*", "\u2581are", "\u2581*", "\u2581holidays", ",", "\u2581probably", "\u2581many", "\u2581different", "\u2581ones", "\u2581in", "\u2581many", "\u2581different", "\u2581communities", ",", "\u2581and", "\u2581we", "\u2581just", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581get", "\u2581to", "\u2581hear", "\u2581about", "\u2581them", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581it", "p", "a", "stor", "n", "\u2581yes", ",", "\u2581but", "\u2581I", "\u2581think", "\u2581you", "\u2581can", "\u2581also", "\u2581take", "\u2581the", "\u2581ones", "\u2581that", "\u2581are", "\u2581described", "\u2581as", "\u2581evidence", "\u2581that", "\u2581there", "\u2581generally", "\u2581*", "\u2581are", "\u2581*", "\u2581holidays", ",", "\u2581probably", "\u2581many", "\u2581different", "\u2581ones", "\u2581in", "\u2581many", "\u2581different", "\u2581communities", ",", "\u2581and", "\u2581we", "\u2581just", "\u2581do", "\u2581", "n", "'", "\u2581", "t", "\u2581get", "\u2581to", "\u2581hear", "\u2581about", "\u2581them", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 41, 42, 43, 44, 45, 46, 47, 48], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_655", "sentence": ["\u2581@", "\u2581Wild", "card", "\u2581", "if", "\u2581hope", "\u2581you", "'", "\u2581", "ve", "\u2581done", "\u2581the", "\u2581over", "\u25818", "\u2581years", "\u2581it", "'", "\u2581", "s", "\u2581required", "\u2581in", "\u2581most", "\u2581of", "\u2581the", "\u2581western", "\u2581world", "'", "\u2581", "s", "\u2581universities", "\u2581to", "\u2581complete", "\u2581", "a", "\u2581", "psy", "c", "ology", "\u2581or", "\u2581", "psych", "i", "a", "try", "\u2581B", "s", "c", "\u2581+", "\u2581M", "s", "C", "\u2581+", "\u2581M", "IR", "\u2581", "/", "\u2581P", "IR", "\u2581Degree", "\u2581for", "\u2581your", "\u2581facts", ",", "\u2581rather", "\u2581than", "\u2581", "a", "\u2581internet", "\u2581blog", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Wild", "card", "\u2581", "if", "\u2581hope", "\u2581you", "'", "\u2581", "ve", "\u2581done", "\u2581the", "\u2581over", "\u25818", "\u2581years", "\u2581it", "'", "\u2581", "s", "\u2581required", "\u2581in", "\u2581most", "\u2581of", "\u2581the", "\u2581western", "\u2581world", "'", "\u2581", "s", "\u2581universities", "\u2581to", "\u2581complete", "\u2581", "a", "\u2581", "psy", "c", "ology", "\u2581or", "\u2581", "psych", "i", "a", "try", "\u2581B", "s", "c", "\u2581+", "\u2581M", "s", "C", "\u2581+", "\u2581M", "IR", "\u2581", "/", "\u2581P", "IR", "\u2581Degree", "\u2581for", "\u2581your", "\u2581facts", ",", "\u2581rather", "\u2581than", "\u2581", "a", "\u2581internet", "\u2581blog", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Wild", "card", "\u2581", "if", "\u2581hope", "\u2581you", "'", "\u2581", "ve", "\u2581done", "\u2581the", "\u2581over", "\u25818", "\u2581years", "\u2581it", "'", "\u2581", "s", "\u2581required", "\u2581in", "\u2581most", "\u2581of", "\u2581the", "\u2581western", "\u2581world", "'", "\u2581", "s", "\u2581universities", "\u2581to", "\u2581complete", "\u2581", "a", "\u2581", "psy", "c", "ology", "\u2581or", "\u2581", "psych", "i", "a", "try", "\u2581B", "s", "c", "\u2581+", "\u2581M", "s", "C", "\u2581+", "\u2581M", "IR", "\u2581", "/", "\u2581P", "IR", "\u2581Degree", "\u2581for", "\u2581your", "\u2581facts", ",", "\u2581rather", "\u2581than", "\u2581", "a", "\u2581internet", "\u2581blog", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 27, 28, 28, 28, 28, 29, 30, 30, 30, 30, 30, 31, 31, 31, 32, 33, 33, 33, 34, 35, 35, 36, 36, 37, 37, 38, 39, 40, 41, 42, 43, 44, 45, 45, 46, 47, 48, 49], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_656", "sentence": ["\u2581S", "chro", "e", "der", "'", "\u2581", "s", "\u2581Min", "kowski", "\u2581Space", "\u2581Integr", "al", "\u2581", "-", "\u2581Concern", "s", "\u2581about", "\u2581Wick", "\u2581Rot", "ations", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581S", "chro", "e", "der", "'", "\u2581", "s", "\u2581Min", "kowski", "\u2581Space", "\u2581Integr", "al", "\u2581", "-", "\u2581Concern", "s", "\u2581about", "\u2581Wick", "\u2581Rot", "ations", "</s>"], "target_sentence": ["<m>", "\u2581S", "chro", "e", "der", "</m>", "'", "\u2581", "s", "<m>", "<m>", "<m>", "\u2581Min", "kowski", "</m>", "</m>", "\u2581Space", "\u2581Integr", "al", "</m>", "\u2581", "-", "\u2581Concern", "s", "\u2581about", "<m>", "\u2581Wick", "</m>", "\u2581Rot", "ations", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6, 7, 7, 8, 9, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, -1, -1, 1, 2, 3, -1, -1, 1, 2, -1, -1, -1, 3, -1, -1, -1, -1, -1, 4, -1, 4, -1, -1, -1]}, {"doc_id": "emerging.test_657", "sentence": ["\u2581@", "\u2581Gall", "if", "re", "y", "an", ",", "\u2581good", "\u2581question", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Gall", "if", "re", "y", "an", ",", "\u2581good", "\u2581question", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "<m>", "\u2581Gall", "if", "re", "y", "an", "</m>", "</m>", ",", "\u2581good", "\u2581question", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1], "ent_indices": [-1, 1, 0, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_658", "sentence": ["\u2581Similar", "\u2581to", "\u2581http", "://", "security", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "43", "69", "/", "why", "-", "is", "-", "http", "s", "-", "not", "-", "the", "-", "default", "-", "pro", "to", "col", "also", "comp", "are", "\u2581http", "://", "web", "master", "s", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/18", "23", "/", "http", "s", "-", "for", "-", "en", "tire", "-", "site", "v", "s", "\u2581http", "://", "web", "master", "s", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/3", "148", "/", "d", "o", "e", "s", "-", "s", "s", "l", "-", "re", "ally", "-", "m", "atter", "-", "for", "-", "most", "-", "web", "site", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Similar", "\u2581to", "\u2581http", "://", "security", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "43", "69", "/", "why", "-", "is", "-", "http", "s", "-", "not", "-", "the", "-", "default", "-", "pro", "to", "col", "also", "comp", "are", "\u2581http", "://", "web", "master", "s", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/18", "23", "/", "http", "s", "-", "for", "-", "en", "tire", "-", "site", "v", "s", "\u2581http", "://", "web", "master", "s", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/3", "148", "/", "d", "o", "e", "s", "-", "s", "s", "l", "-", "re", "ally", "-", "m", "atter", "-", "for", "-", "most", "-", "web", "site", "s", "</s>"], "target_sentence": ["\u2581Similar", "\u2581to", "\u2581http", "://", "security", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/", "43", "69", "/", "why", "-", "is", "-", "http", "s", "-", "not", "-", "the", "-", "default", "-", "pro", "to", "col", "also", "comp", "are", "\u2581http", "://", "web", "master", "s", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/18", "23", "/", "http", "s", "-", "for", "-", "en", "tire", "-", "site", "v", "s", "\u2581http", "://", "web", "master", "s", ".", "s", "t", "ack", "ex", "change", ".", "com", "/", "quest", "ions", "/3", "148", "/", "d", "o", "e", "s", "-", "s", "s", "l", "-", "re", "ally", "-", "m", "atter", "-", "for", "-", "most", "-", "web", "site", "s", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_659", "sentence": ["\u2581@", "\u2581Kru", "m", "i", "a", ":", "\u2581P", "reci", "s", "e", "ly", ".", "\u2581This", "\u2581answer", "\u2581is", "\u2581flat", "ly", "\u2581wrong", ".", "\u2581Resolution", "\u2581power", "\u2581of", "\u2581an", "\u2581optical", "\u2581detector", "\u2581(", "\u2581eye", "ball", "\u2581or", "\u2581otherwise", ")", "\u2581has", "\u2581nothing", "\u2581to", "\u2581do", "\u2581with", "\u2581the", "\u2581intensity", "\u2581of", "\u2581incident", "\u2581photo", "n", "s", "\u2581(", "\u2581of", "\u2581", "a", "\u2581given", "\u2581frequency", ")", "\u2581that", "\u2581is", "\u2581needed", "\u2581for", "\u2581it", "\u2581to", "\u2581detect", "\u2581", "a", "\u2581difference", "\u2581from", "\u2581no", "\u2581light", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Kru", "m", "i", "a", ":", "\u2581P", "reci", "s", "e", "ly", ".", "\u2581This", "\u2581answer", "\u2581is", "\u2581flat", "ly", "\u2581wrong", ".", "\u2581Resolution", "\u2581power", "\u2581of", "\u2581an", "\u2581optical", "\u2581detector", "\u2581(", "\u2581eye", "ball", "\u2581or", "\u2581otherwise", ")", "\u2581has", "\u2581nothing", "\u2581to", "\u2581do", "\u2581with", "\u2581the", "\u2581intensity", "\u2581of", "\u2581incident", "\u2581photo", "n", "s", "\u2581(", "\u2581of", "\u2581", "a", "\u2581given", "\u2581frequency", ")", "\u2581that", "\u2581is", "\u2581needed", "\u2581for", "\u2581it", "\u2581to", "\u2581detect", "\u2581", "a", "\u2581difference", "\u2581from", "\u2581no", "\u2581light", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Kru", "m", "i", "a", ":", "\u2581P", "reci", "s", "e", "ly", ".", "\u2581This", "\u2581answer", "\u2581is", "\u2581flat", "ly", "\u2581wrong", ".", "\u2581Resolution", "\u2581power", "\u2581of", "\u2581an", "\u2581optical", "\u2581detector", "\u2581(", "\u2581eye", "ball", "\u2581or", "\u2581otherwise", ")", "\u2581has", "\u2581nothing", "\u2581to", "\u2581do", "\u2581with", "\u2581the", "\u2581intensity", "\u2581of", "\u2581incident", "\u2581photo", "n", "s", "\u2581(", "\u2581of", "\u2581", "a", "\u2581given", "\u2581frequency", ")", "\u2581that", "\u2581is", "\u2581needed", "\u2581for", "\u2581it", "\u2581to", "\u2581detect", "\u2581", "a", "\u2581difference", "\u2581from", "\u2581no", "\u2581light", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 31, 31, 32, 33, 34, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 45, 46, 47, 48, 49, 50, 51], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_660", "sentence": ["\u2581Short", "\u2581story", "\u2581published", "\u2581in", "\u2581As", "i", "mov", "'", "\u2581", "s", "\u2581in", "\u2581the", "\u258190", "'", "\u2581", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Short", "\u2581story", "\u2581published", "\u2581in", "\u2581As", "i", "mov", "'", "\u2581", "s", "\u2581in", "\u2581the", "\u258190", "'", "\u2581", "s", "</s>"], "target_sentence": ["\u2581Short", "\u2581story", "\u2581published", "\u2581in", "<m>", "<m>", "\u2581As", "i", "mov", "</m>", "</m>", "'", "\u2581", "s", "\u2581in", "\u2581the", "\u258190", "'", "\u2581", "s", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 1, 0, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_661", "sentence": ["\u2581Alternative", "s", "\u2581to", "\u2581brut", "e", "force", "\u2581Ke", "e", "Pass", "\u2581Crack", "er", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Alternative", "s", "\u2581to", "\u2581brut", "e", "force", "\u2581Ke", "e", "Pass", "\u2581Crack", "er", "</s>"], "target_sentence": ["\u2581Alternative", "s", "\u2581to", "<m>", "\u2581brut", "e", "force", "<m>", "<m>", "\u2581Ke", "e", "Pass", "</m>", "</m>", "\u2581Crack", "er", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 3, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 4, -1, -1, 5, -1], "ent_indices": [-1, -1, -1, 2, -1, -1, -1, 0, 1, -1, -1, -1, 0, 1, -1, -1, 2, -1]}, {"doc_id": "emerging.test_662", "sentence": ["\u2581@", "\u2581Panda", "\u2581Thanks", "\u2581for", "\u2581", "t", "agging", "\u2581that", "\u2581question", ".", "\u2581My", "\u2581question", "'", "\u2581", "s", "\u2581title", "\u2581was", "\u2581an", "\u2581", "homage", "\u2581to", "\u2581it", ".", "\u2581I", "\u2581just", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581sure", "\u2581", "if", "\u2581I", "\u2581should", "\u2581", "\\", "\u2581how", "\u2581to", "\u2581draw", "\u2581attention", "\u2581to", "\u2581it", "\u2581as", "\u2581well", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Panda", "\u2581Thanks", "\u2581for", "\u2581", "t", "agging", "\u2581that", "\u2581question", ".", "\u2581My", "\u2581question", "'", "\u2581", "s", "\u2581title", "\u2581was", "\u2581an", "\u2581", "homage", "\u2581to", "\u2581it", ".", "\u2581I", "\u2581just", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581sure", "\u2581", "if", "\u2581I", "\u2581should", "\u2581", "\\", "\u2581how", "\u2581to", "\u2581draw", "\u2581attention", "\u2581to", "\u2581it", "\u2581as", "\u2581well", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Panda", "</m>", "\u2581Thanks", "\u2581for", "\u2581", "t", "agging", "\u2581that", "\u2581question", ".", "\u2581My", "\u2581question", "'", "\u2581", "s", "\u2581title", "\u2581was", "\u2581an", "\u2581", "homage", "\u2581to", "\u2581it", ".", "\u2581I", "\u2581just", "\u2581was", "\u2581", "n", "'", "\u2581", "t", "\u2581sure", "\u2581", "if", "\u2581I", "\u2581should", "\u2581", "\\", "\u2581how", "\u2581to", "\u2581draw", "\u2581attention", "\u2581to", "\u2581it", "\u2581as", "\u2581well", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 24, 25, 26, 26, 27, 28, 29, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], "ent_type_sequence": [-1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_663", "sentence": ["\u2581Need", "\u2581some", "\u2581help", "\u2581understanding", "\u2581Pel", "tier", "\u2581Plate", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Need", "\u2581some", "\u2581help", "\u2581understanding", "\u2581Pel", "tier", "\u2581Plate", "s", "</s>"], "target_sentence": ["\u2581Need", "\u2581some", "\u2581help", "\u2581understanding", "<m>", "\u2581Pel", "tier", "\u2581Plate", "s", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_664", "sentence": ["\u2581Your", "\u2581name", "\u2581suggests", "\u2581you", "\u2581may", "\u2581be", "\u2581Italian", ".", "\u2581If", "\u2581you", "\u2581can", "\u2581edit", "\u2581your", "\u2581question", "\u2581to", "\u2581include", "\u2581an", "\u2581Italian", "\u2581version", ",", "\u2581I", "\u2581will", "\u2581happily", "\u2581translate", "\u2581it", "\u2581", "if", "\u2581nobody", "\u2581else", "\u2581gets", "\u2581to", "\u2581it", "\u2581before", "\u2581I", "\u2581do", ".", "\u2581The", "\u2581current", "\u2581English", "\u2581version", "\u2581of", "\u2581the", "\u2581question", "\u2581is", "\u2581almost", "\u2581impossible", "\u2581to", "\u2581make", "\u2581sense", "\u2581of", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Your", "\u2581name", "\u2581suggests", "\u2581you", "\u2581may", "\u2581be", "\u2581Italian", ".", "\u2581If", "\u2581you", "\u2581can", "\u2581edit", "\u2581your", "\u2581question", "\u2581to", "\u2581include", "\u2581an", "\u2581Italian", "\u2581version", ",", "\u2581I", "\u2581will", "\u2581happily", "\u2581translate", "\u2581it", "\u2581", "if", "\u2581nobody", "\u2581else", "\u2581gets", "\u2581to", "\u2581it", "\u2581before", "\u2581I", "\u2581do", ".", "\u2581The", "\u2581current", "\u2581English", "\u2581version", "\u2581of", "\u2581the", "\u2581question", "\u2581is", "\u2581almost", "\u2581impossible", "\u2581to", "\u2581make", "\u2581sense", "\u2581of", ".", "</s>"], "target_sentence": ["\u2581Your", "\u2581name", "\u2581suggests", "\u2581you", "\u2581may", "\u2581be", "\u2581Italian", ".", "\u2581If", "\u2581you", "\u2581can", "\u2581edit", "\u2581your", "\u2581question", "\u2581to", "\u2581include", "\u2581an", "\u2581Italian", "\u2581version", ",", "\u2581I", "\u2581will", "\u2581happily", "\u2581translate", "\u2581it", "\u2581", "if", "\u2581nobody", "\u2581else", "\u2581gets", "\u2581to", "\u2581it", "\u2581before", "\u2581I", "\u2581do", ".", "\u2581The", "\u2581current", "\u2581English", "\u2581version", "\u2581of", "\u2581the", "\u2581question", "\u2581is", "\u2581almost", "\u2581impossible", "\u2581to", "\u2581make", "\u2581sense", "\u2581of", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_665", "sentence": ["\u2581Jedi", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581that", ",", "\u2581because", "\u2581PHP", "\u2581is", "\u2581of", "\u2581the", "\u2581Dark", "\u2581Side", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Jedi", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581that", ",", "\u2581because", "\u2581PHP", "\u2581is", "\u2581of", "\u2581the", "\u2581Dark", "\u2581Side", ".", "</s>"], "target_sentence": ["<m>", "\u2581Jedi", "</m>", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581do", "\u2581that", ",", "\u2581because", "\u2581PHP", "\u2581is", "\u2581of", "\u2581the", "<m>", "\u2581Dark", "\u2581Side", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1], "ent_indices": [0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_666", "sentence": ["\u2581@", "\u2581", "j", "pm", "c", "\u258126", "\u2581It", "\u2581is", "\u2581difficult", "\u2581to", "\u2581objective", "ly", "\u2581say", "\u2581that", "\u2581the", "\u2581ability", "\u2581for", "\u2581the", "\u2581military", "\u2581to", "\u2581accomplish", "\u2581its", "\u2581current", "\u2581mission", "\u2581is", "\u2581diminished", ".", "\u2581We", "\u2581are", "\u2581only", "\u2581at", "\u2581the", "\u2581point", "\u2581where", "\u2581maintenance", "\u2581has", "\u2581been", "\u2581de", "fer", "red", ",", "\u2581flight", "\u2581hours", "\u2581for", "\u2581training", "\u2581have", "\u2581been", "\u2581reduced", ",", "\u2581and", "\u2581underway", "s", "\u2581for", "\u2581Naval", "\u2581ships", "\u2581have", "\u2581been", "\u2581closely", "\u2581controlled", "\u2581for", "\u2581fuel", "\u2581costs", ".", "\u2581The", "\u2581consequence", "\u2581of", "\u2581the", "\u2581Military", "\u2581being", "\u2581forced", "\u2581to", "\u2581choose", "\u2581operational", "\u2581", "tempo", "\u2581over", "\u2581maintenance", "\u2581has", "\u2581not", "\u2581yet", "\u2581been", "\u2581app", "reci", "ably", "\u2581felt", ",", "\u2581but", "\u2581the", "\u2581bill", "\u2581can", "\u2581be", "\u2581seen", "\u2581on", "\u2581the", "\u2581", "horizon", "\u2581with", "\u2581", "a", "\u2581weather", "\u2581eye", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "j", "pm", "c", "\u258126", "\u2581It", "\u2581is", "\u2581difficult", "\u2581to", "\u2581objective", "ly", "\u2581say", "\u2581that", "\u2581the", "\u2581ability", "\u2581for", "\u2581the", "\u2581military", "\u2581to", "\u2581accomplish", "\u2581its", "\u2581current", "\u2581mission", "\u2581is", "\u2581diminished", ".", "\u2581We", "\u2581are", "\u2581only", "\u2581at", "\u2581the", "\u2581point", "\u2581where", "\u2581maintenance", "\u2581has", "\u2581been", "\u2581de", "fer", "red", ",", "\u2581flight", "\u2581hours", "\u2581for", "\u2581training", "\u2581have", "\u2581been", "\u2581reduced", ",", "\u2581and", "\u2581underway", "s", "\u2581for", "\u2581Naval", "\u2581ships", "\u2581have", "\u2581been", "\u2581closely", "\u2581controlled", "\u2581for", "\u2581fuel", "\u2581costs", ".", "\u2581The", "\u2581consequence", "\u2581of", "\u2581the", "\u2581Military", "\u2581being", "\u2581forced", "\u2581to", "\u2581choose", "\u2581operational", "\u2581", "tempo", "\u2581over", "\u2581maintenance", "\u2581has", "\u2581not", "\u2581yet", "\u2581been", "\u2581app", "reci", "ably", "\u2581felt", ",", "\u2581but", "\u2581the", "\u2581bill", "\u2581can", "\u2581be", "\u2581seen", "\u2581on", "\u2581the", "\u2581", "horizon", "\u2581with", "\u2581", "a", "\u2581weather", "\u2581eye", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "j", "pm", "c", "\u258126", "</m>", "\u2581It", "\u2581is", "\u2581difficult", "\u2581to", "\u2581objective", "ly", "\u2581say", "\u2581that", "\u2581the", "\u2581ability", "\u2581for", "\u2581the", "\u2581military", "\u2581to", "\u2581accomplish", "\u2581its", "\u2581current", "\u2581mission", "\u2581is", "\u2581diminished", ".", "\u2581We", "\u2581are", "\u2581only", "\u2581at", "\u2581the", "\u2581point", "\u2581where", "\u2581maintenance", "\u2581has", "\u2581been", "\u2581de", "fer", "red", ",", "\u2581flight", "\u2581hours", "\u2581for", "\u2581training", "\u2581have", "\u2581been", "\u2581reduced", ",", "\u2581and", "\u2581underway", "s", "\u2581for", "\u2581Naval", "\u2581ships", "\u2581have", "\u2581been", "\u2581closely", "\u2581controlled", "\u2581for", "\u2581fuel", "\u2581costs", ".", "\u2581The", "\u2581consequence", "\u2581of", "\u2581the", "\u2581Military", "\u2581being", "\u2581forced", "\u2581to", "\u2581choose", "\u2581operational", "\u2581", "tempo", "\u2581over", "\u2581maintenance", "\u2581has", "\u2581not", "\u2581yet", "\u2581been", "\u2581app", "reci", "ably", "\u2581felt", ",", "\u2581but", "\u2581the", "\u2581bill", "\u2581can", "\u2581be", "\u2581seen", "\u2581on", "\u2581the", "\u2581", "horizon", "\u2581with", "\u2581", "a", "\u2581weather", "\u2581eye", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 33, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 66, 67, 68, 69, 70, 71, 72, 73, 73, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 84, 85, 86, 86, 87, 88, 89, 90], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_667", "sentence": ["\u2581Gedanken", "ex", "peri", "ment", "\u2581in", "\u2581thermo", "dynamic", "s", ":", "\u2581what", "\u2581is", "\u2581wrong", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Gedanken", "ex", "peri", "ment", "\u2581in", "\u2581thermo", "dynamic", "s", ":", "\u2581what", "\u2581is", "\u2581wrong", "?", "</s>"], "target_sentence": ["\u2581Gedanken", "ex", "peri", "ment", "\u2581in", "\u2581thermo", "dynamic", "s", ":", "\u2581what", "\u2581is", "\u2581wrong", "?", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_668", "sentence": ["\u2581@", "\u2581Lake", "b", "um", "\u2581Please", "\u2581mark", "\u2581this", "\u2581answer", "\u2581as", "\u2581the", "\u2581correct", "\u2581one", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Lake", "b", "um", "\u2581Please", "\u2581mark", "\u2581this", "\u2581answer", "\u2581as", "\u2581the", "\u2581correct", "\u2581one", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Lake", "b", "um", "\u2581Please", "\u2581mark", "\u2581this", "\u2581answer", "\u2581as", "\u2581the", "\u2581correct", "\u2581one", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_669", "sentence": ["\u2581This", "\u2581is", "\u2581", "a", "\u2581good", "\u2581answer", ",", "\u2581but", "\u2581it", "\u2581would", "\u2581be", "\u2581improved", "\u2581by", "\u2581emp", "has", "izing", "\u2581the", "\u2581administration", "\u2581", "\u2019", "\u2581", "s", "\u2581reaction", "\u2581to", "\u2581the", "\u2581controversy", "\u2014", "a", "\u2581swift", "\u2581apology", "\u2581would", "\u2581have", "\u2581meant", "\u2581", "a", "\u2581", "thi", "ry", "-", "second", "\u2581story", "\u2581soon", "\u2581forgotten", ",", "\u2581with", "\u2581most", "\u2581people", "\u2581unwilling", "\u2581to", "\u2581assume", "\u2581anti", "s", "e", "mit", "is", "m", "\u2581for", "\u2581what", "\u2581*", "\u2581could", "\u2581*", "\u2581(", "\u2581", "if", "\u2581we", "'", "\u2581", "re", "\u2581being", "\u2581very", "\u2581generous", ")", "\u2581have", "\u2581been", "\u2581", "a", "\u2581mistake", ".", "\u2581But", "\u2581by", "\u2581own", "ing", "\u2581it", "\u2581as", "\u2581intentional", "\u2581and", "\u2581refus", "ing", "\u2581to", "\u2581apologize", ",", "\u2581they", "\u2581eliminated", "\u2581the", "\u2581possibility", "\u2581that", "\u2581they", "\u2581were", "\u2581being", "\u2581mis", "under", "s", "to", "o", "d", ",", "\u2581and", "\u2581indicated", "\u2581that", "\u2581it", "\u2581*", "\u2581was", "\u2581*", "\u2581intentionally", "\u2581anti", "s", "e", "mit", "ic", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581is", "\u2581", "a", "\u2581good", "\u2581answer", ",", "\u2581but", "\u2581it", "\u2581would", "\u2581be", "\u2581improved", "\u2581by", "\u2581emp", "has", "izing", "\u2581the", "\u2581administration", "\u2581", "\u2019", "\u2581", "s", "\u2581reaction", "\u2581to", "\u2581the", "\u2581controversy", "\u2014", "a", "\u2581swift", "\u2581apology", "\u2581would", "\u2581have", "\u2581meant", "\u2581", "a", "\u2581", "thi", "ry", "-", "second", "\u2581story", "\u2581soon", "\u2581forgotten", ",", "\u2581with", "\u2581most", "\u2581people", "\u2581unwilling", "\u2581to", "\u2581assume", "\u2581anti", "s", "e", "mit", "is", "m", "\u2581for", "\u2581what", "\u2581*", "\u2581could", "\u2581*", "\u2581(", "\u2581", "if", "\u2581we", "'", "\u2581", "re", "\u2581being", "\u2581very", "\u2581generous", ")", "\u2581have", "\u2581been", "\u2581", "a", "\u2581mistake", ".", "\u2581But", "\u2581by", "\u2581own", "ing", "\u2581it", "\u2581as", "\u2581intentional", "\u2581and", "\u2581refus", "ing", "\u2581to", "\u2581apologize", ",", "\u2581they", "\u2581eliminated", "\u2581the", "\u2581possibility", "\u2581that", "\u2581they", "\u2581were", "\u2581being", "\u2581mis", "under", "s", "to", "o", "d", ",", "\u2581and", "\u2581indicated", "\u2581that", "\u2581it", "\u2581*", "\u2581was", "\u2581*", "\u2581intentionally", "\u2581anti", "s", "e", "mit", "ic", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581is", "\u2581", "a", "\u2581good", "\u2581answer", ",", "\u2581but", "\u2581it", "\u2581would", "\u2581be", "\u2581improved", "\u2581by", "\u2581emp", "has", "izing", "\u2581the", "\u2581administration", "\u2581", "\u2019", "\u2581", "s", "\u2581reaction", "\u2581to", "\u2581the", "\u2581controversy", "\u2014", "a", "\u2581swift", "\u2581apology", "\u2581would", "\u2581have", "\u2581meant", "\u2581", "a", "\u2581", "thi", "ry", "-", "second", "\u2581story", "\u2581soon", "\u2581forgotten", ",", "\u2581with", "\u2581most", "\u2581people", "\u2581unwilling", "\u2581to", "\u2581assume", "\u2581anti", "s", "e", "mit", "is", "m", "\u2581for", "\u2581what", "\u2581*", "\u2581could", "\u2581*", "\u2581(", "\u2581", "if", "\u2581we", "'", "\u2581", "re", "\u2581being", "\u2581very", "\u2581generous", ")", "\u2581have", "\u2581been", "\u2581", "a", "\u2581mistake", ".", "\u2581But", "\u2581by", "\u2581own", "ing", "\u2581it", "\u2581as", "\u2581intentional", "\u2581and", "\u2581refus", "ing", "\u2581to", "\u2581apologize", ",", "\u2581they", "\u2581eliminated", "\u2581the", "\u2581possibility", "\u2581that", "\u2581they", "\u2581were", "\u2581being", "\u2581mis", "under", "s", "to", "o", "d", ",", "\u2581and", "\u2581indicated", "\u2581that", "\u2581it", "\u2581*", "\u2581was", "\u2581*", "\u2581intentionally", "\u2581anti", "s", "e", "mit", "ic", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 13, 14, 15, 15, 16, 16, 17, 18, 19, 20, 20, 20, 21, 22, 23, 24, 25, 26, 26, 27, 27, 27, 27, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 38, 38, 38, 38, 38, 39, 40, 41, 42, 43, 44, 45, 45, 46, 47, 48, 48, 49, 50, 51, 52, 53, 54, 55, 55, 56, 57, 58, 59, 60, 60, 61, 62, 63, 64, 65, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 77, 77, 77, 77, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 87, 87, 87, 87, 88, 89], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_670", "sentence": ["\u2581TV", "\u2581series", "\u2581where", "\u2581", "a", "\u2581boy", "\u2581moves", "\u2581to", "\u2581", "a", "\u2581weird", "\u2581town", "\u2581with", "\u2581an", "\u2581episode", "\u2581where", "\u2581an", "\u2581angel", "\u2581statue", "\u2581", "c", "ries", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581TV", "\u2581series", "\u2581where", "\u2581", "a", "\u2581boy", "\u2581moves", "\u2581to", "\u2581", "a", "\u2581weird", "\u2581town", "\u2581with", "\u2581an", "\u2581episode", "\u2581where", "\u2581an", "\u2581angel", "\u2581statue", "\u2581", "c", "ries", "</s>"], "target_sentence": ["\u2581TV", "\u2581series", "\u2581where", "\u2581", "a", "\u2581boy", "\u2581moves", "\u2581to", "\u2581", "a", "\u2581weird", "<m>", "\u2581town", "</m>", "\u2581with", "\u2581an", "\u2581episode", "\u2581where", "\u2581an", "\u2581angel", "\u2581statue", "\u2581", "c", "ries", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_671", "sentence": ["\u2581Would", "\u2581love", "\u2581to", "\u2581see", "\u2581this", "\u2581improved", "\u2581with", "\u2581some", "\u2581of", "\u2581those", "\u2581", "cited", "\u2581references", "\u2581and", "\u2581an", "\u2581inclusion", "\u2581of", "\u2581those", "\u2581pictures", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Would", "\u2581love", "\u2581to", "\u2581see", "\u2581this", "\u2581improved", "\u2581with", "\u2581some", "\u2581of", "\u2581those", "\u2581", "cited", "\u2581references", "\u2581and", "\u2581an", "\u2581inclusion", "\u2581of", "\u2581those", "\u2581pictures", "</s>"], "target_sentence": ["\u2581Would", "\u2581love", "<m>", "\u2581to", "</m>", "\u2581see", "\u2581this", "\u2581improved", "\u2581with", "\u2581some", "\u2581of", "\u2581those", "\u2581", "cited", "\u2581references", "\u2581and", "\u2581an", "\u2581inclusion", "\u2581of", "\u2581those", "\u2581pictures", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_672", "sentence": ["\u2581Interpret", "ation", "\u2581of", "\u2581Dy", "n", "kin", "\u2581diagram", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Interpret", "ation", "\u2581of", "\u2581Dy", "n", "kin", "\u2581diagram", "s", "</s>"], "target_sentence": ["\u2581Interpret", "ation", "\u2581of", "\u2581Dy", "n", "kin", "\u2581diagram", "s", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_673", "sentence": ["\u2581Doctor", "\u2581Who", "\u2581", "-", "\u2581How", "\u2581did", "\u2581the", "\u2581season", "\u25816", "\u2581finale", "\u2581work", "\u2581out", "?", "\u2581(", "\u2581Spo", "il", "ers", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Doctor", "\u2581Who", "\u2581", "-", "\u2581How", "\u2581did", "\u2581the", "\u2581season", "\u25816", "\u2581finale", "\u2581work", "\u2581out", "?", "\u2581(", "\u2581Spo", "il", "ers", ")", "</s>"], "target_sentence": ["<m>", "\u2581Doctor", "\u2581Who", "</m>", "\u2581", "-", "\u2581How", "\u2581did", "\u2581the", "\u2581season", "\u25816", "\u2581finale", "\u2581work", "\u2581out", "?", "\u2581(", "\u2581Spo", "il", "ers", ")", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_674", "sentence": ["\u2581This", "\u2581answer", "\u2581describes", "\u2581the", "\u2581design", "\u2581intent", "\u2581for", "\u2581the", "\u2581difference", "\u2581(", "\u2581the", "\u2581ability", "\u2581to", "\u2581block", "\u2581encrypted", "\u2581searches", ")", ".", "\u2581The", "\u2581other", "\u2581answers", "\u2581tested", "\u2581the", "\u2581functional", "\u2581difference", ".", "\u2581The", "\u2581design", "\u2581intent", "\u2581remains", "\u2581unchanged", ".", "\u2581It", "'", "\u2581", "s", "\u2581", "a", "\u2581historical", "\u2581fact", "\u2581at", "\u2581this", "\u2581point", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581answer", "\u2581describes", "\u2581the", "\u2581design", "\u2581intent", "\u2581for", "\u2581the", "\u2581difference", "\u2581(", "\u2581the", "\u2581ability", "\u2581to", "\u2581block", "\u2581encrypted", "\u2581searches", ")", ".", "\u2581The", "\u2581other", "\u2581answers", "\u2581tested", "\u2581the", "\u2581functional", "\u2581difference", ".", "\u2581The", "\u2581design", "\u2581intent", "\u2581remains", "\u2581unchanged", ".", "\u2581It", "'", "\u2581", "s", "\u2581", "a", "\u2581historical", "\u2581fact", "\u2581at", "\u2581this", "\u2581point", ".", "</s>"], "target_sentence": ["\u2581This", "\u2581answer", "\u2581describes", "\u2581the", "\u2581design", "\u2581intent", "\u2581for", "\u2581the", "\u2581difference", "\u2581(", "\u2581the", "\u2581ability", "\u2581to", "\u2581block", "\u2581encrypted", "\u2581searches", ")", ".", "\u2581The", "\u2581other", "\u2581answers", "\u2581tested", "\u2581the", "\u2581functional", "\u2581difference", ".", "\u2581The", "\u2581design", "\u2581intent", "\u2581remains", "\u2581unchanged", ".", "\u2581It", "'", "\u2581", "s", "\u2581", "a", "\u2581historical", "\u2581fact", "\u2581at", "\u2581this", "\u2581point", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 34, 35, 35, 36, 37, 38, 39, 40, 41, 42], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_675", "sentence": ["\u2581So", "\u2581the", "\u2581density", "\u2581of", "\u2581steam", "\u2581will", "\u2581naturally", "\u2581be", "\u2581less", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581So", "\u2581the", "\u2581density", "\u2581of", "\u2581steam", "\u2581will", "\u2581naturally", "\u2581be", "\u2581less", ".", "</s>"], "target_sentence": ["\u2581So", "\u2581the", "\u2581density", "\u2581of", "\u2581steam", "\u2581will", "\u2581naturally", "\u2581be", "\u2581less", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_676", "sentence": ["\u2581If", "\u2581I", "\u2581registered", "\u2581to", "\u2581vote", "\u2581in", "\u2581the", "\u2581", "nov", "\u25812016", "\u2581elections", ",", "\u2581will", "\u2581I", "\u2581also", "\u2581be", "\u2581registered", "\u2581to", "\u2581vote", "\u2581in", "\u2581proceeding", "\u2581special", "\u2581elections", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581I", "\u2581registered", "\u2581to", "\u2581vote", "\u2581in", "\u2581the", "\u2581", "nov", "\u25812016", "\u2581elections", ",", "\u2581will", "\u2581I", "\u2581also", "\u2581be", "\u2581registered", "\u2581to", "\u2581vote", "\u2581in", "\u2581proceeding", "\u2581special", "\u2581elections", "?", "</s>"], "target_sentence": ["\u2581If", "\u2581I", "\u2581registered", "\u2581to", "\u2581vote", "\u2581in", "\u2581the", "\u2581", "nov", "\u25812016", "\u2581elections", ",", "\u2581will", "\u2581I", "\u2581also", "\u2581be", "\u2581registered", "\u2581to", "\u2581vote", "\u2581in", "\u2581proceeding", "\u2581special", "\u2581elections", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_677", "sentence": ["\u2581Bern", "ou", "ll", "i", "'", "\u2581", "s", "\u2581principle", ":", "\u2581Why", "\u2581an", "\u2581increase", "\u2581in", "\u2581the", "\u2581section", "\u2581area", "\u2581in", "\u2581", "a", "\u2581", "hose", "\u2581makes", "\u2581the", "\u2581pressure", "\u2581increase", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Bern", "ou", "ll", "i", "'", "\u2581", "s", "\u2581principle", ":", "\u2581Why", "\u2581an", "\u2581increase", "\u2581in", "\u2581the", "\u2581section", "\u2581area", "\u2581in", "\u2581", "a", "\u2581", "hose", "\u2581makes", "\u2581the", "\u2581pressure", "\u2581increase", "?", "</s>"], "target_sentence": ["<m>", "\u2581Bern", "ou", "ll", "i", "</m>", "'", "\u2581", "s", "\u2581principle", ":", "\u2581Why", "\u2581an", "\u2581increase", "\u2581in", "\u2581the", "\u2581section", "\u2581area", "\u2581in", "\u2581", "a", "\u2581", "hose", "\u2581makes", "\u2581the", "\u2581pressure", "\u2581increase", "?", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_678", "sentence": ["\u2581Might", "\u2581want", "\u2581to", "\u2581note", "\u2581that", "\u2581this", "\u2581Wo", "ok", "i", "pedia", "\u2581excerpt", "\u2581seems", "\u2581to", "\u2581be", "\u2581", "sourced", "\u2581from", "\u2581", "a", "\u2581Legend", "s", "\u2581book", "\u2581that", "\u2581had", "\u2581continuity", "\u2581problems", "\u2581to", "\u2581begin", "\u2581with", ".", "\u2581Not", "\u2581sure", "\u2581what", "\u2581proper", "\u2581Canon", "\u2581sources", "\u2581are", "\u2581for", "\u2581\"", "\u2581detect", "\u2581location", "\u2581of", "\u2581hidden", "\u2581creatures", "\u2581\"", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Might", "\u2581want", "\u2581to", "\u2581note", "\u2581that", "\u2581this", "\u2581Wo", "ok", "i", "pedia", "\u2581excerpt", "\u2581seems", "\u2581to", "\u2581be", "\u2581", "sourced", "\u2581from", "\u2581", "a", "\u2581Legend", "s", "\u2581book", "\u2581that", "\u2581had", "\u2581continuity", "\u2581problems", "\u2581to", "\u2581begin", "\u2581with", ".", "\u2581Not", "\u2581sure", "\u2581what", "\u2581proper", "\u2581Canon", "\u2581sources", "\u2581are", "\u2581for", "\u2581\"", "\u2581detect", "\u2581location", "\u2581of", "\u2581hidden", "\u2581creatures", "\u2581\"", ".", "</s>"], "target_sentence": ["\u2581Might", "\u2581want", "\u2581to", "\u2581note", "\u2581that", "\u2581this", "\u2581Wo", "ok", "i", "pedia", "\u2581excerpt", "\u2581seems", "\u2581to", "\u2581be", "\u2581", "sourced", "\u2581from", "\u2581", "a", "<m>", "\u2581Legend", "s", "</m>", "\u2581book", "\u2581that", "\u2581had", "\u2581continuity", "\u2581problems", "\u2581to", "\u2581begin", "\u2581with", ".", "\u2581Not", "\u2581sure", "\u2581what", "\u2581proper", "\u2581Canon", "\u2581sources", "\u2581are", "\u2581for", "\u2581\"", "\u2581detect", "\u2581location", "\u2581of", "\u2581hidden", "\u2581creatures", "\u2581\"", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_679", "sentence": ["\u2581Did", "\u2581George", "\u2581Smile", "y", "'", "\u2581", "s", "\u2581wife", "\u2581Ann", "\u2581already", "\u2581know", "\u2581that", "\u2581Bill", "\u2581Hay", "don", "\u2581was", "\u2581", "a", "\u2581mo", "le", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Did", "\u2581George", "\u2581Smile", "y", "'", "\u2581", "s", "\u2581wife", "\u2581Ann", "\u2581already", "\u2581know", "\u2581that", "\u2581Bill", "\u2581Hay", "don", "\u2581was", "\u2581", "a", "\u2581mo", "le", "?", "</s>"], "target_sentence": ["\u2581Did", "<m>", "\u2581George", "\u2581Smile", "y", "</m>", "'", "\u2581", "s", "\u2581wife", "<m>", "\u2581Ann", "</m>", "\u2581already", "\u2581know", "\u2581that", "<m>", "\u2581Bill", "\u2581Hay", "don", "</m>", "\u2581was", "\u2581", "a", "\u2581mo", "le", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_680", "sentence": ["\u2581How", "\u2581can", "\u2581the", "\u2581European", "\u2581Union", "\u2581enforce", "\u2581the", "\u2581General", "\u2581Data", "\u2581Protection", "\u2581Regulation", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581can", "\u2581the", "\u2581European", "\u2581Union", "\u2581enforce", "\u2581the", "\u2581General", "\u2581Data", "\u2581Protection", "\u2581Regulation", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581can", "\u2581the", "<m>", "<m>", "\u2581European", "\u2581Union", "</m>", "</m>", "\u2581enforce", "\u2581the", "\u2581General", "\u2581Data", "\u2581Protection", "\u2581Regulation", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_681", "sentence": ["\u2581", "_", "\u2581\"", "\u2581", "a", "\u2581real", "\u2581", "ow", "l", "\u2581that", "\u2581had", "\u2581", "a", "\u2581little", "\u2581prior", "\u2581training", "\u2581so", "\u2581it", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581be", "\u2581scared", "\u2581away", "\u2581by", "\u2581the", "\u2581gun", "fire", "\u2581\"", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581He", "\u2581had", "\u2581heard", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581gun", "fire", "\u2581in", "\u2581the", "\u2581previous", "\u2581weeks", "\u2581so", "\u2581that", "\u2581", "he", "\u2581wouldn", "\u2581", "\u2019", "\u2581", "t", "\u2581get", "\u2581", "f", "right", "ened", "\u2581by", "\u2581it", ".", "\u2581\"", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581The", "\u2581", "ow", "l", "'", "\u2581", "s", "\u2581reaction", "\u2581to", "\u2581Vin", "n", "y", "\u2581shooting", "\u2581the", "\u2581gun", "\u2581was", "\u2581authentic", "\u2581\"", "\u2581", "_", "\u2581Was", "\u2581the", "\u2581reaction", "\u2581authentic", "\u2581or", "\u2581not", "?", "\u2581These", "\u2581quotes", "\u2581are", "\u2581contradict", "or", "y", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "_", "\u2581\"", "\u2581", "a", "\u2581real", "\u2581", "ow", "l", "\u2581that", "\u2581had", "\u2581", "a", "\u2581little", "\u2581prior", "\u2581training", "\u2581so", "\u2581it", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581be", "\u2581scared", "\u2581away", "\u2581by", "\u2581the", "\u2581gun", "fire", "\u2581\"", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581He", "\u2581had", "\u2581heard", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581gun", "fire", "\u2581in", "\u2581the", "\u2581previous", "\u2581weeks", "\u2581so", "\u2581that", "\u2581", "he", "\u2581wouldn", "\u2581", "\u2019", "\u2581", "t", "\u2581get", "\u2581", "f", "right", "ened", "\u2581by", "\u2581it", ".", "\u2581\"", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581The", "\u2581", "ow", "l", "'", "\u2581", "s", "\u2581reaction", "\u2581to", "\u2581Vin", "n", "y", "\u2581shooting", "\u2581the", "\u2581gun", "\u2581was", "\u2581authentic", "\u2581\"", "\u2581", "_", "\u2581Was", "\u2581the", "\u2581reaction", "\u2581authentic", "\u2581or", "\u2581not", "?", "\u2581These", "\u2581quotes", "\u2581are", "\u2581contradict", "or", "y", ".", "</s>"], "target_sentence": ["\u2581", "_", "\u2581\"", "\u2581", "a", "\u2581real", "\u2581", "ow", "l", "\u2581that", "\u2581had", "\u2581", "a", "\u2581little", "\u2581prior", "\u2581training", "\u2581so", "\u2581it", "\u2581would", "\u2581", "n", "'", "\u2581", "t", "\u2581be", "\u2581scared", "\u2581away", "\u2581by", "\u2581the", "\u2581gun", "fire", "\u2581\"", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581He", "\u2581had", "\u2581heard", "\u2581", "a", "\u2581lot", "\u2581of", "\u2581gun", "fire", "\u2581in", "\u2581the", "\u2581previous", "\u2581weeks", "\u2581so", "\u2581that", "\u2581", "he", "\u2581wouldn", "\u2581", "\u2019", "\u2581", "t", "\u2581get", "\u2581", "f", "right", "ened", "\u2581by", "\u2581it", ".", "\u2581\"", "\u2581", "_", "\u2581", "_", "\u2581\"", "\u2581The", "\u2581", "ow", "l", "'", "\u2581", "s", "\u2581reaction", "\u2581to", "<m>", "\u2581Vin", "n", "y", "</m>", "\u2581shooting", "\u2581the", "\u2581gun", "\u2581was", "\u2581authentic", "\u2581\"", "\u2581", "_", "\u2581Was", "\u2581the", "\u2581reaction", "\u2581authentic", "\u2581or", "\u2581not", "?", "\u2581These", "\u2581quotes", "\u2581are", "\u2581contradict", "or", "y", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 4, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 24, 25, 25, 26, 27, 28, 29, 30, 30, 31, 32, 33, 33, 34, 35, 36, 37, 38, 39, 40, 40, 41, 42, 42, 43, 43, 44, 45, 45, 45, 45, 46, 47, 48, 49, 50, 50, 51, 51, 52, 53, 54, 54, 54, 55, 56, 56, 57, 58, 59, 59, 59, 60, 61, 62, 63, 64, 65, 66, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 77, 77, 78, 79], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_682", "sentence": ["\u2581", "Apparently", "\u2581Wikipedia", "\u2581claims", "\u2581that", "\u2581", "insul", "ators", "\u2581and", "\u2581semiconductor", "s", "\u2581lack", "\u2581Fer", "m", "i", "\u2581surfaces", ".", "\u2581Qu", "o", "ting", "\u2581Wikipedia", ":", "\u2581\"", "\u2581A", "\u2581material", "\u2581", "whose", "\u2581Fer", "m", "i", "\u2581level", "\u2581falls", "\u2581in", "\u2581", "a", "\u2581gap", "\u2581between", "\u2581bands", "\u2581is", "\u2581an", "\u2581", "insul", "ator", "\u2581or", "\u2581semiconductor", "\u2581depending", "\u2581on", "\u2581the", "\u2581size", "\u2581of", "\u2581the", "\u2581band", "g", "a", "p", ".", "\u2581When", "\u2581", "a", "\u2581material", "'", "\u2581", "s", "\u2581Fer", "m", "i", "\u2581level", "\u2581falls", "\u2581in", "\u2581", "a", "\u2581band", "g", "a", "p", ",", "\u2581there", "\u2581is", "\u2581no", "\u2581Fer", "m", "i", "\u2581surface", ".", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Apparently", "\u2581Wikipedia", "\u2581claims", "\u2581that", "\u2581", "insul", "ators", "\u2581and", "\u2581semiconductor", "s", "\u2581lack", "\u2581Fer", "m", "i", "\u2581surfaces", ".", "\u2581Qu", "o", "ting", "\u2581Wikipedia", ":", "\u2581\"", "\u2581A", "\u2581material", "\u2581", "whose", "\u2581Fer", "m", "i", "\u2581level", "\u2581falls", "\u2581in", "\u2581", "a", "\u2581gap", "\u2581between", "\u2581bands", "\u2581is", "\u2581an", "\u2581", "insul", "ator", "\u2581or", "\u2581semiconductor", "\u2581depending", "\u2581on", "\u2581the", "\u2581size", "\u2581of", "\u2581the", "\u2581band", "g", "a", "p", ".", "\u2581When", "\u2581", "a", "\u2581material", "'", "\u2581", "s", "\u2581Fer", "m", "i", "\u2581level", "\u2581falls", "\u2581in", "\u2581", "a", "\u2581band", "g", "a", "p", ",", "\u2581there", "\u2581is", "\u2581no", "\u2581Fer", "m", "i", "\u2581surface", ".", "\u2581\"", "</s>"], "target_sentence": ["\u2581", "Apparently", "\u2581Wikipedia", "\u2581claims", "\u2581that", "\u2581", "insul", "ators", "\u2581and", "\u2581semiconductor", "s", "\u2581lack", "\u2581Fer", "m", "i", "\u2581surfaces", ".", "\u2581Qu", "o", "ting", "\u2581Wikipedia", ":", "\u2581\"", "\u2581A", "\u2581material", "\u2581", "whose", "\u2581Fer", "m", "i", "\u2581level", "\u2581falls", "\u2581in", "\u2581", "a", "\u2581gap", "\u2581between", "\u2581bands", "\u2581is", "\u2581an", "\u2581", "insul", "ator", "\u2581or", "\u2581semiconductor", "\u2581depending", "\u2581on", "\u2581the", "\u2581size", "\u2581of", "\u2581the", "\u2581band", "g", "a", "p", ".", "\u2581When", "\u2581", "a", "\u2581material", "'", "\u2581", "s", "\u2581Fer", "m", "i", "\u2581level", "\u2581falls", "\u2581in", "\u2581", "a", "\u2581band", "g", "a", "p", ",", "\u2581there", "\u2581is", "\u2581no", "\u2581Fer", "m", "i", "\u2581surface", ".", "\u2581\"", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 8, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 18, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 28, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 37, 37, 37, 38, 39, 40, 40, 41, 42, 43, 43, 44, 44, 44, 45, 46, 47, 48, 48, 49, 49, 49, 49, 50, 51, 52, 53, 54, 54, 54, 55, 56, 57, 58], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_683", "sentence": ["\u2581Some", "\u2581what", "about", "\u2581is", "\u2581", "t", "u", "\u2581", "quo", "que", "\u2581fall", "acy", ".", "\u2581Some", "\u2581what", "about", "\u2581is", "\u2581", "a", "\u2581reasonable", "\u2581challenge", "\u2581to", "\u2581fair", "ness", ".", "\u2581This", "\u2581post", "\u2581assume", "s", "\u2581all", "\u2581the", "\u2581former", ".", "\u2581Pretty", "\u2581much", "\u2581everyone", "\u2581across", "\u2581the", "\u2581political", "\u2581spectrum", "\u2581believes", "\u2581in", "\u2581some", "\u2581form", "\u2581of", "\u2581\"", "\u2581what", "about", "is", "m", "\u2581\"", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Some", "\u2581what", "about", "\u2581is", "\u2581", "t", "u", "\u2581", "quo", "que", "\u2581fall", "acy", ".", "\u2581Some", "\u2581what", "about", "\u2581is", "\u2581", "a", "\u2581reasonable", "\u2581challenge", "\u2581to", "\u2581fair", "ness", ".", "\u2581This", "\u2581post", "\u2581assume", "s", "\u2581all", "\u2581the", "\u2581former", ".", "\u2581Pretty", "\u2581much", "\u2581everyone", "\u2581across", "\u2581the", "\u2581political", "\u2581spectrum", "\u2581believes", "\u2581in", "\u2581some", "\u2581form", "\u2581of", "\u2581\"", "\u2581what", "about", "is", "m", "\u2581\"", ".", "</s>"], "target_sentence": ["\u2581Some", "\u2581what", "about", "\u2581is", "\u2581", "t", "u", "\u2581", "quo", "que", "\u2581fall", "acy", ".", "\u2581Some", "\u2581what", "about", "\u2581is", "\u2581", "a", "\u2581reasonable", "\u2581challenge", "\u2581to", "\u2581fair", "ness", ".", "\u2581This", "\u2581post", "\u2581assume", "s", "\u2581all", "\u2581the", "\u2581former", ".", "\u2581Pretty", "\u2581much", "\u2581everyone", "\u2581across", "\u2581the", "\u2581political", "\u2581spectrum", "\u2581believes", "\u2581in", "\u2581some", "\u2581form", "\u2581of", "\u2581\"", "\u2581what", "about", "is", "m", "\u2581\"", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 36, 36, 36, 37, 38, 39], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_684", "sentence": ["\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581see", "\u2581any", "\u2581faces", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581see", "\u2581any", "\u2581faces", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581ca", "\u2581", "n", "'", "\u2581", "t", "\u2581see", "\u2581any", "\u2581faces", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_685", "sentence": ["\u2581Why", "\u2581were", "\u2581the", "\u2581K", "ling", "on", "s", "\u2581no", "\u2581longer", "\u2581members", "\u2581of", "\u2581the", "\u2581Federation", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581were", "\u2581the", "\u2581K", "ling", "on", "s", "\u2581no", "\u2581longer", "\u2581members", "\u2581of", "\u2581the", "\u2581Federation", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581were", "\u2581the", "<m>", "<m>", "\u2581K", "ling", "on", "s", "</m>", "</m>", "\u2581no", "\u2581longer", "\u2581members", "\u2581of", "\u2581the", "<m>", "\u2581Federation", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, 2, -1, 2, -1, -1]}, {"doc_id": "emerging.test_686", "sentence": ["\u2581See", ",", "\u2581that", "'", "\u2581", "s", "\u2581part", "\u2581of", "\u2581the", "\u2581problem", ".", ".", ".", "\u2581it", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581defend", "\u2581against", "\u2581these", "\u2581attacks", ".", "\u2581In", "\u2581the", "\u2581case", "\u2581of", "\u2581", "a", "\u2581dis", "gru", "n", "t", "led", "\u2581employee", ".", ".", ".", "\u2581it", "\u2581would", "\u2581require", "\u2581them", "\u2581to", "\u2581change", "\u25811", "\u2581line", "\u2581of", "\u2581code", ".", ".", ".", "\u2581and", "\u2581the", "\u2581whole", "\u2581system", "\u2581is", "\u2581", "void", "\u2581the", "\u2581next", "\u2581time", "\u2581you", "\u2581log", "\u2581in", ".", ".", ".", "\u2581and", "\u2581in", "\u2581terms", "\u2581of", "\u2581", "e", "ve", "\u2581being", "\u2581", "able", "\u2581to", "\u2581monitor", "\u2581the", "\u2581connection", "\u2581but", "\u2581not", "\u2581change", "\u2581anything", ".", ".", ".", "\u2581that", "\u2581is", "n", "t", "\u2581prevented", "\u2581by", "\u2581there", "\u2581\"", "\u2581added", "\u2581security", "\u2581\"", ".", ".", ".", "\u2581its", "\u2581prevented", "\u2581by", "\u2581SSL", "\u2581", "/", "\u2581T", "LS", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581See", ",", "\u2581that", "'", "\u2581", "s", "\u2581part", "\u2581of", "\u2581the", "\u2581problem", ".", ".", ".", "\u2581it", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581defend", "\u2581against", "\u2581these", "\u2581attacks", ".", "\u2581In", "\u2581the", "\u2581case", "\u2581of", "\u2581", "a", "\u2581dis", "gru", "n", "t", "led", "\u2581employee", ".", ".", ".", "\u2581it", "\u2581would", "\u2581require", "\u2581them", "\u2581to", "\u2581change", "\u25811", "\u2581line", "\u2581of", "\u2581code", ".", ".", ".", "\u2581and", "\u2581the", "\u2581whole", "\u2581system", "\u2581is", "\u2581", "void", "\u2581the", "\u2581next", "\u2581time", "\u2581you", "\u2581log", "\u2581in", ".", ".", ".", "\u2581and", "\u2581in", "\u2581terms", "\u2581of", "\u2581", "e", "ve", "\u2581being", "\u2581", "able", "\u2581to", "\u2581monitor", "\u2581the", "\u2581connection", "\u2581but", "\u2581not", "\u2581change", "\u2581anything", ".", ".", ".", "\u2581that", "\u2581is", "n", "t", "\u2581prevented", "\u2581by", "\u2581there", "\u2581\"", "\u2581added", "\u2581security", "\u2581\"", ".", ".", ".", "\u2581its", "\u2581prevented", "\u2581by", "\u2581SSL", "\u2581", "/", "\u2581T", "LS", ".", "</s>"], "target_sentence": ["\u2581See", ",", "\u2581that", "'", "\u2581", "s", "\u2581part", "\u2581of", "\u2581the", "\u2581problem", ".", ".", ".", "\u2581it", "\u2581does", "\u2581", "n", "'", "\u2581", "t", "\u2581defend", "\u2581against", "\u2581these", "\u2581attacks", ".", "\u2581In", "\u2581the", "\u2581case", "\u2581of", "\u2581", "a", "\u2581dis", "gru", "n", "t", "led", "\u2581employee", ".", ".", ".", "\u2581it", "\u2581would", "\u2581require", "\u2581them", "\u2581to", "\u2581change", "\u25811", "\u2581line", "\u2581of", "\u2581code", ".", ".", ".", "\u2581and", "\u2581the", "\u2581whole", "\u2581system", "\u2581is", "\u2581", "void", "\u2581the", "\u2581next", "\u2581time", "\u2581you", "\u2581log", "\u2581in", ".", ".", ".", "\u2581and", "\u2581in", "\u2581terms", "\u2581of", "\u2581", "e", "ve", "\u2581being", "\u2581", "able", "\u2581to", "\u2581monitor", "\u2581the", "\u2581connection", "\u2581but", "\u2581not", "\u2581change", "\u2581anything", ".", ".", ".", "\u2581that", "\u2581is", "n", "t", "\u2581prevented", "\u2581by", "\u2581there", "\u2581\"", "\u2581added", "\u2581security", "\u2581\"", ".", ".", ".", "\u2581its", "\u2581prevented", "\u2581by", "\u2581SSL", "\u2581", "/", "\u2581T", "LS", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 27, 27, 27, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 64, 64, 65, 66, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 79, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 94, 95, 95, 96, 97], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_687", "sentence": ["\u2581The", "\u258122", "\u2581", "nd", "\u2581Amendment", "\u2581is", ",", "\u2581by", "\u2581definition", ",", "\u2581not", "\u2581", "a", "\u2581law", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u258122", "\u2581", "nd", "\u2581Amendment", "\u2581is", ",", "\u2581by", "\u2581definition", ",", "\u2581not", "\u2581", "a", "\u2581law", ".", "</s>"], "target_sentence": ["\u2581The", "\u258122", "\u2581", "nd", "\u2581Amendment", "\u2581is", ",", "\u2581by", "\u2581definition", ",", "\u2581not", "\u2581", "a", "\u2581law", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_688", "sentence": ["\u2581I", "\u2581have", ",", "\u2581", "a", "\u2581few", "\u2581hours", "\u2581ago", ",", "\u2581it", "\u2581only", "\u2581", "o", "ll", "ected", "\u25812", "\u2581neg", "\u2581votes", "\u2581so", "\u2581far", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581have", ",", "\u2581", "a", "\u2581few", "\u2581hours", "\u2581ago", ",", "\u2581it", "\u2581only", "\u2581", "o", "ll", "ected", "\u25812", "\u2581neg", "\u2581votes", "\u2581so", "\u2581far", "</s>"], "target_sentence": ["\u2581I", "\u2581have", ",", "\u2581", "a", "\u2581few", "\u2581hours", "\u2581ago", ",", "\u2581it", "\u2581only", "\u2581", "o", "ll", "ected", "\u25812", "\u2581neg", "\u2581votes", "\u2581so", "\u2581far", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_689", "sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581connection", "\u2581between", "\u2581the", "\u2581Fo", "uca", "ul", "t", "\u2581pe", "ndu", "lum", "\u2581and", "\u2581parallel", "\u2581transport", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581is", "\u2581the", "\u2581connection", "\u2581between", "\u2581the", "\u2581Fo", "uca", "ul", "t", "\u2581pe", "ndu", "lum", "\u2581and", "\u2581parallel", "\u2581transport", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581connection", "\u2581between", "\u2581the", "\u2581Fo", "uca", "ul", "t", "\u2581pe", "ndu", "lum", "\u2581and", "\u2581parallel", "\u2581transport", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 7, 7, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_690", "sentence": ["\u2581it", "\u2581would", "\u2581be", "\u2581very", "\u2581difficult", "\u2581for", "\u2581me", "\u2581to", "\u2581back", "\u2581up", "\u2581that", "\u2581claim", "\u2581because", "\u2581", "i", "\u2581never", "\u2581made", "\u2581it", ".", "\u2581all", "\u2581", "i", "\u2581said", "\u2581is", "\u2581that", "\u2581one", "\u2581should", "\u2581be", "\u2581prepared", "\u2581to", "\u2581evaluate", "\u2581reports", "\u2581", "/", "\u2581claims", "\u2581from", "\u2581all", "\u2581sources", ",", "\u2581including", "\u2581those", "\u2581from", "\u2581the", "\u2581", "n", "go", "s", ".", "\u2581maybe", "\u2581", "re", "-", "reading", "\u2581what", "\u2581I", "\u2581wrote", "\u2581would", "\u2581be", "\u2581helpful", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581it", "\u2581would", "\u2581be", "\u2581very", "\u2581difficult", "\u2581for", "\u2581me", "\u2581to", "\u2581back", "\u2581up", "\u2581that", "\u2581claim", "\u2581because", "\u2581", "i", "\u2581never", "\u2581made", "\u2581it", ".", "\u2581all", "\u2581", "i", "\u2581said", "\u2581is", "\u2581that", "\u2581one", "\u2581should", "\u2581be", "\u2581prepared", "\u2581to", "\u2581evaluate", "\u2581reports", "\u2581", "/", "\u2581claims", "\u2581from", "\u2581all", "\u2581sources", ",", "\u2581including", "\u2581those", "\u2581from", "\u2581the", "\u2581", "n", "go", "s", ".", "\u2581maybe", "\u2581", "re", "-", "reading", "\u2581what", "\u2581I", "\u2581wrote", "\u2581would", "\u2581be", "\u2581helpful", ".", "</s>"], "target_sentence": ["\u2581it", "\u2581would", "\u2581be", "\u2581very", "\u2581difficult", "\u2581for", "\u2581me", "\u2581to", "\u2581back", "\u2581up", "\u2581that", "\u2581claim", "\u2581because", "\u2581", "i", "\u2581never", "\u2581made", "\u2581it", ".", "\u2581all", "\u2581", "i", "\u2581said", "\u2581is", "\u2581that", "\u2581one", "\u2581should", "\u2581be", "\u2581prepared", "\u2581to", "\u2581evaluate", "\u2581reports", "\u2581", "/", "\u2581claims", "\u2581from", "\u2581all", "\u2581sources", ",", "\u2581including", "\u2581those", "\u2581from", "\u2581the", "\u2581", "n", "go", "s", ".", "\u2581maybe", "\u2581", "re", "-", "reading", "\u2581what", "\u2581I", "\u2581wrote", "\u2581would", "\u2581be", "\u2581helpful", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 40, 40, 40, 41, 42, 43, 43, 43, 43, 44, 45, 46, 47, 48, 49, 50, 51], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_691", "sentence": ["\u2581Fre", "que", "ncy", "\u2581of", "\u2581photo", "n", "\u2581and", "\u2581frequency", "\u2581of", "\u2581", "EM", "\u2581wave", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Fre", "que", "ncy", "\u2581of", "\u2581photo", "n", "\u2581and", "\u2581frequency", "\u2581of", "\u2581", "EM", "\u2581wave", "</s>"], "target_sentence": ["\u2581Fre", "que", "ncy", "\u2581of", "\u2581photo", "n", "\u2581and", "\u2581frequency", "\u2581of", "<m>", "\u2581", "EM", "</m>", "\u2581wave", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_692", "sentence": ["\u2581Potential", "\u2581HTTP", "\u2581Ho", "s", "t", "\u2581header", "\u2581attack", "\u2581from", "\u2581malicious", "\u2581IP", ",", "\u2581what", "\u2581does", "\u2581it", "\u2581mean", "\u2581in", "\u2581practical", "\u2581terms", "\u2581for", "\u2581me", "?", "\u2581Should", "\u2581I", "\u2581be", "\u2581concerned", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Potential", "\u2581HTTP", "\u2581Ho", "s", "t", "\u2581header", "\u2581attack", "\u2581from", "\u2581malicious", "\u2581IP", ",", "\u2581what", "\u2581does", "\u2581it", "\u2581mean", "\u2581in", "\u2581practical", "\u2581terms", "\u2581for", "\u2581me", "?", "\u2581Should", "\u2581I", "\u2581be", "\u2581concerned", "?", "</s>"], "target_sentence": ["\u2581Potential", "\u2581HTTP", "\u2581Ho", "s", "t", "\u2581header", "\u2581attack", "\u2581from", "\u2581malicious", "\u2581IP", ",", "\u2581what", "\u2581does", "\u2581it", "\u2581mean", "\u2581in", "\u2581practical", "\u2581terms", "\u2581for", "\u2581me", "?", "\u2581Should", "\u2581I", "\u2581be", "\u2581concerned", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_693", "sentence": ["\u2581Was", "\u2581this", "\u2581", "a", "\u2581typo", "\u2581from", "\u2581the", "\u2581table", "\u2581maker", ",", "\u2581or", "\u2581are", "\u2581other", "\u2581criteria", "\u2581taken", "\u2581into", "\u2581account", "\u2581when", "\u2581", "calculating", "\u2581the", "\u2581overall", "\u2581score", "?", "\u2581He", "'", "\u2581", "s", "\u2581also", "\u2581coincide", "n", "t", "ally", "\u2581the", "\u2581very", "\u2581first", "\u2581example", "\u2581on", "\u2581the", "\u2581page", "\u2581about", "\u2581[", "\u2581genius", "e", "s", "]", "\u2581(", "\u2581http", "://", "mar", "vel", ".", "wiki", "a", ".", "com", "/", "wiki", "/", "Cat", "ego", "ry", ":", "Gen", "i", "us", "_", "In", "tel", "lig", "ence", ")", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Was", "\u2581this", "\u2581", "a", "\u2581typo", "\u2581from", "\u2581the", "\u2581table", "\u2581maker", ",", "\u2581or", "\u2581are", "\u2581other", "\u2581criteria", "\u2581taken", "\u2581into", "\u2581account", "\u2581when", "\u2581", "calculating", "\u2581the", "\u2581overall", "\u2581score", "?", "\u2581He", "'", "\u2581", "s", "\u2581also", "\u2581coincide", "n", "t", "ally", "\u2581the", "\u2581very", "\u2581first", "\u2581example", "\u2581on", "\u2581the", "\u2581page", "\u2581about", "\u2581[", "\u2581genius", "e", "s", "]", "\u2581(", "\u2581http", "://", "mar", "vel", ".", "wiki", "a", ".", "com", "/", "wiki", "/", "Cat", "ego", "ry", ":", "Gen", "i", "us", "_", "In", "tel", "lig", "ence", ")", ".", "</s>"], "target_sentence": ["\u2581Was", "\u2581this", "\u2581", "a", "\u2581typo", "\u2581from", "\u2581the", "\u2581table", "\u2581maker", ",", "\u2581or", "\u2581are", "\u2581other", "\u2581criteria", "\u2581taken", "\u2581into", "\u2581account", "\u2581when", "\u2581", "calculating", "\u2581the", "\u2581overall", "\u2581score", "?", "\u2581He", "'", "\u2581", "s", "\u2581also", "\u2581coincide", "n", "t", "ally", "\u2581the", "\u2581very", "\u2581first", "\u2581example", "\u2581on", "\u2581the", "\u2581page", "\u2581about", "\u2581[", "\u2581genius", "e", "s", "]", "\u2581(", "\u2581http", "://", "mar", "vel", ".", "wiki", "a", ".", "com", "/", "wiki", "/", "Cat", "ego", "ry", ":", "Gen", "i", "us", "_", "In", "tel", "lig", "ence", ")", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 26, 26, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 36, 36, 37, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 41, 42], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_694", "sentence": ["\u2581Green", "s", "\u2581function", "\u2581application", "\u2581A", "bri", "kos", "o", "v", "\u2581", "-", "\u2581Q", "FT", "\u2581in", "\u2581Stat", "is", "tial", "\u2581Physics", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Green", "s", "\u2581function", "\u2581application", "\u2581A", "bri", "kos", "o", "v", "\u2581", "-", "\u2581Q", "FT", "\u2581in", "\u2581Stat", "is", "tial", "\u2581Physics", "</s>"], "target_sentence": ["\u2581Green", "s", "\u2581function", "\u2581application", "\u2581A", "bri", "kos", "o", "v", "\u2581", "-", "\u2581Q", "FT", "\u2581in", "\u2581Stat", "is", "tial", "\u2581Physics", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 3, 3, 4, 4, 5, 5, 6, 7, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_695", "sentence": ["\u2581did", "\u2581the", "\u25815", "\u2581steps", "\u2581in", "\u2581the", "\u2581link", "\u2581not", "\u2581work", "\u2581for", "\u2581you", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581did", "\u2581the", "\u25815", "\u2581steps", "\u2581in", "\u2581the", "\u2581link", "\u2581not", "\u2581work", "\u2581for", "\u2581you", "?", "</s>"], "target_sentence": ["\u2581did", "\u2581the", "\u25815", "\u2581steps", "\u2581in", "\u2581the", "\u2581link", "\u2581not", "\u2581work", "\u2581for", "\u2581you", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_696", "sentence": ["\u2581@", "\u2581S", "Q", "B", "\u2581I", "\u2581meant", "\u2581to", "\u2581say", "\u2581it", "'", "\u2581", "s", "\u2581", "NP", "\u2581hard", "\u2581", "if", "\u2581we", "\u2581solve", "\u2581the", "\u2581general", "\u2581problem", ":", "\u2581", "a", "\u2581sequence", "\u2581of", "\u2581", "n", "\u2581numbers", "\u2581and", "\u2581", "a", "\u2581number", "\u2581M", "\u2581that", "\u2581some", "\u2581sub", "set", "s", "\u2581of", "\u2581the", "\u2581numbers", "\u2581will", "\u2581meet", "\u2581or", "\u2581exceed", ".", "\u2581However", ",", "\u2581I", "\u2581believe", "\u2581I", "\u2581may", "'", "\u2581", "ve", "\u2581found", "\u2581", "a", "\u2581", "re", "curs", "ive", "\u2581approach", "\u2581that", "\u2581takes", "\u2581only", "\u2581linear", "\u2581time", ".", ".", ".", "\u2581maybe", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581S", "Q", "B", "\u2581I", "\u2581meant", "\u2581to", "\u2581say", "\u2581it", "'", "\u2581", "s", "\u2581", "NP", "\u2581hard", "\u2581", "if", "\u2581we", "\u2581solve", "\u2581the", "\u2581general", "\u2581problem", ":", "\u2581", "a", "\u2581sequence", "\u2581of", "\u2581", "n", "\u2581numbers", "\u2581and", "\u2581", "a", "\u2581number", "\u2581M", "\u2581that", "\u2581some", "\u2581sub", "set", "s", "\u2581of", "\u2581the", "\u2581numbers", "\u2581will", "\u2581meet", "\u2581or", "\u2581exceed", ".", "\u2581However", ",", "\u2581I", "\u2581believe", "\u2581I", "\u2581may", "'", "\u2581", "ve", "\u2581found", "\u2581", "a", "\u2581", "re", "curs", "ive", "\u2581approach", "\u2581that", "\u2581takes", "\u2581only", "\u2581linear", "\u2581time", ".", ".", ".", "\u2581maybe", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581S", "Q", "B", "\u2581I", "\u2581meant", "\u2581to", "\u2581say", "\u2581it", "'", "\u2581", "s", "\u2581", "NP", "\u2581hard", "\u2581", "if", "\u2581we", "\u2581solve", "\u2581the", "\u2581general", "\u2581problem", ":", "\u2581", "a", "\u2581sequence", "\u2581of", "\u2581", "n", "\u2581numbers", "\u2581and", "\u2581", "a", "\u2581number", "\u2581M", "\u2581that", "\u2581some", "\u2581sub", "set", "s", "\u2581of", "\u2581the", "\u2581numbers", "\u2581will", "\u2581meet", "\u2581or", "\u2581exceed", ".", "\u2581However", ",", "\u2581I", "\u2581believe", "\u2581I", "\u2581may", "'", "\u2581", "ve", "\u2581found", "\u2581", "a", "\u2581", "re", "curs", "ive", "\u2581approach", "\u2581that", "\u2581takes", "\u2581only", "\u2581linear", "\u2581time", ".", ".", ".", "\u2581maybe", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 21, 22, 23, 24, 24, 25, 26, 27, 28, 29, 29, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 45, 46, 47, 47, 48, 48, 48, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_697", "sentence": ["\u2581Who", "\u2581", "\u2019", "\u2581", "s", "\u2581the", "\u2581villain", "\u2581in", "\u2581the", "\u2581Power", "less", "\u2581trailer", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Who", "\u2581", "\u2019", "\u2581", "s", "\u2581the", "\u2581villain", "\u2581in", "\u2581the", "\u2581Power", "less", "\u2581trailer", "?", "</s>"], "target_sentence": ["\u2581Who", "\u2581", "\u2019", "\u2581", "s", "\u2581the", "\u2581villain", "\u2581in", "\u2581the", "<m>", "<m>", "\u2581Power", "less", "</m>", "</m>", "\u2581trailer", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1]}, {"doc_id": "emerging.test_698", "sentence": ["\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581someone", "\u2581make", "\u2581Li", "ly", "\u2581and", "\u2581James", "\u2581Potter", "\u2581portrait", "s", "\u2581like", "\u2581the", "\u2581dead", "\u2581Ho", "g", "war", "t", "s", "\u2581Head", "master", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581someone", "\u2581make", "\u2581Li", "ly", "\u2581and", "\u2581James", "\u2581Potter", "\u2581portrait", "s", "\u2581like", "\u2581the", "\u2581dead", "\u2581Ho", "g", "war", "t", "s", "\u2581Head", "master", "s", "?", "</s>"], "target_sentence": ["\u2581Why", "\u2581did", "\u2581", "n", "'", "\u2581", "t", "\u2581someone", "\u2581make", "<m>", "\u2581Li", "ly", "</m>", "\u2581and", "<m>", "\u2581James", "\u2581Potter", "</m>", "\u2581portrait", "s", "\u2581like", "\u2581the", "\u2581dead", "\u2581Ho", "g", "war", "t", "s", "\u2581Head", "master", "s", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 15, 15, 15, 15, 16, 16, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_699", "sentence": ["\u2581How", "\u2581long", "\u2581until", "l", "\u2581Qui", "d", "d", "itch", "\u2581is", "\u2581played", "\u2581properly", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581long", "\u2581until", "l", "\u2581Qui", "d", "d", "itch", "\u2581is", "\u2581played", "\u2581properly", "?", "</s>"], "target_sentence": ["\u2581How", "\u2581long", "\u2581until", "l", "\u2581Qui", "d", "d", "itch", "\u2581is", "\u2581played", "\u2581properly", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_700", "sentence": ["\u2581Being", "\u2581insult", "ing", "\u2581and", "\u2581rude", ",", "\u2581because", "\u2581your", "\u2581tribe", "\u2581de", "mon", "ize", "s", "\u2581politicians", "\u2581", "whose", "\u2581beliefs", "\u2581differ", "\u2581with", "\u2581your", "s", "\u2581is", "\u2581not", "\u2581\"", "\u2581the", "\u2581truth", "\u2581\"", ".", "\u2581You", "\u2581can", "\u2581have", "\u2581", "a", "\u2581civil", "\u2581discussion", "\u2581without", "\u2581being", "\u2581strictly", "\u2581PC", ".", "\u2581When", "\u2581you", "\u2581use", "\u2581pe", "jor", "ative", "s", "\u2581like", "\u2581that", ",", "\u2581it", "\u2581diminish", "e", "s", "\u2581the", "\u2581effectiveness", "\u2581of", "\u2581your", "\u2581argument", "\u2581for", "\u2581anyone", "\u2581who", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581already", "\u2581inclined", "\u2581to", "\u2581agree", "\u2581with", "\u2581it", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Being", "\u2581insult", "ing", "\u2581and", "\u2581rude", ",", "\u2581because", "\u2581your", "\u2581tribe", "\u2581de", "mon", "ize", "s", "\u2581politicians", "\u2581", "whose", "\u2581beliefs", "\u2581differ", "\u2581with", "\u2581your", "s", "\u2581is", "\u2581not", "\u2581\"", "\u2581the", "\u2581truth", "\u2581\"", ".", "\u2581You", "\u2581can", "\u2581have", "\u2581", "a", "\u2581civil", "\u2581discussion", "\u2581without", "\u2581being", "\u2581strictly", "\u2581PC", ".", "\u2581When", "\u2581you", "\u2581use", "\u2581pe", "jor", "ative", "s", "\u2581like", "\u2581that", ",", "\u2581it", "\u2581diminish", "e", "s", "\u2581the", "\u2581effectiveness", "\u2581of", "\u2581your", "\u2581argument", "\u2581for", "\u2581anyone", "\u2581who", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581already", "\u2581inclined", "\u2581to", "\u2581agree", "\u2581with", "\u2581it", ".", "</s>"], "target_sentence": ["\u2581Being", "\u2581insult", "ing", "\u2581and", "\u2581rude", ",", "\u2581because", "\u2581your", "\u2581tribe", "\u2581de", "mon", "ize", "s", "\u2581politicians", "\u2581", "whose", "\u2581beliefs", "\u2581differ", "\u2581with", "\u2581your", "s", "\u2581is", "\u2581not", "\u2581\"", "\u2581the", "\u2581truth", "\u2581\"", ".", "\u2581You", "\u2581can", "\u2581have", "\u2581", "a", "\u2581civil", "\u2581discussion", "\u2581without", "\u2581being", "\u2581strictly", "\u2581PC", ".", "\u2581When", "\u2581you", "\u2581use", "\u2581pe", "jor", "ative", "s", "\u2581like", "\u2581that", ",", "\u2581it", "\u2581diminish", "e", "s", "\u2581the", "\u2581effectiveness", "\u2581of", "\u2581your", "\u2581argument", "\u2581for", "\u2581anyone", "\u2581who", "\u2581is", "\u2581", "n", "'", "\u2581", "t", "\u2581already", "\u2581inclined", "\u2581to", "\u2581agree", "\u2581with", "\u2581it", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 9, 10, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 36, 36, 36, 37, 38, 39, 40, 41, 41, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 51, 52, 53, 53, 54, 55, 56, 57, 58, 59, 60, 61], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_701", "sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581significance", "\u2581of", "\u2581but", "t", "ock", "s", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581is", "\u2581the", "\u2581significance", "\u2581of", "\u2581but", "t", "ock", "s", "?", "</s>"], "target_sentence": ["\u2581What", "\u2581is", "\u2581the", "\u2581significance", "\u2581of", "\u2581but", "t", "ock", "s", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_702", "sentence": ["\u2581You", "\u2581get", "\u2581what", "\u2581you", "\u2581accept", ".", "\u2581If", "\u2581you", "\u2581set", "\u2581high", "\u2581standards", "\u2581your", "\u2581employees", "\u2581will", "\u2581rise", "\u2581to", "\u2581the", "\u2581challenge", ".", "\u2581#", "\u2581small", "biz", "\u2581https", "://", "t", ".", "co", "/", "B", "1", "A", "x", "Z", "p", "T", "x", "p", "B", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581get", "\u2581what", "\u2581you", "\u2581accept", ".", "\u2581If", "\u2581you", "\u2581set", "\u2581high", "\u2581standards", "\u2581your", "\u2581employees", "\u2581will", "\u2581rise", "\u2581to", "\u2581the", "\u2581challenge", ".", "\u2581#", "\u2581small", "biz", "\u2581https", "://", "t", ".", "co", "/", "B", "1", "A", "x", "Z", "p", "T", "x", "p", "B", "</s>"], "target_sentence": ["\u2581You", "\u2581get", "\u2581what", "\u2581you", "\u2581accept", ".", "\u2581If", "\u2581you", "\u2581set", "\u2581high", "\u2581standards", "\u2581your", "\u2581employees", "\u2581will", "\u2581rise", "\u2581to", "\u2581the", "\u2581challenge", ".", "\u2581#", "\u2581small", "biz", "\u2581https", "://", "t", ".", "co", "/", "B", "1", "A", "x", "Z", "p", "T", "x", "p", "B", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_703", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ba", "a", "by", "y", "le", "x", ":", "\u2581", "rap", "e", ",", "\u2581in", "c", "est", ",", "\u2581financial", "\u2581issues", ",", "\u2581health", "\u2581issues", ",", "\u2581the", "\u2581millions", "\u2581of", "\u2581children", "\u2581that", "\u2581are", "\u2581already", "\u2581put", "\u2581up", "\u2581for", "\u2581adoption", "\u2581that", "\u2581", "d", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ba", "a", "by", "y", "le", "x", ":", "\u2581", "rap", "e", ",", "\u2581in", "c", "est", ",", "\u2581financial", "\u2581issues", ",", "\u2581health", "\u2581issues", ",", "\u2581the", "\u2581millions", "\u2581of", "\u2581children", "\u2581that", "\u2581are", "\u2581already", "\u2581put", "\u2581up", "\u2581for", "\u2581adoption", "\u2581that", "\u2581", "d", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581ba", "a", "by", "y", "le", "x", ":", "\u2581", "rap", "e", ",", "\u2581in", "c", "est", ",", "\u2581financial", "\u2581issues", ",", "\u2581health", "\u2581issues", ",", "\u2581the", "\u2581millions", "\u2581of", "\u2581children", "\u2581that", "\u2581are", "\u2581already", "\u2581put", "\u2581up", "\u2581for", "\u2581adoption", "\u2581that", "\u2581", "d", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_704", "sentence": ["\u2581EP", "\u25818", ":", "\u2581@", "\u2581", "Y", "ung", "B", "ang", "\u25819", "54", "\u2581\"", "\u2581I", "\u2581Jump", "e", "d", "\u2581off", "\u2581the", "\u2581porch", "\u2581in", "\u2581the", "\u25818", "\u2581", "th", "\u2581or", "\u25819", "\u2581", "th", "\u2581grade", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "n", "SE", "q", "j", "A", "l", "4", "O", "8", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581EP", "\u25818", ":", "\u2581@", "\u2581", "Y", "ung", "B", "ang", "\u25819", "54", "\u2581\"", "\u2581I", "\u2581Jump", "e", "d", "\u2581off", "\u2581the", "\u2581porch", "\u2581in", "\u2581the", "\u25818", "\u2581", "th", "\u2581or", "\u25819", "\u2581", "th", "\u2581grade", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "n", "SE", "q", "j", "A", "l", "4", "O", "8", "</s>"], "target_sentence": ["\u2581EP", "\u25818", ":", "\u2581@", "\u2581", "Y", "ung", "B", "ang", "\u25819", "54", "\u2581\"", "\u2581I", "\u2581Jump", "e", "d", "\u2581off", "\u2581the", "\u2581porch", "\u2581in", "\u2581the", "\u25818", "\u2581", "th", "\u2581or", "\u25819", "\u2581", "th", "\u2581grade", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "n", "SE", "q", "j", "A", "l", "4", "O", "8", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 5, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_705", "sentence": ["\u2581", "RT", "\u2581@", "\u2581so", "your", "e", "like", "that", ":", "\u2581write", "\u2581honestly", "\u2581to", "\u2581yourself", "\u2581or", "\u2581don", "'", "\u2581", "t", "\u2581waste", "\u2581the", "\u2581damn", "\u2581time", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581so", "your", "e", "like", "that", ":", "\u2581write", "\u2581honestly", "\u2581to", "\u2581yourself", "\u2581or", "\u2581don", "'", "\u2581", "t", "\u2581waste", "\u2581the", "\u2581damn", "\u2581time", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581so", "your", "e", "like", "that", "</m>", ":", "\u2581write", "\u2581honestly", "\u2581to", "\u2581yourself", "\u2581or", "\u2581don", "'", "\u2581", "t", "\u2581waste", "\u2581the", "\u2581damn", "\u2581time", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_706", "sentence": ["\u2581Local", "izing", "\u2581Ya", "k", "uza", "\u2581", "0", "\u2581was", "\u2581about", "\u2581", "bala", "ncing", "\u2581clarity", "\u2581and", "\u2581authenticity", ":", "\u2581https", "://", "t", ".", "co", "/", "S", "5", "p", "U", "l", "p", "N", "w", "T", "3", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Local", "izing", "\u2581Ya", "k", "uza", "\u2581", "0", "\u2581was", "\u2581about", "\u2581", "bala", "ncing", "\u2581clarity", "\u2581and", "\u2581authenticity", ":", "\u2581https", "://", "t", ".", "co", "/", "S", "5", "p", "U", "l", "p", "N", "w", "T", "3", "</s>"], "target_sentence": ["\u2581Local", "izing", "<m>", "<m>", "<m>", "\u2581Ya", "k", "uza", "</m>", "\u2581", "0", "</m>", "</m>", "\u2581was", "\u2581about", "\u2581", "bala", "ncing", "\u2581clarity", "\u2581and", "\u2581authenticity", ":", "\u2581https", "://", "t", ".", "co", "/", "S", "5", "p", "U", "l", "p", "N", "w", "T", "3", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 2, 1, 0, -1, -1, -1, 0, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_707", "sentence": ["\u2581There", "\u2581is", "\u2581pleasure", "\u2581in", "\u2581the", "\u2581path", "less", "\u2581wood", "s", "\u2581#", "\u2581Kal", "up", "e", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581There", "\u2581is", "\u2581pleasure", "\u2581in", "\u2581the", "\u2581path", "less", "\u2581wood", "s", "\u2581#", "\u2581Kal", "up", "e", "y", "</s>"], "target_sentence": ["\u2581There", "\u2581is", "\u2581pleasure", "\u2581in", "\u2581the", "\u2581path", "less", "<m>", "\u2581wood", "s", "</m>", "\u2581#", "<m>", "\u2581Kal", "up", "e", "y", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 6, 7, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, 1, -1, -1, -1, -1, 1, -1]}, {"doc_id": "emerging.test_708", "sentence": ["\u2581#", "\u2581", "s", "ex", "\u2581slave", "\u2581sites", "\u2581girl", "\u2581uses", "\u2581", "ur", "inal", "\u2581por", "n", "\u2581https", "://", "t", ".", "co", "/", "h", "r", "o", "X", "O", "j", "t", "y", "e", "m", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581", "s", "ex", "\u2581slave", "\u2581sites", "\u2581girl", "\u2581uses", "\u2581", "ur", "inal", "\u2581por", "n", "\u2581https", "://", "t", ".", "co", "/", "h", "r", "o", "X", "O", "j", "t", "y", "e", "m", "</s>"], "target_sentence": ["\u2581#", "\u2581", "s", "ex", "\u2581slave", "\u2581sites", "\u2581girl", "\u2581uses", "\u2581", "ur", "inal", "\u2581por", "n", "\u2581https", "://", "t", ".", "co", "/", "h", "r", "o", "X", "O", "j", "t", "y", "e", "m", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_709", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "o", "m", "s", "b", "l", "v", "r", ":", "\u2581for", "\u2581myself", ",", "\u2581", "a", "\u2581heart", ".", "\u2581https", "://", "t", ".", "co", "/", "l", "3", "H", "k", "7", "p", "WE", "5", "g", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "o", "m", "s", "b", "l", "v", "r", ":", "\u2581for", "\u2581myself", ",", "\u2581", "a", "\u2581heart", ".", "\u2581https", "://", "t", ".", "co", "/", "l", "3", "H", "k", "7", "p", "WE", "5", "g", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "o", "m", "s", "b", "l", "v", "r", ":", "\u2581for", "\u2581myself", ",", "\u2581", "a", "\u2581heart", ".", "\u2581https", "://", "t", ".", "co", "/", "l", "3", "H", "k", "7", "p", "WE", "5", "g", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_710", "sentence": ["\u2581@", "\u2581skip", "s", "y", "\u2581", "_", "\u2581", "l", "\u2581Right", "?", "!", "\u2581I", "\u2581went", "\u2581to", "\u2581take", "\u2581", "a", "\u2581shower", "\u2581", "&", "\u2581amp", ";", "\u2581head", "\u2581to", "\u2581bed", ".", "\u2581My", "\u2581phone", "\u2581was", "\u2581blow", "ing", "\u2581up", ".", "\u2581I", "\u2581was", "\u2581like", ".", ".", "\u2581", "w", "th", "\u2581is", "\u2581happening", "?", "\u2581The", "n", "\u2581", "boo", "y", "a", "!", "\u2581Hit", "\u2581that", "\u2581", "quot", "a", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581skip", "s", "y", "\u2581", "_", "\u2581", "l", "\u2581Right", "?", "!", "\u2581I", "\u2581went", "\u2581to", "\u2581take", "\u2581", "a", "\u2581shower", "\u2581", "&", "\u2581amp", ";", "\u2581head", "\u2581to", "\u2581bed", ".", "\u2581My", "\u2581phone", "\u2581was", "\u2581blow", "ing", "\u2581up", ".", "\u2581I", "\u2581was", "\u2581like", ".", ".", "\u2581", "w", "th", "\u2581is", "\u2581happening", "?", "\u2581The", "n", "\u2581", "boo", "y", "a", "!", "\u2581Hit", "\u2581that", "\u2581", "quot", "a", "!", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581skip", "s", "y", "</m>", "\u2581", "_", "\u2581", "l", "\u2581Right", "?", "!", "\u2581I", "\u2581went", "\u2581to", "\u2581take", "\u2581", "a", "\u2581shower", "\u2581", "&", "\u2581amp", ";", "\u2581head", "\u2581to", "\u2581bed", ".", "\u2581My", "\u2581phone", "\u2581was", "\u2581blow", "ing", "\u2581up", ".", "\u2581I", "\u2581was", "\u2581like", ".", ".", "\u2581", "w", "th", "\u2581is", "\u2581happening", "?", "\u2581The", "n", "\u2581", "boo", "y", "a", "!", "\u2581Hit", "\u2581that", "\u2581", "quot", "a", "!", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 31, 31, 32, 33, 34, 35, 35, 36, 36, 36, 36, 37, 38, 39, 40, 40, 40, 41, 42], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_711", "sentence": ["\u2581Wait", "list", "\u2581#", "\u25813", "\u2581but", "\u2581doubt", "\u2581I", "'", "\u2581", "ll", "\u2581get", "\u2581in", "\u2581the", "\u2581class", ".", "\u2581Low", "\u2581key", "\u2581not", "\u2581even", "\u2581mad", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Wait", "list", "\u2581#", "\u25813", "\u2581but", "\u2581doubt", "\u2581I", "'", "\u2581", "ll", "\u2581get", "\u2581in", "\u2581the", "\u2581class", ".", "\u2581Low", "\u2581key", "\u2581not", "\u2581even", "\u2581mad", "</s>"], "target_sentence": ["\u2581Wait", "list", "\u2581#", "\u25813", "\u2581but", "\u2581doubt", "\u2581I", "'", "\u2581", "ll", "\u2581get", "\u2581in", "\u2581the", "\u2581class", ".", "\u2581Low", "\u2581key", "\u2581not", "\u2581even", "\u2581mad", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_712", "sentence": ["'", "'", "\u2581Ladies", "\u2581And", "\u2581Gentle", "men", ",", "\u2581We", "\u2581Bring", "\u2581To", "\u2581You", "\u2581The", "\u2581Girl", "\u2581With", "\u2581The", "\u2581Big", "g", "est", "\u2581Va", "gina", "\u2581In", "\u2581The", "\u2581World", "\u2581https", "://", "t", ".", "co", "/6", "J", "Y", "h", "3", "I", "d", "7", "B", "W", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "'", "'", "\u2581Ladies", "\u2581And", "\u2581Gentle", "men", ",", "\u2581We", "\u2581Bring", "\u2581To", "\u2581You", "\u2581The", "\u2581Girl", "\u2581With", "\u2581The", "\u2581Big", "g", "est", "\u2581Va", "gina", "\u2581In", "\u2581The", "\u2581World", "\u2581https", "://", "t", ".", "co", "/6", "J", "Y", "h", "3", "I", "d", "7", "B", "W", "</s>"], "target_sentence": ["'", "'", "\u2581Ladies", "\u2581And", "\u2581Gentle", "men", ",", "\u2581We", "\u2581Bring", "\u2581To", "\u2581You", "\u2581The", "\u2581Girl", "\u2581With", "\u2581The", "\u2581Big", "g", "est", "\u2581Va", "gina", "\u2581In", "\u2581The", "\u2581World", "\u2581https", "://", "t", ".", "co", "/6", "J", "Y", "h", "3", "I", "d", "7", "B", "W", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 15, 15, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_713", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "hey", "im", "be", "e", ":", "\u2581@", "\u2581Stra", "u", "berry", "J", "am", "\u2581S", "HE", "\u2581IS", "\u2581D", "EAD", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "hey", "im", "be", "e", ":", "\u2581@", "\u2581Stra", "u", "berry", "J", "am", "\u2581S", "HE", "\u2581IS", "\u2581D", "EAD", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "hey", "im", "be", "e", "</m>", ":", "\u2581@", "<m>", "\u2581Stra", "u", "berry", "J", "am", "</m>", "\u2581S", "HE", "\u2581IS", "\u2581D", "EAD", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 5, 5, 6, 6, 7, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_714", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "y", "ung", "J", "\u25813", ":", "\u2581I", "\u2581just", "\u2581need", "\u2581my", "\u2581diploma", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "y", "ung", "J", "\u25813", ":", "\u2581I", "\u2581just", "\u2581need", "\u2581my", "\u2581diploma", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "y", "ung", "J", "\u25813", ":", "\u2581I", "\u2581just", "\u2581need", "\u2581my", "\u2581diploma", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_715", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "59", "y", "6", "v", "du", "V", "l", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "59", "y", "6", "v", "du", "V", "l", "w", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "59", "y", "6", "v", "du", "V", "l", "w", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_716", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "LL", "X", "f", "24", "DH", "s", "h", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "LL", "X", "f", "24", "DH", "s", "h", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "LL", "X", "f", "24", "DH", "s", "h", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_717", "sentence": ["\u2581Mom", "\u2581still", "\u2581", "defending", "\u2581the", "\u2581Trump", "\u2581", "s", "exist", "\u2581racist", "\u2581line", ".", "\u2581Work", "e", "d", "\u2581wonder", "s", "\u2581on", "\u2581November", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Mom", "\u2581still", "\u2581", "defending", "\u2581the", "\u2581Trump", "\u2581", "s", "exist", "\u2581racist", "\u2581line", ".", "\u2581Work", "e", "d", "\u2581wonder", "s", "\u2581on", "\u2581November", ".", "</s>"], "target_sentence": ["\u2581Mom", "\u2581still", "\u2581", "defending", "\u2581the", "<m>", "\u2581Trump", "</m>", "\u2581", "s", "exist", "\u2581racist", "\u2581line", ".", "\u2581Work", "e", "d", "\u2581wonder", "s", "\u2581on", "\u2581November", ".", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 9, 9, 10, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_718", "sentence": ["\u2581Children", "'", "\u2581", "s", "\u2581of", "\u2581A", "\u2581is", "\u2581hiring", "!", "\u2581Audi", "ologist", "\u2581", "-", "\u2581B", "\u2581#", "\u2581jobs", "\u2581in", "\u2581", "BI", "RM", "ING", "HAM", "\u2581Apply", "\u2581today", "\u2581https", "://", "t", ".", "co", "/", "w", "KW", "q", "B", "2", "ix", "2", "I", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Children", "'", "\u2581", "s", "\u2581of", "\u2581A", "\u2581is", "\u2581hiring", "!", "\u2581Audi", "ologist", "\u2581", "-", "\u2581B", "\u2581#", "\u2581jobs", "\u2581in", "\u2581", "BI", "RM", "ING", "HAM", "\u2581Apply", "\u2581today", "\u2581https", "://", "t", ".", "co", "/", "w", "KW", "q", "B", "2", "ix", "2", "I", "</s>"], "target_sentence": ["\u2581Children", "'", "\u2581", "s", "\u2581of", "\u2581A", "\u2581is", "\u2581hiring", "!", "<m>", "<m>", "\u2581Audi", "ologist", "</m>", "</m>", "\u2581", "-", "\u2581B", "\u2581#", "\u2581jobs", "\u2581in", "<m>", "\u2581", "BI", "RM", "ING", "HAM", "</m>", "\u2581Apply", "\u2581today", "\u2581https", "://", "t", ".", "co", "/", "w", "KW", "q", "B", "2", "ix", "2", "I", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_719", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "i", "C", "le", "ver", "O", "f", "ficial", ":", "\u2581#", "\u2581Giveaway", "\u2581time", "!", "\u2581", "RT", "\u2581", "&", "\u2581amp", ";", "\u2581Follow", "\u2581us", "\u2581for", "\u2581", "a", "\u2581chance", "\u2581to", "\u2581#", "\u2581", "WIN", "\u2581", "a", "\u2581fitness", "\u2581gift", "\u2581basket", "\u2581full", "\u2581of", "\u2581", "i", "C", "le", "ver", "\u2581products", "!", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "i", "C", "le", "ver", "O", "f", "ficial", ":", "\u2581#", "\u2581Giveaway", "\u2581time", "!", "\u2581", "RT", "\u2581", "&", "\u2581amp", ";", "\u2581Follow", "\u2581us", "\u2581for", "\u2581", "a", "\u2581chance", "\u2581to", "\u2581#", "\u2581", "WIN", "\u2581", "a", "\u2581fitness", "\u2581gift", "\u2581basket", "\u2581full", "\u2581of", "\u2581", "i", "C", "le", "ver", "\u2581products", "!", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "i", "C", "le", "ver", "O", "f", "ficial", ":", "\u2581#", "\u2581Giveaway", "\u2581time", "!", "\u2581", "RT", "\u2581", "&", "\u2581amp", ";", "\u2581Follow", "\u2581us", "\u2581for", "\u2581", "a", "\u2581chance", "\u2581to", "<m>", "\u2581#", "\u2581", "WIN", "\u2581", "a", "\u2581fitness", "\u2581gift", "\u2581basket", "</m>", "\u2581full", "\u2581of", "<m>", "\u2581", "i", "C", "le", "ver", "</m>", "\u2581products", "!", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 19, 20, 20, 21, 22, 23, 24, 25, 26, 26, 26, 26, 26, 27, 28, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_720", "sentence": ["\u2581#", "\u2581adult", "\u2581learning", "\u2581grant", "\u2581china", "\u2581", "teen", "\u2581", "x", "xx", "\u2581https", "://", "t", ".", "co", "/", "j", "n", "P", "q", "o", "l", "Z", "g", "SP", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581adult", "\u2581learning", "\u2581grant", "\u2581china", "\u2581", "teen", "\u2581", "x", "xx", "\u2581https", "://", "t", ".", "co", "/", "j", "n", "P", "q", "o", "l", "Z", "g", "SP", "</s>"], "target_sentence": ["\u2581#", "\u2581adult", "\u2581learning", "\u2581grant", "<m>", "\u2581china", "</m>", "\u2581", "teen", "\u2581", "x", "xx", "\u2581https", "://", "t", ".", "co", "/", "j", "n", "P", "q", "o", "l", "Z", "g", "SP", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_721", "sentence": ["\u2581Celebrate", "\u2581Burn", "s", "\u2581Night", "\u2581with", "\u2581the", "\u2581Bobby", "\u2581Burn", "s", "\u2581cocktail", "\u2581https", "://", "t", ".", "co", "/", "V", "N", "g", "f", "Th", "J", "N", "2", "V", "\u2581#", "\u2581whisk", "y", "\u2581#", "\u2581cocktails", "\u2581#", "\u2581home", "bar", "t", "ender", "\u2581#", "\u2581cocktails", "at", "home", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Celebrate", "\u2581Burn", "s", "\u2581Night", "\u2581with", "\u2581the", "\u2581Bobby", "\u2581Burn", "s", "\u2581cocktail", "\u2581https", "://", "t", ".", "co", "/", "V", "N", "g", "f", "Th", "J", "N", "2", "V", "\u2581#", "\u2581whisk", "y", "\u2581#", "\u2581cocktails", "\u2581#", "\u2581home", "bar", "t", "ender", "\u2581#", "\u2581cocktails", "at", "home", "</s>"], "target_sentence": ["\u2581Celebrate", "\u2581Burn", "s", "\u2581Night", "\u2581with", "\u2581the", "<m>", "\u2581Bobby", "\u2581Burn", "s", "</m>", "\u2581cocktail", "\u2581https", "://", "t", ".", "co", "/", "V", "N", "g", "f", "Th", "J", "N", "2", "V", "\u2581#", "\u2581whisk", "y", "\u2581#", "\u2581cocktails", "\u2581#", "\u2581home", "bar", "t", "ender", "\u2581#", "\u2581cocktails", "at", "home", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10, 11, 12, 13, 14, 14, 14, 14, 15, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_722", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "c", "I", "its", ":", "\u2581Being", "\u2581sexual", "ly", "\u2581frustrated", "\u2581is", "\u2581the", "\u2581worst", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "c", "I", "its", ":", "\u2581Being", "\u2581sexual", "ly", "\u2581frustrated", "\u2581is", "\u2581the", "\u2581worst", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "c", "I", "its", ":", "\u2581Being", "\u2581sexual", "ly", "\u2581frustrated", "\u2581is", "\u2581the", "\u2581worst", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_723", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Cre", "e", "p", "B", "J", ":", "\u2581Wow", "!", "!", "\u2581See", "\u2581thru", "\u2581leg", "ging", "s", "\u2581are", "\u2581awesome", "\u2581https", "://", "t", ".", "co", "/", "Y", "PS", "u", "F", "6", "G", "g", "V", "m", "\u2581via", "\u2581@", "\u2581Se", "x", "y", "S", "ight", "s", "\u2581@", "\u2581Se", "x", "y", "C", "re", "e", "p", "s", "\u2581@", "\u2581Cre", "e", "p", "S", "hot", "s", "Live", "\u2581https", "://", "t", ".", "co", "/", "0", "T", "w", "au", "VE", "T", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Cre", "e", "p", "B", "J", ":", "\u2581Wow", "!", "!", "\u2581See", "\u2581thru", "\u2581leg", "ging", "s", "\u2581are", "\u2581awesome", "\u2581https", "://", "t", ".", "co", "/", "Y", "PS", "u", "F", "6", "G", "g", "V", "m", "\u2581via", "\u2581@", "\u2581Se", "x", "y", "S", "ight", "s", "\u2581@", "\u2581Se", "x", "y", "C", "re", "e", "p", "s", "\u2581@", "\u2581Cre", "e", "p", "S", "hot", "s", "Live", "\u2581https", "://", "t", ".", "co", "/", "0", "T", "w", "au", "VE", "T", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Cre", "e", "p", "B", "J", ":", "\u2581Wow", "!", "!", "\u2581See", "\u2581thru", "\u2581leg", "ging", "s", "\u2581are", "\u2581awesome", "\u2581https", "://", "t", ".", "co", "/", "Y", "PS", "u", "F", "6", "G", "g", "V", "m", "\u2581via", "\u2581@", "\u2581Se", "x", "y", "S", "ight", "s", "\u2581@", "\u2581Se", "x", "y", "C", "re", "e", "p", "s", "\u2581@", "\u2581Cre", "e", "p", "S", "hot", "s", "Live", "\u2581https", "://", "t", ".", "co", "/", "0", "T", "w", "au", "VE", "T", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14, 15, 15, 15, 15, 15, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_724", "sentence": ["\u2581Just", "\u2581posted", "\u2581", "a", "\u2581photo", "\u2581https", "://", "t", ".", "co", "/", "m", "i", "0", "k", "w", "H", "p", "0", "v", "l", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Just", "\u2581posted", "\u2581", "a", "\u2581photo", "\u2581https", "://", "t", ".", "co", "/", "m", "i", "0", "k", "w", "H", "p", "0", "v", "l", "</s>"], "target_sentence": ["\u2581Just", "\u2581posted", "\u2581", "a", "\u2581photo", "\u2581https", "://", "t", ".", "co", "/", "m", "i", "0", "k", "w", "H", "p", "0", "v", "l", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_725", "sentence": ["\u2581Legal", "\u2581Assistant", "\u2581Location", ":", "\u2581Los", "\u2581Angeles", "\u2581https", "://", "t", ".", "co", "/", "k", "RA", "q", "m", "0", "L", "i", "K", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Legal", "\u2581Assistant", "\u2581Location", ":", "\u2581Los", "\u2581Angeles", "\u2581https", "://", "t", ".", "co", "/", "k", "RA", "q", "m", "0", "L", "i", "K", "7", "</s>"], "target_sentence": ["\u2581Legal", "\u2581Assistant", "\u2581Location", ":", "<m>", "\u2581Los", "\u2581Angeles", "</m>", "\u2581https", "://", "t", ".", "co", "/", "k", "RA", "q", "m", "0", "L", "i", "K", "7", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_726", "sentence": ["\u2581O", "MB", "\u2581nominee", "\u2581Mick", "\u2581Mul", "va", "ney", "\u2581wants", "\u2581changes", "\u2581to", "\u2581Social", "\u2581Security", ",", "\u2581Medicare", "\u2581https", "://", "t", ".", "co", "/4", "N", "d", "B", "d", "M", "X", "SC", "3", "\u2581via", "\u2581@", "\u2581", "WS", "J", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581O", "MB", "\u2581nominee", "\u2581Mick", "\u2581Mul", "va", "ney", "\u2581wants", "\u2581changes", "\u2581to", "\u2581Social", "\u2581Security", ",", "\u2581Medicare", "\u2581https", "://", "t", ".", "co", "/4", "N", "d", "B", "d", "M", "X", "SC", "3", "\u2581via", "\u2581@", "\u2581", "WS", "J", "</s>"], "target_sentence": ["\u2581O", "MB", "\u2581nominee", "<m>", "\u2581Mick", "\u2581Mul", "va", "ney", "</m>", "\u2581wants", "\u2581changes", "\u2581to", "\u2581Social", "\u2581Security", ",", "<m>", "<m>", "\u2581Medicare", "</m>", "</m>", "\u2581https", "://", "t", ".", "co", "/4", "N", "d", "B", "d", "M", "X", "SC", "3", "\u2581via", "\u2581@", "\u2581", "WS", "J", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, 2, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_727", "sentence": ["\u2581https", "://", "t", ".", "co", "/3", "C", "q", "Q", "HL", "w", "4", "J", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/3", "C", "q", "Q", "HL", "w", "4", "J", "7", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/3", "C", "q", "Q", "HL", "w", "4", "J", "7", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_728", "sentence": ["\u2581Show", "\u2581H", "N", ":", "\u2581Hi", "b", "\u2581", "\u2014", "\u2581", "a", "\u2581bio", "nic", "\u2581", "c", "y", "cada", "les", ",", "\u2581pre", "co", "c", "i", "ously", "\u2581in", "can", "ted", "\u2581in", "\u2581U", "mple", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Show", "\u2581H", "N", ":", "\u2581Hi", "b", "\u2581", "\u2014", "\u2581", "a", "\u2581bio", "nic", "\u2581", "c", "y", "cada", "les", ",", "\u2581pre", "co", "c", "i", "ously", "\u2581in", "can", "ted", "\u2581in", "\u2581U", "mple", ".", "</s>"], "target_sentence": ["\u2581Show", "\u2581H", "N", ":", "\u2581Hi", "b", "\u2581", "\u2014", "\u2581", "a", "\u2581bio", "nic", "\u2581", "c", "y", "cada", "les", ",", "\u2581pre", "co", "c", "i", "ously", "\u2581in", "can", "ted", "\u2581in", "\u2581U", "mple", ".", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 7, 7, 7, 8, 9, 9, 9, 9, 9, 10, 10, 10, 11, 12, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_729", "sentence": ["\u2581", "RT", "\u2581@", "\u2581G", "wyn", "stone", ":", "\u2581Beautiful", "\u2581", "carved", "\u2581pup", "s", "\u2581are", "\u2581sitting", "\u2581pretty", "\u2581as", "\u2581they", "\u2581", "d", "angle", "\u2581from", "\u2581your", "\u2581ears", ".", "\u2581Just", "\u2581add", "\u2581to", "\u2581your", "\u2581cart", "\u2581and", "\u2581", "t", "\u2581https", "://", "t", ".", "co", "/", "OB", "IG", "o", "O", "p", "w", "k", "I", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581G", "wyn", "stone", ":", "\u2581Beautiful", "\u2581", "carved", "\u2581pup", "s", "\u2581are", "\u2581sitting", "\u2581pretty", "\u2581as", "\u2581they", "\u2581", "d", "angle", "\u2581from", "\u2581your", "\u2581ears", ".", "\u2581Just", "\u2581add", "\u2581to", "\u2581your", "\u2581cart", "\u2581and", "\u2581", "t", "\u2581https", "://", "t", ".", "co", "/", "OB", "IG", "o", "O", "p", "w", "k", "I", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "<m>", "\u2581G", "wyn", "stone", "</m>", "</m>", ":", "\u2581Beautiful", "\u2581", "carved", "\u2581pup", "s", "\u2581are", "\u2581sitting", "\u2581pretty", "\u2581as", "\u2581they", "\u2581", "d", "angle", "\u2581from", "\u2581your", "\u2581ears", ".", "\u2581Just", "\u2581add", "\u2581to", "\u2581your", "\u2581cart", "\u2581and", "\u2581", "t", "\u2581https", "://", "t", ".", "co", "/", "OB", "IG", "o", "O", "p", "w", "k", "I", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_730", "sentence": ["\u2581to", "\u2581", "com", "\u2581fo", "me", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581to", "\u2581", "com", "\u2581fo", "me", "</s>"], "target_sentence": ["\u2581to", "\u2581", "com", "\u2581fo", "me", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_731", "sentence": ["\u2581If", "\u2581", "KI", "TT", "\u2581has", "\u2581all", "\u2581the", "\u2581features", "\u2581of", "\u2581the", "\u2581show", ".", ".", "\u2581The", "n", "\u2581without", "\u2581", "a", "\u2581doubt", "\u2581its", "\u2581Kit", "t", ".", ".", ".", "\u2581But", "\u2581", "if", "\u2581its", "\u2581just", "\u2581appearance", "\u2581the", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "64", "E", "X", "6", "k", "t", "z", "A", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581", "KI", "TT", "\u2581has", "\u2581all", "\u2581the", "\u2581features", "\u2581of", "\u2581the", "\u2581show", ".", ".", "\u2581The", "n", "\u2581without", "\u2581", "a", "\u2581doubt", "\u2581its", "\u2581Kit", "t", ".", ".", ".", "\u2581But", "\u2581", "if", "\u2581its", "\u2581just", "\u2581appearance", "\u2581the", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "64", "E", "X", "6", "k", "t", "z", "A", "a", "</s>"], "target_sentence": ["\u2581If", "<m>", "\u2581", "KI", "TT", "</m>", "\u2581has", "\u2581all", "\u2581the", "\u2581features", "\u2581of", "\u2581the", "\u2581show", ".", ".", "\u2581The", "n", "\u2581without", "\u2581", "a", "\u2581doubt", "\u2581its", "\u2581Kit", "t", ".", ".", ".", "\u2581But", "\u2581", "if", "\u2581its", "\u2581just", "\u2581appearance", "\u2581the", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "64", "E", "X", "6", "k", "t", "z", "A", "a", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 26, 27, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_732", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "b", "w", "echt", ":", "\u2581Rachel", ":", "\u2581Audrey", ",", "\u2581I", "\u2581love", "\u2581you", ".", "\u2581Audrey", "\u2581(", "\u25812", "\u2581", "y", "r", "s", "\u2581old", ")", ":", "\u2581I", "\u2581no", "\u2581love", "\u2581you", "!", "\u2581Rachel", ":", "\u2581Well", ",", "\u2581that", "\u2581makes", "\u2581me", "\u2581sad", ".", "\u2581Audrey", ":", "\u2581C", "ry", "!", "\u2581C", "ry", "\u2581like", "\u2581", "a", "\u2581baby", "\u2581cr", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "b", "w", "echt", ":", "\u2581Rachel", ":", "\u2581Audrey", ",", "\u2581I", "\u2581love", "\u2581you", ".", "\u2581Audrey", "\u2581(", "\u25812", "\u2581", "y", "r", "s", "\u2581old", ")", ":", "\u2581I", "\u2581no", "\u2581love", "\u2581you", "!", "\u2581Rachel", ":", "\u2581Well", ",", "\u2581that", "\u2581makes", "\u2581me", "\u2581sad", ".", "\u2581Audrey", ":", "\u2581C", "ry", "!", "\u2581C", "ry", "\u2581like", "\u2581", "a", "\u2581baby", "\u2581cr", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "b", "w", "echt", ":", "<m>", "\u2581Rachel", "</m>", ":", "<m>", "\u2581Audrey", "</m>", ",", "\u2581I", "\u2581love", "\u2581you", ".", "<m>", "\u2581Audrey", "</m>", "\u2581(", "\u25812", "\u2581", "y", "r", "s", "\u2581old", ")", ":", "\u2581I", "\u2581no", "\u2581love", "\u2581you", "!", "<m>", "\u2581Rachel", "</m>", ":", "\u2581Well", ",", "\u2581that", "\u2581makes", "\u2581me", "\u2581sad", ".", "<m>", "\u2581Audrey", "</m>", ":", "\u2581C", "ry", "!", "\u2581C", "ry", "\u2581like", "\u2581", "a", "\u2581baby", "\u2581cr", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 36, 37, 37, 38, 39, 39, 40, 41, 42, 42, 43], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, 1, -1, 1, -1, -1, -1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_733", "sentence": ["\u2581@", "\u2581Uber", "matik", "\u2581Anti", "\u2581fasci", "s", "t", "\u2581", "r", "acco", "on", "s", "\u2581are", "\u2581", "a", "\u2581thing", "\u2581I", "\u2581can", "\u2581dig", "\u2581", "\ud83d\udc4c", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Uber", "matik", "\u2581Anti", "\u2581fasci", "s", "t", "\u2581", "r", "acco", "on", "s", "\u2581are", "\u2581", "a", "\u2581thing", "\u2581I", "\u2581can", "\u2581dig", "\u2581", "\ud83d\udc4c", "</s>"], "target_sentence": ["\u2581@", "\u2581Uber", "matik", "<m>", "\u2581Anti", "\u2581fasci", "s", "t", "</m>", "<m>", "\u2581", "r", "acco", "on", "s", "</m>", "\u2581are", "\u2581", "a", "\u2581thing", "\u2581I", "\u2581can", "\u2581dig", "\u2581", "\ud83d\udc4c", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_734", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "j", "ello", "m", "boot", "y", "\u25814", ":", "\u2581my", "\u2581heart", "\u2581is", "\u2581beyond", "\u2581happy", "\u2581right", "\u2581now", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "j", "ello", "m", "boot", "y", "\u25814", ":", "\u2581my", "\u2581heart", "\u2581is", "\u2581beyond", "\u2581happy", "\u2581right", "\u2581now", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "j", "ello", "m", "boot", "y", "</m>", "\u25814", ":", "\u2581my", "\u2581heart", "\u2581is", "\u2581beyond", "\u2581happy", "\u2581right", "\u2581now", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_735", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Carol", "S", "an", "kar", ":", "\u2581\u201c", "\u2581The", "\u2581Conf", "ide", "nce", "\u2581Fact", "or", "\u2581for", "\u2581#", "\u2581Women", ":", "\u2581#", "\u2581Equal", "pay", "\u2581is", "\u2581important", ",", "\u2581especially", "\u2581for", "\u2581#", "\u2581girls", "\u2581", "\u201d", "\u2581https", "://", "t", ".", "co", "/", "M", "f", "k", "U", "0", "Q", "L", "H", "s", "0", ".", "\u2581@", "\u2581girls", "rock", "c", "l", "t", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Carol", "S", "an", "kar", ":", "\u2581\u201c", "\u2581The", "\u2581Conf", "ide", "nce", "\u2581Fact", "or", "\u2581for", "\u2581#", "\u2581Women", ":", "\u2581#", "\u2581Equal", "pay", "\u2581is", "\u2581important", ",", "\u2581especially", "\u2581for", "\u2581#", "\u2581girls", "\u2581", "\u201d", "\u2581https", "://", "t", ".", "co", "/", "M", "f", "k", "U", "0", "Q", "L", "H", "s", "0", ".", "\u2581@", "\u2581girls", "rock", "c", "l", "t", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Carol", "S", "an", "kar", ":", "\u2581\u201c", "\u2581The", "\u2581Conf", "ide", "nce", "\u2581Fact", "or", "\u2581for", "\u2581#", "\u2581Women", ":", "\u2581#", "\u2581Equal", "pay", "\u2581is", "\u2581important", ",", "\u2581especially", "\u2581for", "\u2581#", "\u2581girls", "\u2581", "\u201d", "\u2581https", "://", "t", ".", "co", "/", "M", "f", "k", "U", "0", "Q", "L", "H", "s", "0", ".", "\u2581@", "\u2581girls", "rock", "c", "l", "t", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 24, 25, 25, 25, 25, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_736", "sentence": ["\u2581Be", "\u2581someone", "\u2581who", "\u2581makes", "\u2581time", "\u2581for", "\u2581", "a", "\u2581new", "\u2581goal", "\u2581even", "\u2581though", "\u2581the", "\u2581last", "\u25811", ",", "\u25812", ",", "\u2581and", "\u2581or", "\u25813", "\u2581", "r", "d", "\u25811", "\u2581fell", "\u2581through", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Be", "\u2581someone", "\u2581who", "\u2581makes", "\u2581time", "\u2581for", "\u2581", "a", "\u2581new", "\u2581goal", "\u2581even", "\u2581though", "\u2581the", "\u2581last", "\u25811", ",", "\u25812", ",", "\u2581and", "\u2581or", "\u25813", "\u2581", "r", "d", "\u25811", "\u2581fell", "\u2581through", ".", "</s>"], "target_sentence": ["\u2581Be", "\u2581someone", "\u2581who", "\u2581makes", "\u2581time", "\u2581for", "\u2581", "a", "\u2581new", "\u2581goal", "\u2581even", "\u2581though", "\u2581the", "\u2581last", "\u25811", ",", "\u25812", ",", "\u2581and", "\u2581or", "\u25813", "\u2581", "r", "d", "\u25811", "\u2581fell", "\u2581through", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_737", "sentence": ["\u2581@", "\u2581Mi", "zan", "in", "Mag", "ic", "\u2581Since", "\u2581you", "\u2581weren", "'", "\u2581", "t", "\u2581looking", ".", "\u2581", "\ud83d\ude0a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Mi", "zan", "in", "Mag", "ic", "\u2581Since", "\u2581you", "\u2581weren", "'", "\u2581", "t", "\u2581looking", ".", "\u2581", "\ud83d\ude0a", "</s>"], "target_sentence": ["\u2581@", "\u2581Mi", "zan", "in", "Mag", "ic", "\u2581Since", "\u2581you", "\u2581weren", "'", "\u2581", "t", "\u2581looking", ".", "\u2581", "\ud83d\ude0a", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_738", "sentence": ["\u2581Don", "'", "\u2581", "t", "\u2581judge", "\u2581", "a", "\u2581tea", "\u2581by", "\u2581its", "\u2581packaging", "\u2581#", "\u2581tea", "\u2581https", "://", "t", ".", "co", "/", "s", "5", "c", "D", "7", "c", "F", "X", "F", "2", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Don", "'", "\u2581", "t", "\u2581judge", "\u2581", "a", "\u2581tea", "\u2581by", "\u2581its", "\u2581packaging", "\u2581#", "\u2581tea", "\u2581https", "://", "t", ".", "co", "/", "s", "5", "c", "D", "7", "c", "F", "X", "F", "2", "</s>"], "target_sentence": ["\u2581Don", "'", "\u2581", "t", "\u2581judge", "\u2581", "a", "\u2581tea", "\u2581by", "\u2581its", "\u2581packaging", "\u2581#", "\u2581tea", "\u2581https", "://", "t", ".", "co", "/", "s", "5", "c", "D", "7", "c", "F", "X", "F", "2", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_739", "sentence": ["\u2581@", "\u2581", "r", "c", "ava", "\u2581only", "\u2581", "if", "\u2581his", "\u2581$", "\u258113", "\u2581", "MM", "\u2581is", "\u2581holding", "\u2581up", "\u2581FO", "\u2581from", "\u2581spending", "\u2581on", "\u2581bull", "pen", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "r", "c", "ava", "\u2581only", "\u2581", "if", "\u2581his", "\u2581$", "\u258113", "\u2581", "MM", "\u2581is", "\u2581holding", "\u2581up", "\u2581FO", "\u2581from", "\u2581spending", "\u2581on", "\u2581bull", "pen", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581", "r", "c", "ava", "\u2581only", "\u2581", "if", "\u2581his", "\u2581$", "\u258113", "\u2581", "MM", "\u2581is", "\u2581holding", "\u2581up", "\u2581FO", "\u2581from", "\u2581spending", "\u2581on", "\u2581bull", "pen", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_740", "sentence": ["\u2581L", "RT", "\u2581why", "\u2581is", "\u2581nobody", "\u2581talking", "\u2581about", "\u2581Pro", "mp", "to", "'", "\u2581", "s", "\u2581official", "\u2581Ro", "en", "\u2581belt", "?", "\u2581https", "://", "t", ".", "co", "/", "m", "U", "s", "Y", "f", "1", "A", "VR", "3", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581L", "RT", "\u2581why", "\u2581is", "\u2581nobody", "\u2581talking", "\u2581about", "\u2581Pro", "mp", "to", "'", "\u2581", "s", "\u2581official", "\u2581Ro", "en", "\u2581belt", "?", "\u2581https", "://", "t", ".", "co", "/", "m", "U", "s", "Y", "f", "1", "A", "VR", "3", "</s>"], "target_sentence": ["<m>", "\u2581L", "RT", "</m>", "\u2581why", "\u2581is", "\u2581nobody", "\u2581talking", "\u2581about", "<m>", "<m>", "\u2581Pro", "mp", "to", "</m>", "</m>", "'", "\u2581", "s", "\u2581official", "\u2581Ro", "en", "\u2581belt", "?", "\u2581https", "://", "t", ".", "co", "/", "m", "U", "s", "Y", "f", "1", "A", "VR", "3", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, 2, 1, -1, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_741", "sentence": ["\u2581", "RT", "\u2581@", "\u2581its", "life", "though", "t", ":", "\u2581Before", "\u2581you", "\u2581pray", ",", "\u2581believe", ".", "\u2581Before", "\u2581you", "\u2581speak", ",", "\u2581listen", ".", "\u2581Before", "\u2581you", "\u2581spend", ",", "\u2581earn", ".", "\u2581Before", "\u2581you", "\u2581quit", ",", "\u2581try", ".", "\u2581Before", "\u2581you", "\u2581die", ",", "\u2581live", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581its", "life", "though", "t", ":", "\u2581Before", "\u2581you", "\u2581pray", ",", "\u2581believe", ".", "\u2581Before", "\u2581you", "\u2581speak", ",", "\u2581listen", ".", "\u2581Before", "\u2581you", "\u2581spend", ",", "\u2581earn", ".", "\u2581Before", "\u2581you", "\u2581quit", ",", "\u2581try", ".", "\u2581Before", "\u2581you", "\u2581die", ",", "\u2581live", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581its", "life", "though", "t", "</m>", ":", "\u2581Before", "\u2581you", "\u2581pray", ",", "\u2581believe", ".", "\u2581Before", "\u2581you", "\u2581speak", ",", "\u2581listen", ".", "\u2581Before", "\u2581you", "\u2581spend", ",", "\u2581earn", ".", "\u2581Before", "\u2581you", "\u2581quit", ",", "\u2581try", ".", "\u2581Before", "\u2581you", "\u2581die", ",", "\u2581live", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_742", "sentence": ["\u2581How", "\u2581to", "\u2581use", "\u2581the", "\u2581technology", "\u2581you", "\u2581have", "\u2581to", "\u2581recruit", "\u2581the", "\u2581best", "\u2581agents", "\u2581realtor", "\u2581news", "\u2581https", "://", "t", ".", "co", "/", "j", "b", "V", "v", "Y", "8", "z", "O", "e", "d", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581to", "\u2581use", "\u2581the", "\u2581technology", "\u2581you", "\u2581have", "\u2581to", "\u2581recruit", "\u2581the", "\u2581best", "\u2581agents", "\u2581realtor", "\u2581news", "\u2581https", "://", "t", ".", "co", "/", "j", "b", "V", "v", "Y", "8", "z", "O", "e", "d", "</s>"], "target_sentence": ["\u2581How", "\u2581to", "\u2581use", "\u2581the", "\u2581technology", "\u2581you", "\u2581have", "\u2581to", "\u2581recruit", "\u2581the", "\u2581best", "\u2581agents", "\u2581realtor", "\u2581news", "\u2581https", "://", "t", ".", "co", "/", "j", "b", "V", "v", "Y", "8", "z", "O", "e", "d", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_743", "sentence": ["\u2581Daily", "\u2581Audio", "\u2581Bible", "\u2581Program", "\u2581is", "\u2581starting", "\u2581now", "!", "\u2581Listen", "\u2581live", "\u2581here", ":", "\u2581https", "://", "t", ".", "co", "/", "J", "v", "W", "x", "U", "2", "I", "g", "A", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Daily", "\u2581Audio", "\u2581Bible", "\u2581Program", "\u2581is", "\u2581starting", "\u2581now", "!", "\u2581Listen", "\u2581live", "\u2581here", ":", "\u2581https", "://", "t", ".", "co", "/", "J", "v", "W", "x", "U", "2", "I", "g", "A", "y", "</s>"], "target_sentence": ["<m>", "\u2581Daily", "\u2581Audio", "\u2581Bible", "\u2581Program", "</m>", "\u2581is", "\u2581starting", "\u2581now", "!", "\u2581Listen", "\u2581live", "\u2581here", ":", "\u2581https", "://", "t", ".", "co", "/", "J", "v", "W", "x", "U", "2", "I", "g", "A", "y", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_744", "sentence": ["\u2581@", "\u2581Cal", "free", "zy", "\u2581how", "\u2581the", "\u2581act", "\u2581on", "\u2581", "tinde", "r", "\u2581", "v", "s", "\u2581how", "\u2581they", "\u2581are", "\u2581in", "\u2581real", "\u2581life", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Cal", "free", "zy", "\u2581how", "\u2581the", "\u2581act", "\u2581on", "\u2581", "tinde", "r", "\u2581", "v", "s", "\u2581how", "\u2581they", "\u2581are", "\u2581in", "\u2581real", "\u2581life", "</s>"], "target_sentence": ["\u2581@", "\u2581Cal", "free", "zy", "\u2581how", "\u2581the", "\u2581act", "\u2581on", "<m>", "<m>", "\u2581", "tinde", "r", "</m>", "</m>", "\u2581", "v", "s", "\u2581how", "\u2581they", "\u2581are", "\u2581in", "\u2581real", "\u2581life", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_745", "sentence": ["\u2581Devon", "port", ":", "\u2581", "-", "\u2581the", "\u2581current", "\u2581temp", "\u2581is", "\u258123", ".", "\u2581", "0", "\u2581", "\u00b0", "\u2581C", "\u2581|", "\u2581wind", "\u2581speed", "\u2581", "0", ".", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581|", "\u2581gust", "ing", "\u2581", "0", ".", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581|", "\u2581rain", "\u2581today", "\u2581", "0", ".", "\u2581", "0", "\u2581", "mm", "\u2581|", "\u2581https", "://", "t", ".", "co", "/", "L", "8", "X", "w", "x", "d", "2", "i", "z", "S", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Devon", "port", ":", "\u2581", "-", "\u2581the", "\u2581current", "\u2581temp", "\u2581is", "\u258123", ".", "\u2581", "0", "\u2581", "\u00b0", "\u2581C", "\u2581|", "\u2581wind", "\u2581speed", "\u2581", "0", ".", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581|", "\u2581gust", "ing", "\u2581", "0", ".", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581|", "\u2581rain", "\u2581today", "\u2581", "0", ".", "\u2581", "0", "\u2581", "mm", "\u2581|", "\u2581https", "://", "t", ".", "co", "/", "L", "8", "X", "w", "x", "d", "2", "i", "z", "S", "</s>"], "target_sentence": ["<m>", "\u2581Devon", "port", "</m>", ":", "\u2581", "-", "\u2581the", "\u2581current", "\u2581temp", "\u2581is", "\u258123", ".", "\u2581", "0", "\u2581", "\u00b0", "\u2581C", "\u2581|", "\u2581wind", "\u2581speed", "\u2581", "0", ".", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581|", "\u2581gust", "ing", "\u2581", "0", ".", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581|", "\u2581rain", "\u2581today", "\u2581", "0", ".", "\u2581", "0", "\u2581", "mm", "\u2581|", "\u2581https", "://", "t", ".", "co", "/", "L", "8", "X", "w", "x", "d", "2", "i", "z", "S", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 11, 12, 13, 14, 15, 15, 16, 17, 17, 18, 19, 19, 20, 20, 21, 22, 22, 23, 23, 24, 25, 25, 26, 27, 27, 28, 28, 29, 30, 31, 32, 32, 33, 34, 34, 35, 35, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38], "ent_type_sequence": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_746", "sentence": ["\u2581@", "\u2581F", "ANG", "IR", "L", "OVER", "LO", "AD", "\u2581but", "\u2581I", "\u2581do", "\u2581", "\ud83d\ude04", "\u2581once", "\u2581they", "'", "\u2581", "re", "\u2581in", "\u2581stock", "\u2581online", ".", ".", ".", "\u2581I", "'", "\u2581", "ll", "\u2581", "DM", "\u2581you", "\u2581", "\ud83d\ude0e", "\u2581you", "\u2581DE", "SER", "VE", "\u2581", "a", "\u2581Clark", "e", "\u2581as", "\u2581", "a", "\u2581token", "\u2581for", "\u2581being", "\u2581", "a", "\u2581sweet", "he", "art", "\u2581", "\ud83d\ude0a", "\u2581", "\ud83d\udc95", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581F", "ANG", "IR", "L", "OVER", "LO", "AD", "\u2581but", "\u2581I", "\u2581do", "\u2581", "\ud83d\ude04", "\u2581once", "\u2581they", "'", "\u2581", "re", "\u2581in", "\u2581stock", "\u2581online", ".", ".", ".", "\u2581I", "'", "\u2581", "ll", "\u2581", "DM", "\u2581you", "\u2581", "\ud83d\ude0e", "\u2581you", "\u2581DE", "SER", "VE", "\u2581", "a", "\u2581Clark", "e", "\u2581as", "\u2581", "a", "\u2581token", "\u2581for", "\u2581being", "\u2581", "a", "\u2581sweet", "he", "art", "\u2581", "\ud83d\ude0a", "\u2581", "\ud83d\udc95", "</s>"], "target_sentence": ["\u2581@", "\u2581F", "ANG", "IR", "L", "OVER", "LO", "AD", "\u2581but", "\u2581I", "\u2581do", "\u2581", "\ud83d\ude04", "\u2581once", "\u2581they", "'", "\u2581", "re", "\u2581in", "\u2581stock", "\u2581online", ".", ".", ".", "\u2581I", "'", "\u2581", "ll", "\u2581", "DM", "\u2581you", "\u2581", "\ud83d\ude0e", "\u2581you", "\u2581DE", "SER", "VE", "\u2581", "a", "<m>", "<m>", "\u2581Clark", "e", "</m>", "</m>", "\u2581as", "\u2581", "a", "\u2581token", "\u2581for", "\u2581being", "\u2581", "a", "\u2581sweet", "he", "art", "\u2581", "\ud83d\ude0a", "\u2581", "\ud83d\udc95", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 19, 20, 21, 21, 22, 23, 23, 23, 24, 24, 25, 25, 26, 27, 27, 28, 29, 30, 31, 31, 32, 32, 32, 33, 33, 34, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_747", "sentence": ["\u2581K", "elli", "'", "\u2581", "s", "\u2581Cardio", "\u2581Kick", "box", "ing", "\u2581Work", "out", "\u2581", "-", "\u2581Max", "\u2581Cal", "ori", "e", "\u2581Burn", "\u2581Work", "out", "\u2581with", "\u2581no", "\u2581Equipment", "\u2581#", "\u2581fitness", "b", "l", "ender", "\u2581https", "://", "t", ".", "co", "/", "d", "f", "66", "J", "Q", "r", "q", "e", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581K", "elli", "'", "\u2581", "s", "\u2581Cardio", "\u2581Kick", "box", "ing", "\u2581Work", "out", "\u2581", "-", "\u2581Max", "\u2581Cal", "ori", "e", "\u2581Burn", "\u2581Work", "out", "\u2581with", "\u2581no", "\u2581Equipment", "\u2581#", "\u2581fitness", "b", "l", "ender", "\u2581https", "://", "t", ".", "co", "/", "d", "f", "66", "J", "Q", "r", "q", "e", "M", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581K", "elli", "</m>", "'", "\u2581", "s", "\u2581Cardio", "\u2581Kick", "box", "ing", "\u2581Work", "out", "</m>", "\u2581", "-", "<m>", "\u2581Max", "\u2581Cal", "ori", "e", "\u2581Burn", "\u2581Work", "out", "\u2581with", "\u2581no", "\u2581Equipment", "</m>", "\u2581#", "\u2581fitness", "b", "l", "ender", "\u2581https", "://", "t", ".", "co", "/", "d", "f", "66", "J", "Q", "r", "q", "e", "M", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 4, 4, 5, 5, 6, 6, 7, 8, 8, 8, 9, 10, 10, 11, 12, 13, 14, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_748", "sentence": ["\u258128", "\u2581#", "\u2581Information", "S", "e", "cur", "ity", "\u2581Resources", "\u2581Some", "\u2581Information", "\u2581Security", "\u2581Leader", "s", "\u2581C", "ry", "\u2581Out", "\u2581About", ".", "\u2581Please", "\u2581Re", "t", "we", "e", "t", "\u2581https", "://", "t", ".", "co", "/", "B", "CP", "t", "9", "V", "63", "o", "p", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u258128", "\u2581#", "\u2581Information", "S", "e", "cur", "ity", "\u2581Resources", "\u2581Some", "\u2581Information", "\u2581Security", "\u2581Leader", "s", "\u2581C", "ry", "\u2581Out", "\u2581About", ".", "\u2581Please", "\u2581Re", "t", "we", "e", "t", "\u2581https", "://", "t", ".", "co", "/", "B", "CP", "t", "9", "V", "63", "o", "p", "</s>"], "target_sentence": ["\u258128", "\u2581#", "\u2581Information", "S", "e", "cur", "ity", "\u2581Resources", "\u2581Some", "\u2581Information", "\u2581Security", "\u2581Leader", "s", "\u2581C", "ry", "\u2581Out", "\u2581About", ".", "\u2581Please", "\u2581Re", "t", "we", "e", "t", "\u2581https", "://", "t", ".", "co", "/", "B", "CP", "t", "9", "V", "63", "o", "p", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_749", "sentence": ["\u2581This", "\u2581kids", "\u2581will", "\u2581love", "\u2581making", "\u2581this", "\u2581", "e", "rupt", "ing", "\u2581volcano", "\u2581https", "://", "t", ".", "co", "/", "AT", "hem", "Y", "U", "u", "U", "f", "\u2581https", "://", "t", ".", "co", "/", "g", "3", "PR", "3", "PC", "0", "E", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581kids", "\u2581will", "\u2581love", "\u2581making", "\u2581this", "\u2581", "e", "rupt", "ing", "\u2581volcano", "\u2581https", "://", "t", ".", "co", "/", "AT", "hem", "Y", "U", "u", "U", "f", "\u2581https", "://", "t", ".", "co", "/", "g", "3", "PR", "3", "PC", "0", "E", "a", "</s>"], "target_sentence": ["\u2581This", "\u2581kids", "\u2581will", "\u2581love", "\u2581making", "\u2581this", "\u2581", "e", "rupt", "ing", "\u2581volcano", "\u2581https", "://", "t", ".", "co", "/", "AT", "hem", "Y", "U", "u", "U", "f", "\u2581https", "://", "t", ".", "co", "/", "g", "3", "PR", "3", "PC", "0", "E", "a", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_750", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "glo", "f", "u", "I", ":", "\u2581Some", "\u2581people", "\u2581will", "\u2581have", "\u2581to", "\u2581learn", "\u2581how", "\u2581to", "\u2581appreciate", "\u2581you", "\u2581by", "\u2581losing", "\u2581you", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "glo", "f", "u", "I", ":", "\u2581Some", "\u2581people", "\u2581will", "\u2581have", "\u2581to", "\u2581learn", "\u2581how", "\u2581to", "\u2581appreciate", "\u2581you", "\u2581by", "\u2581losing", "\u2581you", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "glo", "f", "u", "I", ":", "\u2581Some", "\u2581people", "\u2581will", "\u2581have", "\u2581to", "\u2581learn", "\u2581how", "\u2581to", "\u2581appreciate", "\u2581you", "\u2581by", "\u2581losing", "\u2581you", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_751", "sentence": ["\u2581@", "\u2581Alice", "s", "d", "r", "The", "\u2581@", "\u2581Cur", "ious", "Cat", "M", "e", "\u2581", "KK", "KK", "KK", "KK", "KK", "\u2581", "v", "c", "\u2581me", "\u2581am", "a", ",", "\u2581", "e", "u", "\u2581", "t", "e", "\u2581avis", "o", "\u2581", "q", "nd", "\u2581", "e", "u", "\u2581for", "\u2581", "f", "z", "r", "\u2581", "pra", "\u2581", "v", "c", "\u2581", "en", "tra", "r", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Alice", "s", "d", "r", "The", "\u2581@", "\u2581Cur", "ious", "Cat", "M", "e", "\u2581", "KK", "KK", "KK", "KK", "KK", "\u2581", "v", "c", "\u2581me", "\u2581am", "a", ",", "\u2581", "e", "u", "\u2581", "t", "e", "\u2581avis", "o", "\u2581", "q", "nd", "\u2581", "e", "u", "\u2581for", "\u2581", "f", "z", "r", "\u2581", "pra", "\u2581", "v", "c", "\u2581", "en", "tra", "r", "</s>"], "target_sentence": ["\u2581@", "\u2581Alice", "s", "d", "r", "The", "\u2581@", "\u2581Cur", "ious", "Cat", "M", "e", "\u2581", "KK", "KK", "KK", "KK", "KK", "\u2581", "v", "c", "\u2581me", "\u2581am", "a", ",", "\u2581", "e", "u", "\u2581", "t", "e", "\u2581avis", "o", "\u2581", "q", "nd", "\u2581", "e", "u", "\u2581for", "\u2581", "f", "z", "r", "\u2581", "pra", "\u2581", "v", "c", "\u2581", "en", "tra", "r", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 6, 7, 7, 8, 9, 9, 9, 10, 10, 10, 11, 11, 12, 12, 12, 13, 13, 13, 14, 15, 15, 15, 15, 16, 16, 17, 17, 17, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_752", "sentence": ["\u2581", "RT", "\u2581@", "\u2581angry", "black", "h", "o", "e", "m", "o", ":", "\u2581But", "\u2581let", "'", "\u2581", "s", "\u2581go", "\u2581along", "\u2581", "w", "\u2581", "/", "\u2581the", "\u2581idea", "\u2581that", "\u2581", "s", "ex", "\u2581is", "\u2581im", "moral", "\u2581and", "\u2581that", "\u2581could", "\u2581be", "\u2581", "a", "\u2581cause", "\u2581for", "\u2581higher", "\u2581HIV", "\u2581diagnose", "s", "\u2581among", "\u2581Black", "\u2581Gay", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581angry", "black", "h", "o", "e", "m", "o", ":", "\u2581But", "\u2581let", "'", "\u2581", "s", "\u2581go", "\u2581along", "\u2581", "w", "\u2581", "/", "\u2581the", "\u2581idea", "\u2581that", "\u2581", "s", "ex", "\u2581is", "\u2581im", "moral", "\u2581and", "\u2581that", "\u2581could", "\u2581be", "\u2581", "a", "\u2581cause", "\u2581for", "\u2581higher", "\u2581HIV", "\u2581diagnose", "s", "\u2581among", "\u2581Black", "\u2581Gay", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581angry", "black", "h", "o", "e", "m", "o", "</m>", ":", "\u2581But", "\u2581let", "'", "\u2581", "s", "\u2581go", "\u2581along", "\u2581", "w", "\u2581", "/", "\u2581the", "\u2581idea", "\u2581that", "\u2581", "s", "ex", "\u2581is", "\u2581im", "moral", "\u2581and", "\u2581that", "\u2581could", "\u2581be", "\u2581", "a", "\u2581cause", "\u2581for", "\u2581higher", "\u2581HIV", "\u2581diagnose", "s", "\u2581among", "\u2581Black", "<m>", "\u2581Gay", "</m>", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 11, 11, 12, 13, 14, 15, 15, 15, 16, 17, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 27, 28, 29, 30, 31, 31, 32], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1]}, {"doc_id": "emerging.test_753", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Beauty", "O", "f", "A", "n", "A", "ries", ":", "\u2581What", "\u2581my", "\u2581mom", "\u2581sent", "\u2581me", ".", "\u2581Pass", "\u2581it", "\u2581along", ".", "\u2581", "\ud83d\ude4f", "\u2581https", "://", "t", ".", "co", "/5", "m", "KW", "2", "m", "d", "A", "s", "O", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Beauty", "O", "f", "A", "n", "A", "ries", ":", "\u2581What", "\u2581my", "\u2581mom", "\u2581sent", "\u2581me", ".", "\u2581Pass", "\u2581it", "\u2581along", ".", "\u2581", "\ud83d\ude4f", "\u2581https", "://", "t", ".", "co", "/5", "m", "KW", "2", "m", "d", "A", "s", "O", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Beauty", "O", "f", "A", "n", "A", "ries", ":", "\u2581What", "\u2581my", "\u2581mom", "\u2581sent", "\u2581me", ".", "\u2581Pass", "\u2581it", "\u2581along", ".", "\u2581", "\ud83d\ude4f", "\u2581https", "://", "t", ".", "co", "/5", "m", "KW", "2", "m", "d", "A", "s", "O", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_754", "sentence": ["\u2581#", "\u2581", "i", "TECH", "\u25812", "\u2581#", "\u2581technology", "\u2581Bot", "s", "\u2581", "_", "\u2581alive", "\u2581kit", "\u2581im", "bu", "e", "s", "\u2581to", "y", "\u2581robot", "s", "\u2581with", "\u2581charming", ",", "\u2581life", "like", "\u2581AI", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "AU", "Q", "R", "SU", "Z", "q", "y", "6", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581", "i", "TECH", "\u25812", "\u2581#", "\u2581technology", "\u2581Bot", "s", "\u2581", "_", "\u2581alive", "\u2581kit", "\u2581im", "bu", "e", "s", "\u2581to", "y", "\u2581robot", "s", "\u2581with", "\u2581charming", ",", "\u2581life", "like", "\u2581AI", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "AU", "Q", "R", "SU", "Z", "q", "y", "6", "</s>"], "target_sentence": ["\u2581#", "\u2581", "i", "TECH", "\u25812", "\u2581#", "\u2581technology", "<m>", "\u2581Bot", "s", "\u2581", "_", "\u2581alive", "\u2581kit", "</m>", "\u2581im", "bu", "e", "s", "\u2581to", "y", "\u2581robot", "s", "\u2581with", "\u2581charming", ",", "\u2581life", "like", "\u2581AI", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "AU", "Q", "R", "SU", "Z", "q", "y", "6", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 5, 6, 6, 7, 8, 9, 9, 9, 9, 10, 10, 11, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_755", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Miss", "M", "c", "C", "le", "ary", ":", "\u2581Am", "\u2581I", "\u2581the", "\u2581only", "\u2581one", "\u2581that", "\u2581gets", "\u2581like", "\u2581", "re", "-", "ang", "ry", "?", "\u2581If", "\u2581I", "\u2581ever", "\u2581talk", "\u2581about", "\u2581anything", "\u2581that", "'", "\u2581", "s", "\u2581ever", "\u2581pi", "s", "sed", "\u2581me", "\u2581off", "\u2581I", "\u2581get", "\u2581pi", "s", "sed", "\u2581off", "\u2581all", "\u2581", "o", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Miss", "M", "c", "C", "le", "ary", ":", "\u2581Am", "\u2581I", "\u2581the", "\u2581only", "\u2581one", "\u2581that", "\u2581gets", "\u2581like", "\u2581", "re", "-", "ang", "ry", "?", "\u2581If", "\u2581I", "\u2581ever", "\u2581talk", "\u2581about", "\u2581anything", "\u2581that", "'", "\u2581", "s", "\u2581ever", "\u2581pi", "s", "sed", "\u2581me", "\u2581off", "\u2581I", "\u2581get", "\u2581pi", "s", "sed", "\u2581off", "\u2581all", "\u2581", "o", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Miss", "M", "c", "C", "le", "ary", "</m>", ":", "\u2581Am", "\u2581I", "\u2581the", "\u2581only", "\u2581one", "\u2581that", "\u2581gets", "\u2581like", "\u2581", "re", "-", "ang", "ry", "?", "\u2581If", "\u2581I", "\u2581ever", "\u2581talk", "\u2581about", "\u2581anything", "\u2581that", "'", "\u2581", "s", "\u2581ever", "\u2581pi", "s", "sed", "\u2581me", "\u2581off", "\u2581I", "\u2581get", "\u2581pi", "s", "sed", "\u2581off", "\u2581all", "\u2581", "o", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 24, 24, 25, 26, 27, 28, 29, 29, 29, 30, 31, 32, 32, 33, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_756", "sentence": ["\u2581#", "\u2581cor", "vette", "\u2581#", "\u2581auction", "\u25812017", "\u2581Chevrolet", "\u2581Cor", "vette", "\u2581MS", "RP", "\u2581$", "\u2581", "102", "520", "\u2581Grand", "\u2581Sport", "\u25813", "\u2581", "LT", "\u2581GPS", "\u2581Leather", "\u2581Tor", "ch", "\u2581Red", "\u2581New", "\u2581Navigation", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "K", "9", "TZ", "a", "a", "La", "7", "k", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581cor", "vette", "\u2581#", "\u2581auction", "\u25812017", "\u2581Chevrolet", "\u2581Cor", "vette", "\u2581MS", "RP", "\u2581$", "\u2581", "102", "520", "\u2581Grand", "\u2581Sport", "\u25813", "\u2581", "LT", "\u2581GPS", "\u2581Leather", "\u2581Tor", "ch", "\u2581Red", "\u2581New", "\u2581Navigation", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "K", "9", "TZ", "a", "a", "La", "7", "k", "</s>"], "target_sentence": ["\u2581#", "<m>", "\u2581cor", "vette", "</m>", "\u2581#", "\u2581auction", "<m>", "<m>", "\u25812017", "<m>", "\u2581Chevrolet", "\u2581Cor", "vette", "</m>", "</m>", "</m>", "\u2581MS", "RP", "\u2581$", "\u2581", "102", "520", "\u2581Grand", "\u2581Sport", "\u25813", "\u2581", "LT", "\u2581GPS", "\u2581Leather", "\u2581Tor", "ch", "\u2581Red", "\u2581New", "\u2581Navigation", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "K", "9", "TZ", "a", "a", "La", "7", "k", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 9, 9, 10, 11, 12, 13, 13, 14, 15, 16, 16, 17, 18, 19, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, 1, 2, -1, 3, -1, -1, -1, 3, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_757", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Nicholas", "P", "e", "gg", ":", "\u2581One", "\u2581of", "\u2581the", "\u2581Doctor", "\u2581", "\u2019", "\u2581", "s", "\u2581finest", "\u2581moments", "\u2581", "-", "\u2581from", "\u2581an", "\u2581episode", "\u2581shown", "\u258140", "\u2581years", "\u2581ago", "\u2581today", ".", "\u2581F", "ancy", "\u2581that", ".", "\u2581https", "://", "t", ".", "co", "/", "n", "e", "U", "9", "E", "t", "3", "d", "0", "B", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Nicholas", "P", "e", "gg", ":", "\u2581One", "\u2581of", "\u2581the", "\u2581Doctor", "\u2581", "\u2019", "\u2581", "s", "\u2581finest", "\u2581moments", "\u2581", "-", "\u2581from", "\u2581an", "\u2581episode", "\u2581shown", "\u258140", "\u2581years", "\u2581ago", "\u2581today", ".", "\u2581F", "ancy", "\u2581that", ".", "\u2581https", "://", "t", ".", "co", "/", "n", "e", "U", "9", "E", "t", "3", "d", "0", "B", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Nicholas", "P", "e", "gg", "</m>", ":", "\u2581One", "\u2581of", "\u2581the", "\u2581Doctor", "\u2581", "\u2019", "\u2581", "s", "\u2581finest", "\u2581moments", "\u2581", "-", "\u2581from", "\u2581an", "\u2581episode", "\u2581shown", "\u258140", "\u2581years", "\u2581ago", "\u2581today", ".", "\u2581F", "ancy", "\u2581that", ".", "\u2581https", "://", "t", ".", "co", "/", "n", "e", "U", "9", "E", "t", "3", "d", "0", "B", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_758", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Media", "it", "e", ":", "\u2581Minnesota", "\u2581Governor", "\u2581Ann", "ounce", "s", "\u2581He", "\u2581", "\u2019", "\u2581", "s", "\u2581Be", "en", "\u2581Diagnose", "d", "\u2581with", "\u2581Pro", "state", "\u2581Cancer", "\u2581https", "://", "t", ".", "co", "/", "c", "i", "k", "5", "Gu", "A", "d", "8", "d", "\u2581(", "\u2581V", "IDE", "O", ")", "\u2581https", "://", "t", ".", "co", "/", "j", "i", "4", "KS", "k", "v", "62", "m", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Media", "it", "e", ":", "\u2581Minnesota", "\u2581Governor", "\u2581Ann", "ounce", "s", "\u2581He", "\u2581", "\u2019", "\u2581", "s", "\u2581Be", "en", "\u2581Diagnose", "d", "\u2581with", "\u2581Pro", "state", "\u2581Cancer", "\u2581https", "://", "t", ".", "co", "/", "c", "i", "k", "5", "Gu", "A", "d", "8", "d", "\u2581(", "\u2581V", "IDE", "O", ")", "\u2581https", "://", "t", ".", "co", "/", "j", "i", "4", "KS", "k", "v", "62", "m", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Media", "it", "e", ":", "<m>", "\u2581Minnesota", "</m>", "\u2581Governor", "\u2581Ann", "ounce", "s", "\u2581He", "\u2581", "\u2019", "\u2581", "s", "\u2581Be", "en", "\u2581Diagnose", "d", "\u2581with", "\u2581Pro", "state", "\u2581Cancer", "\u2581https", "://", "t", ".", "co", "/", "c", "i", "k", "5", "Gu", "A", "d", "8", "d", "\u2581(", "\u2581V", "IDE", "O", ")", "\u2581https", "://", "t", ".", "co", "/", "j", "i", "4", "KS", "k", "v", "62", "m", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 13, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 17, 17, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_759", "sentence": ["\u2581", "RT", "\u2581@", "\u2581is", "safe", "min", "ist", ":", "\u2581", "he", "\u2581was", "\u2581choke", "d", "\u2581up", ",", "\u2581and", "\u2581since", "re", ".", "\u2581mal", "ach", "a", "i", "\u2581park", "er", "\u2581care", "d", "\u2581about", "\u2581bo", "nnie", "\u2581be", "n", "nett", "\u2581and", "\u2581no", "\u2581one", "\u2581can", "\u2581tell", "\u2581me", "\u2581otherwise", ".", "\u2581https", "://", "t", ".", "co", "/", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581is", "safe", "min", "ist", ":", "\u2581", "he", "\u2581was", "\u2581choke", "d", "\u2581up", ",", "\u2581and", "\u2581since", "re", ".", "\u2581mal", "ach", "a", "i", "\u2581park", "er", "\u2581care", "d", "\u2581about", "\u2581bo", "nnie", "\u2581be", "n", "nett", "\u2581and", "\u2581no", "\u2581one", "\u2581can", "\u2581tell", "\u2581me", "\u2581otherwise", ".", "\u2581https", "://", "t", ".", "co", "/", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581is", "safe", "min", "ist", ":", "\u2581", "he", "\u2581was", "\u2581choke", "d", "\u2581up", ",", "\u2581and", "\u2581since", "re", ".", "<m>", "\u2581mal", "ach", "a", "i", "\u2581park", "er", "</m>", "\u2581care", "d", "\u2581about", "<m>", "\u2581bo", "nnie", "\u2581be", "n", "nett", "</m>", "\u2581and", "\u2581no", "\u2581one", "\u2581can", "\u2581tell", "\u2581me", "\u2581otherwise", ".", "\u2581https", "://", "t", ".", "co", "/", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 10, 10, 11, 12, 12, 12, 12, 13, 13, 14, 14, 15, 16, 16, 17, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_760", "sentence": ["\u2581Because", ":", "\u2581Why", "\u2581the", "\u2581hell", "\u2581not", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "L", "ck", "Z", "f", "T", "X", "8", "g", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Because", ":", "\u2581Why", "\u2581the", "\u2581hell", "\u2581not", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "L", "ck", "Z", "f", "T", "X", "8", "g", "</s>"], "target_sentence": ["\u2581Because", ":", "\u2581Why", "\u2581the", "\u2581hell", "\u2581not", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "L", "ck", "Z", "f", "T", "X", "8", "g", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_761", "sentence": ["\u2581Can", "\u2581we", "\u2581talk", "\u2581about", "\u2581how", "\u2581ba", "p", "\u2581are", "\u2581#", "\u25811", "\u2581on", "\u2581", "a", "\u2581list", "\u2581full", "\u2581of", "\u2581rock", "\u2581music", ";", ";", ";", "\u2581only", "\u2581ba", "p", "\u2581could", "\u2581do", "\u2581this", "\u2581", "&", "\u2581", "g", "t", ";", ".", "\u2581", "&", "\u2581", "l", "t", ";", "\u2581", "\u2764", "\u2581https", "://", "t", ".", "co", "/", "Y", "4", "Z", "L", "0", "c", "Y", "p", "2", "V", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Can", "\u2581we", "\u2581talk", "\u2581about", "\u2581how", "\u2581ba", "p", "\u2581are", "\u2581#", "\u25811", "\u2581on", "\u2581", "a", "\u2581list", "\u2581full", "\u2581of", "\u2581rock", "\u2581music", ";", ";", ";", "\u2581only", "\u2581ba", "p", "\u2581could", "\u2581do", "\u2581this", "\u2581", "&", "\u2581", "g", "t", ";", ".", "\u2581", "&", "\u2581", "l", "t", ";", "\u2581", "\u2764", "\u2581https", "://", "t", ".", "co", "/", "Y", "4", "Z", "L", "0", "c", "Y", "p", "2", "V", "</s>"], "target_sentence": ["\u2581Can", "\u2581we", "\u2581talk", "\u2581about", "\u2581how", "<m>", "\u2581ba", "p", "</m>", "\u2581are", "\u2581#", "\u25811", "\u2581on", "\u2581", "a", "\u2581list", "\u2581full", "\u2581of", "\u2581rock", "\u2581music", ";", ";", ";", "\u2581only", "<m>", "\u2581ba", "p", "</m>", "\u2581could", "\u2581do", "\u2581this", "\u2581", "&", "\u2581", "g", "t", ";", ".", "\u2581", "&", "\u2581", "l", "t", ";", "\u2581", "\u2764", "\u2581https", "://", "t", ".", "co", "/", "Y", "4", "Z", "L", "0", "c", "Y", "p", "2", "V", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 24, 25, 25, 25, 26, 27, 28, 28, 29, 29, 29, 30, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_762", "sentence": ["\u2581@", "\u2581T", "PM", "\u2581Stop", "\u2581wh", "in", "ing", "\u2581", "a", "-", "hole", ".", "\u2581https", "://", "t", ".", "co", "/", "138", "J", "a", "BH", "t", "z", "g", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581T", "PM", "\u2581Stop", "\u2581wh", "in", "ing", "\u2581", "a", "-", "hole", ".", "\u2581https", "://", "t", ".", "co", "/", "138", "J", "a", "BH", "t", "z", "g", "</s>"], "target_sentence": ["\u2581@", "\u2581T", "PM", "\u2581Stop", "\u2581wh", "in", "ing", "\u2581", "a", "-", "hole", ".", "\u2581https", "://", "t", ".", "co", "/", "138", "J", "a", "BH", "t", "z", "g", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_763", "sentence": ["\u2581@", "\u2581Rev", "A", "ar", "on", "Mar", "qui", "s", "\u2581Based", "\u2581off", "\u2581E", "LR", ",", "\u2581I", "\u2581assume", "\u2581you", "\u2581smoke", "?", "\u2581If", "\u2581so", ",", "\u2581are", "\u2581you", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581", "RT", "\u2581employees", "\u2581who", "\u2581do", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Rev", "A", "ar", "on", "Mar", "qui", "s", "\u2581Based", "\u2581off", "\u2581E", "LR", ",", "\u2581I", "\u2581assume", "\u2581you", "\u2581smoke", "?", "\u2581If", "\u2581so", ",", "\u2581are", "\u2581you", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581", "RT", "\u2581employees", "\u2581who", "\u2581do", "?", "</s>"], "target_sentence": ["\u2581@", "\u2581Rev", "A", "ar", "on", "Mar", "qui", "s", "\u2581Based", "\u2581off", "\u2581E", "LR", ",", "\u2581I", "\u2581assume", "\u2581you", "\u2581smoke", "?", "\u2581If", "\u2581so", ",", "\u2581are", "\u2581you", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581", "RT", "\u2581employees", "\u2581who", "\u2581do", "?", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_764", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258107", ":", "\u2581", "00", "\u2581AM", ",", "\u2581good", "\u2581morning", "\u2581people", "!", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258107", ":", "\u2581", "00", "\u2581AM", ",", "\u2581good", "\u2581morning", "\u2581people", "!", "!", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258107", ":", "\u2581", "00", "\u2581AM", ",", "\u2581good", "\u2581morning", "\u2581people", "!", "!", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_765", "sentence": ["\u2581@", "\u2581Fin", "B", "er", "g", "in", "\u2581", "Exactly", ",", "\u2581you", "'", "\u2581", "re", "\u2581not", "\u2581in", "\u2581the", "\u2581wrong", "\u2581here", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Fin", "B", "er", "g", "in", "\u2581", "Exactly", ",", "\u2581you", "'", "\u2581", "re", "\u2581not", "\u2581in", "\u2581the", "\u2581wrong", "\u2581here", "</s>"], "target_sentence": ["\u2581@", "\u2581Fin", "B", "er", "g", "in", "\u2581", "Exactly", ",", "\u2581you", "'", "\u2581", "re", "\u2581not", "\u2581in", "\u2581the", "\u2581wrong", "\u2581here", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_766", "sentence": ["\u2581@", "\u2581", "tim", "ka", "ine", "\u2581help", "\u2581us", "\u2581please", ".", ".", "\u2581", "m", "\u2581save", "\u2581us", "\u2581from", "\u2581him", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "tim", "ka", "ine", "\u2581help", "\u2581us", "\u2581please", ".", ".", "\u2581", "m", "\u2581save", "\u2581us", "\u2581from", "\u2581him", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581", "tim", "ka", "ine", "\u2581help", "\u2581us", "\u2581please", ".", ".", "\u2581", "m", "\u2581save", "\u2581us", "\u2581from", "\u2581him", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_767", "sentence": ["\u2581@", "\u2581", "hol", "ly", "d", "o", "lly", "raz", "zy", "\u2581", "u", "\u2581can", "\u2581always", "\u2581pitch", "\u2581", "a", "\u2581tent", "\u2581in", "\u2581some", "\u2581swamp", "l", "and", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "hol", "ly", "d", "o", "lly", "raz", "zy", "\u2581", "u", "\u2581can", "\u2581always", "\u2581pitch", "\u2581", "a", "\u2581tent", "\u2581in", "\u2581some", "\u2581swamp", "l", "and", "!", "</s>"], "target_sentence": ["\u2581@", "\u2581", "hol", "ly", "d", "o", "lly", "raz", "zy", "\u2581", "u", "\u2581can", "\u2581always", "\u2581pitch", "\u2581", "a", "\u2581tent", "\u2581in", "\u2581some", "\u2581swamp", "l", "and", "!", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_768", "sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "CW", "Super", "girl", ":", "\u2581Roulette", "\u2581returns", ".", ".", ".", "\u2581#", "\u2581Super", "girl", "\u2581https", "://", "t", ".", "co", "/", "9", "t", "Q", "6", "nut", "t", "J", "K", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581The", "CW", "Super", "girl", ":", "\u2581Roulette", "\u2581returns", ".", ".", ".", "\u2581#", "\u2581Super", "girl", "\u2581https", "://", "t", ".", "co", "/", "9", "t", "Q", "6", "nut", "t", "J", "K", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581The", "CW", "Super", "girl", "</m>", ":", "\u2581Roulette", "\u2581returns", ".", ".", ".", "\u2581#", "\u2581Super", "girl", "\u2581https", "://", "t", ".", "co", "/", "9", "t", "Q", "6", "nut", "t", "J", "K", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_769", "sentence": ["\u2581Moving", "\u2581your", "\u2581work", "\u2581week", "\u2581along", "\u2581to", "\u2581the", "\u2581weekend", "\u2581with", "\u2581", "a", "\u2581little", "\u2581Marg", "a", "rita", "\u2581Mad", "ness", "\u2581and", "\u2581our", "\u2581fantastic", "\u2581Shri", "mp", "\u2581Fe", "at", ".", "\u2581Join", "\u2581us", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "GH", "Z", "a", "0", "n", "HA", "q", "p", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Moving", "\u2581your", "\u2581work", "\u2581week", "\u2581along", "\u2581to", "\u2581the", "\u2581weekend", "\u2581with", "\u2581", "a", "\u2581little", "\u2581Marg", "a", "rita", "\u2581Mad", "ness", "\u2581and", "\u2581our", "\u2581fantastic", "\u2581Shri", "mp", "\u2581Fe", "at", ".", "\u2581Join", "\u2581us", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "GH", "Z", "a", "0", "n", "HA", "q", "p", "</s>"], "target_sentence": ["\u2581Moving", "\u2581your", "\u2581work", "\u2581week", "\u2581along", "\u2581to", "\u2581the", "\u2581weekend", "\u2581with", "\u2581", "a", "\u2581little", "\u2581Marg", "a", "rita", "\u2581Mad", "ness", "\u2581and", "\u2581our", "\u2581fantastic", "\u2581Shri", "mp", "\u2581Fe", "at", ".", "\u2581Join", "\u2581us", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "GH", "Z", "a", "0", "n", "HA", "q", "p", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 11, 11, 12, 12, 13, 14, 15, 16, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_770", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Bad", "lands", "NP", "S", ":", "\u2581Present", "ly", "\u2581we", "\u2581have", "\u2581nationwide", "\u2581around", "\u258110", "\u2581", "%", "\u2581of", "\u2581their", "\u2581historic", "\u2581population", ".", "\u2581#", "\u2581Park", "Science", "\u2581#", "\u2581big", "horn", "s", "\u2581https", "://", "t", ".", "co", "/", "w", "0", "z", "8", "o", "J", "G", "95", "m", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Bad", "lands", "NP", "S", ":", "\u2581Present", "ly", "\u2581we", "\u2581have", "\u2581nationwide", "\u2581around", "\u258110", "\u2581", "%", "\u2581of", "\u2581their", "\u2581historic", "\u2581population", ".", "\u2581#", "\u2581Park", "Science", "\u2581#", "\u2581big", "horn", "s", "\u2581https", "://", "t", ".", "co", "/", "w", "0", "z", "8", "o", "J", "G", "95", "m", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Bad", "lands", "NP", "S", "</m>", ":", "\u2581Present", "ly", "\u2581we", "\u2581have", "\u2581nationwide", "\u2581around", "\u258110", "\u2581", "%", "\u2581of", "\u2581their", "\u2581historic", "\u2581population", ".", "\u2581#", "<m>", "\u2581Park", "Science", "</m>", "\u2581#", "\u2581big", "horn", "s", "\u2581https", "://", "t", ".", "co", "/", "w", "0", "z", "8", "o", "J", "G", "95", "m", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_771", "sentence": ["\u2581@", "\u2581", "f", "a", "y", "e", "ban", "o", "gon", "\u2581A", "NO", "\u2581TO", "\u2581MAY", "\u2581TR", "ABA", "HO", "\u2581", "KA", "\u2581NA", "\u2581BA", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "f", "a", "y", "e", "ban", "o", "gon", "\u2581A", "NO", "\u2581TO", "\u2581MAY", "\u2581TR", "ABA", "HO", "\u2581", "KA", "\u2581NA", "\u2581BA", "</s>"], "target_sentence": ["\u2581@", "\u2581", "f", "a", "y", "e", "ban", "o", "gon", "\u2581A", "NO", "\u2581TO", "\u2581MAY", "\u2581TR", "ABA", "HO", "\u2581", "KA", "\u2581NA", "\u2581BA", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 4, 5, 5, 5, 6, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_772", "sentence": ["\u2581I", "'", "\u2581", "m", "\u2581just", "\u2581ready", "\u2581to", "\u2581go", "\u2581home", "\u2581", "&", "\u2581amp", ";", "\u2581get", "\u2581in", "\u2581my", "\u2581bed", ".", "\u2581", "Honestly", ".", "\u2581Tru", "ly", ".", "\u2581https", "://", "t", ".", "co", "/8", "a", "Je", "CH", "w", "UA", "h", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "m", "\u2581just", "\u2581ready", "\u2581to", "\u2581go", "\u2581home", "\u2581", "&", "\u2581amp", ";", "\u2581get", "\u2581in", "\u2581my", "\u2581bed", ".", "\u2581", "Honestly", ".", "\u2581Tru", "ly", ".", "\u2581https", "://", "t", ".", "co", "/8", "a", "Je", "CH", "w", "UA", "h", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "m", "\u2581just", "\u2581ready", "\u2581to", "\u2581go", "\u2581home", "\u2581", "&", "\u2581amp", ";", "\u2581get", "\u2581in", "\u2581my", "\u2581bed", ".", "\u2581", "Honestly", ".", "\u2581Tru", "ly", ".", "\u2581https", "://", "t", ".", "co", "/8", "a", "Je", "CH", "w", "UA", "h", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_773", "sentence": ["\u2581https", "://", "t", ".", "co", "/5", "Y", "1", "I", "3", "P", "9", "p", "Z", "8", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/5", "Y", "1", "I", "3", "P", "9", "p", "Z", "8", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/5", "Y", "1", "I", "3", "P", "9", "p", "Z", "8", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_774", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Kid", "D", "i", "r", "t", "y", "J", "o", "kes", ":", "\u2581I", "'", "\u2581", "ve", "\u2581been", "\u2581laughing", "\u2581at", "\u2581this", "\u2581for", "\u258120", "\u2581minutes", "\u2581https", "://", "t", ".", "co", "/", "9", "Q", "5", "W", "8", "t", "4", "V", "J", "p", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Kid", "D", "i", "r", "t", "y", "J", "o", "kes", ":", "\u2581I", "'", "\u2581", "ve", "\u2581been", "\u2581laughing", "\u2581at", "\u2581this", "\u2581for", "\u258120", "\u2581minutes", "\u2581https", "://", "t", ".", "co", "/", "9", "Q", "5", "W", "8", "t", "4", "V", "J", "p", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Kid", "D", "i", "r", "t", "y", "J", "o", "kes", ":", "\u2581I", "'", "\u2581", "ve", "\u2581been", "\u2581laughing", "\u2581at", "\u2581this", "\u2581for", "\u258120", "\u2581minutes", "\u2581https", "://", "t", ".", "co", "/", "9", "Q", "5", "W", "8", "t", "4", "V", "J", "p", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_775", "sentence": ["\u2581@", "\u2581B", "mac", "\u2581", "05", "07", "\u2581@", "\u2581Bi", "a", "sed", "G", "i", "r", "l", "\u2581@", "\u2581", "j", "im", "ger", "agh", "t", "y", "\u2581I", "'", "\u2581", "m", "\u2581trying", "\u2581to", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581B", "mac", "\u2581", "05", "07", "\u2581@", "\u2581Bi", "a", "sed", "G", "i", "r", "l", "\u2581@", "\u2581", "j", "im", "ger", "agh", "t", "y", "\u2581I", "'", "\u2581", "m", "\u2581trying", "\u2581to", "!", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581B", "mac", "\u2581", "05", "07", "</m>", "\u2581@", "\u2581Bi", "a", "sed", "G", "i", "r", "l", "\u2581@", "\u2581", "j", "im", "ger", "agh", "t", "y", "\u2581I", "'", "\u2581", "m", "\u2581trying", "\u2581to", "!", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 7, 8, 9, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_776", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "E", "p", "y", "C", "B", "6", "r", "h", "m", "q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "E", "p", "y", "C", "B", "6", "r", "h", "m", "q", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "E", "p", "y", "C", "B", "6", "r", "h", "m", "q", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_777", "sentence": ["\u2581@", "\u2581roots", "t", "roy", "e", "\u2581", "o", "h", "\u2581", "o", "m", "g", "\u2581", "i", "\u2581forgot", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581live", "\u2581in", "\u2581to", "ront", "o", "\u2581", "o", "OP", "S", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581roots", "t", "roy", "e", "\u2581", "o", "h", "\u2581", "o", "m", "g", "\u2581", "i", "\u2581forgot", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581live", "\u2581in", "\u2581to", "ront", "o", "\u2581", "o", "OP", "S", "</s>"], "target_sentence": ["\u2581@", "\u2581roots", "t", "roy", "e", "\u2581", "o", "h", "\u2581", "o", "m", "g", "\u2581", "i", "\u2581forgot", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581live", "\u2581in", "<m>", "\u2581to", "ront", "o", "</m>", "\u2581", "o", "OP", "S", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 12, 12, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_778", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "e", "less", "ar", "\u258142", ":", "\u2581P", "s", "s", "t", ".", "\u2581Trump", "\u2581saying", "\u2581that", "\u2581millions", "\u2581", "voted", "\u2581illegal", "ly", "\u2581is", "\u2581pre", "text", "\u2581to", "\u2581destroy", "\u2581voting", "\u2581rights", ".", "\u2581Don", "'", "\u2581", "t", "\u2581treat", "\u2581it", "\u2581like", "\u2581some", "\u2581random", "\u2581qu", "irk", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "e", "less", "ar", "\u258142", ":", "\u2581P", "s", "s", "t", ".", "\u2581Trump", "\u2581saying", "\u2581that", "\u2581millions", "\u2581", "voted", "\u2581illegal", "ly", "\u2581is", "\u2581pre", "text", "\u2581to", "\u2581destroy", "\u2581voting", "\u2581rights", ".", "\u2581Don", "'", "\u2581", "t", "\u2581treat", "\u2581it", "\u2581like", "\u2581some", "\u2581random", "\u2581qu", "irk", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "e", "less", "ar", "</m>", "\u258142", ":", "\u2581P", "s", "s", "t", ".", "<m>", "\u2581Trump", "</m>", "\u2581saying", "\u2581that", "\u2581millions", "\u2581", "voted", "\u2581illegal", "ly", "\u2581is", "\u2581pre", "text", "\u2581to", "\u2581destroy", "\u2581voting", "\u2581rights", ".", "\u2581Don", "'", "\u2581", "t", "\u2581treat", "\u2581it", "\u2581like", "\u2581some", "\u2581random", "\u2581qu", "irk", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 5, 5, 5, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 28, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_779", "sentence": ["\u2581@", "\u2581Bull", "s", "\u2581", "_", "\u2581Jay", "\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581think", "\u2581their", "\u2581mess", "\u2581levels", "\u2581are", "\u2581on", "\u2581par", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Bull", "s", "\u2581", "_", "\u2581Jay", "\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581think", "\u2581their", "\u2581mess", "\u2581levels", "\u2581are", "\u2581on", "\u2581par", "</s>"], "target_sentence": ["\u2581@", "\u2581Bull", "s", "\u2581", "_", "\u2581Jay", "\u2581I", "'", "\u2581", "d", "\u2581like", "\u2581to", "\u2581think", "\u2581their", "\u2581mess", "\u2581levels", "\u2581are", "\u2581on", "\u2581par", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_780", "sentence": ["\u2581Making", "\u2581my", "\u2581base", "\u2581secure", ":", ")", "\u2581https", "://", "t", ".", "co", "/", "N", "3", "l", "VS", "Y", "6", "t", "U", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Making", "\u2581my", "\u2581base", "\u2581secure", ":", ")", "\u2581https", "://", "t", ".", "co", "/", "N", "3", "l", "VS", "Y", "6", "t", "U", "X", "</s>"], "target_sentence": ["\u2581Making", "\u2581my", "\u2581base", "\u2581secure", ":", ")", "\u2581https", "://", "t", ".", "co", "/", "N", "3", "l", "VS", "Y", "6", "t", "U", "X", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_781", "sentence": ["\u2581This", "\u2581how", "\u2581female", "s", "\u2581should", "\u2581react", "\u2581when", "\u2581they", "\u2581found", "\u2581out", "\u2581the", "\u2581", "nig", "g", "a", "\u2581been", "\u2581cheat", "ing", "\u2581total", "\u2581respect", "\u2581", "\ud83d\udc4f", "\u2581https", "://", "t", ".", "co", "/", "u", "SV", "w", "o", "e", "Z", "C", "8", "B", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581This", "\u2581how", "\u2581female", "s", "\u2581should", "\u2581react", "\u2581when", "\u2581they", "\u2581found", "\u2581out", "\u2581the", "\u2581", "nig", "g", "a", "\u2581been", "\u2581cheat", "ing", "\u2581total", "\u2581respect", "\u2581", "\ud83d\udc4f", "\u2581https", "://", "t", ".", "co", "/", "u", "SV", "w", "o", "e", "Z", "C", "8", "B", "</s>"], "target_sentence": ["\u2581This", "\u2581how", "\u2581female", "s", "\u2581should", "\u2581react", "\u2581when", "\u2581they", "\u2581found", "\u2581out", "\u2581the", "\u2581", "nig", "g", "a", "\u2581been", "\u2581cheat", "ing", "\u2581total", "\u2581respect", "\u2581", "\ud83d\udc4f", "\u2581https", "://", "t", ".", "co", "/", "u", "SV", "w", "o", "e", "Z", "C", "8", "B", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 12, 13, 14, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_782", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Harry", "\u2581", "_", "\u2581Style", "s", ":", "\u2581Glasgow", "\u25817", ".", "\u258110", ".", "\u258115", ".", "\u2581https", "://", "t", ".", "co", "/", "ok", "t", "J", "P", "82", "l", "D", "d", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Harry", "\u2581", "_", "\u2581Style", "s", ":", "\u2581Glasgow", "\u25817", ".", "\u258110", ".", "\u258115", ".", "\u2581https", "://", "t", ".", "co", "/", "ok", "t", "J", "P", "82", "l", "D", "d", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Harry", "\u2581", "_", "\u2581Style", "s", ":", "<m>", "<m>", "\u2581Glasgow", "</m>", "</m>", "\u25817", ".", "\u258110", ".", "\u258115", ".", "\u2581https", "://", "t", ".", "co", "/", "ok", "t", "J", "P", "82", "l", "D", "d", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_783", "sentence": ["\u2581#", "\u2581SEO", "\u2581Ti", "p", ":", "\u2581Google", "\u2581consider", "s", "\u2581the", "\u2581first", "\u2581lines", "\u2581of", "\u2581the", "\u2581page", "\u2581important", ".", "\u2581Put", "\u2581menu", ",", "\u2581header", "s", "\u2581+", "\u2581important", "\u2581text", "\u2581on", "\u2581top", ".", "\u2581#", "\u2581google", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581SEO", "\u2581Ti", "p", ":", "\u2581Google", "\u2581consider", "s", "\u2581the", "\u2581first", "\u2581lines", "\u2581of", "\u2581the", "\u2581page", "\u2581important", ".", "\u2581Put", "\u2581menu", ",", "\u2581header", "s", "\u2581+", "\u2581important", "\u2581text", "\u2581on", "\u2581top", ".", "\u2581#", "\u2581google", "</s>"], "target_sentence": ["\u2581#", "\u2581SEO", "\u2581Ti", "p", ":", "<m>", "<m>", "\u2581Google", "</m>", "</m>", "\u2581consider", "s", "\u2581the", "\u2581first", "\u2581lines", "\u2581of", "\u2581the", "\u2581page", "\u2581important", ".", "\u2581Put", "\u2581menu", ",", "\u2581header", "s", "\u2581+", "\u2581important", "\u2581text", "\u2581on", "\u2581top", ".", "\u2581#", "<m>", "\u2581google", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 2, -1]}, {"doc_id": "emerging.test_784", "sentence": ["\u2581", "RT", "\u2581@", "\u2581steal", "th", "y", "g", "eek", ":", "\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581remember", "\u2581the", "\u2581rest", "\u2581but", "\u2581the", "\u2581punch", "line", "\u2581is", "\u2581punch", "\u2581Nazi", "s", ".", "\u2581https", "://", "t", ".", "co", "/", "9", "F", "z", "K", "5", "V", "0", "Un", "P", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581steal", "th", "y", "g", "eek", ":", "\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581remember", "\u2581the", "\u2581rest", "\u2581but", "\u2581the", "\u2581punch", "line", "\u2581is", "\u2581punch", "\u2581Nazi", "s", ".", "\u2581https", "://", "t", ".", "co", "/", "9", "F", "z", "K", "5", "V", "0", "Un", "P", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581steal", "th", "y", "g", "eek", ":", "\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581remember", "\u2581the", "\u2581rest", "\u2581but", "\u2581the", "<m>", "\u2581punch", "line", "\u2581is", "\u2581punch", "</m>", "\u2581Nazi", "s", ".", "\u2581https", "://", "t", ".", "co", "/", "9", "F", "z", "K", "5", "V", "0", "Un", "P", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 16, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_785", "sentence": ["\u2581#", "\u2581", "teen", "p", "or", "n", "\u2581#", "\u2581images", "\u2581More", "\u2581@", "\u2581https", "://", "t", ".", "co", "/", "q", "t", "Y", "i", "58", "z", "Y", "n", "P", "\u2581for", "\u2581free", ".", "\u2581No", "\u2581tricks", ".", "\u2581#", "\u2581por", "n", "\u2581#", "\u2581por", "n", "video", "\u2581#", "\u2581", "g", "if", "p", "or", "n", "\u2581#", "\u2581por", "ng", "if", "\u2581https", "://", "t", ".", "co", "/", "GW", "T", "J", "5", "60", "NI", "Q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581", "teen", "p", "or", "n", "\u2581#", "\u2581images", "\u2581More", "\u2581@", "\u2581https", "://", "t", ".", "co", "/", "q", "t", "Y", "i", "58", "z", "Y", "n", "P", "\u2581for", "\u2581free", ".", "\u2581No", "\u2581tricks", ".", "\u2581#", "\u2581por", "n", "\u2581#", "\u2581por", "n", "video", "\u2581#", "\u2581", "g", "if", "p", "or", "n", "\u2581#", "\u2581por", "ng", "if", "\u2581https", "://", "t", ".", "co", "/", "GW", "T", "J", "5", "60", "NI", "Q", "</s>"], "target_sentence": ["\u2581#", "\u2581", "teen", "p", "or", "n", "\u2581#", "\u2581images", "\u2581More", "\u2581@", "\u2581https", "://", "t", ".", "co", "/", "q", "t", "Y", "i", "58", "z", "Y", "n", "P", "\u2581for", "\u2581free", ".", "\u2581No", "\u2581tricks", ".", "\u2581#", "\u2581por", "n", "\u2581#", "\u2581por", "n", "video", "\u2581#", "\u2581", "g", "if", "p", "or", "n", "\u2581#", "\u2581por", "ng", "if", "\u2581https", "://", "t", ".", "co", "/", "GW", "T", "J", "5", "60", "NI", "Q", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 16, 17, 18, 18, 18, 18, 18, 18, 19, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_786", "sentence": ["\u2581Yes", ",", "\u2581I", "\u2581", "\u0301", "\u2581", "ve", "\u2581changed", ".", "\u2581Pain", "\u2581does", "\u2581that", "\u2581to", "\u2581people", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Yes", ",", "\u2581I", "\u2581", "\u0301", "\u2581", "ve", "\u2581changed", ".", "\u2581Pain", "\u2581does", "\u2581that", "\u2581to", "\u2581people", "</s>"], "target_sentence": ["\u2581Yes", ",", "\u2581I", "\u2581", "\u0301", "\u2581", "ve", "\u2581changed", ".", "\u2581Pain", "\u2581does", "\u2581that", "\u2581to", "\u2581people", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_787", "sentence": ["\u2581", "RT", "\u2581@", "\u2581St", "out", "B", "o", "y", "z", ":", "\u2581You", "\u2581already", "\u2581know", "\u2581who", "\u2581fin", "n", "a", "\u2581", "s", "n", "itch", "\u2581", "l", "m", "a", "oooo", "o", "\u2581https", "://", "t", ".", "co", "/", "Ex", "7", "K", "V", "N", "1", "Bu", "B", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581St", "out", "B", "o", "y", "z", ":", "\u2581You", "\u2581already", "\u2581know", "\u2581who", "\u2581fin", "n", "a", "\u2581", "s", "n", "itch", "\u2581", "l", "m", "a", "oooo", "o", "\u2581https", "://", "t", ".", "co", "/", "Ex", "7", "K", "V", "N", "1", "Bu", "B", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581St", "out", "B", "o", "y", "z", ":", "\u2581You", "\u2581already", "\u2581know", "\u2581who", "\u2581fin", "n", "a", "\u2581", "s", "n", "itch", "\u2581", "l", "m", "a", "oooo", "o", "\u2581https", "://", "t", ".", "co", "/", "Ex", "7", "K", "V", "N", "1", "Bu", "B", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_788", "sentence": ["\u2581Bangkok", ",", "\u2581Thailand", ":", "\u2581Land", "\u2581of", "\u2581Smile", "s", "\u2581", "-", "\u2581Day", "\u25811", "\u2581#", "\u2581blog", "\u2581#", "\u2581con", "o", "z", "cop", "a", "blo", "\u2581#", "\u2581Travel", "\u2581https", "://", "t", ".", "co", "/", "q", "x", "L", "m", "N", "6", "l", "GV", "4", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Bangkok", ",", "\u2581Thailand", ":", "\u2581Land", "\u2581of", "\u2581Smile", "s", "\u2581", "-", "\u2581Day", "\u25811", "\u2581#", "\u2581blog", "\u2581#", "\u2581con", "o", "z", "cop", "a", "blo", "\u2581#", "\u2581Travel", "\u2581https", "://", "t", ".", "co", "/", "q", "x", "L", "m", "N", "6", "l", "GV", "4", "</s>"], "target_sentence": ["<m>", "\u2581Bangkok", "</m>", ",", "<m>", "\u2581Thailand", "</m>", ":", "\u2581Land", "\u2581of", "\u2581Smile", "s", "\u2581", "-", "\u2581Day", "\u25811", "\u2581#", "\u2581blog", "\u2581#", "\u2581con", "o", "z", "cop", "a", "blo", "\u2581#", "\u2581Travel", "\u2581https", "://", "t", ".", "co", "/", "q", "x", "L", "m", "N", "6", "l", "GV", "4", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, 0, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_789", "sentence": ["\u2581Lock", "heed", "\u2581says", "\u2581Trump", "\u2581pressure", "\u2581won", "'", "\u2581", "t", "\u2581affect", "\u2581F", "-", "\u258135", "\u2581profitability", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "q", "a", "er", "0", "La", "a", "N", "2", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Lock", "heed", "\u2581says", "\u2581Trump", "\u2581pressure", "\u2581won", "'", "\u2581", "t", "\u2581affect", "\u2581F", "-", "\u258135", "\u2581profitability", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "q", "a", "er", "0", "La", "a", "N", "2", "</s>"], "target_sentence": ["\u2581Lock", "heed", "\u2581says", "<m>", "\u2581Trump", "</m>", "\u2581pressure", "\u2581won", "'", "\u2581", "t", "\u2581affect", "\u2581F", "-", "\u258135", "\u2581profitability", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "q", "a", "er", "0", "La", "a", "N", "2", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_790", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "bri", "an", "kla", "a", "s", ":", "\u2581Bad", "lands", "\u2581National", "\u2581Park", "\u2581posted", "\u2581", "a", "\u2581basic", "\u2581scientific", "\u2581fact", "\u2581that", "\u2581de", "fie", "d", "\u2581Trump", ".", "\u2581Now", ",", "\u2581it", "'", "\u2581", "s", "\u2581been", "\u2581deleted", ".", "\u2581Re", "t", "we", "e", "t", "\u2581anyway", ".", "\u2581https", "://", "t", "....", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "bri", "an", "kla", "a", "s", ":", "\u2581Bad", "lands", "\u2581National", "\u2581Park", "\u2581posted", "\u2581", "a", "\u2581basic", "\u2581scientific", "\u2581fact", "\u2581that", "\u2581de", "fie", "d", "\u2581Trump", ".", "\u2581Now", ",", "\u2581it", "'", "\u2581", "s", "\u2581been", "\u2581deleted", ".", "\u2581Re", "t", "we", "e", "t", "\u2581anyway", ".", "\u2581https", "://", "t", "....", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "bri", "an", "kla", "a", "s", "</m>", ":", "<m>", "\u2581Bad", "lands", "\u2581National", "\u2581Park", "</m>", "\u2581posted", "\u2581", "a", "\u2581basic", "\u2581scientific", "\u2581fact", "\u2581that", "\u2581de", "fie", "d", "<m>", "\u2581Trump", "</m>", ".", "\u2581Now", ",", "\u2581it", "'", "\u2581", "s", "\u2581been", "\u2581deleted", ".", "\u2581Re", "t", "we", "e", "t", "\u2581anyway", ".", "\u2581https", "://", "t", "....", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 24, 24, 24, 24, 25, 26, 27, 27, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_791", "sentence": ["\u2581Just", "\u2581posted", "\u2581", "a", "\u2581photo", "\u2581@", "\u2581Ke", "m", "bar", "\u2581Mas", "\u2581U", "tar", "a", "\u2581", "-", "\u2581Bu", "a", "h", "bat", "u", "\u2581https", "://", "t", ".", "co", "/", "u", "7", "W", "Q", "DG", "c", "SV", "W", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Just", "\u2581posted", "\u2581", "a", "\u2581photo", "\u2581@", "\u2581Ke", "m", "bar", "\u2581Mas", "\u2581U", "tar", "a", "\u2581", "-", "\u2581Bu", "a", "h", "bat", "u", "\u2581https", "://", "t", ".", "co", "/", "u", "7", "W", "Q", "DG", "c", "SV", "W", "</s>"], "target_sentence": ["\u2581Just", "\u2581posted", "\u2581", "a", "\u2581photo", "\u2581@", "<m>", "\u2581Ke", "m", "bar", "\u2581Mas", "</m>", "\u2581U", "tar", "a", "\u2581", "-", "\u2581Bu", "a", "h", "bat", "u", "\u2581https", "://", "t", ".", "co", "/", "u", "7", "W", "Q", "DG", "c", "SV", "W", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_792", "sentence": ["\u2581https", "://", "t", ".", "co", "/3", "k", "P", "s", "B", "84", "H", "8", "C", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/3", "k", "P", "s", "B", "84", "H", "8", "C", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/3", "k", "P", "s", "B", "84", "H", "8", "C", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_793", "sentence": ["\u2581Court", "\u2581Rein", "state", "s", "\u2581Man", "'", "\u2581", "s", "\u2581$", "\u258125", "\u2581Million", "\u2581Award", "\u2581in", "\u2581Ac", "n", "e", "\u2581Drug", "\u2581Case", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "J", "t", "JE", "K", "JO", "c", "v", "U", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Court", "\u2581Rein", "state", "s", "\u2581Man", "'", "\u2581", "s", "\u2581$", "\u258125", "\u2581Million", "\u2581Award", "\u2581in", "\u2581Ac", "n", "e", "\u2581Drug", "\u2581Case", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "J", "t", "JE", "K", "JO", "c", "v", "U", "</s>"], "target_sentence": ["\u2581Court", "\u2581Rein", "state", "s", "\u2581Man", "'", "\u2581", "s", "\u2581$", "\u258125", "\u2581Million", "\u2581Award", "\u2581in", "\u2581Ac", "n", "e", "\u2581Drug", "\u2581Case", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "J", "t", "JE", "K", "JO", "c", "v", "U", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_794", "sentence": ["\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "</s>"], "target_sentence": ["\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "\u2581D", "ING", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_795", "sentence": ["\u2581If", "\u2581only", "\u2581this", "\u2581win", "ch", "\u2581could", "\u2581get", "\u2581us", "\u2581out", "\u2581of", "\u2581going", "\u2581to", "\u2581work", ".", "\u2581Tag", "\u2581someone", "\u2581who", "\u2581should", "\u2581skip", "\u2581work", "\u2581and", "\u2581hit", "\u2581the", "\u2581trails", "\u2581with", "\u2581", "y", "o", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "KW", "14", "L", "H", "f", "OK", "W", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581only", "\u2581this", "\u2581win", "ch", "\u2581could", "\u2581get", "\u2581us", "\u2581out", "\u2581of", "\u2581going", "\u2581to", "\u2581work", ".", "\u2581Tag", "\u2581someone", "\u2581who", "\u2581should", "\u2581skip", "\u2581work", "\u2581and", "\u2581hit", "\u2581the", "\u2581trails", "\u2581with", "\u2581", "y", "o", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "KW", "14", "L", "H", "f", "OK", "W", "</s>"], "target_sentence": ["\u2581If", "\u2581only", "\u2581this", "\u2581win", "ch", "\u2581could", "\u2581get", "\u2581us", "\u2581out", "\u2581of", "\u2581going", "\u2581to", "\u2581work", ".", "\u2581Tag", "\u2581someone", "\u2581who", "\u2581should", "\u2581skip", "\u2581work", "\u2581and", "\u2581hit", "\u2581the", "\u2581trails", "\u2581with", "\u2581", "y", "o", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "KW", "14", "L", "H", "f", "OK", "W", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 24, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_796", "sentence": ["\u2581The", "\u2581iconic", "\u2581\"", "\u2581Let", "'", "\u2581", "s", "\u2581chat", "\u2581later", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "O", "w", "RU", "o", "m", "N", "g", "v", "0", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581iconic", "\u2581\"", "\u2581Let", "'", "\u2581", "s", "\u2581chat", "\u2581later", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "O", "w", "RU", "o", "m", "N", "g", "v", "0", "</s>"], "target_sentence": ["\u2581The", "\u2581iconic", "\u2581\"", "\u2581Let", "'", "\u2581", "s", "\u2581chat", "\u2581later", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "O", "w", "RU", "o", "m", "N", "g", "v", "0", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_797", "sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "V", "i", "d", "S", "pot", ":", "\u2581This", "\u2581awesome", "\u2581invention", "\u2581is", "\u2581basically", "\u2581", "a", "\u2581treadmill", "\u2581rock", "\u2581climbing", "\u2581wall", "\u2581https", "://", "t", ".", "co", "/", "r", "du", "h", "y", "j", "v", "MG", "q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581The", "V", "i", "d", "S", "pot", ":", "\u2581This", "\u2581awesome", "\u2581invention", "\u2581is", "\u2581basically", "\u2581", "a", "\u2581treadmill", "\u2581rock", "\u2581climbing", "\u2581wall", "\u2581https", "://", "t", ".", "co", "/", "r", "du", "h", "y", "j", "v", "MG", "q", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "V", "i", "d", "S", "pot", ":", "\u2581This", "\u2581awesome", "\u2581invention", "\u2581is", "\u2581basically", "\u2581", "a", "\u2581treadmill", "\u2581rock", "\u2581climbing", "\u2581wall", "\u2581https", "://", "t", ".", "co", "/", "r", "du", "h", "y", "j", "v", "MG", "q", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_798", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "l", "is", "a", "a", "g", "\u25819", "23", ":", "\u2581Life", "\u2581takes", "\u2581us", "\u2581on", "\u2581some", "\u2581incredible", "\u2581journey", "s", ".", "\u2581At", "\u2581times", "\u2581we", "\u2581feel", "\u2581lost", "\u2581or", "\u2581", "unsure", "\u2581of", "\u2581the", "\u2581decisions", "\u2581we", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "0", "A", "km", "H", "X", "q", "9", "WG", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "l", "is", "a", "a", "g", "\u25819", "23", ":", "\u2581Life", "\u2581takes", "\u2581us", "\u2581on", "\u2581some", "\u2581incredible", "\u2581journey", "s", ".", "\u2581At", "\u2581times", "\u2581we", "\u2581feel", "\u2581lost", "\u2581or", "\u2581", "unsure", "\u2581of", "\u2581the", "\u2581decisions", "\u2581we", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "0", "A", "km", "H", "X", "q", "9", "WG", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "l", "is", "a", "a", "g", "\u25819", "23", ":", "\u2581Life", "\u2581takes", "\u2581us", "\u2581on", "\u2581some", "\u2581incredible", "\u2581journey", "s", ".", "\u2581At", "\u2581times", "\u2581we", "\u2581feel", "\u2581lost", "\u2581or", "\u2581", "unsure", "\u2581of", "\u2581the", "\u2581decisions", "\u2581we", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "0", "A", "km", "H", "X", "q", "9", "WG", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_799", "sentence": ["\u2581On", "\u2581the", "\u2581Street", "\u2581", "...", "\u2581The", "\u2581Fort", "e", "zza", ",", "\u2581Florence", "\u2581#", "\u2581photos", "\u2581https", "://", "t", ".", "co", "/8", "r", "0", "A", "HF", "8", "M", "f", "f", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581On", "\u2581the", "\u2581Street", "\u2581", "...", "\u2581The", "\u2581Fort", "e", "zza", ",", "\u2581Florence", "\u2581#", "\u2581photos", "\u2581https", "://", "t", ".", "co", "/8", "r", "0", "A", "HF", "8", "M", "f", "f", "</s>"], "target_sentence": ["\u2581On", "\u2581the", "\u2581Street", "\u2581", "...", "<m>", "\u2581The", "\u2581Fort", "e", "zza", "</m>", ",", "<m>", "\u2581Florence", "</m>", "\u2581#", "\u2581photos", "\u2581https", "://", "t", ".", "co", "/8", "r", "0", "A", "HF", "8", "M", "f", "f", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_800", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "z", "v", "hir", "X", "X", ":", "\u2581girls", "\u2581please", "\u2581bring", "\u2581these", "\u2581back", ".", "\u2581https", "://", "t", ".", "co", "/2", "WG", "Q", "1", "H", "8", "w", "6", "o", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "z", "v", "hir", "X", "X", ":", "\u2581girls", "\u2581please", "\u2581bring", "\u2581these", "\u2581back", ".", "\u2581https", "://", "t", ".", "co", "/2", "WG", "Q", "1", "H", "8", "w", "6", "o", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "z", "v", "hir", "X", "X", ":", "\u2581girls", "\u2581please", "\u2581bring", "\u2581these", "\u2581back", ".", "\u2581https", "://", "t", ".", "co", "/2", "WG", "Q", "1", "H", "8", "w", "6", "o", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_801", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Kni", "f", "ing", "T", "our", "ney", ":", "\u2581The", "\u2581Kni", "f", "ing", "\u2581Tour", "ney", "\u25812017", "\u2581Judge", "s", ".", "\u2581https", "://", "t", ".", "co", "/", "0", "x", "LP", "X", "96", "N", "HA", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Kni", "f", "ing", "T", "our", "ney", ":", "\u2581The", "\u2581Kni", "f", "ing", "\u2581Tour", "ney", "\u25812017", "\u2581Judge", "s", ".", "\u2581https", "://", "t", ".", "co", "/", "0", "x", "LP", "X", "96", "N", "HA", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Kni", "f", "ing", "T", "our", "ney", ":", "<m>", "\u2581The", "\u2581Kni", "f", "ing", "\u2581Tour", "ney", "</m>", "\u25812017", "<m>", "\u2581Judge", "s", "</m>", ".", "\u2581https", "://", "t", ".", "co", "/", "0", "x", "LP", "X", "96", "N", "HA", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 6, 6, 7, 8, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_802", "sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "V", "i", "d", "S", "pot", ":", "\u2581This", "\u2581awesome", "\u2581invention", "\u2581is", "\u2581basically", "\u2581", "a", "\u2581treadmill", "\u2581rock", "\u2581climbing", "\u2581wall", "\u2581https", "://", "t", ".", "co", "/", "r", "du", "h", "y", "j", "v", "MG", "q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581The", "V", "i", "d", "S", "pot", ":", "\u2581This", "\u2581awesome", "\u2581invention", "\u2581is", "\u2581basically", "\u2581", "a", "\u2581treadmill", "\u2581rock", "\u2581climbing", "\u2581wall", "\u2581https", "://", "t", ".", "co", "/", "r", "du", "h", "y", "j", "v", "MG", "q", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581The", "V", "i", "d", "S", "pot", "</m>", ":", "\u2581This", "\u2581awesome", "\u2581invention", "\u2581is", "\u2581basically", "\u2581", "a", "\u2581treadmill", "\u2581rock", "\u2581climbing", "\u2581wall", "\u2581https", "://", "t", ".", "co", "/", "r", "du", "h", "y", "j", "v", "MG", "q", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_803", "sentence": ["\u2581Someone", "\u2581be", "\u2581down", "\u2581to", "\u2581go", "\u2581to", "\u2581Jo", "J", "o", "'", "\u2581", "s", "\u2581concert", "\u2581with", "\u2581me", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Someone", "\u2581be", "\u2581down", "\u2581to", "\u2581go", "\u2581to", "\u2581Jo", "J", "o", "'", "\u2581", "s", "\u2581concert", "\u2581with", "\u2581me", "</s>"], "target_sentence": ["\u2581Someone", "\u2581be", "\u2581down", "\u2581to", "\u2581go", "\u2581to", "<m>", "\u2581Jo", "J", "o", "</m>", "'", "\u2581", "s", "\u2581concert", "\u2581with", "\u2581me", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_804", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Gray", "son", "Do", "lan", ":", "\u2581Yeah", "\u2581I", "\u2581deleted", "\u2581the", "\u2581first", "\u2581version", "\u2581of", "\u2581that", "\u2581tweet", "\u2581because", "\u2581of", "\u2581spill", "ing", "\u2581errors", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Gray", "son", "Do", "lan", ":", "\u2581Yeah", "\u2581I", "\u2581deleted", "\u2581the", "\u2581first", "\u2581version", "\u2581of", "\u2581that", "\u2581tweet", "\u2581because", "\u2581of", "\u2581spill", "ing", "\u2581errors", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Gray", "son", "Do", "lan", "</m>", ":", "\u2581Yeah", "\u2581I", "\u2581deleted", "\u2581the", "\u2581first", "\u2581version", "\u2581of", "\u2581that", "\u2581tweet", "\u2581because", "\u2581of", "\u2581spill", "ing", "\u2581errors", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_805", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Du", "mp", "Tru", "mp", "\u258122", ":", "\u2581#", "\u2581Spice", "r", "F", "act", "s", "\u2581https", "://", "t", ".", "co", "/", "Q", "g", "TM", "u", "K", "N", "7", "m", "T", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Du", "mp", "Tru", "mp", "\u258122", ":", "\u2581#", "\u2581Spice", "r", "F", "act", "s", "\u2581https", "://", "t", ".", "co", "/", "Q", "g", "TM", "u", "K", "N", "7", "m", "T", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Du", "mp", "Tru", "mp", "\u258122", ":", "\u2581#", "\u2581Spice", "r", "F", "act", "s", "\u2581https", "://", "t", ".", "co", "/", "Q", "g", "TM", "u", "K", "N", "7", "m", "T", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_806", "sentence": ["\u2581#", "\u2581por", "n", "\u2581star", "\u2581brand", "y", "\u2581free", "\u2581old", "\u2581man", "\u2581", "s", "ex", "\u2581https", "://", "t", ".", "co", "/", "I", "z", "j", "Q", "GV", "En", "x", "g", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581por", "n", "\u2581star", "\u2581brand", "y", "\u2581free", "\u2581old", "\u2581man", "\u2581", "s", "ex", "\u2581https", "://", "t", ".", "co", "/", "I", "z", "j", "Q", "GV", "En", "x", "g", "</s>"], "target_sentence": ["\u2581#", "\u2581por", "n", "\u2581star", "<m>", "\u2581brand", "y", "</m>", "\u2581free", "\u2581old", "\u2581man", "\u2581", "s", "ex", "\u2581https", "://", "t", ".", "co", "/", "I", "z", "j", "Q", "GV", "En", "x", "g", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 6, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_807", "sentence": ["\u2581Do", "ing", "\u2581play", "\u2581by", "\u2581play", "\u2581with", "\u2581my", "\u2581buddy", "\u2581@", "\u2581", "j", "f", "radi", "o", "show", "\u2581for", "\u2581the", "\u2581Senate", "\u2581", "v", "\u2581house", "\u2581basketball", "\u2581game", ".", "\u2581Let", "'", "\u2581", "s", "\u2581go", "\u2581Senate", "!", "\u2581https", "://", "t", ".", "co", "/", "g", "f", "0", "q", "0", "v", "LB", "V", "1", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Do", "ing", "\u2581play", "\u2581by", "\u2581play", "\u2581with", "\u2581my", "\u2581buddy", "\u2581@", "\u2581", "j", "f", "radi", "o", "show", "\u2581for", "\u2581the", "\u2581Senate", "\u2581", "v", "\u2581house", "\u2581basketball", "\u2581game", ".", "\u2581Let", "'", "\u2581", "s", "\u2581go", "\u2581Senate", "!", "\u2581https", "://", "t", ".", "co", "/", "g", "f", "0", "q", "0", "v", "LB", "V", "1", "</s>"], "target_sentence": ["\u2581Do", "ing", "\u2581play", "\u2581by", "\u2581play", "\u2581with", "\u2581my", "\u2581buddy", "\u2581@", "<m>", "\u2581", "j", "f", "radi", "o", "show", "</m>", "\u2581for", "\u2581the", "<m>", "\u2581Senate", "</m>", "\u2581", "v", "<m>", "\u2581house", "</m>", "\u2581basketball", "\u2581game", ".", "\u2581Let", "'", "\u2581", "s", "\u2581go", "<m>", "\u2581Senate", "</m>", "!", "\u2581https", "://", "t", ".", "co", "/", "g", "f", "0", "q", "0", "v", "LB", "V", "1", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, 1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_808", "sentence": ["\u25812017", "\u2581", "-", "\u258101", "\u2581", "-", "\u258125", "\u258101", ":", "\u2581", "00", ":", "\u258111", ".", "\u25815", "304", "90", "\u2581(", "\u2581Sensor", ":", "\u258117", "\u2581#", "\u2581", "Temp", ":", "\u258117", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258138", ".", "\u2581000", ")", "\u2581(", "\u2581Sensor", ":", "\u258118", "\u2581#", "\u2581", "Temp", ":", "\u258115", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258137", ".", "\u2581000", ")", "\u2581(", "\u2581Sensor", ":", "\u258127", "\u2581#", "\u2581", "Temp", ":", "\u258115", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258136", ".", "\u2581000", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u25812017", "\u2581", "-", "\u258101", "\u2581", "-", "\u258125", "\u258101", ":", "\u2581", "00", ":", "\u258111", ".", "\u25815", "304", "90", "\u2581(", "\u2581Sensor", ":", "\u258117", "\u2581#", "\u2581", "Temp", ":", "\u258117", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258138", ".", "\u2581000", ")", "\u2581(", "\u2581Sensor", ":", "\u258118", "\u2581#", "\u2581", "Temp", ":", "\u258115", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258137", ".", "\u2581000", ")", "\u2581(", "\u2581Sensor", ":", "\u258127", "\u2581#", "\u2581", "Temp", ":", "\u258115", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258136", ".", "\u2581000", ")", "</s>"], "target_sentence": ["\u25812017", "\u2581", "-", "\u258101", "\u2581", "-", "\u258125", "\u258101", ":", "\u2581", "00", ":", "\u258111", ".", "\u25815", "304", "90", "\u2581(", "\u2581Sensor", ":", "\u258117", "\u2581#", "\u2581", "Temp", ":", "\u258117", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258138", ".", "\u2581000", ")", "\u2581(", "\u2581Sensor", ":", "\u258118", "\u2581#", "\u2581", "Temp", ":", "\u258115", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258137", ".", "\u2581000", ")", "\u2581(", "\u2581Sensor", ":", "\u258127", "\u2581#", "\u2581", "Temp", ":", "\u258115", ".", "\u2581000", "\u2581#", "\u2581Hum", "i", ":", "\u258136", ".", "\u2581000", ")", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 34, 35, 36, 37, 38, 39, 40, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 51, 52, 53, 54, 55, 56, 57, 57, 58, 59, 60, 61, 62, 63], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_809", "sentence": ["\u2581#", "\u2581Good", "\u2581New", "\u2581#", "\u2581Nike", "\u2581Air", "\u2581Jordan", "\u258111", "\u2581", "X", "I", "\u2581#", "\u2581Retro", "\u2581Low", "\u2581Cherry", "\u2581Var", "s", "ity", "\u2581Red", "\u2581100", "\u2581", "%", "\u2581", "Authentic", "\u2581Size", "\u258110", ".", "\u25815", "\u2581https", "://", "t", ".", "co", "/", "S", "n", "s", "O", "c", "5", "p", "E", "w", "P", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "m", "o", "O", "b", "6", "H", "9", "Y", "D", "8", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581Good", "\u2581New", "\u2581#", "\u2581Nike", "\u2581Air", "\u2581Jordan", "\u258111", "\u2581", "X", "I", "\u2581#", "\u2581Retro", "\u2581Low", "\u2581Cherry", "\u2581Var", "s", "ity", "\u2581Red", "\u2581100", "\u2581", "%", "\u2581", "Authentic", "\u2581Size", "\u258110", ".", "\u25815", "\u2581https", "://", "t", ".", "co", "/", "S", "n", "s", "O", "c", "5", "p", "E", "w", "P", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "m", "o", "O", "b", "6", "H", "9", "Y", "D", "8", "</s>"], "target_sentence": ["\u2581#", "\u2581Good", "\u2581New", "\u2581#", "<m>", "<m>", "\u2581Nike", "</m>", "\u2581Air", "\u2581Jordan", "</m>", "\u258111", "\u2581", "X", "I", "\u2581#", "\u2581Retro", "\u2581Low", "\u2581Cherry", "\u2581Var", "s", "ity", "\u2581Red", "\u2581100", "\u2581", "%", "\u2581", "Authentic", "\u2581Size", "\u258110", ".", "\u25815", "\u2581https", "://", "t", ".", "co", "/", "S", "n", "s", "O", "c", "5", "p", "E", "w", "P", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "m", "o", "O", "b", "6", "H", "9", "Y", "D", "8", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 16, 17, 17, 18, 19, 20, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, 1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_810", "sentence": ["\u2581", "RT", "\u2581@", "\u2581I", "g", "b", "try", "den", ":", "\u2581\u201c", "\u2581@", "\u2581", "e", "d", "s", "he", "er", "an", ":", "\u2581My", "\u2581best", "\u2581friend", "\u2581is", "\u2581getting", "\u2581married", "\u2581today", ".", "\u2581Mega", "\u2581awesome", "\u2581wicked", "\u2581cool", ".", "\u2581", "\u201d", "\u2581http", "://", "t", ".", "co", "/", "De", "q", "PM", "d", "o", "y", "o", "B", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581I", "g", "b", "try", "den", ":", "\u2581\u201c", "\u2581@", "\u2581", "e", "d", "s", "he", "er", "an", ":", "\u2581My", "\u2581best", "\u2581friend", "\u2581is", "\u2581getting", "\u2581married", "\u2581today", ".", "\u2581Mega", "\u2581awesome", "\u2581wicked", "\u2581cool", ".", "\u2581", "\u201d", "\u2581http", "://", "t", ".", "co", "/", "De", "q", "PM", "d", "o", "y", "o", "B", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581I", "g", "b", "try", "den", ":", "\u2581\u201c", "\u2581@", "<m>", "\u2581", "e", "d", "s", "he", "er", "an", "</m>", ":", "\u2581My", "\u2581best", "\u2581friend", "\u2581is", "\u2581getting", "\u2581married", "\u2581today", ".", "\u2581Mega", "\u2581awesome", "\u2581wicked", "\u2581cool", ".", "\u2581", "\u201d", "\u2581http", "://", "t", ".", "co", "/", "De", "q", "PM", "d", "o", "y", "o", "B", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_811", "sentence": ["\u2581Man", "\u2581Finn", "a", "\u2581bring", "\u2581me", "\u2581", "a", "\u2581", "\ud83c\udf55", "\u2581up", "\u2581to", "\u2581my", "\u2581job", "\u2581", "\ud83d\ude0e", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Man", "\u2581Finn", "a", "\u2581bring", "\u2581me", "\u2581", "a", "\u2581", "\ud83c\udf55", "\u2581up", "\u2581to", "\u2581my", "\u2581job", "\u2581", "\ud83d\ude0e", "</s>"], "target_sentence": ["\u2581Man", "\u2581Finn", "a", "\u2581bring", "\u2581me", "\u2581", "a", "\u2581", "\ud83c\udf55", "\u2581up", "\u2581to", "\u2581my", "\u2581job", "\u2581", "\ud83d\ude0e", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 5, 5, 6, 7, 8, 9, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_812", "sentence": ["\u2581@", "\u2581Jen", "n", "a", "J", "ack", "son", "\u258116", "\u2581kill", "\u2581you", "\u2581during", "\u2581birth", "\u2581I", "\u2581think", "\u2581it", "'", "\u2581", "s", "\u2581", "a", "\u2581selfish", "\u2581act", "\u2581because", "\u2581that", "'", "\u2581", "s", "\u2581", "a", "\u2581life", "\u2581even", "\u2581", "if", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581think", "\u2581it", "\u2581is", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Jen", "n", "a", "J", "ack", "son", "\u258116", "\u2581kill", "\u2581you", "\u2581during", "\u2581birth", "\u2581I", "\u2581think", "\u2581it", "'", "\u2581", "s", "\u2581", "a", "\u2581selfish", "\u2581act", "\u2581because", "\u2581that", "'", "\u2581", "s", "\u2581", "a", "\u2581life", "\u2581even", "\u2581", "if", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581think", "\u2581it", "\u2581is", "</s>"], "target_sentence": ["\u2581@", "\u2581Jen", "n", "a", "J", "ack", "son", "\u258116", "\u2581kill", "\u2581you", "\u2581during", "\u2581birth", "\u2581I", "\u2581think", "\u2581it", "'", "\u2581", "s", "\u2581", "a", "\u2581selfish", "\u2581act", "\u2581because", "\u2581that", "'", "\u2581", "s", "\u2581", "a", "\u2581life", "\u2581even", "\u2581", "if", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581think", "\u2581it", "\u2581is", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 14, 15, 16, 17, 18, 18, 19, 19, 20, 21, 22, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_813", "sentence": ["\u2581", "RT", "\u2581@", "\u2581da", "z", "b", "\u2581160", ":", "\u2581@", "\u2581Glen", "n", "Temp", "\u2581@", "\u2581adidas", "an", "or", "ak", "\u2581@", "\u2581Dead", "stock", "U", "t", "opia", "\u2581@", "\u2581Original", "So", "le", "o", "g", "\u2581Indoor", "\u2581Super", "\u2581at", "\u2581the", "\u2581moment", ".", "\u2581Summer", "\u2581wear", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581da", "z", "b", "\u2581160", ":", "\u2581@", "\u2581Glen", "n", "Temp", "\u2581@", "\u2581adidas", "an", "or", "ak", "\u2581@", "\u2581Dead", "stock", "U", "t", "opia", "\u2581@", "\u2581Original", "So", "le", "o", "g", "\u2581Indoor", "\u2581Super", "\u2581at", "\u2581the", "\u2581moment", ".", "\u2581Summer", "\u2581wear", "!", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581da", "z", "b", "\u2581160", "</m>", ":", "\u2581@", "<m>", "<m>", "\u2581Glen", "n", "Temp", "</m>", "</m>", "\u2581@", "<m>", "<m>", "\u2581adidas", "an", "or", "ak", "</m>", "</m>", "\u2581@", "<m>", "\u2581Dead", "stock", "U", "t", "opia", "</m>", "\u2581@", "<m>", "\u2581Original", "So", "le", "o", "g", "</m>", "\u2581Indoor", "\u2581Super", "\u2581at", "\u2581the", "\u2581moment", ".", "\u2581Summer", "\u2581wear", "!", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 8, 8, 8, 9, 10, 10, 10, 10, 10, 11, 12, 12, 12, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, 2, 1, -1, -1, -1, 2, 1, -1, 3, 4, -1, -1, -1, -1, 3, 4, -1, 5, -1, -1, -1, -1, -1, 5, -1, 6, -1, -1, -1, -1, -1, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_814", "sentence": ["\u2581Sach", "a", "\u2581Bar", "on", "\u2581Cohen", "\u2581turns", "\u2581football", "\u2581ho", "oli", "gan", "\u2581as", "\u2581his", "\u2581The", "\u2581Brothers", ".", ".", ".", "\u2581#", "\u2581Sach", "a", "Bar", "on", "Co", "hen", "\u2581https", "://", "t", ".", "co", "/", "j", "5", "s", "X", "47", "79", "35", "\u2581#", "\u2581", "s", "ach", "a", "bar", "on", "co", "hen", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Sach", "a", "\u2581Bar", "on", "\u2581Cohen", "\u2581turns", "\u2581football", "\u2581ho", "oli", "gan", "\u2581as", "\u2581his", "\u2581The", "\u2581Brothers", ".", ".", ".", "\u2581#", "\u2581Sach", "a", "Bar", "on", "Co", "hen", "\u2581https", "://", "t", ".", "co", "/", "j", "5", "s", "X", "47", "79", "35", "\u2581#", "\u2581", "s", "ach", "a", "bar", "on", "co", "hen", "</s>"], "target_sentence": ["<m>", "\u2581Sach", "a", "\u2581Bar", "on", "\u2581Cohen", "</m>", "\u2581turns", "\u2581football", "\u2581ho", "oli", "gan", "\u2581as", "\u2581his", "<m>", "\u2581The", "\u2581Brothers", "</m>", ".", ".", ".", "\u2581#", "<m>", "\u2581Sach", "a", "Bar", "on", "Co", "hen", "</m>", "\u2581https", "://", "t", ".", "co", "/", "j", "5", "s", "X", "47", "79", "35", "\u2581#", "\u2581", "s", "ach", "a", "bar", "on", "co", "hen", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_815", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ka", "ley", "ram", "s", ":", "\u2581I", "\u2581just", "\u2581", "s", "cream", "e", "d", "\u2581\"", "\u2581I", "\u2581hate", "\u2581myself", "\u2581\"", "\u2581and", "\u25812", "\u2581minutes", "\u2581later", "\u2581I", "\u2581hear", "\u2581my", "\u2581little", "\u2581brother", "\u2581sliding", "\u2581this", "\u2581note", "\u2581under", "\u2581my", "\u2581door", "\u2581https", "://", "t", ".", "co", "/", "WN", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "ka", "ley", "ram", "s", ":", "\u2581I", "\u2581just", "\u2581", "s", "cream", "e", "d", "\u2581\"", "\u2581I", "\u2581hate", "\u2581myself", "\u2581\"", "\u2581and", "\u25812", "\u2581minutes", "\u2581later", "\u2581I", "\u2581hear", "\u2581my", "\u2581little", "\u2581brother", "\u2581sliding", "\u2581this", "\u2581note", "\u2581under", "\u2581my", "\u2581door", "\u2581https", "://", "t", ".", "co", "/", "WN", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "ka", "ley", "ram", "s", "</m>", ":", "\u2581I", "\u2581just", "\u2581", "s", "cream", "e", "d", "\u2581\"", "\u2581I", "\u2581hate", "\u2581myself", "\u2581\"", "\u2581and", "\u25812", "\u2581minutes", "\u2581later", "\u2581I", "\u2581hear", "\u2581my", "\u2581little", "\u2581brother", "\u2581sliding", "\u2581this", "\u2581note", "\u2581under", "\u2581my", "\u2581door", "\u2581https", "://", "t", ".", "co", "/", "WN", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_816", "sentence": ["\u2581Do", "\u2581not", "\u2581blame", "\u2581your", "\u2581past", ",", "\u2581because", "\u2581the", "\u2581past", "\u2581will", "\u2581never", "\u2581change", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Do", "\u2581not", "\u2581blame", "\u2581your", "\u2581past", ",", "\u2581because", "\u2581the", "\u2581past", "\u2581will", "\u2581never", "\u2581change", ".", "</s>"], "target_sentence": ["\u2581Do", "\u2581not", "\u2581blame", "\u2581your", "\u2581past", ",", "\u2581because", "\u2581the", "\u2581past", "\u2581will", "\u2581never", "\u2581change", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_817", "sentence": ["\u2581Your", "\u2581friends", "\u2581and", "\u2581associate", "s", "\u2581might", "\u2581not", "\u2581be", "\u2581there", "\u2581to", "\u2581support", "\u2581you", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Aqua", "rius", "\u2581https", "://", "t", ".", "co", "/6", "R", "6", "L", "36", "d", "V", "n", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Your", "\u2581friends", "\u2581and", "\u2581associate", "s", "\u2581might", "\u2581not", "\u2581be", "\u2581there", "\u2581to", "\u2581support", "\u2581you", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Aqua", "rius", "\u2581https", "://", "t", ".", "co", "/6", "R", "6", "L", "36", "d", "V", "n", "M", "</s>"], "target_sentence": ["\u2581Your", "\u2581friends", "\u2581and", "\u2581associate", "s", "\u2581might", "\u2581not", "\u2581be", "\u2581there", "\u2581to", "\u2581support", "\u2581you", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Aqua", "rius", "\u2581https", "://", "t", ".", "co", "/6", "R", "6", "L", "36", "d", "V", "n", "M", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_818", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581Out", "O", "f", "The", "S", "e", "a", "\u2581", "_", "\u2581", "X", ":", "\u2581After", "\u2581so", "\u2581many", "\u2581years", "\u2581I", "\u2581do", "\u2581not", "\u2581understand", "\u2581why", "\u2581Barbie", "\u2581and", "\u2581", "ken", "\u2581don", "'", "\u2581", "t", "\u2581live", "\u2581together", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581Out", "O", "f", "The", "S", "e", "a", "\u2581", "_", "\u2581", "X", ":", "\u2581After", "\u2581so", "\u2581many", "\u2581years", "\u2581I", "\u2581do", "\u2581not", "\u2581understand", "\u2581why", "\u2581Barbie", "\u2581and", "\u2581", "ken", "\u2581don", "'", "\u2581", "t", "\u2581live", "\u2581together", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581Out", "O", "f", "The", "S", "e", "a", "\u2581", "_", "\u2581", "X", ":", "\u2581After", "\u2581so", "\u2581many", "\u2581years", "\u2581I", "\u2581do", "\u2581not", "\u2581understand", "\u2581why", "<m>", "\u2581Barbie", "</m>", "\u2581and", "<m>", "\u2581", "ken", "</m>", "\u2581don", "'", "\u2581", "t", "\u2581live", "\u2581together", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_819", "sentence": ["\u2581", "RT", "\u2581@", "\u2581When", "n", "B", "o", "y", "s", ":", "\u2581I", "\u2581want", "\u2581", "a", "\u2581boyfriend", "\u2581who", "\u2581will", "\u2581take", "\u2581me", "\u2581to", "\u2581concerts", ".", ".", "\u2581or", "\u2581just", "\u2581", "a", "\u2581boyfriend", ".", ".", "\u2581or", "\u2581just", "\u2581concert", "\u2581tickets", ".", ".", "\u2581or", "\u2581concert", "\u2581tickets", "\u2581to", "\u2581see", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581When", "n", "B", "o", "y", "s", ":", "\u2581I", "\u2581want", "\u2581", "a", "\u2581boyfriend", "\u2581who", "\u2581will", "\u2581take", "\u2581me", "\u2581to", "\u2581concerts", ".", ".", "\u2581or", "\u2581just", "\u2581", "a", "\u2581boyfriend", ".", ".", "\u2581or", "\u2581just", "\u2581concert", "\u2581tickets", ".", ".", "\u2581or", "\u2581concert", "\u2581tickets", "\u2581to", "\u2581see", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581When", "n", "B", "o", "y", "s", ":", "\u2581I", "\u2581want", "\u2581", "a", "\u2581boyfriend", "\u2581who", "\u2581will", "\u2581take", "\u2581me", "\u2581to", "\u2581concerts", ".", ".", "\u2581or", "\u2581just", "\u2581", "a", "\u2581boyfriend", ".", ".", "\u2581or", "\u2581just", "\u2581concert", "\u2581tickets", ".", ".", "\u2581or", "\u2581concert", "\u2581tickets", "\u2581to", "\u2581see", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_820", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Por", "n", "Har", "d", "d", ":", "\u2581@", "\u2581", "69", "\u2581", "s", "ex", "xx", "o", "\u2581@", "\u2581Teddy", "s", "\u2581", "_", "\u2581take", "over", "\u2581@", "\u2581", "i", "r", "in", "a", "go", "m", "ez", "\u258160", "\u2581@", "\u2581Chic", "a", "s", "\u2581", "_", "\u2581Web", "\u2581@", "\u2581Virtu", "A", "s", "s", "\u2581@", "\u2581", "s", "ex", "o", "t", "x", "\u2581@", "\u2581", "t", "i", "a", "s", "\u2581", "_", "\u2581", "t", "wit", "er", "\u2581@", "\u2581Por", "n", "Har", "d", "d", "\u2581@", "\u2581", "oph", "elia", "\u258123", "10", "13", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Por", "n", "Har", "d", "d", ":", "\u2581@", "\u2581", "69", "\u2581", "s", "ex", "xx", "o", "\u2581@", "\u2581Teddy", "s", "\u2581", "_", "\u2581take", "over", "\u2581@", "\u2581", "i", "r", "in", "a", "go", "m", "ez", "\u258160", "\u2581@", "\u2581Chic", "a", "s", "\u2581", "_", "\u2581Web", "\u2581@", "\u2581Virtu", "A", "s", "s", "\u2581@", "\u2581", "s", "ex", "o", "t", "x", "\u2581@", "\u2581", "t", "i", "a", "s", "\u2581", "_", "\u2581", "t", "wit", "er", "\u2581@", "\u2581Por", "n", "Har", "d", "d", "\u2581@", "\u2581", "oph", "elia", "\u258123", "10", "13", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Por", "n", "Har", "d", "d", ":", "\u2581@", "\u2581", "69", "\u2581", "s", "ex", "xx", "o", "\u2581@", "<m>", "\u2581Teddy", "s", "</m>", "\u2581", "_", "\u2581take", "over", "\u2581@", "<m>", "\u2581", "i", "r", "in", "a", "go", "m", "ez", "</m>", "\u258160", "\u2581@", "\u2581Chic", "a", "s", "\u2581", "_", "\u2581Web", "\u2581@", "\u2581Virtu", "A", "s", "s", "\u2581@", "\u2581", "s", "ex", "o", "t", "x", "\u2581@", "\u2581", "t", "i", "a", "s", "\u2581", "_", "\u2581", "t", "wit", "er", "\u2581@", "\u2581Por", "n", "Har", "d", "d", "\u2581@", "\u2581", "oph", "elia", "\u258123", "10", "13", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 6, 6, 6, 6, 7, 8, 8, 9, 9, 10, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14, 15, 15, 15, 16, 16, 17, 18, 19, 19, 19, 19, 20, 21, 21, 21, 21, 21, 21, 22, 23, 23, 23, 23, 23, 24, 24, 25, 25, 25, 25, 26, 27, 27, 27, 27, 27, 28, 29, 29, 29, 30, 30, 30, 31, 31, 32], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_821", "sentence": ["\u2581@", "\u2581", "r", "m", "a", "this", "\u258115", "\u2581Nicole", "'", "\u2581", "s", "\u2581raspberry", "\u2581", "sorb", "e", "t", "\u2581gum", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "r", "m", "a", "this", "\u258115", "\u2581Nicole", "'", "\u2581", "s", "\u2581raspberry", "\u2581", "sorb", "e", "t", "\u2581gum", "?", "</s>"], "target_sentence": ["\u2581@", "\u2581", "r", "m", "a", "this", "\u258115", "\u2581Nicole", "'", "\u2581", "s", "<m>", "<m>", "\u2581raspberry", "\u2581", "sorb", "e", "t", "\u2581gum", "</m>", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 7, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1]}, {"doc_id": "emerging.test_822", "sentence": ["\u2581@", "\u2581", "gri", "gio", "s", "l", "u", "t", "s", "\u2581@", "\u2581Art", "pop", "Re", "mix", "e", "d", "\u2581you", "\u2581keep", "\u2581saying", "\u2581\"", "\u2581", "if", "\u2581\"", "\u2581it", "\u2581didn", "'", "\u2581", "t", "\u2581face", "\u2581it", "\u2581", "f", "f", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "gri", "gio", "s", "l", "u", "t", "s", "\u2581@", "\u2581Art", "pop", "Re", "mix", "e", "d", "\u2581you", "\u2581keep", "\u2581saying", "\u2581\"", "\u2581", "if", "\u2581\"", "\u2581it", "\u2581didn", "'", "\u2581", "t", "\u2581face", "\u2581it", "\u2581", "f", "f", "s", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "gri", "gio", "s", "l", "u", "t", "s", "</m>", "\u2581@", "<m>", "\u2581Art", "pop", "Re", "mix", "e", "d", "</m>", "\u2581you", "\u2581keep", "\u2581saying", "\u2581\"", "\u2581", "if", "\u2581\"", "\u2581it", "\u2581didn", "'", "\u2581", "t", "\u2581face", "\u2581it", "\u2581", "f", "f", "s", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_823", "sentence": ["\u2581", "RT", "\u2581@", "\u2581bro", "o", "d", "ing", "b", "rahm", "in", ":", "\u2581As", "\u2581", "a", "\u2581veteran", ",", "\u2581this", "\u2581fill", "s", "\u2581me", "\u2581with", "\u2581", "rage", ".", "\u2581Cont", "empt", "uous", "\u2581disregard", "\u2581for", "\u2581those", "\u2581who", "\u2581", "fought", "\u2581and", "\u2581died", "\u2581honor", "ably", "\u2581serving", "\u2581this", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581bro", "o", "d", "ing", "b", "rahm", "in", ":", "\u2581As", "\u2581", "a", "\u2581veteran", ",", "\u2581this", "\u2581fill", "s", "\u2581me", "\u2581with", "\u2581", "rage", ".", "\u2581Cont", "empt", "uous", "\u2581disregard", "\u2581for", "\u2581those", "\u2581who", "\u2581", "fought", "\u2581and", "\u2581died", "\u2581honor", "ably", "\u2581serving", "\u2581this", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581bro", "o", "d", "ing", "b", "rahm", "in", ":", "\u2581As", "\u2581", "a", "\u2581veteran", ",", "\u2581this", "\u2581fill", "s", "\u2581me", "\u2581with", "\u2581", "rage", ".", "\u2581Cont", "empt", "uous", "\u2581disregard", "\u2581for", "\u2581those", "\u2581who", "\u2581", "fought", "\u2581and", "\u2581died", "\u2581honor", "ably", "\u2581serving", "\u2581this", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 10, 11, 12, 12, 13, 14, 14, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 22, 23, 24, 25, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_824", "sentence": ["\u2581", "RT", "\u2581@", "\u2581roman", "hip", "a", "ul", "a", ":", "\u2581https", "://", "t", ".", "co", "/", "M", "z", "X", "u", "2", "u", "q", "OM", "C", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581roman", "hip", "a", "ul", "a", ":", "\u2581https", "://", "t", ".", "co", "/", "M", "z", "X", "u", "2", "u", "q", "OM", "C", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581roman", "hip", "a", "ul", "a", ":", "\u2581https", "://", "t", ".", "co", "/", "M", "z", "X", "u", "2", "u", "q", "OM", "C", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_825", "sentence": ["\u2581The", "\u2581River", "\u2581Rom", ",", "\u2581also", "\u2581in", "\u2581places", "\u2581known", "\u2581as", "\u2581the", "\u2581River", "\u2581Be", "am", ",", "\u2581is", "\u2581", "a", "\u2581river", "\u2581in", "\u2581Essex", "\u2581which", "\u2581becomes", "\u2581", "a", "\u2581", "tribu", "t", "ary", "\u2581of", "\u2581the", "\u2581River", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "j", "zz", "w", "4", "l", "S", "s", "J", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581River", "\u2581Rom", ",", "\u2581also", "\u2581in", "\u2581places", "\u2581known", "\u2581as", "\u2581the", "\u2581River", "\u2581Be", "am", ",", "\u2581is", "\u2581", "a", "\u2581river", "\u2581in", "\u2581Essex", "\u2581which", "\u2581becomes", "\u2581", "a", "\u2581", "tribu", "t", "ary", "\u2581of", "\u2581the", "\u2581River", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "j", "zz", "w", "4", "l", "S", "s", "J", "a", "</s>"], "target_sentence": ["\u2581The", "<m>", "<m>", "\u2581River", "\u2581Rom", "</m>", ",", "</m>", "\u2581also", "\u2581in", "\u2581places", "\u2581known", "\u2581as", "\u2581the", "<m>", "<m>", "\u2581River", "\u2581Be", "am", "</m>", "</m>", ",", "\u2581is", "\u2581", "a", "\u2581river", "\u2581in", "<m>", "<m>", "\u2581Essex", "</m>", "</m>", "\u2581which", "\u2581becomes", "\u2581", "a", "\u2581", "tribu", "t", "ary", "\u2581of", "\u2581the", "\u2581River", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "j", "zz", "w", "4", "l", "S", "s", "J", "a", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21, 21, 21, 22, 23, 24, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, 1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1, 2, 3, -1, -1, -1, -1, -1, -1, 4, 5, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_826", "sentence": ["\u2581", "RT", "\u2581@", "\u2581je", "s", "us", "wore", "cro", "c", "s", ":", "\u2581This", "\u2581is", "\u2581what", "\u2581happens", "\u2581when", "\u2581you", "\u2581give", "\u2581", "a", "\u2581baby", "\u2581", "a", "\u2581vegan", "\u2581smoothie", "\u2581https", "://", "t", ".", "co", "/", "37", "w", "HY", "S", "3", "G", "Z", "q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581je", "s", "us", "wore", "cro", "c", "s", ":", "\u2581This", "\u2581is", "\u2581what", "\u2581happens", "\u2581when", "\u2581you", "\u2581give", "\u2581", "a", "\u2581baby", "\u2581", "a", "\u2581vegan", "\u2581smoothie", "\u2581https", "://", "t", ".", "co", "/", "37", "w", "HY", "S", "3", "G", "Z", "q", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581je", "s", "us", "wore", "cro", "c", "s", ":", "\u2581This", "\u2581is", "\u2581what", "\u2581happens", "\u2581when", "\u2581you", "\u2581give", "\u2581", "a", "\u2581baby", "\u2581", "a", "\u2581vegan", "\u2581smoothie", "\u2581https", "://", "t", ".", "co", "/", "37", "w", "HY", "S", "3", "G", "Z", "q", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_827", "sentence": ["\u25818", "\u2581https", "://", "t", ".", "co", "/", "h", "V", "w", "m", "i", "PR", "b", "PI", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u25818", "\u2581https", "://", "t", ".", "co", "/", "h", "V", "w", "m", "i", "PR", "b", "PI", "</s>"], "target_sentence": ["\u25818", "\u2581https", "://", "t", ".", "co", "/", "h", "V", "w", "m", "i", "PR", "b", "PI", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_828", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "Z", "DA", "NO", "d", "13", "L", "v", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "Z", "DA", "NO", "d", "13", "L", "v", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "Z", "DA", "NO", "d", "13", "L", "v", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_829", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "h", "q", "w", "C", "w", "E", "t", "j", "J", "v", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "h", "q", "w", "C", "w", "E", "t", "j", "J", "v", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "h", "q", "w", "C", "w", "E", "t", "j", "J", "v", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_830", "sentence": ["\u2581", "f", "rug", "ali", "s", "c", "ious", ":", "\u2581It", "'", "\u2581", "s", "\u2581", "Arr", "i", "'", "\u2581", "s", "\u2581Play", "time", "\u2581T", "v", ":", "\u2581how", "\u2581to", "\u2581start", "\u2581The", "\u2581Fisher", "-", "\u2581P", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "r", "S", "i", "O", "w", "f", "OS", "W", "Y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "f", "rug", "ali", "s", "c", "ious", ":", "\u2581It", "'", "\u2581", "s", "\u2581", "Arr", "i", "'", "\u2581", "s", "\u2581Play", "time", "\u2581T", "v", ":", "\u2581how", "\u2581to", "\u2581start", "\u2581The", "\u2581Fisher", "-", "\u2581P", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "r", "S", "i", "O", "w", "f", "OS", "W", "Y", "</s>"], "target_sentence": ["\u2581", "f", "rug", "ali", "s", "c", "ious", ":", "\u2581It", "'", "\u2581", "s", "<m>", "<m>", "\u2581", "Arr", "i", "</m>", "'", "\u2581", "s", "<m>", "\u2581Play", "time", "\u2581T", "v", "</m>", "</m>", ":", "\u2581how", "\u2581to", "\u2581start", "\u2581The", "\u2581Fisher", "-", "\u2581P", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "r", "S", "i", "O", "w", "f", "OS", "W", "Y", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 4, 5, 5, 5, 6, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, -1, -1, -1, 2, -1, -1, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_831", "sentence": ["\u2581#", "\u2581naked", "\u2581on", "\u2581the", "\u2581", "s", "tre", "e", "\u2581", "teen", "\u2581male", "\u2581mature", "\u2581woman", "\u2581https", "://", "t", ".", "co", "/", "T", "l", "R", "r", "NT", "1", "w", "w", "I", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581naked", "\u2581on", "\u2581the", "\u2581", "s", "tre", "e", "\u2581", "teen", "\u2581male", "\u2581mature", "\u2581woman", "\u2581https", "://", "t", ".", "co", "/", "T", "l", "R", "r", "NT", "1", "w", "w", "I", "</s>"], "target_sentence": ["\u2581#", "\u2581naked", "\u2581on", "\u2581the", "\u2581", "s", "tre", "e", "\u2581", "teen", "\u2581male", "\u2581mature", "\u2581woman", "\u2581https", "://", "t", ".", "co", "/", "T", "l", "R", "r", "NT", "1", "w", "w", "I", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 5, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_832", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Thomas", "B", "eau", "t", "y", "y", ":", "\u2581Do", "\u2581you", "\u2581get", "\u2581assault", "e", "d", ",", "\u2581murdered", ",", "\u2581or", "\u2581your", "\u2581rights", "\u2581taken", "\u2581away", "\u2581from", "\u2581being", "\u2581", "a", "\u2581white", "\u2581bit", "ch", "\u2581with", "\u2581", "a", "\u2581big", "\u2581mouth", "?", "\u2581Yes", "\u2581or", "\u2581no", "?", "\u2581https", "://", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Thomas", "B", "eau", "t", "y", "y", ":", "\u2581Do", "\u2581you", "\u2581get", "\u2581assault", "e", "d", ",", "\u2581murdered", ",", "\u2581or", "\u2581your", "\u2581rights", "\u2581taken", "\u2581away", "\u2581from", "\u2581being", "\u2581", "a", "\u2581white", "\u2581bit", "ch", "\u2581with", "\u2581", "a", "\u2581big", "\u2581mouth", "?", "\u2581Yes", "\u2581or", "\u2581no", "?", "\u2581https", "://", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Thomas", "B", "eau", "t", "y", "y", "</m>", ":", "\u2581Do", "\u2581you", "\u2581get", "\u2581assault", "e", "d", ",", "\u2581murdered", ",", "\u2581or", "\u2581your", "\u2581rights", "\u2581taken", "\u2581away", "\u2581from", "\u2581being", "\u2581", "a", "\u2581white", "\u2581bit", "ch", "\u2581with", "\u2581", "a", "\u2581big", "\u2581mouth", "?", "\u2581Yes", "\u2581or", "\u2581no", "?", "\u2581https", "://", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_833", "sentence": ["\u2581#", "\u2581Asta", "n", "a", "\u2581talks", "\u2581end", "\u2581with", "\u2581breakthrough", "\u2581#", "\u2581To", "\u2581resolve", "\u2581#", "\u2581Syria", "\u2581crisis", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "p", "W", "f", "NB", "e", "m", "i", "3", "N", "\u2581https", "://", "t", ".", "co", "/", "o", "c", "5", "R", "d", "1", "E", "H", "0", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581Asta", "n", "a", "\u2581talks", "\u2581end", "\u2581with", "\u2581breakthrough", "\u2581#", "\u2581To", "\u2581resolve", "\u2581#", "\u2581Syria", "\u2581crisis", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "p", "W", "f", "NB", "e", "m", "i", "3", "N", "\u2581https", "://", "t", ".", "co", "/", "o", "c", "5", "R", "d", "1", "E", "H", "0", "z", "</s>"], "target_sentence": ["\u2581#", "<m>", "\u2581Asta", "n", "a", "</m>", "\u2581talks", "\u2581end", "\u2581with", "\u2581breakthrough", "\u2581#", "\u2581To", "\u2581resolve", "\u2581#", "<m>", "\u2581Syria", "</m>", "\u2581crisis", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "p", "W", "f", "NB", "e", "m", "i", "3", "N", "\u2581https", "://", "t", ".", "co", "/", "o", "c", "5", "R", "d", "1", "E", "H", "0", "z", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_834", "sentence": ["\u2581Sweet", "er", "\u2581than", "\u2581", "a", "\u2581", "s", "w", "ish", "a", "a", "a", ",", "\u2581mad", "\u2581cu", "z", "\u2581im", "\u2581cut", "er", "\u2581than", "\u2581the", "\u2581girl", "\u2581that", "s", "\u2581witch", "y", "a", "a", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Sweet", "er", "\u2581than", "\u2581", "a", "\u2581", "s", "w", "ish", "a", "a", "a", ",", "\u2581mad", "\u2581cu", "z", "\u2581im", "\u2581cut", "er", "\u2581than", "\u2581the", "\u2581girl", "\u2581that", "s", "\u2581witch", "y", "a", "a", "a", "</s>"], "target_sentence": ["\u2581Sweet", "er", "\u2581than", "\u2581", "a", "\u2581", "s", "w", "ish", "a", "a", "a", ",", "\u2581mad", "\u2581cu", "z", "\u2581im", "\u2581cut", "er", "\u2581than", "\u2581the", "\u2581girl", "\u2581that", "s", "\u2581witch", "y", "a", "a", "a", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 12, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_835", "sentence": ["\u2581#", "\u2581F", "\u25814", "\u2581F", "\u2581#", "\u2581M", "GW", "V", "\u2581#", "\u2581Follow", "T", "rick", "\u2581#", "\u2581Team", "F", "o", "l", "low", "Back", "\u2581#", "\u2581Another", "F", "o", "l", "low", "Tra", "in", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581F", "\u25814", "\u2581F", "\u2581#", "\u2581M", "GW", "V", "\u2581#", "\u2581Follow", "T", "rick", "\u2581#", "\u2581Team", "F", "o", "l", "low", "Back", "\u2581#", "\u2581Another", "F", "o", "l", "low", "Tra", "in", "</s>"], "target_sentence": ["\u2581#", "\u2581F", "\u25814", "\u2581F", "\u2581#", "\u2581M", "GW", "V", "\u2581#", "\u2581Follow", "T", "rick", "\u2581#", "\u2581Team", "F", "o", "l", "low", "Back", "\u2581#", "\u2581Another", "F", "o", "l", "low", "Tra", "in", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 7, 7, 8, 9, 9, 9, 9, 9, 9, 10, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_836", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "m", "c", "greg", "or", "\u2581", "_", "\u2581", "e", "wan", ":", "\u2581Was", "\u2581going", "\u2581on", "\u2581Good", "\u2581Morning", "\u2581Britain", ",", "\u2581didn", "'", "\u2581", "t", "\u2581realise", "\u2581@", "\u2581", "pier", "s", "m", "organ", "\u2581was", "\u2581host", ".", "\u2581W", "on", "'", "\u2581", "t", "\u2581go", "\u2581on", "\u2581with", "\u2581him", "\u2581after", "\u2581his", "\u2581comments", "\u2581about", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "m", "c", "greg", "or", "\u2581", "_", "\u2581", "e", "wan", ":", "\u2581Was", "\u2581going", "\u2581on", "\u2581Good", "\u2581Morning", "\u2581Britain", ",", "\u2581didn", "'", "\u2581", "t", "\u2581realise", "\u2581@", "\u2581", "pier", "s", "m", "organ", "\u2581was", "\u2581host", ".", "\u2581W", "on", "'", "\u2581", "t", "\u2581go", "\u2581on", "\u2581with", "\u2581him", "\u2581after", "\u2581his", "\u2581comments", "\u2581about", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "m", "c", "greg", "or", "</m>", "\u2581", "_", "<m>", "\u2581", "e", "wan", "</m>", ":", "\u2581Was", "\u2581going", "\u2581on", "<m>", "\u2581Good", "\u2581Morning", "<m>", "\u2581Britain", "</m>", "</m>", ",", "\u2581didn", "'", "\u2581", "t", "\u2581realise", "\u2581@", "<m>", "\u2581", "pier", "s", "m", "organ", "</m>", "\u2581was", "\u2581host", ".", "\u2581W", "on", "'", "\u2581", "t", "\u2581go", "\u2581on", "\u2581with", "\u2581him", "\u2581after", "\u2581his", "\u2581comments", "\u2581about", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 18, 18, 18, 18, 19, 20, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 2, -1, -1, 3, -1, 3, 2, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_837", "sentence": ["\u2581@", "\u2581", "j", "elli", "bun", "\u2581", "h", "m", "mm", "\u2581", "i", "'", "\u2581", "ll", "\u2581prob", "\u2581do", "\u2581that", "\u2581next", "\u2581week", "\u2581", "i", "\u2581", "gotta", "\u2581secure", "\u2581my", "\u2581seat", "\u2581at", "\u2581all", "\u2581costs", "\u2581", "\ud83d\udc4a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "j", "elli", "bun", "\u2581", "h", "m", "mm", "\u2581", "i", "'", "\u2581", "ll", "\u2581prob", "\u2581do", "\u2581that", "\u2581next", "\u2581week", "\u2581", "i", "\u2581", "gotta", "\u2581secure", "\u2581my", "\u2581seat", "\u2581at", "\u2581all", "\u2581costs", "\u2581", "\ud83d\udc4a", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "j", "elli", "bun", "</m>", "\u2581", "h", "m", "mm", "\u2581", "i", "'", "\u2581", "ll", "\u2581prob", "\u2581do", "\u2581that", "\u2581next", "\u2581week", "\u2581", "i", "\u2581", "gotta", "\u2581secure", "\u2581my", "\u2581seat", "\u2581at", "\u2581all", "\u2581costs", "\u2581", "\ud83d\udc4a", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_838", "sentence": ["\u2581On", "\u2581god", "\u2581Da", "rius", "\u2581plug", "s", "\u2581un", "re", "liable", "\u2581as", "f", "\u2581https", "://", "t", ".", "co", "/", "a", "T", "J", "d", "j", "52", "t", "N", "v", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581On", "\u2581god", "\u2581Da", "rius", "\u2581plug", "s", "\u2581un", "re", "liable", "\u2581as", "f", "\u2581https", "://", "t", ".", "co", "/", "a", "T", "J", "d", "j", "52", "t", "N", "v", "</s>"], "target_sentence": ["\u2581On", "\u2581god", "<m>", "<m>", "\u2581Da", "rius", "</m>", "</m>", "\u2581plug", "s", "\u2581un", "re", "liable", "\u2581as", "f", "\u2581https", "://", "t", ".", "co", "/", "a", "T", "J", "d", "j", "52", "t", "N", "v", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_839", "sentence": ["\u2581The", "\u2581She", "e", "p", "\u2581#", "\u2581poetry", "\u2581#", "\u2581poem", "\u2581#", "\u2581writing", "\u2581#", "\u2581am", "writing", "\u2581#", "\u2581words", "\u2581#", "\u2581political", "\u2581#", "\u2581Du", "mp", "Tru", "mp", "\u2581https", "://", "t", ".", "co", "/", "Z", "6", "d", "y", "L", "c", "X", "l", "W", "F", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581She", "e", "p", "\u2581#", "\u2581poetry", "\u2581#", "\u2581poem", "\u2581#", "\u2581writing", "\u2581#", "\u2581am", "writing", "\u2581#", "\u2581words", "\u2581#", "\u2581political", "\u2581#", "\u2581Du", "mp", "Tru", "mp", "\u2581https", "://", "t", ".", "co", "/", "Z", "6", "d", "y", "L", "c", "X", "l", "W", "F", "</s>"], "target_sentence": ["<m>", "\u2581The", "\u2581She", "e", "p", "</m>", "\u2581#", "\u2581poetry", "\u2581#", "\u2581poem", "\u2581#", "\u2581writing", "\u2581#", "\u2581am", "writing", "\u2581#", "\u2581words", "\u2581#", "\u2581political", "\u2581#", "<m>", "\u2581Du", "mp", "Tru", "mp", "</m>", "\u2581https", "://", "t", ".", "co", "/", "Z", "6", "d", "y", "L", "c", "X", "l", "W", "F", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_840", "sentence": ["\u2581I", "\u2581think", "\u2581", "obi", "\u2581", "wan", "\u2581Ken", "obi", "\u2581had", "\u2581short", "\u2581term", "\u2581memory", "\u2581loss", "\u2581when", "\u2581", "he", "\u2581forgot", "\u2581to", "\u2581mention", "\u2581that", "\u2581Dar", "th", "\u2581is", "\u2581your", "\u2581father", "\u2581and", "\u2581you", "\u2581have", "\u2581", "a", "\u2581sister", "\u2581@", "\u2581Ham", "ill", "H", "im", "self", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581think", "\u2581", "obi", "\u2581", "wan", "\u2581Ken", "obi", "\u2581had", "\u2581short", "\u2581term", "\u2581memory", "\u2581loss", "\u2581when", "\u2581", "he", "\u2581forgot", "\u2581to", "\u2581mention", "\u2581that", "\u2581Dar", "th", "\u2581is", "\u2581your", "\u2581father", "\u2581and", "\u2581you", "\u2581have", "\u2581", "a", "\u2581sister", "\u2581@", "\u2581Ham", "ill", "H", "im", "self", "</s>"], "target_sentence": ["\u2581I", "\u2581think", "<m>", "<m>", "\u2581", "obi", "\u2581", "wan", "\u2581Ken", "obi", "</m>", "</m>", "\u2581had", "\u2581short", "\u2581term", "\u2581memory", "\u2581loss", "\u2581when", "\u2581", "he", "\u2581forgot", "\u2581to", "\u2581mention", "\u2581that", "<m>", "<m>", "\u2581Dar", "th", "</m>", "</m>", "\u2581is", "\u2581your", "\u2581father", "\u2581and", "\u2581you", "\u2581have", "\u2581", "a", "\u2581sister", "\u2581@", "<m>", "\u2581Ham", "ill", "H", "im", "self", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1], "ent_indices": [-1, -1, 1, 0, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 2, -1, -1, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, 4, -1]}, {"doc_id": "emerging.test_841", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "f", "a", "e", "riel", "i", ":", "\u258111", ":", "\u258111", "\u2581cake", "!", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "f", "a", "e", "riel", "i", ":", "\u258111", ":", "\u258111", "\u2581cake", "!", "!", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "f", "a", "e", "riel", "i", ":", "\u258111", ":", "\u258111", "\u2581cake", "!", "!", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_842", "sentence": ["\u2581#", "\u2581author", "con", "fession", "\u2581D", "\u258125", ":", "\u2581F", "avour", "it", "e", "\u2581Inspiration", "al", "\u2581Quote", "\u2581https", "://", "t", ".", "co", "/", "W", "5", "V", "c", "DV", "0", "K", "z", "I", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581author", "con", "fession", "\u2581D", "\u258125", ":", "\u2581F", "avour", "it", "e", "\u2581Inspiration", "al", "\u2581Quote", "\u2581https", "://", "t", ".", "co", "/", "W", "5", "V", "c", "DV", "0", "K", "z", "I", "</s>"], "target_sentence": ["\u2581#", "\u2581author", "con", "fession", "\u2581D", "\u258125", ":", "\u2581F", "avour", "it", "e", "\u2581Inspiration", "al", "\u2581Quote", "\u2581https", "://", "t", ".", "co", "/", "W", "5", "V", "c", "DV", "0", "K", "z", "I", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 5, 5, 5, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_843", "sentence": ["\u2581Re", "t", "we", "e", "ting", "\u2581for", "\u2581@", "\u2581Bad", "lands", "NP", "S", ".", "\u2581#", "\u2581Climate", "Ch", "ange", "\u2581is", "\u2581real", "!", "\u2581#", "\u2581The", "Re", "s", "i", "stance", "\u2581#", "\u2581", "Def", "y", "Tru", "mp", "\u2581#", "\u2581Trump", "Le", "ak", "s", "\u2581#", "\u2581D", "work", "in", "Re", "port", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/1", "b", "7", "q", "I", "h", "t", "q", "w", "H", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Re", "t", "we", "e", "ting", "\u2581for", "\u2581@", "\u2581Bad", "lands", "NP", "S", ".", "\u2581#", "\u2581Climate", "Ch", "ange", "\u2581is", "\u2581real", "!", "\u2581#", "\u2581The", "Re", "s", "i", "stance", "\u2581#", "\u2581", "Def", "y", "Tru", "mp", "\u2581#", "\u2581Trump", "Le", "ak", "s", "\u2581#", "\u2581D", "work", "in", "Re", "port", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/1", "b", "7", "q", "I", "h", "t", "q", "w", "H", "</s>"], "target_sentence": ["\u2581Re", "t", "we", "e", "ting", "\u2581for", "\u2581@", "<m>", "\u2581Bad", "lands", "NP", "S", "</m>", ".", "\u2581#", "\u2581Climate", "Ch", "ange", "\u2581is", "\u2581real", "!", "\u2581#", "<m>", "\u2581The", "Re", "s", "i", "stance", "</m>", "\u2581#", "\u2581", "Def", "y", "Tru", "mp", "\u2581#", "\u2581Trump", "Le", "ak", "s", "\u2581#", "\u2581D", "work", "in", "Re", "port", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/1", "b", "7", "q", "I", "h", "t", "q", "w", "H", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 12, 13, 13, 13, 13, 13, 14, 15, 15, 15, 15, 16, 17, 17, 17, 17, 17, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_844", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "v", "l", "N", "er", "7", "z", "5", "w", "6", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "v", "l", "N", "er", "7", "z", "5", "w", "6", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "v", "l", "N", "er", "7", "z", "5", "w", "6", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_845", "sentence": ["\u2581", "o", "m", "g", "\u2581this", "\u2581song", "\u2581makes", "\u2581me", "\u2581cry", "\u2581every", "time", "\u2581https", "://", "t", ".", "co", "/", "F", "m", "5", "R", "s", "z", "m", "X", "Hz", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "o", "m", "g", "\u2581this", "\u2581song", "\u2581makes", "\u2581me", "\u2581cry", "\u2581every", "time", "\u2581https", "://", "t", ".", "co", "/", "F", "m", "5", "R", "s", "z", "m", "X", "Hz", "</s>"], "target_sentence": ["\u2581", "o", "m", "g", "\u2581this", "\u2581song", "\u2581makes", "\u2581me", "\u2581cry", "\u2581every", "time", "\u2581https", "://", "t", ".", "co", "/", "F", "m", "5", "R", "s", "z", "m", "X", "Hz", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_846", "sentence": ["\u2581\u201c", "\u2581La", "\u2581La", "\u2581Land", "\u2581", "\u201d", "\u2581received", "\u258114", "\u2581Academy", "\u2581Award", "\u2581nomination", "s", ",", "\u2581", "t", "ying", "\u2581the", "\u2581record", "\u2581set", "\u2581by", "\u2581the", "\u2581films", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "u", "by", "j", "CHI", "W", "K", "D", "\u2581by", "\u2581#", "\u2581CNN", "\u2581via", "\u2581@", "\u2581", "c", "\u2581", "0", "\u2581", "n", "ve", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\u201c", "\u2581La", "\u2581La", "\u2581Land", "\u2581", "\u201d", "\u2581received", "\u258114", "\u2581Academy", "\u2581Award", "\u2581nomination", "s", ",", "\u2581", "t", "ying", "\u2581the", "\u2581record", "\u2581set", "\u2581by", "\u2581the", "\u2581films", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "u", "by", "j", "CHI", "W", "K", "D", "\u2581by", "\u2581#", "\u2581CNN", "\u2581via", "\u2581@", "\u2581", "c", "\u2581", "0", "\u2581", "n", "ve", "y", "</s>"], "target_sentence": ["\u2581\u201c", "<m>", "\u2581La", "\u2581La", "\u2581Land", "</m>", "\u2581", "\u201d", "\u2581received", "\u258114", "\u2581Academy", "\u2581Award", "\u2581nomination", "s", ",", "\u2581", "t", "ying", "\u2581the", "\u2581record", "\u2581set", "\u2581by", "\u2581the", "\u2581films", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "u", "by", "j", "CHI", "W", "K", "D", "\u2581by", "\u2581#", "\u2581CNN", "\u2581via", "\u2581@", "\u2581", "c", "\u2581", "0", "\u2581", "n", "ve", "y", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 23, 24, 25, 26, 27, 27, 28, 28, 29, 29, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_847", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Mas", "o", "o", "d", "R", "a", "w", ":", "\u2581Can", "\u2581you", "\u2581ask", "\u2581them", "\u2581when", "\u2581", "rama", "dan", "\u2581is", "\u2581https", "://", "t", ".", "co", "/", "n", "I", "i", "6", "LOG", "k", "P", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Mas", "o", "o", "d", "R", "a", "w", ":", "\u2581Can", "\u2581you", "\u2581ask", "\u2581them", "\u2581when", "\u2581", "rama", "dan", "\u2581is", "\u2581https", "://", "t", ".", "co", "/", "n", "I", "i", "6", "LOG", "k", "P", "s", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Mas", "o", "o", "d", "R", "a", "w", ":", "\u2581Can", "\u2581you", "\u2581ask", "\u2581them", "\u2581when", "\u2581", "rama", "dan", "\u2581is", "\u2581https", "://", "t", ".", "co", "/", "n", "I", "i", "6", "LOG", "k", "P", "s", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_848", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Wor", "I", "d", "Star", "Co", "med", "y", ":", "\u2581Everything", "\u2581this", "\u2581guy", "\u2581does", "\u2581is", "\u2581so", "\u2581joke", "s", "\u2581", "\ud83d\ude02", "\u2581https", "://", "t", ".", "co", "/", "u", "h", "x", "my", "b", "h", "s", "Y", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Wor", "I", "d", "Star", "Co", "med", "y", ":", "\u2581Everything", "\u2581this", "\u2581guy", "\u2581does", "\u2581is", "\u2581so", "\u2581joke", "s", "\u2581", "\ud83d\ude02", "\u2581https", "://", "t", ".", "co", "/", "u", "h", "x", "my", "b", "h", "s", "Y", "z", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Wor", "I", "d", "Star", "Co", "med", "y", "</m>", ":", "\u2581Everything", "\u2581this", "\u2581guy", "\u2581does", "\u2581is", "\u2581so", "\u2581joke", "s", "\u2581", "\ud83d\ude02", "\u2581https", "://", "t", ".", "co", "/", "u", "h", "x", "my", "b", "h", "s", "Y", "z", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_849", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "s", "a", "v", "mont", "an", "o", ":", "\u2581https", "://", "t", ".", "co", "/", "f", "D", "c", "1", "n", "J", "7", "W", "Q", "6", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "s", "a", "v", "mont", "an", "o", ":", "\u2581https", "://", "t", ".", "co", "/", "f", "D", "c", "1", "n", "J", "7", "W", "Q", "6", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "s", "a", "v", "mont", "an", "o", "</m>", ":", "\u2581https", "://", "t", ".", "co", "/", "f", "D", "c", "1", "n", "J", "7", "W", "Q", "6", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_850", "sentence": ["\u2581", "RT", "\u2581@", "\u2581mi", "y", "u", "\u2581", "_", "\u2581mon", ":", "\u2581Beauty", "\u2581comes", "\u2581from", "\u2581within", ".", "\u2581https", "://", "t", ".", "co", "/", "Y", "LE", "8", "Y", "l", "86", "Y", "E", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581mi", "y", "u", "\u2581", "_", "\u2581mon", ":", "\u2581Beauty", "\u2581comes", "\u2581from", "\u2581within", ".", "\u2581https", "://", "t", ".", "co", "/", "Y", "LE", "8", "Y", "l", "86", "Y", "E", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581mi", "y", "u", "\u2581", "_", "\u2581mon", ":", "\u2581Beauty", "\u2581comes", "\u2581from", "<m>", "\u2581within", "</m>", ".", "\u2581https", "://", "t", ".", "co", "/", "Y", "LE", "8", "Y", "l", "86", "Y", "E", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_851", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Panda", "s", "D", "a", "i", "I", "y", ":", "\u2581me", "\u2581after", "\u2581studying", "\u2581for", "\u25817", "\u2581seconds", "\u2581https", "://", "t", ".", "co", "/", "bu", "7", "a", "B", "k", "I", "j", "Y", "j", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Panda", "s", "D", "a", "i", "I", "y", ":", "\u2581me", "\u2581after", "\u2581studying", "\u2581for", "\u25817", "\u2581seconds", "\u2581https", "://", "t", ".", "co", "/", "bu", "7", "a", "B", "k", "I", "j", "Y", "j", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Panda", "s", "D", "a", "i", "I", "y", ":", "\u2581me", "\u2581after", "\u2581studying", "\u2581for", "\u25817", "\u2581seconds", "\u2581https", "://", "t", ".", "co", "/", "bu", "7", "a", "B", "k", "I", "j", "Y", "j", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_852", "sentence": ["\u2581Now", "\u2581playing", ":", "\u2581In", "\u2581My", "\u2581Bed", "\u2581by", "\u2581Amy", "\u2581Wine", "house", "\u2581#", "\u2581now", "play", "ing", "\u2581Listen", "\u2581live", ":", "\u2581https", "://", "t", ".", "co", "/", "p", "H", "X", "LO", "1", "e", "b", "4", "v", "\u2581https", "://", "t", ".", "co", "/", "M", "Z", "N", "l", "O", "y", "v", "AJ", "4", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Now", "\u2581playing", ":", "\u2581In", "\u2581My", "\u2581Bed", "\u2581by", "\u2581Amy", "\u2581Wine", "house", "\u2581#", "\u2581now", "play", "ing", "\u2581Listen", "\u2581live", ":", "\u2581https", "://", "t", ".", "co", "/", "p", "H", "X", "LO", "1", "e", "b", "4", "v", "\u2581https", "://", "t", ".", "co", "/", "M", "Z", "N", "l", "O", "y", "v", "AJ", "4", "</s>"], "target_sentence": ["\u2581Now", "\u2581playing", ":", "<m>", "\u2581In", "\u2581My", "\u2581Bed", "\u2581by", "<m>", "<m>", "\u2581Amy", "\u2581Wine", "house", "</m>", "</m>", "</m>", "\u2581#", "\u2581now", "play", "ing", "<m>", "\u2581Listen", "\u2581live", "</m>", ":", "\u2581https", "://", "t", ".", "co", "/", "p", "H", "X", "LO", "1", "e", "b", "4", "v", "\u2581https", "://", "t", ".", "co", "/", "M", "Z", "N", "l", "O", "y", "v", "AJ", "4", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 1, 2, -1, -1, -1, 1, 0, 2, -1, -1, -1, -1, 3, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_853", "sentence": ["\u2581Clean", "\u2581Sw", "e", "e", "p", "\u2581as", "\u2581cathedral", "\u2581links", "\u2581up", "\u2581with", "\u2581city", "\u2581charity", "\u2581https", "://", "t", ".", "co", "/5", "VE", "I", "B", "K", "2", "28", "B", "\u2581https", "://", "t", ".", "co", "/", "D", "c", "w", "F", "j", "8", "k", "5", "X", "E", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Clean", "\u2581Sw", "e", "e", "p", "\u2581as", "\u2581cathedral", "\u2581links", "\u2581up", "\u2581with", "\u2581city", "\u2581charity", "\u2581https", "://", "t", ".", "co", "/5", "VE", "I", "B", "K", "2", "28", "B", "\u2581https", "://", "t", ".", "co", "/", "D", "c", "w", "F", "j", "8", "k", "5", "X", "E", "</s>"], "target_sentence": ["\u2581Clean", "\u2581Sw", "e", "e", "p", "\u2581as", "\u2581cathedral", "\u2581links", "\u2581up", "\u2581with", "\u2581city", "\u2581charity", "\u2581https", "://", "t", ".", "co", "/5", "VE", "I", "B", "K", "2", "28", "B", "\u2581https", "://", "t", ".", "co", "/", "D", "c", "w", "F", "j", "8", "k", "5", "X", "E", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_854", "sentence": ["\u2581Blog", "\u2581Technology", "\u2581to", "\u2581review", "\u2581the", "\u2581electronic", "\u2581devices", "\u2581and", "\u2581accessories", "\u2581and", "\u2581other", ".", "\u2581https", "://", "t", ".", "co", "/", "i", "5", "w", "a", "TF", "D", "1", "Z", "p", "\u2581|", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258103", ":", "\u2581", "00", "\u2581AM", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Blog", "\u2581Technology", "\u2581to", "\u2581review", "\u2581the", "\u2581electronic", "\u2581devices", "\u2581and", "\u2581accessories", "\u2581and", "\u2581other", ".", "\u2581https", "://", "t", ".", "co", "/", "i", "5", "w", "a", "TF", "D", "1", "Z", "p", "\u2581|", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258103", ":", "\u2581", "00", "\u2581AM", "</s>"], "target_sentence": ["<m>", "\u2581Blog", "\u2581Technology", "</m>", "\u2581to", "\u2581review", "\u2581the", "\u2581electronic", "\u2581devices", "\u2581and", "\u2581accessories", "\u2581and", "\u2581other", ".", "\u2581https", "://", "t", ".", "co", "/", "i", "5", "w", "a", "TF", "D", "1", "Z", "p", "\u2581|", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258103", ":", "\u2581", "00", "\u2581AM", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_855", "sentence": ["\u2581", "RT", "\u2581@", "\u2581say", "kom", "al", "a", ":", "\u2581Good", "\u2581morning", "gg", "\u2581", "~", "\u2581#", "\u2581Miss", "Univers", "e", "\u2581#", "\u2581Indonesia", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581say", "kom", "al", "a", ":", "\u2581Good", "\u2581morning", "gg", "\u2581", "~", "\u2581#", "\u2581Miss", "Univers", "e", "\u2581#", "\u2581Indonesia", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581say", "kom", "al", "a", ":", "\u2581Good", "\u2581morning", "gg", "\u2581", "~", "\u2581#", "<m>", "<m>", "\u2581Miss", "Univers", "e", "</m>", "</m>", "\u2581#", "<m>", "\u2581Indonesia", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 5, 6, 6, 7, 8, 8, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 1, 0, -1, 2, -1, 2, -1]}, {"doc_id": "emerging.test_856", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Lawrence", ":", "\u2581Hug", "e", "\u2581breakthrough", "!", "\u2581@", "\u2581", "n", "y", "time", "s", "\u2581calling", "\u2581", "a", "\u2581lie", "\u2581", "a", "\u2581lie", ".", "\u2581In", "\u2581front", "\u2581page", "\u2581headline", ".", "\u2581Should", "'", "\u2581", "ve", "\u2581done", "\u2581it", "\u2581every", "\u2581day", "\u2581of", "\u2581campaign", ".", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Lawrence", ":", "\u2581Hug", "e", "\u2581breakthrough", "!", "\u2581@", "\u2581", "n", "y", "time", "s", "\u2581calling", "\u2581", "a", "\u2581lie", "\u2581", "a", "\u2581lie", ".", "\u2581In", "\u2581front", "\u2581page", "\u2581headline", ".", "\u2581Should", "'", "\u2581", "ve", "\u2581done", "\u2581it", "\u2581every", "\u2581day", "\u2581of", "\u2581campaign", ".", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Lawrence", "</m>", ":", "\u2581Hug", "e", "\u2581breakthrough", "!", "\u2581@", "\u2581", "n", "y", "time", "s", "\u2581calling", "\u2581", "a", "\u2581lie", "\u2581", "a", "\u2581lie", ".", "\u2581In", "\u2581front", "\u2581page", "\u2581headline", ".", "\u2581Should", "'", "\u2581", "ve", "\u2581done", "\u2581it", "\u2581every", "\u2581day", "\u2581of", "\u2581campaign", ".", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 8, 8, 8, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 30, 30, 30, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_857", "sentence": ["\u2581this", "\u258114", "92", "\u2581", "tru", "mp", "\u2581adventure", "\u2581might", "\u2581not", "\u2581work", "\u2581for", "\u2581", "tru", "mp", "\u2581and", "\u2581this", "\u2581time", "\u2581", "he", "\u2581cannot", "\u2581blame", "\u2581so", "ros", ".", "!", "!", "!", "\u2581the", "\u2581wall", "\u2581in", "\u2581me", "x", "ico", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "D", "9", "Y", "O", "o", "LL", "u", "R", "q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581this", "\u258114", "92", "\u2581", "tru", "mp", "\u2581adventure", "\u2581might", "\u2581not", "\u2581work", "\u2581for", "\u2581", "tru", "mp", "\u2581and", "\u2581this", "\u2581time", "\u2581", "he", "\u2581cannot", "\u2581blame", "\u2581so", "ros", ".", "!", "!", "!", "\u2581the", "\u2581wall", "\u2581in", "\u2581me", "x", "ico", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "D", "9", "Y", "O", "o", "LL", "u", "R", "q", "</s>"], "target_sentence": ["\u2581this", "\u258114", "92", "<m>", "\u2581", "tru", "mp", "</m>", "\u2581adventure", "\u2581might", "\u2581not", "\u2581work", "\u2581for", "<m>", "\u2581", "tru", "mp", "</m>", "\u2581and", "\u2581this", "\u2581time", "\u2581", "he", "\u2581cannot", "\u2581blame", "\u2581so", "ros", ".", "!", "!", "!", "\u2581the", "\u2581wall", "\u2581in", "<m>", "\u2581me", "x", "ico", "</m>", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "D", "9", "Y", "O", "o", "LL", "u", "R", "q", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 24, 25, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_858", "sentence": ["\u2581Il", "lumina", "t", "i", "am", ":", "\u2581The", "\u2581First", "\u2581Testament", "\u2581Of", "\u2581The", "\u2581Il", "lumina", "t", "i", "\u2581https", "://", "t", ".", "co", "/", "D", "z", "w", "R", "WG", "m", "6", "f", "B", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Il", "lumina", "t", "i", "am", ":", "\u2581The", "\u2581First", "\u2581Testament", "\u2581Of", "\u2581The", "\u2581Il", "lumina", "t", "i", "\u2581https", "://", "t", ".", "co", "/", "D", "z", "w", "R", "WG", "m", "6", "f", "B", "</s>"], "target_sentence": ["<m>", "\u2581Il", "lumina", "t", "i", "am", ":", "\u2581The", "\u2581First", "\u2581Testament", "\u2581Of", "\u2581The", "\u2581Il", "lumina", "t", "i", "</m>", "\u2581https", "://", "t", ".", "co", "/", "D", "z", "w", "R", "WG", "m", "6", "f", "B", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_859", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Prison", "Plan", "e", "t", ":", "\u2581Trump", "\u2581vow", "s", "\u2581to", "\u2581stop", "\u2581Islamic", "\u2581", "terrorism", "!", "\u2581How", "\u2581dar", "e", "\u2581", "he", "?", "\u2581This", "\u2581might", "\u2581offen", "d", "\u2581Islamic", "\u2581terrorist", "s", "!", "\u2581I", "'", "\u2581", "m", "\u2581literally", "\u2581shaking", ".", "\u2581https", ":", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Prison", "Plan", "e", "t", ":", "\u2581Trump", "\u2581vow", "s", "\u2581to", "\u2581stop", "\u2581Islamic", "\u2581", "terrorism", "!", "\u2581How", "\u2581dar", "e", "\u2581", "he", "?", "\u2581This", "\u2581might", "\u2581offen", "d", "\u2581Islamic", "\u2581terrorist", "s", "!", "\u2581I", "'", "\u2581", "m", "\u2581literally", "\u2581shaking", ".", "\u2581https", ":", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Prison", "Plan", "e", "t", ":", "<m>", "\u2581Trump", "</m>", "\u2581vow", "s", "\u2581to", "\u2581stop", "<m>", "\u2581Islamic", "\u2581", "terrorism", "</m>", "!", "\u2581How", "\u2581dar", "e", "\u2581", "he", "?", "\u2581This", "\u2581might", "\u2581offen", "d", "\u2581Islamic", "\u2581terrorist", "s", "!", "\u2581I", "'", "\u2581", "m", "\u2581literally", "\u2581shaking", ".", "\u2581https", ":", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16, 17, 17, 18, 19, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_860", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ban", "go", "o", "an", "\u2581", "_", "\u2581", "a", "e", "k", ":", "\u2581https", "://", "t", ".", "co", "/", "h", "s", "o", "My", "2", "H", "am", "k", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ban", "go", "o", "an", "\u2581", "_", "\u2581", "a", "e", "k", ":", "\u2581https", "://", "t", ".", "co", "/", "h", "s", "o", "My", "2", "H", "am", "k", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581ban", "go", "o", "an", "\u2581", "_", "\u2581", "a", "e", "k", ":", "\u2581https", "://", "t", ".", "co", "/", "h", "s", "o", "My", "2", "H", "am", "k", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_861", "sentence": ["\u2581", "Probably", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581people", "\u2581who", "\u2581have", "\u2581always", "\u2581known", "\u2581what", "\u2581I", "\u2581am", "\u2581capable", "\u2581of", "\u2581", "\ud83d\udcaa", "\u2581", "\ud83d\udcaf", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Probably", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581people", "\u2581who", "\u2581have", "\u2581always", "\u2581known", "\u2581what", "\u2581I", "\u2581am", "\u2581capable", "\u2581of", "\u2581", "\ud83d\udcaa", "\u2581", "\ud83d\udcaf", "</s>"], "target_sentence": ["\u2581", "Probably", "\u2581one", "\u2581of", "\u2581the", "\u2581few", "\u2581people", "\u2581who", "\u2581have", "\u2581always", "\u2581known", "\u2581what", "\u2581I", "\u2581am", "\u2581capable", "\u2581of", "\u2581", "\ud83d\udcaa", "\u2581", "\ud83d\udcaf", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_862", "sentence": ["\u2581", "RT", "\u2581@", "\u2581me", "o", "y", "u", "a", "s", "a", ":", "\u2581Love", "\u2581", "&", "\u2581amp", ";", "\u2581kindness", "\u2581move", "\u2581mountains", ".", "\u2581https", "://", "t", ".", "co", "/", "cu", "6", "s", "6", "d", "f", "pop", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581me", "o", "y", "u", "a", "s", "a", ":", "\u2581Love", "\u2581", "&", "\u2581amp", ";", "\u2581kindness", "\u2581move", "\u2581mountains", ".", "\u2581https", "://", "t", ".", "co", "/", "cu", "6", "s", "6", "d", "f", "pop", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581me", "o", "y", "u", "a", "s", "a", "</m>", ":", "\u2581Love", "\u2581", "&", "\u2581amp", ";", "\u2581kindness", "\u2581move", "\u2581mountains", ".", "\u2581https", "://", "t", ".", "co", "/", "cu", "6", "s", "6", "d", "f", "pop", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_863", "sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581just", "\u2581", "voted", "\u2581for", "\u2581@", "\u2581fifth", "har", "mony", "\u2581to", "\u2581win", "\u2581#", "\u2581Best", "F", "ans", "\u25812017", "!", "\u2581#", "\u25815", "\u2581H", "Best", "F", "ans", "\u2581https", "://", "t", ".", "co", "/", "f", "x", "FN", "h", "n", "v", "Z", "4", "t", "\u2581", "\ud83d\ude0a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "ve", "\u2581just", "\u2581", "voted", "\u2581for", "\u2581@", "\u2581fifth", "har", "mony", "\u2581to", "\u2581win", "\u2581#", "\u2581Best", "F", "ans", "\u25812017", "!", "\u2581#", "\u25815", "\u2581H", "Best", "F", "ans", "\u2581https", "://", "t", ".", "co", "/", "f", "x", "FN", "h", "n", "v", "Z", "4", "t", "\u2581", "\ud83d\ude0a", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581just", "\u2581", "voted", "\u2581for", "\u2581@", "\u2581fifth", "har", "mony", "\u2581to", "\u2581win", "\u2581#", "\u2581Best", "F", "ans", "\u25812017", "!", "\u2581#", "\u25815", "\u2581H", "Best", "F", "ans", "\u2581https", "://", "t", ".", "co", "/", "f", "x", "FN", "h", "n", "v", "Z", "4", "t", "\u2581", "\ud83d\ude0a", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_864", "sentence": ["\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 8, 8, 8, 9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_865", "sentence": ["\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "target_sentence": ["\u2581", "RT", "<m>", "\u2581@", "\u25815", "\u2581Hon", "T", "our", "</m>", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 8, 8, 8, 9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_866", "sentence": ["\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u25815", "<m>", "\u2581Hon", "T", "our", "</m>", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 8, 8, 8, 9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_867", "sentence": ["\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u25815", "\u2581Hon", "T", "our", ":", "\u2581#", "\u2581Work", "From", "Home", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u25815", "<m>", "\u2581Hon", "T", "our", "</m>", ":", "\u2581#", "<m>", "\u2581Work", "From", "Home", "</m>", "\u2581#", "\u2581Best", "Music", "Video", "\u2581#", "\u2581", "i", "He", "art", "A", "ward", "s", "\u2581https", "://", "t", ".", "co", "/", "GW", "d", "K", "7", "L", "7", "R", "t", "R", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 8, 8, 8, 9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_868", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Ju", "ven", "s", "\u258190", ":", "\u2581If", "\u2581you", "\u2581always", "\u2581date", "\u2581people", "\u2581that", "\u2581are", "n", "'", "\u2581", "t", "\u2581", "s", "hit", ",", "\u2581you", "'", "\u2581", "re", "\u2581at", "tracted", "\u2581to", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581", "s", "hit", "\u2581people", ",", "\u2581cause", "\u2581you", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581", "s", "hit", "\u2581either", ".", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Ju", "ven", "s", "\u258190", ":", "\u2581If", "\u2581you", "\u2581always", "\u2581date", "\u2581people", "\u2581that", "\u2581are", "n", "'", "\u2581", "t", "\u2581", "s", "hit", ",", "\u2581you", "'", "\u2581", "re", "\u2581at", "tracted", "\u2581to", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581", "s", "hit", "\u2581people", ",", "\u2581cause", "\u2581you", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581", "s", "hit", "\u2581either", ".", ".", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Ju", "ven", "s", "\u258190", ":", "\u2581If", "\u2581you", "\u2581always", "\u2581date", "\u2581people", "\u2581that", "\u2581are", "n", "'", "\u2581", "t", "\u2581", "s", "hit", ",", "\u2581you", "'", "\u2581", "re", "\u2581at", "tracted", "\u2581to", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581", "s", "hit", "\u2581people", ",", "\u2581cause", "\u2581you", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581", "s", "hit", "\u2581either", ".", ".", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 14, 14, 15, 16, 17, 18, 18, 19, 19, 20, 21, 21, 21, 22, 23, 23, 24, 24, 24, 25, 26, 27, 28, 29, 29, 29, 30, 31, 31, 32, 32, 32, 33, 34, 35, 36, 37], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_869", "sentence": ["\u2581", "RT", "\u2581@", "\u2581cop", "pol", "an", "at", ":", "\u2581San", "a", "\u2581", "t", "u", "\u2581", "\u2764", "\u2581Rec", "o", "nect", "a", "\u2581con", "\u2581", "e", "l", "\u2581Am", "or", ".", "\u2581The", "\u2581Angel", "s", "\u2581are", "\u2581Listen", "ing", ":", "\u2581S", "n", "at", "am", "\u2581Ka", "ur", "\u2581sing", "s", "\u2581Su", "\u1e49", "i", "-", "a", "i", "\u2581with", "\u2581A", "je", "e", "t", "\u2581Ka", "ur", "\u2581at", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581cop", "pol", "an", "at", ":", "\u2581San", "a", "\u2581", "t", "u", "\u2581", "\u2764", "\u2581Rec", "o", "nect", "a", "\u2581con", "\u2581", "e", "l", "\u2581Am", "or", ".", "\u2581The", "\u2581Angel", "s", "\u2581are", "\u2581Listen", "ing", ":", "\u2581S", "n", "at", "am", "\u2581Ka", "ur", "\u2581sing", "s", "\u2581Su", "\u1e49", "i", "-", "a", "i", "\u2581with", "\u2581A", "je", "e", "t", "\u2581Ka", "ur", "\u2581at", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581cop", "pol", "an", "at", ":", "\u2581San", "a", "\u2581", "t", "u", "\u2581", "\u2764", "\u2581Rec", "o", "nect", "a", "\u2581con", "\u2581", "e", "l", "\u2581Am", "or", ".", "<m>", "\u2581The", "<m>", "\u2581Angel", "s", "</m>", "\u2581are", "\u2581Listen", "ing", "</m>", ":", "<m>", "\u2581S", "n", "at", "am", "\u2581Ka", "ur", "</m>", "\u2581sing", "s", "\u2581Su", "\u1e49", "i", "-", "a", "i", "\u2581with", "<m>", "\u2581A", "je", "e", "t", "\u2581Ka", "ur", "</m>", "\u2581at", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 5, 5, 5, 6, 6, 7, 7, 7, 7, 8, 9, 9, 9, 10, 10, 11, 12, 13, 13, 14, 15, 15, 16, 17, 17, 17, 17, 18, 18, 19, 19, 20, 20, 20, 20, 20, 20, 21, 22, 22, 22, 22, 23, 23, 24, 25, 26, 27, 28, 28, 28, 28, 28, 28, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 0, -1, -1, 0, -1, -1, -1, 1, -1, 2, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_870", "sentence": ["\u2581@", "\u2581L", "CG", "il", "a", "\u258107", "\u2581@", "\u2581Cur", "ious", "Cat", "M", "e", "\u2581", "kk", "kk", "kk", "kk", "k", "kk", "kk", "kk", ",", "\u2581", "p", "q", "p", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581L", "CG", "il", "a", "\u258107", "\u2581@", "\u2581Cur", "ious", "Cat", "M", "e", "\u2581", "kk", "kk", "kk", "kk", "k", "kk", "kk", "kk", ",", "\u2581", "p", "q", "p", "</s>"], "target_sentence": ["\u2581@", "\u2581L", "CG", "il", "a", "\u258107", "\u2581@", "\u2581Cur", "ious", "Cat", "M", "e", "\u2581", "kk", "kk", "kk", "kk", "k", "kk", "kk", "kk", ",", "\u2581", "p", "q", "p", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_871", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "V", "b", "w", "d", "Y", "o", "S", "c", "R", "n", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "V", "b", "w", "d", "Y", "o", "S", "c", "R", "n", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "V", "b", "w", "d", "Y", "o", "S", "c", "R", "n", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_872", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Zo", "e", "\u2581", "_", "\u2581Clark", "\u2581", "_", "\u2581", "x", "xx", ":", "\u2581Im", "\u2581ready", "\u2581for", "\u2581you", "\u2581da", "ddy", "\u2581you", "\u2581can", "\u2581cum", "\u2581in", "\u2581my", "\u2581pretty", "\u2581little", "\u2581mouth", "\u2581and", "\u2581pretty", "\u2581face", "\u2581da", "ddy", ".", "\u2581", "\ud83d\ude3b", "\u2581", "\ud83d\ude3b", "\u2581", "\ud83d\udc45", "\u2581", "\ud83d\udc45", "\u2581", "\ud83d\udc45", "\u2581https", "://", "t", ".", "co", "/", "m", "E", "K", "h", "f", "s", "a", "U", "X", "o", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Zo", "e", "\u2581", "_", "\u2581Clark", "\u2581", "_", "\u2581", "x", "xx", ":", "\u2581Im", "\u2581ready", "\u2581for", "\u2581you", "\u2581da", "ddy", "\u2581you", "\u2581can", "\u2581cum", "\u2581in", "\u2581my", "\u2581pretty", "\u2581little", "\u2581mouth", "\u2581and", "\u2581pretty", "\u2581face", "\u2581da", "ddy", ".", "\u2581", "\ud83d\ude3b", "\u2581", "\ud83d\ude3b", "\u2581", "\ud83d\udc45", "\u2581", "\ud83d\udc45", "\u2581", "\ud83d\udc45", "\u2581https", "://", "t", ".", "co", "/", "m", "E", "K", "h", "f", "s", "a", "U", "X", "o", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Zo", "e", "\u2581", "_", "\u2581Clark", "\u2581", "_", "\u2581", "x", "xx", ":", "\u2581Im", "\u2581ready", "\u2581for", "\u2581you", "\u2581da", "ddy", "\u2581you", "\u2581can", "\u2581cum", "\u2581in", "\u2581my", "\u2581pretty", "\u2581little", "\u2581mouth", "\u2581and", "\u2581pretty", "\u2581face", "\u2581da", "ddy", ".", "\u2581", "\ud83d\ude3b", "\u2581", "\ud83d\ude3b", "\u2581", "\ud83d\udc45", "\u2581", "\ud83d\udc45", "\u2581", "\ud83d\udc45", "\u2581https", "://", "t", ".", "co", "/", "m", "E", "K", "h", "f", "s", "a", "U", "X", "o", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_873", "sentence": ["\u2581", "RT", "\u2581@", "\u2581L", "ating", "low", "\u2581", "_", ":", "\u2581Cu", "a", "ca", "\u2581ma", "hal", "\u2581br", "ur", "r", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581L", "ating", "low", "\u2581", "_", ":", "\u2581Cu", "a", "ca", "\u2581ma", "hal", "\u2581br", "ur", "r", ".", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581L", "ating", "low", "\u2581", "_", ":", "\u2581Cu", "a", "ca", "\u2581ma", "hal", "\u2581br", "ur", "r", ".", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 5, 5, 5, 6, 6, 7, 7, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_874", "sentence": ["\u2581", "RT", "\u2581@", "\u2581span", "ish", "c", "v", "nd", "y", ":", "\u2581If", "\u2581we", "\u2581can", "'", "\u2581", "t", "\u2581raise", "\u2581", "a", "\u2581dog", "\u2581together", ",", "\u2581then", "\u2581we", "\u2581not", "\u2581meant", "\u2581to", "\u2581be", "\u2581together", "\u2581https", "://", "t", ".", "co", "/", "o", "K", "c", "66", "a", "we", "s", "p", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581span", "ish", "c", "v", "nd", "y", ":", "\u2581If", "\u2581we", "\u2581can", "'", "\u2581", "t", "\u2581raise", "\u2581", "a", "\u2581dog", "\u2581together", ",", "\u2581then", "\u2581we", "\u2581not", "\u2581meant", "\u2581to", "\u2581be", "\u2581together", "\u2581https", "://", "t", ".", "co", "/", "o", "K", "c", "66", "a", "we", "s", "p", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581span", "ish", "c", "v", "nd", "y", ":", "\u2581If", "\u2581we", "\u2581can", "'", "\u2581", "t", "\u2581raise", "\u2581", "a", "\u2581dog", "\u2581together", ",", "\u2581then", "\u2581we", "\u2581not", "\u2581meant", "\u2581to", "\u2581be", "\u2581together", "\u2581https", "://", "t", ".", "co", "/", "o", "K", "c", "66", "a", "we", "s", "p", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_875", "sentence": ["\u2581#", "\u2581mature", "\u2581group", "\u2581", "s", "ex", "\u2581clips", "\u2581", "f", "uck", "ing", "\u2581black", "\u2581", "bab", "e", "\u2581https", "://", "t", ".", "co", "/", "WS", "4", "m", "E", "w", "t", "g", "n", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581mature", "\u2581group", "\u2581", "s", "ex", "\u2581clips", "\u2581", "f", "uck", "ing", "\u2581black", "\u2581", "bab", "e", "\u2581https", "://", "t", ".", "co", "/", "WS", "4", "m", "E", "w", "t", "g", "n", "w", "</s>"], "target_sentence": ["\u2581#", "\u2581mature", "\u2581group", "\u2581", "s", "ex", "\u2581clips", "\u2581", "f", "uck", "ing", "\u2581black", "\u2581", "bab", "e", "\u2581https", "://", "t", ".", "co", "/", "WS", "4", "m", "E", "w", "t", "g", "n", "w", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_876", "sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "Le", "a", "d", "C", "NN", ":", ".", "\u2581@", "\u2581ja", "ket", "a", "pper", ":", "\u2581There", "\u2581is", "\u2581", "a", "\u2581reason", "\u2581White", "\u2581House", "\u2581is", "\u2581providing", "\u2581no", "\u2581evidence", "\u2581about", "\u2581voter", "\u2581fraud", "\u2581claim", "\u2581", "\u2013", "\u2581there", "\u2581is", "\u2581no", "\u2581evidence", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581The", "Le", "a", "d", "C", "NN", ":", ".", "\u2581@", "\u2581ja", "ket", "a", "pper", ":", "\u2581There", "\u2581is", "\u2581", "a", "\u2581reason", "\u2581White", "\u2581House", "\u2581is", "\u2581providing", "\u2581no", "\u2581evidence", "\u2581about", "\u2581voter", "\u2581fraud", "\u2581claim", "\u2581", "\u2013", "\u2581there", "\u2581is", "\u2581no", "\u2581evidence", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "<m>", "\u2581The", "Le", "a", "d", "C", "NN", "</m>", "</m>", ":", ".", "\u2581@", "<m>", "\u2581ja", "ket", "a", "pper", "</m>", ":", "\u2581There", "\u2581is", "\u2581", "a", "\u2581reason", "\u2581White", "\u2581House", "\u2581is", "\u2581providing", "\u2581no", "\u2581evidence", "\u2581about", "\u2581voter", "\u2581fraud", "\u2581claim", "\u2581", "\u2013", "\u2581there", "\u2581is", "\u2581no", "\u2581evidence", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 2, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_877", "sentence": ["\u2581Leave", "s", "!", "\u2581https", "://", "t", ".", "co", "/", "R", "a", "RN", "J", "6", "cu", "9", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Leave", "s", "!", "\u2581https", "://", "t", ".", "co", "/", "R", "a", "RN", "J", "6", "cu", "9", "a", "</s>"], "target_sentence": ["<m>", "\u2581Leave", "s", "</m>", "!", "\u2581https", "://", "t", ".", "co", "/", "R", "a", "RN", "J", "6", "cu", "9", "a", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_878", "sentence": ["\u2581", "RT", "\u2581@", "\u2581noch", "ill", "th", "alia", ":", "\u25811", ".", "\u2581so", "\u2581lets", "\u2581start", "\u2581", "w", "\u2581this", "\u2581iconic", "\u2581vine", "\u2581https", "://", "t", ".", "co", "/", "G", "f", "a", "K", "No", "5", "ND", "S", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581noch", "ill", "th", "alia", ":", "\u25811", ".", "\u2581so", "\u2581lets", "\u2581start", "\u2581", "w", "\u2581this", "\u2581iconic", "\u2581vine", "\u2581https", "://", "t", ".", "co", "/", "G", "f", "a", "K", "No", "5", "ND", "S", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581noch", "ill", "th", "alia", ":", "\u25811", ".", "\u2581so", "\u2581lets", "\u2581start", "\u2581", "w", "\u2581this", "\u2581iconic", "\u2581vine", "\u2581https", "://", "t", ".", "co", "/", "G", "f", "a", "K", "No", "5", "ND", "S", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_879", "sentence": ["\u2581@", "\u2581Ji", "o", "v", "anni", "V", "ar", "gas", "\u2581she", "\u2581might", "\u2581just", "\u2581have", "\u2581to", ".", "\u2581I", "\u2581swear", "\u2581", "if", "\u2581she", "\u2581den", "ies", "\u2581it", "\u2581when", "\u2581I", "\u2581confront", "\u2581her", "\u2581Im", "a", "\u2581throw", "\u2581", "a", "\u2581punch", "\u2581", "\ud83d\ude02", "\u2581", "\ud83d\ude02", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Ji", "o", "v", "anni", "V", "ar", "gas", "\u2581she", "\u2581might", "\u2581just", "\u2581have", "\u2581to", ".", "\u2581I", "\u2581swear", "\u2581", "if", "\u2581she", "\u2581den", "ies", "\u2581it", "\u2581when", "\u2581I", "\u2581confront", "\u2581her", "\u2581Im", "a", "\u2581throw", "\u2581", "a", "\u2581punch", "\u2581", "\ud83d\ude02", "\u2581", "\ud83d\ude02", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Ji", "o", "v", "anni", "V", "ar", "gas", "</m>", "\u2581she", "\u2581might", "\u2581just", "\u2581have", "\u2581to", ".", "\u2581I", "\u2581swear", "\u2581", "if", "\u2581she", "\u2581den", "ies", "\u2581it", "\u2581when", "\u2581I", "\u2581confront", "\u2581her", "\u2581Im", "a", "\u2581throw", "\u2581", "a", "\u2581punch", "\u2581", "\ud83d\ude02", "\u2581", "\ud83d\ude02", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 20, 21, 22, 22, 23, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_880", "sentence": ["\u2581Check", "\u2581out", "\u2581\"", "\u2581Yo", "\u2581so", "y", "\u2581Mo", "an", "a", "\u2581(", "\u2581Can", "to", "\u2581ancestral", ")", "\u2581\"", "\u2581on", "\u2581#", "\u2581S", "mul", "e", ":", "\u2581https", "://", "t", ".", "co", "/", "m", "C", "x", "of", "i", "CK", "q", "d", "\u2581#", "\u2581S", "ing", "K", "ara", "ok", "e", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Check", "\u2581out", "\u2581\"", "\u2581Yo", "\u2581so", "y", "\u2581Mo", "an", "a", "\u2581(", "\u2581Can", "to", "\u2581ancestral", ")", "\u2581\"", "\u2581on", "\u2581#", "\u2581S", "mul", "e", ":", "\u2581https", "://", "t", ".", "co", "/", "m", "C", "x", "of", "i", "CK", "q", "d", "\u2581#", "\u2581S", "ing", "K", "ara", "ok", "e", "</s>"], "target_sentence": ["\u2581Check", "\u2581out", "\u2581\"", "<m>", "\u2581Yo", "\u2581so", "y", "\u2581Mo", "an", "a", "</m>", "\u2581(", "<m>", "\u2581Can", "to", "\u2581ancestral", "</m>", ")", "\u2581\"", "\u2581on", "\u2581#", "\u2581S", "mul", "e", ":", "\u2581https", "://", "t", ".", "co", "/", "m", "C", "x", "of", "i", "CK", "q", "d", "\u2581#", "\u2581S", "ing", "K", "ara", "ok", "e", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_881", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "kar", "tik", "a", "a", "w", "\u258132", ":", "\u2581Tweet", "\u2581", "tru", "s", "\u2581for", "\u2581K", "ezi", "a", "\u2581War", "ou", "w", "\u2581#", "\u2581Miss", "Univers", "e", "\u2581#", "\u2581Indonesia", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "kar", "tik", "a", "a", "w", "\u258132", ":", "\u2581Tweet", "\u2581", "tru", "s", "\u2581for", "\u2581K", "ezi", "a", "\u2581War", "ou", "w", "\u2581#", "\u2581Miss", "Univers", "e", "\u2581#", "\u2581Indonesia", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "kar", "tik", "a", "a", "w", "\u258132", ":", "\u2581Tweet", "\u2581", "tru", "s", "\u2581for", "\u2581K", "ezi", "a", "\u2581War", "ou", "w", "\u2581#", "<m>", "\u2581Miss", "Univers", "e", "</m>", "\u2581#", "<m>", "\u2581Indonesia", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 8, 8, 9, 9, 9, 10, 11, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, 1, -1, 1, -1]}, {"doc_id": "emerging.test_882", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "l", "t", "s", "FR", "I", "END", "S", "post", "s", ":", "\u2581Liter", "ally", "\u2581me", ":", "\u2581https", "://", "t", ".", "co", "/", "s", "58", "w", "l", "be", "m", "VP", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "l", "t", "s", "FR", "I", "END", "S", "post", "s", ":", "\u2581Liter", "ally", "\u2581me", ":", "\u2581https", "://", "t", ".", "co", "/", "s", "58", "w", "l", "be", "m", "VP", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "l", "t", "s", "FR", "I", "END", "S", "post", "s", "</m>", ":", "<m>", "\u2581Liter", "ally", "\u2581me", "</m>", ":", "\u2581https", "://", "t", ".", "co", "/", "s", "58", "w", "l", "be", "m", "VP", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_883", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Nathan", "Z", "e", "d", ":", "\u2581", "he", "\u2581was", "\u2581the", "\u2581only", "\u2581black", "\u2581barb", "er", "\u2581at", "\u2581the", "\u2581shop", "\u2581here", ".", "\u2581I", "'", "\u2581", "m", "\u2581going", "\u2581to", "\u2581have", "\u2581to", "\u2581put", "\u2581my", "\u2581faith", "\u2581in", "\u2581", "a", "\u2581ca", "uca", "sian", "\u2581man", ".", "\u2581First", "\u2581the", "\u2581country", ",", "\u2581now", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Nathan", "Z", "e", "d", ":", "\u2581", "he", "\u2581was", "\u2581the", "\u2581only", "\u2581black", "\u2581barb", "er", "\u2581at", "\u2581the", "\u2581shop", "\u2581here", ".", "\u2581I", "'", "\u2581", "m", "\u2581going", "\u2581to", "\u2581have", "\u2581to", "\u2581put", "\u2581my", "\u2581faith", "\u2581in", "\u2581", "a", "\u2581ca", "uca", "sian", "\u2581man", ".", "\u2581First", "\u2581the", "\u2581country", ",", "\u2581now", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Nathan", "Z", "e", "d", "</m>", ":", "\u2581", "he", "\u2581was", "\u2581the", "\u2581only", "\u2581black", "\u2581barb", "er", "\u2581at", "\u2581the", "\u2581shop", "\u2581here", ".", "\u2581I", "'", "\u2581", "m", "\u2581going", "\u2581to", "\u2581have", "\u2581to", "\u2581put", "\u2581my", "\u2581faith", "\u2581in", "\u2581", "a", "\u2581ca", "uca", "sian", "\u2581man", ".", "\u2581First", "\u2581the", "<m>", "\u2581country", "</m>", ",", "\u2581now", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 27, 27, 28, 29, 30, 31, 32, 33, 34, 35, 35, 36], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_884", "sentence": ["\u2581The", "\u2581time", "\u2581is", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258112", ":", "\u2581", "00", "\u2581AM", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581time", "\u2581is", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258112", ":", "\u2581", "00", "\u2581AM", ".", "</s>"], "target_sentence": ["\u2581The", "\u2581time", "\u2581is", "\u2581January", "\u258125", ",", "\u25812017", "\u2581at", "\u258112", ":", "\u2581", "00", "\u2581AM", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_885", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Pretty", "boy", "\u2581", "_", "\u2581fla", "k", "o", ":", "\u2581Who", "\u2581do", "\u2581", "y", "all", "\u2581think", "\u2581would", "\u2581win", "\u2581in", "\u2581", "a", "\u2581fight", "?", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Pretty", "boy", "\u2581", "_", "\u2581fla", "k", "o", ":", "\u2581Who", "\u2581do", "\u2581", "y", "all", "\u2581think", "\u2581would", "\u2581win", "\u2581in", "\u2581", "a", "\u2581fight", "?", "?", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Pretty", "boy", "</m>", "\u2581", "_", "<m>", "\u2581fla", "k", "o", "</m>", ":", "\u2581Who", "\u2581do", "\u2581", "y", "all", "\u2581think", "\u2581would", "\u2581win", "\u2581in", "\u2581", "a", "\u2581fight", "?", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_886", "sentence": ["\u2581Seoul", "-", "\u2581In", "che", "on", ",", "\u2581South", "\u2581Korea", ":", "\u2581Old", "\u2581Meet", "s", "\u2581New", "\u2581Part", "\u25812", "\u2581#", "\u2581blog", "\u2581#", "\u2581", "Feature", "d", "\u2581#", "\u2581con", "o", "z", "cop", "a", "blo", "\u2581#", "\u2581Travel", "\u2581https", "://", "t", ".", "co", "/3", "O", "z", "E", "AU", "Y", "K", "j", "x", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Seoul", "-", "\u2581In", "che", "on", ",", "\u2581South", "\u2581Korea", ":", "\u2581Old", "\u2581Meet", "s", "\u2581New", "\u2581Part", "\u25812", "\u2581#", "\u2581blog", "\u2581#", "\u2581", "Feature", "d", "\u2581#", "\u2581con", "o", "z", "cop", "a", "blo", "\u2581#", "\u2581Travel", "\u2581https", "://", "t", ".", "co", "/3", "O", "z", "E", "AU", "Y", "K", "j", "x", "</s>"], "target_sentence": ["<m>", "\u2581Seoul", "-", "\u2581In", "che", "on", "</m>", ",", "<m>", "\u2581South", "\u2581Korea", "</m>", ":", "\u2581Old", "\u2581Meet", "s", "\u2581New", "\u2581Part", "\u25812", "\u2581#", "\u2581blog", "\u2581#", "\u2581", "Feature", "d", "\u2581#", "\u2581con", "o", "z", "cop", "a", "blo", "\u2581#", "\u2581Travel", "\u2581https", "://", "t", ".", "co", "/3", "O", "z", "E", "AU", "Y", "K", "j", "x", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 15, 16, 16, 16, 16, 16, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_887", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Martin", "Be", "l", "am", ":", "\u2581As", "\u2581long", "\u2581as", "\u2581you", "\u2581live", "\u2581you", "'", "\u2581", "ll", "\u2581never", "\u2581see", "\u2581", "a", "\u2581photograph", "\u2581of", "\u25817", "\u2581women", "\u2581signing", "\u2581legislation", "\u2581about", "\u2581what", "\u2581men", "\u2581can", "\u2581do", "\u2581with", "\u2581their", "\u2581", "r", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Martin", "Be", "l", "am", ":", "\u2581As", "\u2581long", "\u2581as", "\u2581you", "\u2581live", "\u2581you", "'", "\u2581", "ll", "\u2581never", "\u2581see", "\u2581", "a", "\u2581photograph", "\u2581of", "\u25817", "\u2581women", "\u2581signing", "\u2581legislation", "\u2581about", "\u2581what", "\u2581men", "\u2581can", "\u2581do", "\u2581with", "\u2581their", "\u2581", "r", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Martin", "Be", "l", "am", "</m>", ":", "\u2581As", "\u2581long", "\u2581as", "\u2581you", "\u2581live", "\u2581you", "'", "\u2581", "ll", "\u2581never", "\u2581see", "\u2581", "a", "\u2581photograph", "\u2581of", "\u25817", "\u2581women", "\u2581signing", "\u2581legislation", "\u2581about", "\u2581what", "\u2581men", "\u2581can", "\u2581do", "\u2581with", "\u2581their", "\u2581", "r", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_888", "sentence": ["\u2581", "RT", "\u2581@", "\u2581In", "gra", "ham", "Ang", "le", ":", "\u2581On", "\u2581my", "\u2581show", "\u2581today", "\u2581@", "\u2581se", "an", "han", "n", "ity", "\u2581", "&", "\u2581amp", ";", "\u2581I", "\u2581warn", "\u2581@", "\u2581real", "Don", "al", "d", "Tru", "mp", "\u2581ab", "t", "\u2581staff", "\u2581already", "\u2581", "leaking", "\u2581to", "\u2581media", ".", "\u2581https", "://", "t", ".", "co", "/", "R", "j", "B", "W", "z", "du", "Y", "IP", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581In", "gra", "ham", "Ang", "le", ":", "\u2581On", "\u2581my", "\u2581show", "\u2581today", "\u2581@", "\u2581se", "an", "han", "n", "ity", "\u2581", "&", "\u2581amp", ";", "\u2581I", "\u2581warn", "\u2581@", "\u2581real", "Don", "al", "d", "Tru", "mp", "\u2581ab", "t", "\u2581staff", "\u2581already", "\u2581", "leaking", "\u2581to", "\u2581media", ".", "\u2581https", "://", "t", ".", "co", "/", "R", "j", "B", "W", "z", "du", "Y", "IP", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581In", "gra", "ham", "Ang", "le", ":", "\u2581On", "\u2581my", "\u2581show", "\u2581today", "\u2581@", "<m>", "\u2581se", "an", "han", "n", "ity", "</m>", "\u2581", "&", "\u2581amp", ";", "\u2581I", "\u2581warn", "\u2581@", "<m>", "\u2581real", "Don", "al", "d", "Tru", "mp", "</m>", "\u2581ab", "t", "\u2581staff", "\u2581already", "\u2581", "leaking", "\u2581to", "\u2581media", ".", "\u2581https", "://", "t", ".", "co", "/", "R", "j", "B", "W", "z", "du", "Y", "IP", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 10, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 17, 17, 18, 19, 20, 20, 21, 22, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_889", "sentence": ["\u2581@", "\u2581Mary", "K", "a", "y", "C", "a", "bot", "\u2581@", "\u2581The", "K", "en", "n", "y", "R", "o", "d", "a", "\u2581@", "\u2581", "c", "level", "and", "d", "o", "t", "com", "\u2581https", "://", "t", ".", "co", "/", "z", "S", "a", "c", "M", "2", "i", "q", "b", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Mary", "K", "a", "y", "C", "a", "bot", "\u2581@", "\u2581The", "K", "en", "n", "y", "R", "o", "d", "a", "\u2581@", "\u2581", "c", "level", "and", "d", "o", "t", "com", "\u2581https", "://", "t", ".", "co", "/", "z", "S", "a", "c", "M", "2", "i", "q", "b", "7", "</s>"], "target_sentence": ["\u2581@", "\u2581Mary", "K", "a", "y", "C", "a", "bot", "\u2581@", "\u2581The", "K", "en", "n", "y", "R", "o", "d", "a", "\u2581@", "<m>", "\u2581", "c", "level", "and", "d", "o", "t", "com", "</m>", "\u2581https", "://", "t", ".", "co", "/", "z", "S", "a", "c", "M", "2", "i", "q", "b", "7", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_890", "sentence": ["\u2581The", "\u2581Line", "\u2581That", "\u2581Separat", "e", "s", "\u2581You", "\u2581From", "\u2581Massiv", "e", "\u2581#", "\u2581Success", "\u2581https", "://", "t", ".", "co", "/", "h", "E", "W", "Y", "C", "04", "c", "H", "w", "\u2581https", "://", "t", ".", "co", "/", "z", "h", "9", "Q", "l", "6", "P", "1", "K", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581Line", "\u2581That", "\u2581Separat", "e", "s", "\u2581You", "\u2581From", "\u2581Massiv", "e", "\u2581#", "\u2581Success", "\u2581https", "://", "t", ".", "co", "/", "h", "E", "W", "Y", "C", "04", "c", "H", "w", "\u2581https", "://", "t", ".", "co", "/", "z", "h", "9", "Q", "l", "6", "P", "1", "K", "y", "</s>"], "target_sentence": ["\u2581The", "\u2581Line", "\u2581That", "\u2581Separat", "e", "s", "\u2581You", "\u2581From", "\u2581Massiv", "e", "\u2581#", "\u2581Success", "\u2581https", "://", "t", ".", "co", "/", "h", "E", "W", "Y", "C", "04", "c", "H", "w", "\u2581https", "://", "t", ".", "co", "/", "z", "h", "9", "Q", "l", "6", "P", "1", "K", "y", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 6, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_891", "sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581missed", "\u2581you", "\u2581dar", "ling", ".", ".", ".", "\u2581@", "\u2581table", "F", "IVE", "\u258108", "\u2581https", "://", "t", ".", "co", "/", "p", "Y", "r", "s", "X", "CE", "g", "Z", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "ve", "\u2581missed", "\u2581you", "\u2581dar", "ling", ".", ".", ".", "\u2581@", "\u2581table", "F", "IVE", "\u258108", "\u2581https", "://", "t", ".", "co", "/", "p", "Y", "r", "s", "X", "CE", "g", "Z", "y", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581missed", "\u2581you", "\u2581dar", "ling", ".", ".", ".", "\u2581@", "\u2581table", "F", "IVE", "\u258108", "\u2581https", "://", "t", ".", "co", "/", "p", "Y", "r", "s", "X", "CE", "g", "Z", "y", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_892", "sentence": ["\u2581", "RT", "\u2581@", "\u2581glow", "kit", ":", "\u2581followers", "\u2581will", "\u2581be", "\u2581chosen", "\u2581today", "\u2581+", "\u2581one", "\u2581", "insta", "gram", "\u2581follow", "er", "\u2581so", "\u25814", "\u2581winners", "\u2581in", "\u2581total", "!", "!", ")", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581glow", "kit", ":", "\u2581followers", "\u2581will", "\u2581be", "\u2581chosen", "\u2581today", "\u2581+", "\u2581one", "\u2581", "insta", "gram", "\u2581follow", "er", "\u2581so", "\u25814", "\u2581winners", "\u2581in", "\u2581total", "!", "!", ")", "</s>"], "target_sentence": ["\u2581", "RT", "<m>", "\u2581@", "<m>", "\u2581glow", "kit", "</m>", "</m>", ":", "\u2581followers", "\u2581will", "\u2581be", "\u2581chosen", "\u2581today", "\u2581+", "\u2581one", "<m>", "\u2581", "insta", "gram", "</m>", "\u2581follow", "er", "\u2581so", "\u25814", "\u2581winners", "\u2581in", "\u2581total", "!", "!", ")", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_893", "sentence": ["\u2581L", "UB", "\u2581expir", "e", "s", "\u2581Wind", "\u2581", "Advisory", "\u2581till", "\u25816", ":", "\u2581", "00", "\u2581PM", "\u2581C", "ST", "\u2581https", "://", "t", ".", "co", "/", "x", "5", "d", "a", "9", "y", "i", "g", "j", "Y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581L", "UB", "\u2581expir", "e", "s", "\u2581Wind", "\u2581", "Advisory", "\u2581till", "\u25816", ":", "\u2581", "00", "\u2581PM", "\u2581C", "ST", "\u2581https", "://", "t", ".", "co", "/", "x", "5", "d", "a", "9", "y", "i", "g", "j", "Y", "</s>"], "target_sentence": ["<m>", "\u2581L", "UB", "</m>", "\u2581expir", "e", "s", "\u2581Wind", "\u2581", "Advisory", "\u2581till", "\u25816", ":", "\u2581", "00", "\u2581PM", "\u2581C", "ST", "\u2581https", "://", "t", ".", "co", "/", "x", "5", "d", "a", "9", "y", "i", "g", "j", "Y", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_894", "sentence": ["\u2581Judge", "\u2581rules", "\u2581Tam", "ara", "\u2581Love", "t", "t", "\u2581guilty", "\u2581of", "\u2581criminal", "\u2581negligence", "\u2581", "causing", "\u2581her", ".", ".", ".", "\u2581#", "\u2581Discovery", "R", "i", "d", "ge", "\u2581https", "://", "t", ".", "co", "/", "r", "o", "0", "D", "x", "Q", "v", "UL", "0", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Judge", "\u2581rules", "\u2581Tam", "ara", "\u2581Love", "t", "t", "\u2581guilty", "\u2581of", "\u2581criminal", "\u2581negligence", "\u2581", "causing", "\u2581her", ".", ".", ".", "\u2581#", "\u2581Discovery", "R", "i", "d", "ge", "\u2581https", "://", "t", ".", "co", "/", "r", "o", "0", "D", "x", "Q", "v", "UL", "0", "</s>"], "target_sentence": ["\u2581Judge", "\u2581rules", "<m>", "\u2581Tam", "ara", "\u2581Love", "t", "t", "</m>", "\u2581guilty", "\u2581of", "\u2581criminal", "\u2581negligence", "\u2581", "causing", "\u2581her", ".", ".", ".", "\u2581#", "\u2581Discovery", "R", "i", "d", "ge", "\u2581https", "://", "t", ".", "co", "/", "r", "o", "0", "D", "x", "Q", "v", "UL", "0", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_895", "sentence": ["\u2581@", "\u2581Beat", "riz", "D", "je", "e", "\u2581MA", "A", "X", "\u2581", "QUE", "\u2581B", "OM", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Beat", "riz", "D", "je", "e", "\u2581MA", "A", "X", "\u2581", "QUE", "\u2581B", "OM", "</s>"], "target_sentence": ["\u2581@", "<m>", "<m>", "\u2581Beat", "riz", "D", "je", "e", "</m>", "</m>", "\u2581MA", "A", "X", "\u2581", "QUE", "\u2581B", "OM", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 1, 0, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_896", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Fill", "We", "rrell", ":", "\u2581I", "\u2581shouldn", "'", "\u2581", "t", "\u2581have", "\u2581laughed", "\u2581so", "\u2581hard", "\u2581https", "://", "t", ".", "co", "/", "N", "x", "a", "AR", "p", "Re", "EV", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Fill", "We", "rrell", ":", "\u2581I", "\u2581shouldn", "'", "\u2581", "t", "\u2581have", "\u2581laughed", "\u2581so", "\u2581hard", "\u2581https", "://", "t", ".", "co", "/", "N", "x", "a", "AR", "p", "Re", "EV", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Fill", "We", "rrell", ":", "\u2581I", "\u2581shouldn", "'", "\u2581", "t", "\u2581have", "\u2581laughed", "\u2581so", "\u2581hard", "\u2581https", "://", "t", ".", "co", "/", "N", "x", "a", "AR", "p", "Re", "EV", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_897", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "w", "v", "u", "co", "be", ":", "\u2581Good", "\u2581luck", "\u2581to", "\u2581@", "\u2581Coach", "H", "ugg", "s", "\u2581and", "\u2581@", "\u2581W", "V", "U", "h", "oop", "s", "\u2581tonight", "!", "\u2581Don", "'", "\u2581", "t", "\u2581forget", "\u2581it", "'", "\u2581", "s", "\u2581Gold", "\u2581Rush", "\u2581and", "\u2581the", "\u2581pre", "game", "\u2581light", "\u2581show", "!", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "w", "v", "u", "co", "be", ":", "\u2581Good", "\u2581luck", "\u2581to", "\u2581@", "\u2581Coach", "H", "ugg", "s", "\u2581and", "\u2581@", "\u2581W", "V", "U", "h", "oop", "s", "\u2581tonight", "!", "\u2581Don", "'", "\u2581", "t", "\u2581forget", "\u2581it", "'", "\u2581", "s", "\u2581Gold", "\u2581Rush", "\u2581and", "\u2581the", "\u2581pre", "game", "\u2581light", "\u2581show", "!", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "w", "v", "u", "co", "be", ":", "\u2581Good", "\u2581luck", "\u2581to", "\u2581@", "<m>", "\u2581Coach", "H", "ugg", "s", "</m>", "\u2581and", "\u2581@", "<m>", "\u2581W", "V", "U", "h", "oop", "s", "</m>", "\u2581tonight", "!", "\u2581Don", "'", "\u2581", "t", "\u2581forget", "\u2581it", "'", "\u2581", "s", "<m>", "\u2581Gold", "\u2581Rush", "</m>", "\u2581and", "\u2581the", "\u2581pre", "game", "\u2581light", "\u2581show", "!", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 9, 10, 11, 11, 11, 11, 11, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_898", "sentence": ["\u2581@", "\u2581Lance", "\u2581", "210", "\u2581I", "\u2581love", "\u2581that", "\u2581", "p", "rank", "\u2581where", "\u2581you", "\u2581", "s", "qui", "r", "ted", "\u2581the", "\u2581water", "\u2581on", "\u2581that", "\u2581one", "\u2581guys", "\u2581shoe", "\u2581and", "\u2581", "he", "\u2581", "slipped", "\u2581", "\ud83d\ude02", "\u2581", "\ud83d\ude02", "!", "\u2581What", "\u2581happened", "\u2581after", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Lance", "\u2581", "210", "\u2581I", "\u2581love", "\u2581that", "\u2581", "p", "rank", "\u2581where", "\u2581you", "\u2581", "s", "qui", "r", "ted", "\u2581the", "\u2581water", "\u2581on", "\u2581that", "\u2581one", "\u2581guys", "\u2581shoe", "\u2581and", "\u2581", "he", "\u2581", "slipped", "\u2581", "\ud83d\ude02", "\u2581", "\ud83d\ude02", "!", "\u2581What", "\u2581happened", "\u2581after", "?", "</s>"], "target_sentence": ["\u2581@", "\u2581Lance", "\u2581", "210", "\u2581I", "\u2581love", "\u2581that", "\u2581", "p", "rank", "\u2581where", "\u2581you", "\u2581", "s", "qui", "r", "ted", "\u2581the", "\u2581water", "\u2581on", "\u2581that", "\u2581one", "\u2581guys", "\u2581shoe", "\u2581and", "\u2581", "he", "\u2581", "slipped", "\u2581", "\ud83d\ude02", "\u2581", "\ud83d\ude02", "!", "\u2581What", "\u2581happened", "\u2581after", "?", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 9, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 23, 24, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_899", "sentence": ["\u2581Die", "ting", "\u2581as", "\u2581demonstrated", "\u2581by", "\u2581fitness", "\u2581bloggers", "\u2581", "v", "s", ".", "\u2581die", "ting", "\u2581I", "RL", "\u2581#", "\u2581", "NH", "s", "m", "c", "\u2581https", "://", "t", ".", "co", "/2", "o", "z", "6", "u", "8", "auf", "r", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Die", "ting", "\u2581as", "\u2581demonstrated", "\u2581by", "\u2581fitness", "\u2581bloggers", "\u2581", "v", "s", ".", "\u2581die", "ting", "\u2581I", "RL", "\u2581#", "\u2581", "NH", "s", "m", "c", "\u2581https", "://", "t", ".", "co", "/2", "o", "z", "6", "u", "8", "auf", "r", "</s>"], "target_sentence": ["\u2581Die", "ting", "\u2581as", "\u2581demonstrated", "\u2581by", "\u2581fitness", "\u2581bloggers", "\u2581", "v", "s", ".", "\u2581die", "ting", "\u2581I", "RL", "\u2581#", "\u2581", "NH", "s", "m", "c", "\u2581https", "://", "t", ".", "co", "/2", "o", "z", "6", "u", "8", "auf", "r", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 8, 9, 9, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_900", "sentence": ["\u2581@", "\u2581tir", "ck", "t", "\u2581you", "\u2581made", "\u2581Me", "\u2581pick", "\u2581up", "\u2581Super", "\u2581gal", "s", "\u2581so", "\u2581I", "'", "\u2581", "ll", "\u2581trust", "\u2581you", "\u2581On", "\u2581this", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581tir", "ck", "t", "\u2581you", "\u2581made", "\u2581Me", "\u2581pick", "\u2581up", "\u2581Super", "\u2581gal", "s", "\u2581so", "\u2581I", "'", "\u2581", "ll", "\u2581trust", "\u2581you", "\u2581On", "\u2581this", "!", "</s>"], "target_sentence": ["\u2581@", "\u2581tir", "ck", "t", "\u2581you", "\u2581made", "\u2581Me", "\u2581pick", "\u2581up", "\u2581Super", "\u2581gal", "s", "\u2581so", "\u2581I", "'", "\u2581", "ll", "\u2581trust", "\u2581you", "\u2581On", "\u2581this", "!", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_901", "sentence": ["\u2581My", "\u2581Ly", "f", "t", "\u2581is", "\u2581lit", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581My", "\u2581Ly", "f", "t", "\u2581is", "\u2581lit", "!", "</s>"], "target_sentence": ["\u2581My", "<m>", "\u2581Ly", "f", "t", "</m>", "\u2581is", "\u2581lit", "!", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, 2, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1]}, {"doc_id": "emerging.test_902", "sentence": ["\u2581@", "\u2581", "s", "ally", "k", "ohn", "\u2581you", "\u2581are", "\u2581", "a", "\u2581special", "\u2581kind", "\u2581of", "\u2581stupid", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "s", "ally", "k", "ohn", "\u2581you", "\u2581are", "\u2581", "a", "\u2581special", "\u2581kind", "\u2581of", "\u2581stupid", "!", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "s", "ally", "k", "ohn", "</m>", "\u2581you", "\u2581are", "\u2581", "a", "\u2581special", "\u2581kind", "\u2581of", "\u2581stupid", "!", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_903", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "e", "liz", "a", "be", "th", "\u2581", "_", "\u2581mac", "g", ":", "\u2581Me", "\u25812", "\u2581weeks", "\u2581ago", ":", "\u2581I", "'", "\u2581", "m", "\u2581", "gonna", "\u2581get", "\u2581organized", ",", "\u2581get", "\u2581healthy", ",", "\u2581and", "\u2581get", "\u2581my", "\u2581life", "\u2581together", "!", "\u2581Me", "\u2581now", ":", "\u2581living", "\u2581off", "\u2581an", "\u2581old", "\u2581bag", "\u2581of", "\u2581M", "\u2581", "&", "\u2581amp", ";", "\u2581M", "s", ",", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "e", "liz", "a", "be", "th", "\u2581", "_", "\u2581mac", "g", ":", "\u2581Me", "\u25812", "\u2581weeks", "\u2581ago", ":", "\u2581I", "'", "\u2581", "m", "\u2581", "gonna", "\u2581get", "\u2581organized", ",", "\u2581get", "\u2581healthy", ",", "\u2581and", "\u2581get", "\u2581my", "\u2581life", "\u2581together", "!", "\u2581Me", "\u2581now", ":", "\u2581living", "\u2581off", "\u2581an", "\u2581old", "\u2581bag", "\u2581of", "\u2581M", "\u2581", "&", "\u2581amp", ";", "\u2581M", "s", ",", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "e", "liz", "a", "be", "th", "</m>", "\u2581", "_", "\u2581mac", "g", ":", "\u2581Me", "\u25812", "\u2581weeks", "\u2581ago", ":", "\u2581I", "'", "\u2581", "m", "\u2581", "gonna", "\u2581get", "\u2581organized", ",", "\u2581get", "\u2581healthy", ",", "\u2581and", "\u2581get", "\u2581my", "\u2581life", "\u2581together", "!", "\u2581Me", "\u2581now", ":", "\u2581living", "\u2581off", "\u2581an", "\u2581old", "\u2581bag", "\u2581of", "\u2581M", "\u2581", "&", "\u2581amp", ";", "\u2581M", "s", ",", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 37, 38, 39, 40, 40, 41, 42, 42, 43], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_904", "sentence": ["\u2581", "RT", "\u2581@", "\u2581au", "du", "bon", "soci", "e", "t", "y", ":", ".", "\u2581@", "\u2581Bad", "lands", "NP", "S", "\u2581is", "\u2581", "a", "\u2581great", "\u2581place", "\u2581to", "\u2581find", "\u2581climate", "-", "end", "ange", "red", "\u2581birds", "\u2581like", "\u2581the", "\u2581Golden", "\u2581Eagle", ".", "\u2581https", "://", "t", ".", "co", "/", "s", "h", "CT", "BC", "g", "PO", "J", "\u2581https", "://", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581au", "du", "bon", "soci", "e", "t", "y", ":", ".", "\u2581@", "\u2581Bad", "lands", "NP", "S", "\u2581is", "\u2581", "a", "\u2581great", "\u2581place", "\u2581to", "\u2581find", "\u2581climate", "-", "end", "ange", "red", "\u2581birds", "\u2581like", "\u2581the", "\u2581Golden", "\u2581Eagle", ".", "\u2581https", "://", "t", ".", "co", "/", "s", "h", "CT", "BC", "g", "PO", "J", "\u2581https", "://", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581au", "du", "bon", "soci", "e", "t", "y", "</m>", ":", ".", "\u2581@", "<m>", "\u2581Bad", "lands", "NP", "S", "</m>", "\u2581is", "\u2581", "a", "\u2581great", "\u2581place", "\u2581to", "\u2581find", "\u2581climate", "-", "end", "ange", "red", "\u2581birds", "\u2581like", "\u2581the", "\u2581Golden", "\u2581Eagle", ".", "\u2581https", "://", "t", ".", "co", "/", "s", "h", "CT", "BC", "g", "PO", "J", "\u2581https", "://", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_905", "sentence": ["\u2581@", "\u2581ball", "hard", "\u2581", "_", "\u2581", "kor", "in", "\u2581hopefully", "\u2581it", "\u2581wasn", "'", "\u2581", "t", "\u2581loaded", "\u2581", "\ud83d\ude02", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581ball", "hard", "\u2581", "_", "\u2581", "kor", "in", "\u2581hopefully", "\u2581it", "\u2581wasn", "'", "\u2581", "t", "\u2581loaded", "\u2581", "\ud83d\ude02", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581ball", "hard", "</m>", "\u2581", "_", "<m>", "\u2581", "kor", "in", "</m>", "\u2581hopefully", "\u2581it", "\u2581wasn", "'", "\u2581", "t", "\u2581loaded", "\u2581", "\ud83d\ude02", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_906", "sentence": ["\u2581", "RT", "\u2581@", "\u2581I", "am", "A", "ka", "de", "mik", "s", ":", "\u2581Don", "'", "\u2581", "t", "\u2581let", "\u2581that", "\u2581family", "\u2581show", "\u2581fool", "\u2581", "u", "\u2581to", "\u2581forget", "\u2581that", "\u2581", "TI", "\u2581the", "\u2581Rubber", "band", "\u2581man", ".", "\u2581https", "://", "t", ".", "co", "/2", "u", "4", "m", "V", "82", "X", "q", "l", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581I", "am", "A", "ka", "de", "mik", "s", ":", "\u2581Don", "'", "\u2581", "t", "\u2581let", "\u2581that", "\u2581family", "\u2581show", "\u2581fool", "\u2581", "u", "\u2581to", "\u2581forget", "\u2581that", "\u2581", "TI", "\u2581the", "\u2581Rubber", "band", "\u2581man", ".", "\u2581https", "://", "t", ".", "co", "/2", "u", "4", "m", "V", "82", "X", "q", "l", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581I", "am", "A", "ka", "de", "mik", "s", ":", "\u2581Don", "'", "\u2581", "t", "\u2581let", "\u2581that", "\u2581family", "\u2581show", "\u2581fool", "\u2581", "u", "\u2581to", "\u2581forget", "\u2581that", "<m>", "\u2581", "TI", "</m>", "\u2581the", "\u2581Rubber", "band", "\u2581man", ".", "\u2581https", "://", "t", ".", "co", "/2", "u", "4", "m", "V", "82", "X", "q", "l", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 16, 17, 18, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_907", "sentence": ["\u2581", "kin", "a", "\u2581", "s", "ex", "\u2581an", "al", "\u2581https", "://", "t", ".", "co", "/", "i", "D", "26", "U", "o", "P", "7", "t", "l", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "kin", "a", "\u2581", "s", "ex", "\u2581an", "al", "\u2581https", "://", "t", ".", "co", "/", "i", "D", "26", "U", "o", "P", "7", "t", "l", "</s>"], "target_sentence": ["\u2581", "kin", "a", "\u2581", "s", "ex", "\u2581an", "al", "\u2581https", "://", "t", ".", "co", "/", "i", "D", "26", "U", "o", "P", "7", "t", "l", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_908", "sentence": ["\u2581Don", "'", "\u2581", "t", "\u2581worry", "\u2581si", "s", "s", "y", ",", "\u2581I", "\u2581made", "\u2581it", "\u2581", "\ud83d\udccd", "\u2581https", "://", "t", ".", "co", "/", "F", "m", "9", "W", "B", "5", "T", "6", "IV", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Don", "'", "\u2581", "t", "\u2581worry", "\u2581si", "s", "s", "y", ",", "\u2581I", "\u2581made", "\u2581it", "\u2581", "\ud83d\udccd", "\u2581https", "://", "t", ".", "co", "/", "F", "m", "9", "W", "B", "5", "T", "6", "IV", "</s>"], "target_sentence": ["\u2581Don", "'", "\u2581", "t", "\u2581worry", "\u2581si", "s", "s", "y", ",", "\u2581I", "\u2581made", "\u2581it", "\u2581", "\ud83d\udccd", "\u2581https", "://", "t", ".", "co", "/", "F", "m", "9", "W", "B", "5", "T", "6", "IV", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_909", "sentence": ["\u2581More", "\u2581than", "\u2581500", "\u2581Smok", "ers", "\u2581Qui", "t", "\u2581by", "\u2581Hy", "p", "nos", "is", "!", "\u2581https", "://", "t", ".", "co", "/", "h", "w", "5", "p", "ve", "d", "8", "n", "S", "\u258125", ",", "\u25812017", "\u2581at", "\u258109", ":", "\u2581", "00", "\u2581AM", "\u2581https", "://", "t", ".", "co", "/", "9", "f", "R", "8", "C", "r", "v", "BL", "i", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581More", "\u2581than", "\u2581500", "\u2581Smok", "ers", "\u2581Qui", "t", "\u2581by", "\u2581Hy", "p", "nos", "is", "!", "\u2581https", "://", "t", ".", "co", "/", "h", "w", "5", "p", "ve", "d", "8", "n", "S", "\u258125", ",", "\u25812017", "\u2581at", "\u258109", ":", "\u2581", "00", "\u2581AM", "\u2581https", "://", "t", ".", "co", "/", "9", "f", "R", "8", "C", "r", "v", "BL", "i", "</s>"], "target_sentence": ["\u2581More", "\u2581than", "\u2581500", "\u2581Smok", "ers", "\u2581Qui", "t", "\u2581by", "\u2581Hy", "p", "nos", "is", "!", "\u2581https", "://", "t", ".", "co", "/", "h", "w", "5", "p", "ve", "d", "8", "n", "S", "\u258125", ",", "\u25812017", "\u2581at", "\u258109", ":", "\u2581", "00", "\u2581AM", "\u2581https", "://", "t", ".", "co", "/", "9", "f", "R", "8", "C", "r", "v", "BL", "i", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 4, 5, 6, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_910", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Ma", "iko", "K", "it", "am", "ura", ":", "\u2581The", "\u2581way", "\u2581she", "\u2581stare", "s", "\u2581at", "\u2581him", "\u2581", "\u2764", "\u2581", "\ufe0f", "\u2581FO", "OL", "ISH", "\u2581LOVE", "\u2581PRE", "M", "IER", "E", "\u2581N", "IGHT", "\u2581#", "\u2581", "LL", "Re", "lation", "ship", "Go", "als", "\u2581https", "://", "t", ".", "co", "/", "V", "r", "b", "n", "KA", "v", "c", "V", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Ma", "iko", "K", "it", "am", "ura", ":", "\u2581The", "\u2581way", "\u2581she", "\u2581stare", "s", "\u2581at", "\u2581him", "\u2581", "\u2764", "\u2581", "\ufe0f", "\u2581FO", "OL", "ISH", "\u2581LOVE", "\u2581PRE", "M", "IER", "E", "\u2581N", "IGHT", "\u2581#", "\u2581", "LL", "Re", "lation", "ship", "Go", "als", "\u2581https", "://", "t", ".", "co", "/", "V", "r", "b", "n", "KA", "v", "c", "V", "y", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Ma", "iko", "K", "it", "am", "ura", "</m>", ":", "\u2581The", "\u2581way", "\u2581she", "\u2581stare", "s", "\u2581at", "\u2581him", "\u2581", "\u2764", "\u2581", "\ufe0f", "<m>", "\u2581FO", "OL", "ISH", "\u2581LOVE", "\u2581PRE", "M", "IER", "E", "</m>", "\u2581N", "IGHT", "\u2581#", "\u2581", "LL", "Re", "lation", "ship", "Go", "als", "\u2581https", "://", "t", ".", "co", "/", "V", "r", "b", "n", "KA", "v", "c", "V", "y", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 11, 11, 12, 12, 12, 13, 14, 14, 14, 14, 15, 15, 16, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_911", "sentence": ["\u2581Low", "on", "gan", "\u2581", "PT", "\u2581Citi", "link", "\u2581Indonesia", "\u2581", "-", "\u2581Recruitment", "\u2581For", "F", "re", "s", "h", "\u2581Graduate", "\u2581Management", "\u2581Train", "e", "e", "\u2581Citi", "link", "\u2581January", "\u25812017", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "GI", "G", "Q", "n", "l", "4", "q", "TY", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Low", "on", "gan", "\u2581", "PT", "\u2581Citi", "link", "\u2581Indonesia", "\u2581", "-", "\u2581Recruitment", "\u2581For", "F", "re", "s", "h", "\u2581Graduate", "\u2581Management", "\u2581Train", "e", "e", "\u2581Citi", "link", "\u2581January", "\u25812017", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "GI", "G", "Q", "n", "l", "4", "q", "TY", "</s>"], "target_sentence": ["<m>", "\u2581Low", "on", "gan", "\u2581", "PT", "</m>", "\u2581Citi", "link", "<m>", "\u2581Indonesia", "</m>", "\u2581", "-", "\u2581Recruitment", "\u2581For", "F", "re", "s", "h", "\u2581Graduate", "\u2581Management", "\u2581Train", "e", "e", "\u2581Citi", "link", "\u2581January", "\u25812017", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "GI", "G", "Q", "n", "l", "4", "q", "TY", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 2, 2, 3, 4, 4, 5, 6, 6, 6, 6, 6, 7, 8, 9, 9, 9, 10, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_912", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Gir", "I", "fession", ":", "\u2581Me", "\u2581when", "\u2581I", "\u2581get", "\u2581my", "\u2581own", "\u2581house", "\u2581https", "://", "t", ".", "co", "/", "We", "am", "a", "v", "p", "IM", "Q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Gir", "I", "fession", ":", "\u2581Me", "\u2581when", "\u2581I", "\u2581get", "\u2581my", "\u2581own", "\u2581house", "\u2581https", "://", "t", ".", "co", "/", "We", "am", "a", "v", "p", "IM", "Q", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Gir", "I", "fession", ":", "\u2581Me", "\u2581when", "\u2581I", "\u2581get", "\u2581my", "\u2581own", "\u2581house", "\u2581https", "://", "t", ".", "co", "/", "We", "am", "a", "v", "p", "IM", "Q", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_913", "sentence": ["\u2581", "RT", "\u2581@", "\u2581min", "s", "uga", "pic", "s", ":", "\u2581https", "://", "t", ".", "co", "/", "50", "Q", "6", "D", "4", "G", "KI", "J", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581min", "s", "uga", "pic", "s", ":", "\u2581https", "://", "t", ".", "co", "/", "50", "Q", "6", "D", "4", "G", "KI", "J", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581min", "s", "uga", "pic", "s", ":", "\u2581https", "://", "t", ".", "co", "/", "50", "Q", "6", "D", "4", "G", "KI", "J", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_914", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Mat", "s", "M", "at", "s", "\u2581", "94", ":", "\u2581@", "\u2581rolling", "\u2581", "_", "\u25812", "\u2581@", "\u2581Natalie", "GB", "or", "den", "\u2581that", "\u2581is", "\u2581B", "annon", "'", "\u2581", "s", "\u2581goal", ".", "\u2581https", "://", "t", ".", "co", "/", "O", "o", "m", "s", "N", "d", "Q", "o", "c", "f", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Mat", "s", "M", "at", "s", "\u2581", "94", ":", "\u2581@", "\u2581rolling", "\u2581", "_", "\u25812", "\u2581@", "\u2581Natalie", "GB", "or", "den", "\u2581that", "\u2581is", "\u2581B", "annon", "'", "\u2581", "s", "\u2581goal", ".", "\u2581https", "://", "t", ".", "co", "/", "O", "o", "m", "s", "N", "d", "Q", "o", "c", "f", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Mat", "s", "M", "at", "s", "\u2581", "94", ":", "\u2581@", "\u2581rolling", "\u2581", "_", "\u25812", "\u2581@", "<m>", "\u2581Natalie", "GB", "or", "den", "</m>", "\u2581that", "\u2581is", "<m>", "\u2581B", "annon", "</m>", "'", "\u2581", "s", "\u2581goal", ".", "\u2581https", "://", "t", ".", "co", "/", "O", "o", "m", "s", "N", "d", "Q", "o", "c", "f", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 13, 14, 15, 15, 16, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_915", "sentence": ["\u2581@", "\u2581", "kim", "isch", "ill", "ing", "\u2581there", "'", "\u2581", "s", "\u2581always", "\u2581something", "\u2581https", "://", "t", ".", "co", "/", "r", "NG", "TY", "Q", "S", "DU", "Y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "kim", "isch", "ill", "ing", "\u2581there", "'", "\u2581", "s", "\u2581always", "\u2581something", "\u2581https", "://", "t", ".", "co", "/", "r", "NG", "TY", "Q", "S", "DU", "Y", "</s>"], "target_sentence": ["\u2581@", "\u2581", "kim", "isch", "ill", "ing", "\u2581there", "'", "\u2581", "s", "\u2581always", "\u2581something", "\u2581https", "://", "t", ".", "co", "/", "r", "NG", "TY", "Q", "S", "DU", "Y", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_916", "sentence": ["\u2581Student", "\u2581Guest", "\u2581Program", "\u2581#", "\u2581Both", "ell", "\u2581https", "://", "t", ".", "co", "/", "B", "r", "q", "v", "FF", "s", "l", "A", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Student", "\u2581Guest", "\u2581Program", "\u2581#", "\u2581Both", "ell", "\u2581https", "://", "t", ".", "co", "/", "B", "r", "q", "v", "FF", "s", "l", "A", "z", "</s>"], "target_sentence": ["\u2581Student", "\u2581Guest", "\u2581Program", "\u2581#", "\u2581Both", "ell", "\u2581https", "://", "t", ".", "co", "/", "B", "r", "q", "v", "FF", "s", "l", "A", "z", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_917", "sentence": ["\u2581I", "\u2581see", "\u2581why", "\u2581its", "\u2581rope", "\u2581", "gang", "\u2581now", "\u2581", "\ud83d\ude02", "\u2581big", "\u2581", "d", "ick", "\u2581cliqu", "e", "\u2581@", "\u2581on", "some", "s", "hit", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581see", "\u2581why", "\u2581its", "\u2581rope", "\u2581", "gang", "\u2581now", "\u2581", "\ud83d\ude02", "\u2581big", "\u2581", "d", "ick", "\u2581cliqu", "e", "\u2581@", "\u2581on", "some", "s", "hit", "</s>"], "target_sentence": ["\u2581I", "\u2581see", "\u2581why", "\u2581its", "\u2581rope", "\u2581", "gang", "\u2581now", "\u2581", "\ud83d\ude02", "\u2581big", "\u2581", "d", "ick", "\u2581cliqu", "e", "\u2581@", "\u2581on", "some", "s", "hit", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 9, 9, 10, 10, 11, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_918", "sentence": ["\u2581@", "\u2581used", "gov", "\u2581Do", "\u2581it", "\u2581while", "\u2581you", "\u2581can", "!", "\u2581Who", "\u2581knows", "\u2581what", "\u2581will", "\u2581happen", "\u2581in", "\u2581the", "\u2581coming", "\u2581year", "\u2581(", "\u2581", "s", ")", ".", "\u2581", "\ud83d\ude12", "\u2581", "\ud83d\ude14", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581used", "gov", "\u2581Do", "\u2581it", "\u2581while", "\u2581you", "\u2581can", "!", "\u2581Who", "\u2581knows", "\u2581what", "\u2581will", "\u2581happen", "\u2581in", "\u2581the", "\u2581coming", "\u2581year", "\u2581(", "\u2581", "s", ")", ".", "\u2581", "\ud83d\ude12", "\u2581", "\ud83d\ude14", "</s>"], "target_sentence": ["\u2581@", "\u2581used", "gov", "\u2581Do", "\u2581it", "\u2581while", "\u2581you", "\u2581can", "!", "\u2581Who", "\u2581knows", "\u2581what", "\u2581will", "\u2581happen", "\u2581in", "\u2581the", "\u2581coming", "\u2581year", "\u2581(", "\u2581", "s", ")", ".", "\u2581", "\ud83d\ude12", "\u2581", "\ud83d\ude14", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 21, 22, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_919", "sentence": ["\u2581@", "\u2581Two", "B", "lind", "Bro", "s", "\u2581Fantastic", "\u2581piece", "\u2581on", "\u2581@", "\u2581", "NBC", "N", "ight", "ly", "New", "s", "\u2581tonight", "!", "!", "!", "\u2581Love", "\u2581you", "\u2581guys", "!", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Two", "B", "lind", "Bro", "s", "\u2581Fantastic", "\u2581piece", "\u2581on", "\u2581@", "\u2581", "NBC", "N", "ight", "ly", "New", "s", "\u2581tonight", "!", "!", "!", "\u2581Love", "\u2581you", "\u2581guys", "!", "!", "</s>"], "target_sentence": ["\u2581@", "\u2581Two", "B", "lind", "Bro", "s", "\u2581Fantastic", "\u2581piece", "\u2581on", "\u2581@", "<m>", "<m>", "<m>", "\u2581", "NBC", "N", "ight", "ly", "New", "s", "</m>", "</m>", "</m>", "\u2581tonight", "!", "!", "!", "\u2581Love", "\u2581you", "\u2581guys", "!", "!", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 0, 1, -1, -1, -1, -1, -1, -1, -1, 2, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_920", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "kar", "i", "brow", "n", "n", "n", ":", "\u2581\"", "\u2581Oh", "\u2581how", "\u2581it", "\u2581must", "\u2581break", "\u2581His", "\u2581heart", "\u2581when", "\u2581we", "\u2581walk", "\u2581around", "\u2581so", "\u2581desperately", "\u2581for", "\u2581", "a", "\u2581love", "\u2581He", "\u2581wait", "s", "\u2581to", "\u2581give", "\u2581us", "\u2581each", "\u2581and", "\u2581everyday", ".", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "kar", "i", "brow", "n", "n", "n", ":", "\u2581\"", "\u2581Oh", "\u2581how", "\u2581it", "\u2581must", "\u2581break", "\u2581His", "\u2581heart", "\u2581when", "\u2581we", "\u2581walk", "\u2581around", "\u2581so", "\u2581desperately", "\u2581for", "\u2581", "a", "\u2581love", "\u2581He", "\u2581wait", "s", "\u2581to", "\u2581give", "\u2581us", "\u2581each", "\u2581and", "\u2581everyday", ".", "\u2581\"", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "kar", "i", "brow", "n", "n", "n", "</m>", ":", "\u2581\"", "\u2581Oh", "\u2581how", "\u2581it", "\u2581must", "\u2581break", "\u2581His", "\u2581heart", "\u2581when", "\u2581we", "\u2581walk", "\u2581around", "\u2581so", "\u2581desperately", "\u2581for", "\u2581", "a", "\u2581love", "\u2581He", "\u2581wait", "s", "\u2581to", "\u2581give", "\u2581us", "\u2581each", "\u2581and", "\u2581everyday", ".", "\u2581\"", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_921", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "t", "t", "g", "m", ":", "\u2581Don", "'", "\u2581", "t", "\u2581ever", "\u2581think", "\u2581you", "\u2581got", "\u2581it", "\u2581like", "\u2581that", "\u2581with", "\u2581me", "\u2581cause", "\u2581the", "\u2581moment", "\u2581you", "\u2581do", "\u2581I", "'", "\u2581", "ll", "\u2581show", "\u2581you", "\u2581that", "\u2581you", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581have", "\u2581it", "\u2581like", "\u2581you", "\u2581think", "\u2581you", "\u2581do", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "t", "t", "g", "m", ":", "\u2581Don", "'", "\u2581", "t", "\u2581ever", "\u2581think", "\u2581you", "\u2581got", "\u2581it", "\u2581like", "\u2581that", "\u2581with", "\u2581me", "\u2581cause", "\u2581the", "\u2581moment", "\u2581you", "\u2581do", "\u2581I", "'", "\u2581", "ll", "\u2581show", "\u2581you", "\u2581that", "\u2581you", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581have", "\u2581it", "\u2581like", "\u2581you", "\u2581think", "\u2581you", "\u2581do", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "t", "t", "g", "m", ":", "\u2581Don", "'", "\u2581", "t", "\u2581ever", "\u2581think", "\u2581you", "\u2581got", "\u2581it", "\u2581like", "\u2581that", "\u2581with", "\u2581me", "\u2581cause", "\u2581the", "\u2581moment", "\u2581you", "\u2581do", "\u2581I", "'", "\u2581", "ll", "\u2581show", "\u2581you", "\u2581that", "\u2581you", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581have", "\u2581it", "\u2581like", "\u2581you", "\u2581think", "\u2581you", "\u2581do", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 27, 28, 29, 29, 29, 30, 31, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 40], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_922", "sentence": ["\u2581@", "\u2581War", "G", "it", "\u2581@", "\u2581north", "umb", "rian", "a", "\u2581If", "\u2581Ne", "y", "\u2581had", "\u2581appeared", "\u2581in", "\u2581Marsh", "als", "\u2581uniform", "\u2581", "he", "\u2581would", "\u2581have", "\u2581been", "\u2581de", "grade", "d", ".", "\u2581All", "\u2581his", "\u2581stars", "\u2581and", "\u2581medal", "s", "\u2581to", "r", "n", "\u2581off", "\u2581into", "\u2581the", "\u2581", "mud", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581War", "G", "it", "\u2581@", "\u2581north", "umb", "rian", "a", "\u2581If", "\u2581Ne", "y", "\u2581had", "\u2581appeared", "\u2581in", "\u2581Marsh", "als", "\u2581uniform", "\u2581", "he", "\u2581would", "\u2581have", "\u2581been", "\u2581de", "grade", "d", ".", "\u2581All", "\u2581his", "\u2581stars", "\u2581and", "\u2581medal", "s", "\u2581to", "r", "n", "\u2581off", "\u2581into", "\u2581the", "\u2581", "mud", "</s>"], "target_sentence": ["\u2581@", "\u2581War", "G", "it", "\u2581@", "\u2581north", "umb", "rian", "a", "\u2581If", "\u2581Ne", "y", "\u2581had", "\u2581appeared", "\u2581in", "\u2581Marsh", "als", "\u2581uniform", "\u2581", "he", "\u2581would", "\u2581have", "\u2581been", "\u2581de", "grade", "d", ".", "\u2581All", "\u2581his", "\u2581stars", "\u2581and", "\u2581medal", "s", "\u2581to", "r", "n", "\u2581off", "\u2581into", "\u2581the", "\u2581", "mud", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 3, 3, 3, 4, 5, 5, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13, 14, 15, 15, 15, 16, 17, 18, 19, 20, 21, 21, 22, 22, 22, 23, 24, 25, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_923", "sentence": ["\u2581D", "ELL", "\u2581In", "s", "pir", "on", "\u258117", "\u2581R", "\u2581", "57", "21", "\u2581Core", "\u2581", "i", "\u25815", "\u2581", "-", "\u258133", "17", "\u2581U", "\u25811", ".", "\u25817", "\u2581", "GHz", "\u25816", "\u2581G", "b", "\u2581", "750", "\u2581G", "b", "\u2581DVD", "R", "W", "\u258117", ".", "\u25813", "\u2581\"", "\u2581Laptop", "\u2581https", "://", "t", ".", "co", "/", "S", "v", "P", "m", "1", "Q", "m", "5", "d", "g", "\u2581https", "://", "t", ".", "co", "/", "e", "G", "2", "GW", "Q", "5", "J", "v", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581D", "ELL", "\u2581In", "s", "pir", "on", "\u258117", "\u2581R", "\u2581", "57", "21", "\u2581Core", "\u2581", "i", "\u25815", "\u2581", "-", "\u258133", "17", "\u2581U", "\u25811", ".", "\u25817", "\u2581", "GHz", "\u25816", "\u2581G", "b", "\u2581", "750", "\u2581G", "b", "\u2581DVD", "R", "W", "\u258117", ".", "\u25813", "\u2581\"", "\u2581Laptop", "\u2581https", "://", "t", ".", "co", "/", "S", "v", "P", "m", "1", "Q", "m", "5", "d", "g", "\u2581https", "://", "t", ".", "co", "/", "e", "G", "2", "GW", "Q", "5", "J", "v", "7", "</s>"], "target_sentence": ["<m>", "\u2581D", "ELL", "</m>", "<m>", "\u2581In", "s", "pir", "on", "</m>", "\u258117", "\u2581R", "\u2581", "57", "21", "\u2581Core", "\u2581", "i", "\u25815", "\u2581", "-", "\u258133", "17", "\u2581U", "\u25811", ".", "\u25817", "\u2581", "GHz", "\u25816", "\u2581G", "b", "\u2581", "750", "\u2581G", "b", "\u2581DVD", "R", "W", "\u258117", ".", "\u25813", "\u2581\"", "\u2581Laptop", "\u2581https", "://", "t", ".", "co", "/", "S", "v", "P", "m", "1", "Q", "m", "5", "d", "g", "\u2581https", "://", "t", ".", "co", "/", "e", "G", "2", "GW", "Q", "5", "J", "v", "7", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 1, 2, 3, 4, 4, 4, 5, 6, 6, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 20, 21, 22, 23, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, 2, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_924", "sentence": ["\u2581Get", "\u2581", "s", "ex", "y", "\u2581girls", "\u2581in", "\u2581the", "\u2581palm", "\u2581of", "\u2581hand", "!", "\u2581Video", "\u2581chat", "\u2581live", "\u2581on", "\u2581your", "\u2581mobile", "\u2581https", "://", "t", ".", "co", "/7", "p", "K", "PP", "5", "I", "z", "b", "9", "\u2581#", "\u2581", "er", "otic", "\u2581#", "\u2581", "bab", "e", "s", "\u2581#", "\u2581cam", "girl", "s", "\u2581https", "://", "t", ".", "co", "/", "Go", "TH", "B", "4", "GS", "or", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Get", "\u2581", "s", "ex", "y", "\u2581girls", "\u2581in", "\u2581the", "\u2581palm", "\u2581of", "\u2581hand", "!", "\u2581Video", "\u2581chat", "\u2581live", "\u2581on", "\u2581your", "\u2581mobile", "\u2581https", "://", "t", ".", "co", "/7", "p", "K", "PP", "5", "I", "z", "b", "9", "\u2581#", "\u2581", "er", "otic", "\u2581#", "\u2581", "bab", "e", "s", "\u2581#", "\u2581cam", "girl", "s", "\u2581https", "://", "t", ".", "co", "/", "Go", "TH", "B", "4", "GS", "or", "</s>"], "target_sentence": ["\u2581Get", "\u2581", "s", "ex", "y", "\u2581girls", "\u2581in", "\u2581the", "\u2581palm", "\u2581of", "\u2581hand", "!", "\u2581Video", "\u2581chat", "\u2581live", "\u2581on", "\u2581your", "\u2581mobile", "\u2581https", "://", "t", ".", "co", "/7", "p", "K", "PP", "5", "I", "z", "b", "9", "\u2581#", "\u2581", "er", "otic", "\u2581#", "\u2581", "bab", "e", "s", "\u2581#", "\u2581cam", "girl", "s", "\u2581https", "://", "t", ".", "co", "/", "Go", "TH", "B", "4", "GS", "or", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 17, 17, 17, 18, 19, 19, 19, 19, 20, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_925", "sentence": ["\u2581It", "\u2581is", "\u2581not", "\u2581", "a", "\u2581problem", "\u2581for", "\u2581her", "\u2581to", "\u2581bend", "\u2581over", "\u2581spreading", "\u2581her", "\u2581as", "s", "\u2581and", "\u2581slowly", "\u2581finger", "\u2581her", "\u2581tight", "\u2581as", "s", "hole", ".", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/8", "b", "W", "c", "g", "5", "o", "MO", "K", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "\u2581is", "\u2581not", "\u2581", "a", "\u2581problem", "\u2581for", "\u2581her", "\u2581to", "\u2581bend", "\u2581over", "\u2581spreading", "\u2581her", "\u2581as", "s", "\u2581and", "\u2581slowly", "\u2581finger", "\u2581her", "\u2581tight", "\u2581as", "s", "hole", ".", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/8", "b", "W", "c", "g", "5", "o", "MO", "K", "</s>"], "target_sentence": ["\u2581It", "\u2581is", "\u2581not", "\u2581", "a", "\u2581problem", "\u2581for", "\u2581her", "\u2581to", "\u2581bend", "\u2581over", "\u2581spreading", "\u2581her", "\u2581as", "s", "\u2581and", "\u2581slowly", "\u2581finger", "\u2581her", "\u2581tight", "\u2581as", "s", "hole", ".", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/8", "b", "W", "c", "g", "5", "o", "MO", "K", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 18, 18, 19, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_926", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Prison", "Plan", "e", "t", ":", "\u2581Left", "ist", "s", "\u2581love", "\u2581women", "\u2581in", "\u2581positions", "\u2581of", "\u2581power", ".", "\u2581Look", "\u2581at", "\u2581all", "\u2581the", "\u2581white", "\u2581powder", "\u2581candy", "\u2581they", "'", "\u2581", "re", "\u2581sending", "\u2581to", "\u2581Kelly", "anne", ".", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Prison", "Plan", "e", "t", ":", "\u2581Left", "ist", "s", "\u2581love", "\u2581women", "\u2581in", "\u2581positions", "\u2581of", "\u2581power", ".", "\u2581Look", "\u2581at", "\u2581all", "\u2581the", "\u2581white", "\u2581powder", "\u2581candy", "\u2581they", "'", "\u2581", "re", "\u2581sending", "\u2581to", "\u2581Kelly", "anne", ".", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Prison", "Plan", "e", "t", "</m>", ":", "\u2581Left", "ist", "s", "\u2581love", "\u2581women", "\u2581in", "\u2581positions", "\u2581of", "\u2581power", ".", "\u2581Look", "\u2581at", "\u2581all", "\u2581the", "\u2581white", "\u2581powder", "\u2581candy", "\u2581they", "'", "\u2581", "re", "\u2581sending", "\u2581to", "<m>", "\u2581Kelly", "anne", "</m>", ".", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 22, 23, 24, 24, 25, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_927", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Half", "On", "i", "on", "In", "AB", "a", "g", ":", "\u2581What", "\u2581", "if", "\u2581this", "\u2581account", "\u2581that", "\u2581is", "\u2581simply", "\u2581half", "\u2581an", "\u2581onion", "\u2581in", "\u2581", "a", "\u2581Zip", "loc", "\u2581bag", "\u2581ended", "\u2581up", "\u2581with", "\u2581more", "\u2581followers", "\u2581than", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Half", "On", "i", "on", "In", "AB", "a", "g", ":", "\u2581What", "\u2581", "if", "\u2581this", "\u2581account", "\u2581that", "\u2581is", "\u2581simply", "\u2581half", "\u2581an", "\u2581onion", "\u2581in", "\u2581", "a", "\u2581Zip", "loc", "\u2581bag", "\u2581ended", "\u2581up", "\u2581with", "\u2581more", "\u2581followers", "\u2581than", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Half", "On", "i", "on", "In", "AB", "a", "g", ":", "\u2581What", "\u2581", "if", "\u2581this", "\u2581account", "\u2581that", "\u2581is", "\u2581simply", "\u2581half", "\u2581an", "\u2581onion", "\u2581in", "\u2581", "a", "<m>", "\u2581Zip", "loc", "</m>", "\u2581bag", "\u2581ended", "\u2581up", "\u2581with", "\u2581more", "\u2581followers", "\u2581than", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_928", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "E", "4", "q", "b", "K", "e", "Q", "n", "q", "K", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "E", "4", "q", "b", "K", "e", "Q", "n", "q", "K", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "E", "4", "q", "b", "K", "e", "Q", "n", "q", "K", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_929", "sentence": ["\u2581@", "\u2581CNN", "Pol", "i", "tics", "\u2581this", "\u2581is", "\u2581", "a", "\u2581joke", "\u2581right", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581CNN", "Pol", "i", "tics", "\u2581this", "\u2581is", "\u2581", "a", "\u2581joke", "\u2581right", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581CNN", "Pol", "i", "tics", "</m>", "\u2581this", "\u2581is", "\u2581", "a", "\u2581joke", "\u2581right", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_930", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Half", "On", "i", "on", "In", "AB", "a", "g", ":", "\u2581When", "\u2581you", "\u2581realize", "\u2581you", "\u2581would", "'", "\u2581", "ve", "\u2581been", "\u2581better", "\u2581off", "\u2581married", "\u2581to", "\u2581half", "\u2581an", "\u2581onion", "\u2581in", "\u2581", "a", "\u2581plastic", "\u2581bag", ":", "\u2581https", "://", "t", ".", "co", "/", "G", "s", "j", "Z", "K", "D", "x", "o", "R", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Half", "On", "i", "on", "In", "AB", "a", "g", ":", "\u2581When", "\u2581you", "\u2581realize", "\u2581you", "\u2581would", "'", "\u2581", "ve", "\u2581been", "\u2581better", "\u2581off", "\u2581married", "\u2581to", "\u2581half", "\u2581an", "\u2581onion", "\u2581in", "\u2581", "a", "\u2581plastic", "\u2581bag", ":", "\u2581https", "://", "t", ".", "co", "/", "G", "s", "j", "Z", "K", "D", "x", "o", "R", "z", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Half", "On", "i", "on", "In", "AB", "a", "g", ":", "\u2581When", "\u2581you", "\u2581realize", "\u2581you", "\u2581would", "'", "\u2581", "ve", "\u2581been", "\u2581better", "\u2581off", "\u2581married", "\u2581to", "\u2581half", "\u2581an", "\u2581onion", "\u2581in", "\u2581", "a", "\u2581plastic", "\u2581bag", ":", "\u2581https", "://", "t", ".", "co", "/", "G", "s", "j", "Z", "K", "D", "x", "o", "R", "z", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_931", "sentence": ["\u2581", "RT", "\u2581@", "\u2581su", "a", "v", "\u25811", "\u2581be", ":", "\u2581https", "://", "t", ".", "co", "/", "r", "b", "d", "LU", "A", "e", "HK", "5", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581su", "a", "v", "\u25811", "\u2581be", ":", "\u2581https", "://", "t", ".", "co", "/", "r", "b", "d", "LU", "A", "e", "HK", "5", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581su", "a", "v", "\u25811", "\u2581be", ":", "\u2581https", "://", "t", ".", "co", "/", "r", "b", "d", "LU", "A", "e", "HK", "5", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_932", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Hot", "Free", "style", ":", "\u25814", "\u2581more", "\u2581days", "\u2581till", "\u2581Mi", "go", "s", "\u2581drop", "\u2581their", "\u2581album", "\u2581\"", "\u2581Culture", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "Z", "0", "P", "x", "A", "8", "g", "t", "F", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Hot", "Free", "style", ":", "\u25814", "\u2581more", "\u2581days", "\u2581till", "\u2581Mi", "go", "s", "\u2581drop", "\u2581their", "\u2581album", "\u2581\"", "\u2581Culture", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "Z", "0", "P", "x", "A", "8", "g", "t", "F", "w", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Hot", "Free", "style", "</m>", ":", "\u25814", "\u2581more", "\u2581days", "\u2581till", "<m>", "\u2581Mi", "go", "s", "</m>", "\u2581drop", "\u2581their", "\u2581album", "\u2581\"", "<m>", "\u2581Culture", "</m>", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "Z", "0", "P", "x", "A", "8", "g", "t", "F", "w", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_933", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Re", "la", "table", "Qu", "o", "t", "e", ":", "\u2581Oh", "\u2581wo", "w", "\u2581I", "'", "\u2581", "m", "\u2581so", "\u2581surprised", "\u2581https", "://", "t", ".", "co", "/", "v", "c", "D", "y", "R", "f", "sie", "6", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Re", "la", "table", "Qu", "o", "t", "e", ":", "\u2581Oh", "\u2581wo", "w", "\u2581I", "'", "\u2581", "m", "\u2581so", "\u2581surprised", "\u2581https", "://", "t", ".", "co", "/", "v", "c", "D", "y", "R", "f", "sie", "6", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Re", "la", "table", "Qu", "o", "t", "e", ":", "\u2581Oh", "\u2581wo", "w", "\u2581I", "'", "\u2581", "m", "\u2581so", "\u2581surprised", "\u2581https", "://", "t", ".", "co", "/", "v", "c", "D", "y", "R", "f", "sie", "6", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_934", "sentence": ["\u2581@", "\u2581V", "roni", "que", "Per", "s", "ic", "\u25811", "\u2581@", "\u2581", "hort", "tim", "\u2581@", "\u2581", "s", "erin", "a", "\u2581", "_", "\u2581", "s", "g", "ill", "\u2581@", "\u2581pris", "c", "ill", "a", "NK", "\u258127", "\u2581@", "\u2581ja", "net", "\u258123", "\u2581", "h", "b", "k", "\u2581@", "\u2581Ana", "Pro", "g", "l", "\u25811", "\u2581@", "\u2581Mar", "u", "j", "k", "\u25811", "\u2581@", "\u2581St", "acy", "\u2581", "_", "\u2581Wahl", "Love", "\u2581@", "\u2581Do", "nnie", "W", "a", "h", "l", "berg", "\u2581#", "\u2581", "t", "w", "u", "g", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581V", "roni", "que", "Per", "s", "ic", "\u25811", "\u2581@", "\u2581", "hort", "tim", "\u2581@", "\u2581", "s", "erin", "a", "\u2581", "_", "\u2581", "s", "g", "ill", "\u2581@", "\u2581pris", "c", "ill", "a", "NK", "\u258127", "\u2581@", "\u2581ja", "net", "\u258123", "\u2581", "h", "b", "k", "\u2581@", "\u2581Ana", "Pro", "g", "l", "\u25811", "\u2581@", "\u2581Mar", "u", "j", "k", "\u25811", "\u2581@", "\u2581St", "acy", "\u2581", "_", "\u2581Wahl", "Love", "\u2581@", "\u2581Do", "nnie", "W", "a", "h", "l", "berg", "\u2581#", "\u2581", "t", "w", "u", "g", "</s>"], "target_sentence": ["\u2581@", "\u2581V", "roni", "que", "Per", "s", "ic", "\u25811", "\u2581@", "\u2581", "hort", "tim", "\u2581@", "\u2581", "s", "erin", "a", "\u2581", "_", "\u2581", "s", "g", "ill", "\u2581@", "\u2581pris", "c", "ill", "a", "NK", "\u258127", "\u2581@", "<m>", "\u2581ja", "net", "</m>", "\u258123", "\u2581", "h", "b", "k", "\u2581@", "\u2581Ana", "Pro", "g", "l", "\u25811", "\u2581@", "\u2581Mar", "u", "j", "k", "\u25811", "\u2581@", "<m>", "\u2581St", "acy", "</m>", "\u2581", "_", "\u2581Wahl", "Love", "\u2581@", "\u2581Do", "nnie", "W", "a", "h", "l", "berg", "\u2581#", "\u2581", "t", "w", "u", "g", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 2, 3, 4, 4, 4, 5, 6, 6, 6, 6, 7, 7, 8, 8, 8, 8, 9, 10, 10, 10, 10, 10, 11, 12, 13, 13, 14, 15, 15, 15, 15, 16, 17, 17, 17, 17, 18, 19, 20, 20, 20, 20, 21, 22, 23, 23, 24, 24, 25, 25, 26, 27, 27, 27, 27, 27, 27, 27, 28, 29, 29, 29, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_935", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Thir", "t", "y", "S", "e", "c", "F", "ight", "s", ":", "\u2581Du", "de", "\u2581gets", "\u2581his", "\u2581as", "s", "\u2581beat", "\u2581for", "\u2581bullying", "\u2581boys", "\u2581nephew", "\u2581https", "://", "t", ".", "co", "/", "Q", "t", "U", "8", "e", "6", "s", "6", "SK", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Thir", "t", "y", "S", "e", "c", "F", "ight", "s", ":", "\u2581Du", "de", "\u2581gets", "\u2581his", "\u2581as", "s", "\u2581beat", "\u2581for", "\u2581bullying", "\u2581boys", "\u2581nephew", "\u2581https", "://", "t", ".", "co", "/", "Q", "t", "U", "8", "e", "6", "s", "6", "SK", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Thir", "t", "y", "S", "e", "c", "F", "ight", "s", ":", "\u2581Du", "de", "\u2581gets", "\u2581his", "\u2581as", "s", "\u2581beat", "\u2581for", "\u2581bullying", "\u2581boys", "\u2581nephew", "\u2581https", "://", "t", ".", "co", "/", "Q", "t", "U", "8", "e", "6", "s", "6", "SK", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_936", "sentence": ["\u2581", "UG", "!", "\u2581CO", "MED", "Y", "\u2581SH", "OW", "!", "\u2581at", "\u2581No", "\u2581Fun", "\u2581Bar", "\u2581Start", "s", "\u2581in", "\u25811", "\u2581Hour", "-", "http", "s", ":", "\u2581", "/", "\u2581", "/", "\u2581", "t", ".", "\u2581co", "\u2581", "/", "\u2581", "Y", "p", "SU", "s", "a", "W", "r", "PF", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "UG", "!", "\u2581CO", "MED", "Y", "\u2581SH", "OW", "!", "\u2581at", "\u2581No", "\u2581Fun", "\u2581Bar", "\u2581Start", "s", "\u2581in", "\u25811", "\u2581Hour", "-", "http", "s", ":", "\u2581", "/", "\u2581", "/", "\u2581", "t", ".", "\u2581co", "\u2581", "/", "\u2581", "Y", "p", "SU", "s", "a", "W", "r", "PF", "</s>"], "target_sentence": ["\u2581", "UG", "!", "\u2581CO", "MED", "Y", "\u2581SH", "OW", "!", "\u2581at", "<m>", "\u2581No", "\u2581Fun", "\u2581Bar", "\u2581Start", "s", "</m>", "\u2581in", "\u25811", "\u2581Hour", "-", "http", "s", ":", "\u2581", "/", "\u2581", "/", "\u2581", "t", ".", "\u2581co", "\u2581", "/", "\u2581", "Y", "p", "SU", "s", "a", "W", "r", "PF", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 12, 12, 12, 13, 14, 14, 15, 15, 16, 16, 17, 18, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_937", "sentence": ["\u2581", "RT", "\u2581@", "\u2581in", "va", "I", "i", "date", ":", "\u2581Respect", "\u2581yourself", "\u2581enough", "\u2581to", "\u2581walk", "\u2581away", "\u2581from", "\u2581anything", "\u2581that", "\u2581no", "\u2581longer", "\u2581serves", "\u2581you", ",", "\u2581grows", "\u2581you", ",", "\u2581or", "\u2581makes", "\u2581you", "\u2581happy", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581in", "va", "I", "i", "date", ":", "\u2581Respect", "\u2581yourself", "\u2581enough", "\u2581to", "\u2581walk", "\u2581away", "\u2581from", "\u2581anything", "\u2581that", "\u2581no", "\u2581longer", "\u2581serves", "\u2581you", ",", "\u2581grows", "\u2581you", ",", "\u2581or", "\u2581makes", "\u2581you", "\u2581happy", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581in", "va", "I", "i", "date", ":", "\u2581Respect", "\u2581yourself", "\u2581enough", "\u2581to", "\u2581walk", "\u2581away", "\u2581from", "\u2581anything", "\u2581that", "\u2581no", "\u2581longer", "\u2581serves", "\u2581you", ",", "\u2581grows", "\u2581you", ",", "\u2581or", "\u2581makes", "\u2581you", "\u2581happy", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_938", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Craig", "RB", "ritt", "a", "in", ":", "\u2581I", "\u2581would", "\u2581rather", "\u2581deal", "\u2581with", "\u2581robot", "s", "\u2581", "/", "\u2581computers", "\u2581than", "\u2581left", "ist", "s", ",", "\u2581because", "\u2581I", "\u2581know", "\u2581how", "\u2581to", "\u2581deal", "\u2581with", "\u2581the", "\u2581step", "-", "by", "-", "step", "\u2581programming", "\u2581", "o", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Craig", "RB", "ritt", "a", "in", ":", "\u2581I", "\u2581would", "\u2581rather", "\u2581deal", "\u2581with", "\u2581robot", "s", "\u2581", "/", "\u2581computers", "\u2581than", "\u2581left", "ist", "s", ",", "\u2581because", "\u2581I", "\u2581know", "\u2581how", "\u2581to", "\u2581deal", "\u2581with", "\u2581the", "\u2581step", "-", "by", "-", "step", "\u2581programming", "\u2581", "o", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Craig", "RB", "ritt", "a", "in", "</m>", ":", "\u2581I", "\u2581would", "\u2581rather", "\u2581deal", "\u2581with", "\u2581robot", "s", "\u2581", "/", "\u2581computers", "\u2581than", "\u2581left", "ist", "s", ",", "\u2581because", "\u2581I", "\u2581know", "\u2581how", "\u2581to", "\u2581deal", "\u2581with", "\u2581the", "\u2581step", "-", "by", "-", "step", "\u2581programming", "\u2581", "o", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 23, 23, 24, 25, 25, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_939", "sentence": ["\u2581Local", "\u2581", "/", "\u2581Online", "\u2581Services", ":", "\u2581Small", "\u2581Business", "\u2581Go", "\u2581To", ":", "\u2581https", "://", "t", ".", "co", "/", "Z", "Z", "q", "j", "TD", "g", "L", "c", "C", "\u2581Advertise", "\u2581Anything", "\u2581", "-", "\u2581Free", ".", "\u2581#", "\u2581Promote", "Business", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Local", "\u2581", "/", "\u2581Online", "\u2581Services", ":", "\u2581Small", "\u2581Business", "\u2581Go", "\u2581To", ":", "\u2581https", "://", "t", ".", "co", "/", "Z", "Z", "q", "j", "TD", "g", "L", "c", "C", "\u2581Advertise", "\u2581Anything", "\u2581", "-", "\u2581Free", ".", "\u2581#", "\u2581Promote", "Business", "</s>"], "target_sentence": ["\u2581Local", "\u2581", "/", "\u2581Online", "\u2581Services", ":", "\u2581Small", "\u2581Business", "\u2581Go", "\u2581To", ":", "\u2581https", "://", "t", ".", "co", "/", "Z", "Z", "q", "j", "TD", "g", "L", "c", "C", "\u2581Advertise", "\u2581Anything", "\u2581", "-", "\u2581Free", ".", "\u2581#", "\u2581Promote", "Business", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 13, 13, 14, 15, 16, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_940", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "WS", "HH", "V", "l", "DS", ":", "\u2581", "IM", "\u2581S", "CR", "EAM", "ING", "GG", "GG", "GG", "GG", "GG", "GG", "\u2581https", "://", "t", ".", "co", "/", "PF", "e", "X", "W", "W", "c", "Y", "x", "Y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "WS", "HH", "V", "l", "DS", ":", "\u2581", "IM", "\u2581S", "CR", "EAM", "ING", "GG", "GG", "GG", "GG", "GG", "GG", "\u2581https", "://", "t", ".", "co", "/", "PF", "e", "X", "W", "W", "c", "Y", "x", "Y", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "WS", "HH", "V", "l", "DS", ":", "\u2581", "IM", "\u2581S", "CR", "EAM", "ING", "GG", "GG", "GG", "GG", "GG", "GG", "\u2581https", "://", "t", ".", "co", "/", "PF", "e", "X", "W", "W", "c", "Y", "x", "Y", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_941", "sentence": ["\u2581You", "\u2581might", "\u2581not", "\u2581understand", "\u2581why", ",", "\u2581but", "\u2581it", "\u2581seems", "\u2581as", "\u2581", "if", "\u2581people", "\u2581are", "\u2581ha", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Libra", "\u2581https", "://", "t", ".", "co", "/", "e", "w", "I", "2", "W", "6", "U", "q", "R", "1", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581might", "\u2581not", "\u2581understand", "\u2581why", ",", "\u2581but", "\u2581it", "\u2581seems", "\u2581as", "\u2581", "if", "\u2581people", "\u2581are", "\u2581ha", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Libra", "\u2581https", "://", "t", ".", "co", "/", "e", "w", "I", "2", "W", "6", "U", "q", "R", "1", "</s>"], "target_sentence": ["\u2581You", "\u2581might", "\u2581not", "\u2581understand", "\u2581why", ",", "\u2581but", "\u2581it", "\u2581seems", "\u2581as", "\u2581", "if", "\u2581people", "\u2581are", "\u2581ha", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Libra", "\u2581https", "://", "t", ".", "co", "/", "e", "w", "I", "2", "W", "6", "U", "q", "R", "1", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_942", "sentence": ["\u2581", "RT", "\u2581@", "\u2581so", "o", "mp", "i", ":", "\u2581I", "CY", "MI", "-", "\u2581Lee", "\u2581Jo", "on", "\u2581Gi", "\u2581", "\u2019", "\u2581", "s", "\u2581Agency", "\u2581Respond", "s", "\u2581To", "\u2581Rum", "or", "s", "\u2581Of", "\u2581The", "\u2581Act", "or", "\u2581Dating", "\u2581", "IU", "\u2581https", "://", "t", ".", "co", "/", "c", "y", "7", "C", "i", "r", "3", "r", "h", "q", "\u2581https", "://", "t", ".", "co", "/6", "j", "G", "VO", "y", "QA", "t", "e", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581so", "o", "mp", "i", ":", "\u2581I", "CY", "MI", "-", "\u2581Lee", "\u2581Jo", "on", "\u2581Gi", "\u2581", "\u2019", "\u2581", "s", "\u2581Agency", "\u2581Respond", "s", "\u2581To", "\u2581Rum", "or", "s", "\u2581Of", "\u2581The", "\u2581Act", "or", "\u2581Dating", "\u2581", "IU", "\u2581https", "://", "t", ".", "co", "/", "c", "y", "7", "C", "i", "r", "3", "r", "h", "q", "\u2581https", "://", "t", ".", "co", "/6", "j", "G", "VO", "y", "QA", "t", "e", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581so", "o", "mp", "i", "</m>", ":", "<m>", "\u2581I", "CY", "MI", "-", "</m>", "<m>", "\u2581Lee", "\u2581Jo", "on", "\u2581Gi", "</m>", "\u2581", "\u2019", "\u2581", "s", "\u2581Agency", "\u2581Respond", "s", "\u2581To", "\u2581Rum", "or", "s", "\u2581Of", "\u2581The", "\u2581Act", "or", "\u2581Dating", "\u2581", "IU", "\u2581https", "://", "t", ".", "co", "/", "c", "y", "7", "C", "i", "r", "3", "r", "h", "q", "\u2581https", "://", "t", ".", "co", "/6", "j", "G", "VO", "y", "QA", "t", "e", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 4, 4, 5, 6, 6, 7, 8, 8, 9, 9, 10, 11, 11, 12, 13, 13, 13, 14, 15, 16, 16, 17, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_943", "sentence": ["\u2581when", "\u2581you", "\u2581need", "\u2581money", "\u2581and", "\u2581you", "\u2581remember", "\u2581about", "\u2581that", "\u2581un", "opened", "\u2581bottle", "\u2581of", "\u2581ga", "vis", "con", "\u2581you", "'", "\u2581", "ve", "\u2581got", "\u2581in", "\u2581your", "\u2581cupboard", "\u2581", "x", "\u2581https", "://", "t", ".", "co", "/", "Du", "7", "W", "b", "f", "d", "X", "6", "i", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581when", "\u2581you", "\u2581need", "\u2581money", "\u2581and", "\u2581you", "\u2581remember", "\u2581about", "\u2581that", "\u2581un", "opened", "\u2581bottle", "\u2581of", "\u2581ga", "vis", "con", "\u2581you", "'", "\u2581", "ve", "\u2581got", "\u2581in", "\u2581your", "\u2581cupboard", "\u2581", "x", "\u2581https", "://", "t", ".", "co", "/", "Du", "7", "W", "b", "f", "d", "X", "6", "i", "</s>"], "target_sentence": ["\u2581when", "\u2581you", "\u2581need", "\u2581money", "\u2581and", "\u2581you", "\u2581remember", "\u2581about", "\u2581that", "\u2581un", "opened", "\u2581bottle", "\u2581of", "<m>", "\u2581ga", "vis", "con", "</m>", "\u2581you", "'", "\u2581", "ve", "\u2581got", "\u2581in", "\u2581your", "\u2581cupboard", "\u2581", "x", "\u2581https", "://", "t", ".", "co", "/", "Du", "7", "W", "b", "f", "d", "X", "6", "i", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_944", "sentence": ["\u2581get", "\u2581$", "\u258120", "\u2581discount", "\u2581when", "\u2581you", "\u2581book", "\u2581in", "\u2581air", "b", "n", "b", ",", "\u2581use", "\u2581this", "\u2581link", "\u2581https", "://", "t", ".", "co", "/", "R", "0", "D", "y", "O", "p", "or", "86", "\u2581#", "\u2581air", "b", "n", "b", "\u2581#", "\u2581discount", "\u2581#", "\u2581coupon", "\u2581#", "\u2581code", "\u2581https", "://", "t", ".", "co", "/", "t", "Q", "d", "C", "e", "w", "R", "v", "I", "W", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581get", "\u2581$", "\u258120", "\u2581discount", "\u2581when", "\u2581you", "\u2581book", "\u2581in", "\u2581air", "b", "n", "b", ",", "\u2581use", "\u2581this", "\u2581link", "\u2581https", "://", "t", ".", "co", "/", "R", "0", "D", "y", "O", "p", "or", "86", "\u2581#", "\u2581air", "b", "n", "b", "\u2581#", "\u2581discount", "\u2581#", "\u2581coupon", "\u2581#", "\u2581code", "\u2581https", "://", "t", ".", "co", "/", "t", "Q", "d", "C", "e", "w", "R", "v", "I", "W", "</s>"], "target_sentence": ["\u2581get", "\u2581$", "\u258120", "\u2581discount", "\u2581when", "\u2581you", "\u2581book", "\u2581in", "<m>", "\u2581air", "b", "n", "b", "</m>", ",", "\u2581use", "\u2581this", "\u2581link", "\u2581https", "://", "t", ".", "co", "/", "R", "0", "D", "y", "O", "p", "or", "86", "\u2581#", "<m>", "\u2581air", "b", "n", "b", "</m>", "\u2581#", "\u2581discount", "\u2581#", "\u2581coupon", "\u2581#", "\u2581code", "\u2581https", "://", "t", ".", "co", "/", "t", "Q", "d", "C", "e", "w", "R", "v", "I", "W", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 15, 15, 15, 15, 16, 17, 18, 19, 20, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_945", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ba", "a", "by", "y", "le", "x", ":", "\u2581", "rap", "e", ",", "\u2581in", "c", "est", ",", "\u2581financial", "\u2581issues", ",", "\u2581health", "\u2581issues", ",", "\u2581the", "\u2581millions", "\u2581of", "\u2581children", "\u2581that", "\u2581are", "\u2581already", "\u2581put", "\u2581up", "\u2581for", "\u2581adoption", "\u2581that", "\u2581", "d", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ba", "a", "by", "y", "le", "x", ":", "\u2581", "rap", "e", ",", "\u2581in", "c", "est", ",", "\u2581financial", "\u2581issues", ",", "\u2581health", "\u2581issues", ",", "\u2581the", "\u2581millions", "\u2581of", "\u2581children", "\u2581that", "\u2581are", "\u2581already", "\u2581put", "\u2581up", "\u2581for", "\u2581adoption", "\u2581that", "\u2581", "d", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581ba", "a", "by", "y", "le", "x", ":", "\u2581", "rap", "e", ",", "\u2581in", "c", "est", ",", "\u2581financial", "\u2581issues", ",", "\u2581health", "\u2581issues", ",", "\u2581the", "\u2581millions", "\u2581of", "\u2581children", "\u2581that", "\u2581are", "\u2581already", "\u2581put", "\u2581up", "\u2581for", "\u2581adoption", "\u2581that", "\u2581", "d", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_946", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Hu", "got", "D", "re", ":", "\u2581I", "\u2581hate", "\u2581people", "\u2581who", "\u2581pretend", "\u2581to", "\u2581be", "\u2581my", "\u2581friend", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Hu", "got", "D", "re", ":", "\u2581I", "\u2581hate", "\u2581people", "\u2581who", "\u2581pretend", "\u2581to", "\u2581be", "\u2581my", "\u2581friend", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Hu", "got", "D", "re", "</m>", ":", "\u2581I", "\u2581hate", "\u2581people", "\u2581who", "\u2581pretend", "\u2581to", "\u2581be", "\u2581my", "\u2581friend", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_947", "sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "F", "un", "n", "y", "T", "e", "en", "s", ":", "\u2581best", "\u2581friend", "\u2581starter", "\u2581pack", "\u2581https", "://", "t", ".", "co", "/", "a", "U", "Q", "P", "l", "TT", "u", "P", "6", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581The", "F", "un", "n", "y", "T", "e", "en", "s", ":", "\u2581best", "\u2581friend", "\u2581starter", "\u2581pack", "\u2581https", "://", "t", ".", "co", "/", "a", "U", "Q", "P", "l", "TT", "u", "P", "6", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "F", "un", "n", "y", "T", "e", "en", "s", ":", "\u2581best", "\u2581friend", "\u2581starter", "\u2581pack", "\u2581https", "://", "t", ".", "co", "/", "a", "U", "Q", "P", "l", "TT", "u", "P", "6", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_948", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ell", "s", "a", "v", "elli", ":", "\u2581At", "\u2581least", "\u2581dying", "'", "\u2581", "s", "\u2581permanent", "\u2581https", "://", "t", ".", "co", "/", "R", "i", "48", "R", "Q", "T", "03", "e", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "ell", "s", "a", "v", "elli", ":", "\u2581At", "\u2581least", "\u2581dying", "'", "\u2581", "s", "\u2581permanent", "\u2581https", "://", "t", ".", "co", "/", "R", "i", "48", "R", "Q", "T", "03", "e", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "ell", "s", "a", "v", "elli", "</m>", ":", "\u2581At", "\u2581least", "\u2581dying", "'", "\u2581", "s", "\u2581permanent", "\u2581https", "://", "t", ".", "co", "/", "R", "i", "48", "R", "Q", "T", "03", "e", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_949", "sentence": ["\u2581", "RT", "\u2581@", "\u2581beat", "face", "le", "a", "h", ":", "\u2581I", "\u2581was", "\u2581bored", "\u2581earlier", "\u2581so", "\u2581I", "\u2581did", "\u2581this", "\u2581", "\u2728", "\u2581https", "://", "t", ".", "co", "/", "X", "D", "3", "u", "Z", "NG", "Q", "TN", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581beat", "face", "le", "a", "h", ":", "\u2581I", "\u2581was", "\u2581bored", "\u2581earlier", "\u2581so", "\u2581I", "\u2581did", "\u2581this", "\u2581", "\u2728", "\u2581https", "://", "t", ".", "co", "/", "X", "D", "3", "u", "Z", "NG", "Q", "TN", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581beat", "face", "le", "a", "h", "</m>", ":", "\u2581I", "\u2581was", "\u2581bored", "\u2581earlier", "\u2581so", "\u2581I", "\u2581did", "\u2581this", "\u2581", "\u2728", "\u2581https", "://", "t", ".", "co", "/", "X", "D", "3", "u", "Z", "NG", "Q", "TN", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_950", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "bri", "ank", "oppel", "man", ":", "\u2581Yeah", ",", "\u2581man", ".", "\u2581@", "\u2581ja", "ket", "a", "pper", "\u2581is", "\u2581handling", "\u2581this", "\u2581as", "\u2581well", "\u2581and", "\u2581professionally", "\u2581and", "\u2581even", "\u2581heroic", "ally", "\u2581as", "\u2581one", "\u2581can", ".", "\u2581Good", "\u2581on", "\u2581you", ",", "\u2581Ja", "k", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "bri", "ank", "oppel", "man", ":", "\u2581Yeah", ",", "\u2581man", ".", "\u2581@", "\u2581ja", "ket", "a", "pper", "\u2581is", "\u2581handling", "\u2581this", "\u2581as", "\u2581well", "\u2581and", "\u2581professionally", "\u2581and", "\u2581even", "\u2581heroic", "ally", "\u2581as", "\u2581one", "\u2581can", ".", "\u2581Good", "\u2581on", "\u2581you", ",", "\u2581Ja", "k", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "bri", "ank", "oppel", "man", ":", "\u2581Yeah", ",", "\u2581man", ".", "\u2581@", "\u2581ja", "ket", "a", "pper", "\u2581is", "\u2581handling", "\u2581this", "\u2581as", "\u2581well", "\u2581and", "\u2581professionally", "\u2581and", "\u2581even", "\u2581heroic", "ally", "\u2581as", "\u2581one", "\u2581can", ".", "\u2581Good", "\u2581on", "\u2581you", ",", "\u2581Ja", "k", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_951", "sentence": ["\u2581", "RT", "\u2581@", "\u258130", "\u2581second", "rock", ":", "\u2581The", "\u2581Black", "\u2581Key", "s", "\u2581", "-", "\u2581\"", "\u2581L", "one", "ly", "\u2581Boy", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "k", "1", "h", "x", "m", "2", "U", "1", "M", "q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u258130", "\u2581second", "rock", ":", "\u2581The", "\u2581Black", "\u2581Key", "s", "\u2581", "-", "\u2581\"", "\u2581L", "one", "ly", "\u2581Boy", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "k", "1", "h", "x", "m", "2", "U", "1", "M", "q", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u258130", "\u2581second", "rock", ":", "<m>", "<m>", "\u2581The", "<m>", "\u2581Black", "\u2581Key", "s", "</m>", "</m>", "</m>", "\u2581", "-", "\u2581\"", "<m>", "<m>", "\u2581L", "one", "ly", "\u2581Boy", "</m>", "</m>", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "k", "1", "h", "x", "m", "2", "U", "1", "M", "q", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 5, 6, 7, 7, 8, 8, 9, 10, 10, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 2, -1, -1, -1, 1, 2, 0, -1, -1, -1, 4, 3, -1, -1, -1, -1, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_952", "sentence": ["\u25819", "\u2581Resources", "\u2581For", "\u2581Craft", "ing", "\u2581The", "\u2581Perfect", "\u2581Outreach", "\u2581Email", "\u2581by", "\u2581@", "\u2581step", "hen", "je", "ske", "\u2581via", "\u2581@", "\u2581qu", "or", "a", "\u2581https", "://", "t", ".", "co", "/", "c", "66", "x", "410", "IU", "r", "\u2581#", "\u2581email", "marketing", "\u2581#", "\u2581startup", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u25819", "\u2581Resources", "\u2581For", "\u2581Craft", "ing", "\u2581The", "\u2581Perfect", "\u2581Outreach", "\u2581Email", "\u2581by", "\u2581@", "\u2581step", "hen", "je", "ske", "\u2581via", "\u2581@", "\u2581qu", "or", "a", "\u2581https", "://", "t", ".", "co", "/", "c", "66", "x", "410", "IU", "r", "\u2581#", "\u2581email", "marketing", "\u2581#", "\u2581startup", "</s>"], "target_sentence": ["\u25819", "\u2581Resources", "\u2581For", "\u2581Craft", "ing", "\u2581The", "\u2581Perfect", "\u2581Outreach", "\u2581Email", "\u2581by", "\u2581@", "<m>", "\u2581step", "hen", "je", "ske", "</m>", "\u2581via", "\u2581@", "\u2581qu", "or", "a", "\u2581https", "://", "t", ".", "co", "/", "c", "66", "x", "410", "IU", "r", "\u2581#", "\u2581email", "marketing", "\u2581#", "\u2581startup", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 16, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_953", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Kra", "gar", "\u2581", "_", "\u2581L", "GF", ":", "\u2581\u201c", "\u2581In", "\u2581times", "\u2581of", "\u2581universal", "\u2581de", "ce", "it", ",", "\u2581telling", "\u2581the", "\u2581truth", "\u2581is", "\u2581", "a", "\u2581revolutionary", "\u2581act", "\u2581", "\u201d", ".", "\u2581#", "\u2581Res", "ist", "Tru", "mp", "\u2581https", "://", "t", ".", "co", "/", "i", "R", "z", "L", "9", "NT", "0", "Ru", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Kra", "gar", "\u2581", "_", "\u2581L", "GF", ":", "\u2581\u201c", "\u2581In", "\u2581times", "\u2581of", "\u2581universal", "\u2581de", "ce", "it", ",", "\u2581telling", "\u2581the", "\u2581truth", "\u2581is", "\u2581", "a", "\u2581revolutionary", "\u2581act", "\u2581", "\u201d", ".", "\u2581#", "\u2581Res", "ist", "Tru", "mp", "\u2581https", "://", "t", ".", "co", "/", "i", "R", "z", "L", "9", "NT", "0", "Ru", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Kra", "gar", "</m>", "\u2581", "_", "\u2581L", "GF", ":", "\u2581\u201c", "\u2581In", "\u2581times", "\u2581of", "\u2581universal", "\u2581de", "ce", "it", ",", "\u2581telling", "\u2581the", "\u2581truth", "\u2581is", "\u2581", "a", "\u2581revolutionary", "\u2581act", "\u2581", "\u201d", ".", "\u2581#", "\u2581Res", "ist", "Tru", "mp", "\u2581https", "://", "t", ".", "co", "/", "i", "R", "z", "L", "9", "NT", "0", "Ru", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 20, 21, 22, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_954", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Just", "D", "i", "d", "I", "t", "Sport", ":", "\u2581When", "\u2581coach", "\u2581cancel", "s", "\u2581practice", "\u2581https", "://", "t", ".", "co", "/", "02", "y", "y", "2", "CF", "m", "DR", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Just", "D", "i", "d", "I", "t", "Sport", ":", "\u2581When", "\u2581coach", "\u2581cancel", "s", "\u2581practice", "\u2581https", "://", "t", ".", "co", "/", "02", "y", "y", "2", "CF", "m", "DR", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Just", "D", "i", "d", "I", "t", "Sport", ":", "\u2581When", "\u2581coach", "\u2581cancel", "s", "\u2581practice", "\u2581https", "://", "t", ".", "co", "/", "02", "y", "y", "2", "CF", "m", "DR", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_955", "sentence": ["\u2581@", "\u2581", "g", "is", "iez", "\u2581Yes", ",", "\u2581I", "\u2581will", "\u2581try", ".", ".", "\u2581", "i", "'", "\u2581", "m", "\u2581looking", "\u2581for", "\u2581Linux", "\u2581OS", "\u2581have", "\u2581", "a", "\u2581look", "\u2581good", ",", "\u2581unlike", "\u2581the", "\u2581Ubuntu", "\u2581it", "'", "\u2581", "s", "\u2581primitive", ".", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "g", "is", "iez", "\u2581Yes", ",", "\u2581I", "\u2581will", "\u2581try", ".", ".", "\u2581", "i", "'", "\u2581", "m", "\u2581looking", "\u2581for", "\u2581Linux", "\u2581OS", "\u2581have", "\u2581", "a", "\u2581look", "\u2581good", ",", "\u2581unlike", "\u2581the", "\u2581Ubuntu", "\u2581it", "'", "\u2581", "s", "\u2581primitive", ".", ".", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581", "g", "is", "iez", "\u2581Yes", ",", "\u2581I", "\u2581will", "\u2581try", ".", ".", "\u2581", "i", "'", "\u2581", "m", "\u2581looking", "\u2581for", "<m>", "<m>", "\u2581Linux", "\u2581OS", "</m>", "</m>", "\u2581have", "\u2581", "a", "\u2581look", "\u2581good", ",", "\u2581unlike", "\u2581the", "<m>", "<m>", "\u2581Ubuntu", "</m>", "</m>", "\u2581it", "'", "\u2581", "s", "\u2581primitive", ".", ".", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_956", "sentence": ["\u2581", "RT", "\u2581@", "\u2581max", "ine", "j", "iji", ":", "\u2581Don", "'", "\u2581", "t", "\u2581keep", "\u2581calm", ".", "\u2581You", "'", "\u2581", "re", "\u2581in", "\u2581my", "\u2581inappropriate", "\u2581thoughts", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581max", "ine", "j", "iji", ":", "\u2581Don", "'", "\u2581", "t", "\u2581keep", "\u2581calm", ".", "\u2581You", "'", "\u2581", "re", "\u2581in", "\u2581my", "\u2581inappropriate", "\u2581thoughts", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581max", "ine", "j", "iji", "</m>", ":", "\u2581Don", "'", "\u2581", "t", "\u2581keep", "\u2581calm", ".", "\u2581You", "'", "\u2581", "re", "\u2581in", "\u2581my", "\u2581inappropriate", "\u2581thoughts", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_957", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "j", "z", "aff", "o", "s", ":", "\u2581Hey", "\u2581federal", "\u2581scientists", ":", "\u2581@", "\u2581high", "country", "news", "\u2581is", "\u2581collecting", "\u2581reports", "\u2581of", "\u2581interference", "\u2581or", "\u2581intimid", "ation", ".", "\u2581Conf", "i", "d", "ential", "\u2581form", ":", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "j", "z", "aff", "o", "s", ":", "\u2581Hey", "\u2581federal", "\u2581scientists", ":", "\u2581@", "\u2581high", "country", "news", "\u2581is", "\u2581collecting", "\u2581reports", "\u2581of", "\u2581interference", "\u2581or", "\u2581intimid", "ation", ".", "\u2581Conf", "i", "d", "ential", "\u2581form", ":", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "j", "z", "aff", "o", "s", ":", "\u2581Hey", "\u2581federal", "\u2581scientists", ":", "\u2581@", "\u2581high", "country", "news", "\u2581is", "\u2581collecting", "\u2581reports", "\u2581of", "\u2581interference", "\u2581or", "\u2581intimid", "ation", ".", "\u2581Conf", "i", "d", "ential", "\u2581form", ":", "\u2581https", "://", "t", ".", "c", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 18, 18, 18, 19, 20, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_958", "sentence": ["\u2581Don", "'", "\u2581", "t", "\u2581get", "\u2581kettle", "d", ".", "\u2581Made", "\u2581up", "\u2581charges", "\u2581will", "\u2581follow", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "8", "l", "s", "M", "KI", "H", "d", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Don", "'", "\u2581", "t", "\u2581get", "\u2581kettle", "d", ".", "\u2581Made", "\u2581up", "\u2581charges", "\u2581will", "\u2581follow", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "8", "l", "s", "M", "KI", "H", "d", "a", "</s>"], "target_sentence": ["\u2581Don", "'", "\u2581", "t", "\u2581get", "\u2581kettle", "d", ".", "\u2581Made", "\u2581up", "\u2581charges", "\u2581will", "\u2581follow", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "8", "l", "s", "M", "KI", "H", "d", "a", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_959", "sentence": ["\u2581", "RT", "\u2581@", "\u2581September", "\u2581", "_", "\u2581baby", "y", ":", "\u2581Five", "\u2581Guys", "\u2581", "wit", "\u2581", "a", "h", "\u2581quick", "ness", "\u2581https", "://", "t", ".", "co", "/", "w", "BD", "20", "J", "s", "i", "C", "8", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581September", "\u2581", "_", "\u2581baby", "y", ":", "\u2581Five", "\u2581Guys", "\u2581", "wit", "\u2581", "a", "h", "\u2581quick", "ness", "\u2581https", "://", "t", ".", "co", "/", "w", "BD", "20", "J", "s", "i", "C", "8", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581September", "\u2581", "_", "\u2581baby", "y", ":", "<m>", "\u2581Five", "\u2581Guys", "</m>", "\u2581", "wit", "\u2581", "a", "h", "\u2581quick", "ness", "\u2581https", "://", "t", ".", "co", "/", "w", "BD", "20", "J", "s", "i", "C", "8", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 4, 5, 6, 7, 8, 8, 9, 9, 9, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_960", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "er", "\u25811", "\u2581cm", "au", ":", "\u2581#", "\u2581Cat", "al", "onia", "'", "\u2581", "s", "\u2581foreign", "\u2581minister", "\u2581@", "\u2581", "rau", "l", "rome", "va", ":", "\u2581\"", "\u2581legally", "\u2581voting", "\u2581to", "\u2581chose", "\u2581one", "'", "\u2581", "s", "\u2581future", "\u2581is", "\u2581", "rooted", "\u2581in", "\u2581European", "\u2581practice", "\u2581\"", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "er", "\u25811", "\u2581cm", "au", ":", "\u2581#", "\u2581Cat", "al", "onia", "'", "\u2581", "s", "\u2581foreign", "\u2581minister", "\u2581@", "\u2581", "rau", "l", "rome", "va", ":", "\u2581\"", "\u2581legally", "\u2581voting", "\u2581to", "\u2581chose", "\u2581one", "'", "\u2581", "s", "\u2581future", "\u2581is", "\u2581", "rooted", "\u2581in", "\u2581European", "\u2581practice", "\u2581\"", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "er", "\u25811", "\u2581cm", "au", ":", "\u2581#", "\u2581Cat", "al", "onia", "'", "\u2581", "s", "\u2581foreign", "\u2581minister", "\u2581@", "<m>", "\u2581", "rau", "l", "rome", "va", "</m>", ":", "\u2581\"", "\u2581legally", "\u2581voting", "\u2581to", "\u2581chose", "\u2581one", "'", "\u2581", "s", "\u2581future", "\u2581is", "\u2581", "rooted", "\u2581in", "\u2581European", "\u2581practice", "\u2581\"", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 7, 8, 9, 9, 10, 11, 12, 13, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_961", "sentence": ["\u2581@", "\u2581", "a", "king", "he", "s", "\u2581si", "i", "im", "\u2581tip", "o", ",", "\u2581", "e", "u", "\u2581to", "\u2581", "kk", "kk", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "a", "king", "he", "s", "\u2581si", "i", "im", "\u2581tip", "o", ",", "\u2581", "e", "u", "\u2581to", "\u2581", "kk", "kk", "</s>"], "target_sentence": ["\u2581@", "\u2581", "a", "king", "he", "s", "\u2581si", "i", "im", "\u2581tip", "o", ",", "\u2581", "e", "u", "\u2581to", "\u2581", "kk", "kk", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 5, 5, 5, 6, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_962", "sentence": ["\u2581hair", "less", "\u2581", "teen", "\u2581https", "://", "t", ".", "co", "/", "f", "h", "g", "1", "V", "x", "e", "LF", "2", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581hair", "less", "\u2581", "teen", "\u2581https", "://", "t", ".", "co", "/", "f", "h", "g", "1", "V", "x", "e", "LF", "2", "</s>"], "target_sentence": ["\u2581hair", "less", "\u2581", "teen", "\u2581https", "://", "t", ".", "co", "/", "f", "h", "g", "1", "V", "x", "e", "LF", "2", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_963", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Gay", "Pri", "de", "Be", "l", "ize", ":", "\u2581#", "\u2581Miss", "Univers", "e", "\u2581#", "\u2581Belize", "\u2581Let", "'", "\u2581", "s", "\u2581Go", "\u2581Belize", ".", "\u2581https", "://", "t", ".", "co", "/", "9", "s", "u", "Un", "g", "v", "G", "7", "T", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Gay", "Pri", "de", "Be", "l", "ize", ":", "\u2581#", "\u2581Miss", "Univers", "e", "\u2581#", "\u2581Belize", "\u2581Let", "'", "\u2581", "s", "\u2581Go", "\u2581Belize", ".", "\u2581https", "://", "t", ".", "co", "/", "9", "s", "u", "Un", "g", "v", "G", "7", "T", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Gay", "Pri", "de", "Be", "l", "ize", "</m>", ":", "\u2581#", "<m>", "\u2581Miss", "Univers", "e", "</m>", "\u2581#", "<m>", "\u2581Belize", "</m>", "\u2581Let", "'", "\u2581", "s", "\u2581Go", "<m>", "\u2581Belize", "</m>", ".", "\u2581https", "://", "t", ".", "co", "/", "9", "s", "u", "Un", "g", "v", "G", "7", "T", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, 2, -1, 2, -1, -1, -1, -1, -1, 3, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_964", "sentence": ["\u2581", "RT", "\u2581@", "\u2581B", "s", "b", "Life", "style", "\u2581", "_", "\u2581", "_", ":", "\u2581Another", "\u2581young", "\u2581star", "\u2581gone", "\u2581way", "\u2581too", "\u2581soon", "\u2581", "\ud83d\ude22", "\u2581", "\ud83d\ude22", "\u2581", "\ud83d\ude22", "\u2581https", "://", "t", ".", "co", "/", "HA", "z", "33", "b", "S", "8", "h", "n", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581B", "s", "b", "Life", "style", "\u2581", "_", "\u2581", "_", ":", "\u2581Another", "\u2581young", "\u2581star", "\u2581gone", "\u2581way", "\u2581too", "\u2581soon", "\u2581", "\ud83d\ude22", "\u2581", "\ud83d\ude22", "\u2581", "\ud83d\ude22", "\u2581https", "://", "t", ".", "co", "/", "HA", "z", "33", "b", "S", "8", "h", "n", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581B", "s", "b", "Life", "style", "\u2581", "_", "\u2581", "_", ":", "\u2581Another", "\u2581young", "\u2581star", "\u2581gone", "\u2581way", "\u2581too", "\u2581soon", "\u2581", "\ud83d\ude22", "\u2581", "\ud83d\ude22", "\u2581", "\ud83d\ude22", "\u2581https", "://", "t", ".", "co", "/", "HA", "z", "33", "b", "S", "8", "h", "n", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 14, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_965", "sentence": ["\u2581#", "\u2581Now", "Play", "ing", "\u2581She", "\u2581In", "\u2581Here", "\u2581Right", "\u2581Now", "\u2581by", "\u2581Big", "g", "D", "a", "w", "g", "\u2581C", "\u2581Lo", "c", "\u2581on", "\u2581https", "://", "t", ".", "co", "/", "N", "2", "E", "e", "Q", "h", "k", "s", "i", "0", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581Now", "Play", "ing", "\u2581She", "\u2581In", "\u2581Here", "\u2581Right", "\u2581Now", "\u2581by", "\u2581Big", "g", "D", "a", "w", "g", "\u2581C", "\u2581Lo", "c", "\u2581on", "\u2581https", "://", "t", ".", "co", "/", "N", "2", "E", "e", "Q", "h", "k", "s", "i", "0", "</s>"], "target_sentence": ["\u2581#", "\u2581Now", "Play", "ing", "\u2581She", "\u2581In", "\u2581Here", "\u2581Right", "\u2581Now", "\u2581by", "<m>", "<m>", "\u2581Big", "g", "D", "a", "w", "g", "\u2581C", "\u2581Lo", "c", "</m>", "</m>", "\u2581on", "\u2581https", "://", "t", ".", "co", "/", "N", "2", "E", "e", "Q", "h", "k", "s", "i", "0", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 9, 10, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_966", "sentence": ["\u2581You", "\u2581can", "\u2581amaze", "\u2581your", "\u2581friends", "\u2581and", "\u2581fellow", "\u2581workers", "\u2581today", "\u2581by", "\u2581your", "\u2581ab", ".", ".", ".", "\u2581More", "\u2581for", "\u2581", "Vir", "go", "\u2581https", "://", "t", ".", "co", "/", "K", "D", "4", "R", "y", "s", "i", "y", "a", "Z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581can", "\u2581amaze", "\u2581your", "\u2581friends", "\u2581and", "\u2581fellow", "\u2581workers", "\u2581today", "\u2581by", "\u2581your", "\u2581ab", ".", ".", ".", "\u2581More", "\u2581for", "\u2581", "Vir", "go", "\u2581https", "://", "t", ".", "co", "/", "K", "D", "4", "R", "y", "s", "i", "y", "a", "Z", "</s>"], "target_sentence": ["\u2581You", "\u2581can", "\u2581amaze", "\u2581your", "\u2581friends", "\u2581and", "\u2581fellow", "\u2581workers", "\u2581today", "\u2581by", "\u2581your", "\u2581ab", ".", ".", ".", "\u2581More", "\u2581for", "<m>", "\u2581", "Vir", "go", "</m>", "\u2581https", "://", "t", ".", "co", "/", "K", "D", "4", "R", "y", "s", "i", "y", "a", "Z", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_967", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Dam", "n", "F", "e", "e", "ling", "s", ":", "\u2581I", "\u2581could", "\u2581hug", "\u2581you", "\u2581for", "\u2581hours", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Dam", "n", "F", "e", "e", "ling", "s", ":", "\u2581I", "\u2581could", "\u2581hug", "\u2581you", "\u2581for", "\u2581hours", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Dam", "n", "F", "e", "e", "ling", "s", ":", "\u2581I", "\u2581could", "\u2581hug", "\u2581you", "\u2581for", "\u2581hours", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_968", "sentence": ["\u2581Fly", "\u2581away", "\u2581fly", "\u2581away", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Fly", "\u2581away", "\u2581fly", "\u2581away", "</s>"], "target_sentence": ["\u2581Fly", "\u2581away", "\u2581fly", "\u2581away", "</s>"], "subtoken_map": [0, 1, 2, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_969", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Klein", "IS", "D", ":", "\u2581The", "\u2581@", "\u2581Klein", "IS", "D", "\u2581Daily", "\u2581is", "\u2581out", "!", "\u2581https", "://", "t", ".", "co", "/", "K", "LC", "f", "Y", "m", "Z", "N", "c", "C", "\u2581Stories", "\u2581via", "\u2581@", "\u2581", "KI", "SD", "\u2581", "_", "\u2581Mul", "t", "ling", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Klein", "IS", "D", ":", "\u2581The", "\u2581@", "\u2581Klein", "IS", "D", "\u2581Daily", "\u2581is", "\u2581out", "!", "\u2581https", "://", "t", ".", "co", "/", "K", "LC", "f", "Y", "m", "Z", "N", "c", "C", "\u2581Stories", "\u2581via", "\u2581@", "\u2581", "KI", "SD", "\u2581", "_", "\u2581Mul", "t", "ling", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "<m>", "<m>", "\u2581Klein", "IS", "D", "</m>", "</m>", "</m>", ":", "\u2581The", "\u2581@", "<m>", "<m>", "<m>", "<m>", "\u2581Klein", "IS", "D", "</m>", "\u2581Daily", "</m>", "</m>", "</m>", "\u2581is", "\u2581out", "!", "\u2581https", "://", "t", ".", "co", "/", "K", "LC", "f", "Y", "m", "Z", "N", "c", "C", "\u2581Stories", "\u2581via", "\u2581@", "\u2581", "KI", "SD", "\u2581", "_", "\u2581Mul", "t", "ling", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13, 14, 15, 15, 15, 16, 16, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, 2, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, 2, -1, -1, -1, 1, 0, 2, -1, -1, -1, 6, 3, 4, 5, -1, -1, -1, 3, -1, 6, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_970", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "a", "p", "r", "ender", "ing", "les", "z", ":", "\u2581Life", "\u2581is", "\u2581meant", "\u2581to", "\u2581be", "\u2581fun", ":", "\u2581A", "\u2581", "vid", "a", "\u2581pare", "ce", "\u2581ser", "\u2581diver", "t", "i", "d", "a", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "a", "p", "r", "ender", "ing", "les", "z", ":", "\u2581Life", "\u2581is", "\u2581meant", "\u2581to", "\u2581be", "\u2581fun", ":", "\u2581A", "\u2581", "vid", "a", "\u2581pare", "ce", "\u2581ser", "\u2581diver", "t", "i", "d", "a", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "a", "p", "r", "ender", "ing", "les", "z", ":", "\u2581Life", "\u2581is", "\u2581meant", "\u2581to", "\u2581be", "\u2581fun", ":", "\u2581A", "\u2581", "vid", "a", "\u2581pare", "ce", "\u2581ser", "\u2581diver", "t", "i", "d", "a", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 13, 13, 14, 15, 15, 15, 15, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_971", "sentence": ["\u2581", "RT", "\u2581@", "\u2581female", "book", ":", "\u2581@", "\u2581my", "\u2581crush", "\u2581https", "://", "t", ".", "co", "/", "r", "i", "U", "z", "x", "Z", "q", "q", "G", "Q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581female", "book", ":", "\u2581@", "\u2581my", "\u2581crush", "\u2581https", "://", "t", ".", "co", "/", "r", "i", "U", "z", "x", "Z", "q", "q", "G", "Q", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581female", "book", ":", "\u2581@", "\u2581my", "\u2581crush", "\u2581https", "://", "t", ".", "co", "/", "r", "i", "U", "z", "x", "Z", "q", "q", "G", "Q", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_972", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Doctor", "Z", "en", ":", "\u2581Ge", "ologists", ",", "\u2581", "phy", "s", "ic", "ist", "s", ",", "\u2581", "chem", "ist", "s", ",", "\u2581", "anthropo", "logists", ",", "\u2581genetic", "ist", "s", "\u2581", "-", "\u2581", "-", "\u2581every", "\u2581discipline", "\u2581better", "\u2581den", "ounce", "\u2581any", "\u2581action", "\u2581against", "\u2581", "EPA", ".", "\u2581#", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Doctor", "Z", "en", ":", "\u2581Ge", "ologists", ",", "\u2581", "phy", "s", "ic", "ist", "s", ",", "\u2581", "chem", "ist", "s", ",", "\u2581", "anthropo", "logists", ",", "\u2581genetic", "ist", "s", "\u2581", "-", "\u2581", "-", "\u2581every", "\u2581discipline", "\u2581better", "\u2581den", "ounce", "\u2581any", "\u2581action", "\u2581against", "\u2581", "EPA", ".", "\u2581#", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Doctor", "Z", "en", ":", "<m>", "\u2581Ge", "ologists", "</m>", ",", "<m>", "\u2581", "phy", "s", "ic", "ist", "s", "</m>", ",", "<m>", "\u2581", "chem", "ist", "s", "</m>", ",", "<m>", "\u2581", "anthropo", "logists", "</m>", ",", "<m>", "\u2581genetic", "ist", "s", "</m>", "\u2581", "-", "\u2581", "-", "\u2581every", "\u2581discipline", "\u2581better", "\u2581den", "ounce", "\u2581any", "\u2581action", "\u2581against", "<m>", "<m>", "\u2581", "EPA", "</m>", "</m>", ".", "\u2581#", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 4, 5, 6, 6, 6, 6, 6, 6, 7, 8, 8, 8, 8, 9, 10, 10, 10, 11, 12, 12, 12, 13, 13, 14, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 22, 23, 24, 25, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 2, -1, -1, -1, -1, 2, -1, 3, -1, -1, -1, 3, -1, 4, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 6, 5, -1, -1, 6, 5, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_973", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Vic", "M", "en", "s", "a", ":", "\u2581Album", "\u2581in", "\u2581the", "\u2581homes", "tre", "t", "ch", ".", ".", ".", "\u2581CL", "OSE", "!", "\u2581", "\ud83d\udc40", "\u2581https", "://", "t", ".", "co", "/", "u", "q", "z", "6", "z", "P", "r", "5", "l", "6", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Vic", "M", "en", "s", "a", ":", "\u2581Album", "\u2581in", "\u2581the", "\u2581homes", "tre", "t", "ch", ".", ".", ".", "\u2581CL", "OSE", "!", "\u2581", "\ud83d\udc40", "\u2581https", "://", "t", ".", "co", "/", "u", "q", "z", "6", "z", "P", "r", "5", "l", "6", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Vic", "M", "en", "s", "a", ":", "\u2581Album", "\u2581in", "\u2581the", "\u2581homes", "tre", "t", "ch", ".", ".", ".", "\u2581CL", "OSE", "!", "\u2581", "\ud83d\udc40", "\u2581https", "://", "t", ".", "co", "/", "u", "q", "z", "6", "z", "P", "r", "5", "l", "6", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_974", "sentence": ["\u2581@", "\u2581Legal", "G", "e", "a", "gle", "\u2581I", "\u2581feel", "\u2581like", "\u2581this", "\u2581may", "\u2581turn", "\u2581out", "\u2581to", "\u2581be", "\u2581way", "\u2581worse", ".", "\u2581|", "\u2581Che", "ney", "\u2581Rule", ".", "\u2581Nice", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Legal", "G", "e", "a", "gle", "\u2581I", "\u2581feel", "\u2581like", "\u2581this", "\u2581may", "\u2581turn", "\u2581out", "\u2581to", "\u2581be", "\u2581way", "\u2581worse", ".", "\u2581|", "\u2581Che", "ney", "\u2581Rule", ".", "\u2581Nice", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Legal", "G", "e", "a", "gle", "\u2581I", "\u2581feel", "\u2581like", "\u2581this", "\u2581may", "\u2581turn", "\u2581out", "\u2581to", "\u2581be", "\u2581way", "\u2581worse", ".", "\u2581|", "<m>", "\u2581Che", "ney", "</m>", "\u2581Rule", ".", "\u2581Nice", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_975", "sentence": ["\u2581@", "\u2581", "KA", "THER", "ll", "NE", "\u2581All", "\u2581she", "\u2581was", "\u2581doing", "\u2581was", "\u2581encouraging", "\u2581someone", "\u2581no", "\u2581harm", "\u2581there", "\u2581", "bud", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "KA", "THER", "ll", "NE", "\u2581All", "\u2581she", "\u2581was", "\u2581doing", "\u2581was", "\u2581encouraging", "\u2581someone", "\u2581no", "\u2581harm", "\u2581there", "\u2581", "bud", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "KA", "THER", "ll", "NE", "</m>", "\u2581All", "\u2581she", "\u2581was", "\u2581doing", "\u2581was", "\u2581encouraging", "\u2581someone", "\u2581no", "\u2581harm", "\u2581there", "\u2581", "bud", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_976", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "a", "\u2581", "_", "\u2581mo", "f", "i", "a", ":", "\u2581Adult", "hood", ":", "\u2581https", "://", "t", ".", "co", "/", "c", "0", "ar", "J", "l", "1", "b", "z", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "a", "\u2581", "_", "\u2581mo", "f", "i", "a", ":", "\u2581Adult", "hood", ":", "\u2581https", "://", "t", ".", "co", "/", "c", "0", "ar", "J", "l", "1", "b", "z", "M", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "a", "\u2581", "_", "\u2581mo", "f", "i", "a", ":", "\u2581Adult", "hood", ":", "\u2581https", "://", "t", ".", "co", "/", "c", "0", "ar", "J", "l", "1", "b", "z", "M", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_977", "sentence": ["\u2581How", "\u2581to", "\u2581start", "\u2581", "a", "\u2581Neighborhood", "\u2581Watch", "\u2581in", "\u2581#", "\u2581N", "apa", "\u2581https", "://", "t", ".", "co", "/", "ck", "MR", "u", "at", "V", "DD", "\u2581via", "\u2581@", "\u2581N", "apa", "Reg", "ister", "\u2581@", "\u2581N", "apa", "PD", "\u2581#", "\u2581Neighborhood", "Watch", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "T", "3", "T", "q", "J", "h", "o", "C", "j", "U", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581to", "\u2581start", "\u2581", "a", "\u2581Neighborhood", "\u2581Watch", "\u2581in", "\u2581#", "\u2581N", "apa", "\u2581https", "://", "t", ".", "co", "/", "ck", "MR", "u", "at", "V", "DD", "\u2581via", "\u2581@", "\u2581N", "apa", "Reg", "ister", "\u2581@", "\u2581N", "apa", "PD", "\u2581#", "\u2581Neighborhood", "Watch", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "T", "3", "T", "q", "J", "h", "o", "C", "j", "U", "</s>"], "target_sentence": ["\u2581How", "\u2581to", "\u2581start", "\u2581", "a", "\u2581Neighborhood", "\u2581Watch", "\u2581in", "\u2581#", "\u2581N", "apa", "\u2581https", "://", "t", ".", "co", "/", "ck", "MR", "u", "at", "V", "DD", "\u2581via", "\u2581@", "\u2581N", "apa", "Reg", "ister", "\u2581@", "\u2581N", "apa", "PD", "\u2581#", "\u2581Neighborhood", "Watch", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "T", "3", "T", "q", "J", "h", "o", "C", "j", "U", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 12, 12, 12, 12, 13, 14, 14, 14, 15, 16, 16, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_978", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Southern", "Ho", "m", "o", ":", "\u2581It", "'", "\u2581", "s", "\u2581like", "\u2581", "y", "'", "\u2581all", "\u2581elected", "\u2581that", "\u2581damn", "\u2581Clo", "y", "d", "\u2581River", "s", "\u2581account", "\u2581to", "\u2581be", "\u2581president", ".", "\u2581I", "\u2581swear", "\u2581to", "\u2581G", "OD", "\u2581I", "'", "\u2581", "d", "\u2581rather", "\u2581have", "\u2581Dor", "y", ".", "\u2581https", "://", "t", ".", "co", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Southern", "Ho", "m", "o", ":", "\u2581It", "'", "\u2581", "s", "\u2581like", "\u2581", "y", "'", "\u2581all", "\u2581elected", "\u2581that", "\u2581damn", "\u2581Clo", "y", "d", "\u2581River", "s", "\u2581account", "\u2581to", "\u2581be", "\u2581president", ".", "\u2581I", "\u2581swear", "\u2581to", "\u2581G", "OD", "\u2581I", "'", "\u2581", "d", "\u2581rather", "\u2581have", "\u2581Dor", "y", ".", "\u2581https", "://", "t", ".", "co", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Southern", "Ho", "m", "o", ":", "\u2581It", "'", "\u2581", "s", "\u2581like", "\u2581", "y", "'", "\u2581all", "\u2581elected", "\u2581that", "\u2581damn", "<m>", "\u2581Clo", "y", "d", "\u2581River", "s", "</m>", "\u2581account", "\u2581to", "\u2581be", "\u2581president", ".", "\u2581I", "\u2581swear", "\u2581to", "\u2581G", "OD", "\u2581I", "'", "\u2581", "d", "\u2581rather", "\u2581have", "<m>", "<m>", "\u2581Dor", "y", "</m>", "</m>", ".", "\u2581https", "://", "t", ".", "co", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 27, 27, 28, 29, 30, 30, 31, 32, 32, 32, 32, 32, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 1, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_979", "sentence": ["\u2581Pretty", "\u2581much", "\u2581https", "://", "t", ".", "co", "/", "X", "Je", "d", "T", "um", "m", "Z", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Pretty", "\u2581much", "\u2581https", "://", "t", ".", "co", "/", "X", "Je", "d", "T", "um", "m", "Z", "z", "</s>"], "target_sentence": ["\u2581Pretty", "\u2581much", "\u2581https", "://", "t", ".", "co", "/", "X", "Je", "d", "T", "um", "m", "Z", "z", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_980", "sentence": ["\u2581", "RT", "\u2581@", "\u2581broken", ":", "\u2581how", "\u2581to", "\u2581trust", "\u2581someone", ":", "\u2581you", "\u2581don", "'", "\u2581", "t", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581broken", ":", "\u2581how", "\u2581to", "\u2581trust", "\u2581someone", ":", "\u2581you", "\u2581don", "'", "\u2581", "t", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581broken", ":", "\u2581how", "\u2581to", "\u2581trust", "\u2581someone", ":", "\u2581you", "\u2581don", "'", "\u2581", "t", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_981", "sentence": ["\u2581Want", "\u2581to", "\u2581pretend", "\u2581you", "\u2581", "\u2019", "\u2581", "re", "\u2581performing", "\u2581in", "\u2581front", "\u2581of", "\u258110", ",", "\u2581000", "\u2581people", "?", "\u2581The", "n", "\u2581decide", "\u2581#", "\u2581what", "should", "play", "n", "ext", "\u2581on", "\u2581Power", "\u258195", ".", "\u25813", "\u2581https", "://", "t", ".", "co", "/", "o", "j", "p", "W", "d", "x", "1", "g", "IT", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Want", "\u2581to", "\u2581pretend", "\u2581you", "\u2581", "\u2019", "\u2581", "re", "\u2581performing", "\u2581in", "\u2581front", "\u2581of", "\u258110", ",", "\u2581000", "\u2581people", "?", "\u2581The", "n", "\u2581decide", "\u2581#", "\u2581what", "should", "play", "n", "ext", "\u2581on", "\u2581Power", "\u258195", ".", "\u25813", "\u2581https", "://", "t", ".", "co", "/", "o", "j", "p", "W", "d", "x", "1", "g", "IT", "</s>"], "target_sentence": ["\u2581Want", "\u2581to", "\u2581pretend", "\u2581you", "\u2581", "\u2019", "\u2581", "re", "\u2581performing", "\u2581in", "\u2581front", "\u2581of", "\u258110", ",", "\u2581000", "\u2581people", "?", "\u2581The", "n", "\u2581decide", "\u2581#", "\u2581what", "should", "play", "n", "ext", "\u2581on", "<m>", "\u2581Power", "\u258195", ".", "\u25813", "</m>", "\u2581https", "://", "t", ".", "co", "/", "o", "j", "p", "W", "d", "x", "1", "g", "IT", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 18, 18, 18, 18, 19, 20, 21, 22, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_982", "sentence": ["\u2581\"", "\u2581When", "\u2581you", "\u2581understand", "\u2581that", "\u2581life", "\u2581is", "\u2581", "a", "\u2581test", ",", "\u2581you", "\u2581realize", "\u2581that", "\u2581nothing", "\u2581is", "\u2581in", "significant", "\u2581in", "\u2581your", "\u2581life", ".", "\u2581\"", "\u2581Rick", "\u2581Warren", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\"", "\u2581When", "\u2581you", "\u2581understand", "\u2581that", "\u2581life", "\u2581is", "\u2581", "a", "\u2581test", ",", "\u2581you", "\u2581realize", "\u2581that", "\u2581nothing", "\u2581is", "\u2581in", "significant", "\u2581in", "\u2581your", "\u2581life", ".", "\u2581\"", "\u2581Rick", "\u2581Warren", "</s>"], "target_sentence": ["\u2581\"", "\u2581When", "\u2581you", "\u2581understand", "\u2581that", "\u2581life", "\u2581is", "\u2581", "a", "\u2581test", ",", "\u2581you", "\u2581realize", "\u2581that", "\u2581nothing", "\u2581is", "\u2581in", "significant", "\u2581in", "\u2581your", "\u2581life", ".", "\u2581\"", "<m>", "\u2581Rick", "\u2581Warren", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1]}, {"doc_id": "emerging.test_983", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "x", "o", "x", "o", "\u2581", "_", "\u2581", "ka", "th", "ly", "n", ":", "\u2581L", "m", "x", "ska", "s", "k", "s", "k", "s", "s", "s", "kk", "s", "\u2581", "i", "\u2581know", "\u2581you", "\u2581not", "\u2581talking", "\u2581https", "://", "t", ".", "co", "/", "Z", "L", "c", "D", "56", "L", "6", "l", "T", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "x", "o", "x", "o", "\u2581", "_", "\u2581", "ka", "th", "ly", "n", ":", "\u2581L", "m", "x", "ska", "s", "k", "s", "k", "s", "s", "s", "kk", "s", "\u2581", "i", "\u2581know", "\u2581you", "\u2581not", "\u2581talking", "\u2581https", "://", "t", ".", "co", "/", "Z", "L", "c", "D", "56", "L", "6", "l", "T", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "x", "o", "x", "o", "\u2581", "_", "<m>", "\u2581", "ka", "th", "ly", "n", "</m>", ":", "\u2581L", "m", "x", "ska", "s", "k", "s", "k", "s", "s", "s", "kk", "s", "\u2581", "i", "\u2581know", "\u2581you", "\u2581not", "\u2581talking", "\u2581https", "://", "t", ".", "co", "/", "Z", "L", "c", "D", "56", "L", "6", "l", "T", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 3, 3, 4, 4, 5, 5, 5, 5, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_984", "sentence": ["\u2581@", "\u2581Marcus", "b", "\u25813", "\u2581", "_", "\u2581@", "\u2581Rich", "Ho", "mie", "Hu", "ang", "\u2581I", "'", "\u2581", "ve", "\u2581seen", "\u2581", "ur", "\u2581dog", "\u2581", "lick", "\u2581beer", "\u2581off", "\u2581the", "\u2581concrete", ".", "\u2581Him", "\u2581and", "\u2581Alan", "\u2581can", "\u2581bond", "\u2581better", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Marcus", "b", "\u25813", "\u2581", "_", "\u2581@", "\u2581Rich", "Ho", "mie", "Hu", "ang", "\u2581I", "'", "\u2581", "ve", "\u2581seen", "\u2581", "ur", "\u2581dog", "\u2581", "lick", "\u2581beer", "\u2581off", "\u2581the", "\u2581concrete", ".", "\u2581Him", "\u2581and", "\u2581Alan", "\u2581can", "\u2581bond", "\u2581better", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Marcus", "b", "</m>", "\u25813", "\u2581", "_", "\u2581@", "<m>", "\u2581Rich", "Ho", "mie", "Hu", "ang", "</m>", "\u2581I", "'", "\u2581", "ve", "\u2581seen", "\u2581", "ur", "\u2581dog", "\u2581", "lick", "\u2581beer", "\u2581off", "\u2581the", "\u2581concrete", ".", "\u2581Him", "\u2581and", "<m>", "\u2581Alan", "</m>", "\u2581can", "\u2581bond", "\u2581better", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 5, 5, 5, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 2, -1, -1, -1, -1]}, {"doc_id": "emerging.test_985", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "x", "to", "j", "b", "CD", "5", "RB", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "x", "to", "j", "b", "CD", "5", "RB", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "x", "to", "j", "b", "CD", "5", "RB", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_986", "sentence": ["\u2581@", "\u2581Hard", "Count", "FO", "X", "\u2581follow", "\u2581the", "\u2581money", ".", ".", ".", "\u2581very", "\u2581doubt", "ful", "\u2581", "he", "\u2581retire", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Hard", "Count", "FO", "X", "\u2581follow", "\u2581the", "\u2581money", ".", ".", ".", "\u2581very", "\u2581doubt", "ful", "\u2581", "he", "\u2581retire", "s", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Hard", "Count", "FO", "X", "</m>", "\u2581follow", "\u2581the", "\u2581money", ".", ".", ".", "\u2581very", "\u2581doubt", "ful", "\u2581", "he", "\u2581retire", "s", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_987", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "X", "Q", "2", "s", "W", "d", "r", "9", "v", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "X", "Q", "2", "s", "W", "d", "r", "9", "v", "M", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "X", "Q", "2", "s", "W", "d", "r", "9", "v", "M", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_988", "sentence": ["\u2581@", "\u2581Sean", "y", "Re", "i", "d", "y", "\u2581anything", "\u2581well", "\u2581done", "\u2581for", "\u2581that", "\u2581matter", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Sean", "y", "Re", "i", "d", "y", "\u2581anything", "\u2581well", "\u2581done", "\u2581for", "\u2581that", "\u2581matter", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Sean", "y", "Re", "i", "d", "y", "</m>", "\u2581anything", "\u2581well", "\u2581done", "\u2581for", "\u2581that", "\u2581matter", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_989", "sentence": ["\u2581New", "\u2581Post", ":", "\u25812000", "\u2581AD", "\u2581At", "\u2581The", "\u2581Cartoon", "\u2581Museum", "\u2581https", "://", "t", ".", "co", "/", "k", "1", "w", "MU", "7", "K", "v", "s", "t", "\u2581https", "://", "t", ".", "co", "/", "h", "1", "j", "G", "f", "A", "x", "4", "e", "9", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581New", "\u2581Post", ":", "\u25812000", "\u2581AD", "\u2581At", "\u2581The", "\u2581Cartoon", "\u2581Museum", "\u2581https", "://", "t", ".", "co", "/", "k", "1", "w", "MU", "7", "K", "v", "s", "t", "\u2581https", "://", "t", ".", "co", "/", "h", "1", "j", "G", "f", "A", "x", "4", "e", "9", "</s>"], "target_sentence": ["\u2581New", "\u2581Post", ":", "\u25812000", "\u2581AD", "\u2581At", "<m>", "\u2581The", "\u2581Cartoon", "\u2581Museum", "</m>", "\u2581https", "://", "t", ".", "co", "/", "k", "1", "w", "MU", "7", "K", "v", "s", "t", "\u2581https", "://", "t", ".", "co", "/", "h", "1", "j", "G", "f", "A", "x", "4", "e", "9", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_990", "sentence": ["\u2581", "RT", "\u2581@", "\u2581da", "vid", "f", "rum", ":", "\u2581The", "\u2581president", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581has", "\u2581the", "\u2581power", "\u2581to", "\u2581end", "\u2581human", "\u2581life", "\u2581on", "\u2581earth", ".", "\u2581It", "\u2581", "\u2019", "\u2581", "s", "\u2581important", "\u2581that", "\u2581", "he", "\u2581not", "\u2581be", "\u2581disconnected", "\u2581from", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581da", "vid", "f", "rum", ":", "\u2581The", "\u2581president", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581has", "\u2581the", "\u2581power", "\u2581to", "\u2581end", "\u2581human", "\u2581life", "\u2581on", "\u2581earth", ".", "\u2581It", "\u2581", "\u2019", "\u2581", "s", "\u2581important", "\u2581that", "\u2581", "he", "\u2581not", "\u2581be", "\u2581disconnected", "\u2581from", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581da", "vid", "f", "rum", "</m>", ":", "\u2581The", "\u2581president", "\u2581of", "\u2581the", "<m>", "\u2581United", "\u2581States", "</m>", "\u2581has", "\u2581the", "\u2581power", "\u2581to", "\u2581end", "\u2581human", "\u2581life", "\u2581on", "\u2581earth", ".", "\u2581It", "\u2581", "\u2019", "\u2581", "s", "\u2581important", "\u2581that", "\u2581", "he", "\u2581not", "\u2581be", "\u2581disconnected", "\u2581from", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 22, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_991", "sentence": ["\u2581Sel", "a", "mat", "\u2581", "pag", "i", "\u2581ce", "gg", "\u2581", "ku", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Sel", "a", "mat", "\u2581", "pag", "i", "\u2581ce", "gg", "\u2581", "ku", "</s>"], "target_sentence": ["\u2581Sel", "a", "mat", "\u2581", "pag", "i", "\u2581ce", "gg", "\u2581", "ku", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_992", "sentence": ["\u258110", "\u2581hot", "\u2581toys", "\u2581that", "\u2581are", "\u2581getting", "\u2581couples", "\u2581into", "\u2581", "BD", "SM", "\u2581https", "://", "t", ".", "co", "/", "C", "m", "O", "up", "NG", "ku", "f", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u258110", "\u2581hot", "\u2581toys", "\u2581that", "\u2581are", "\u2581getting", "\u2581couples", "\u2581into", "\u2581", "BD", "SM", "\u2581https", "://", "t", ".", "co", "/", "C", "m", "O", "up", "NG", "ku", "f", "</s>"], "target_sentence": ["\u258110", "\u2581hot", "\u2581toys", "\u2581that", "\u2581are", "\u2581getting", "\u2581couples", "\u2581into", "\u2581", "BD", "SM", "\u2581https", "://", "t", ".", "co", "/", "C", "m", "O", "up", "NG", "ku", "f", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_993", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "DY", "L", "pick", "le", "\u258113", ":", "\u2581\"", "\u2581What", "\u2581were", "\u2581the", "\u2581women", "\u2581even", "\u2581march", "ing", "\u2581for", "?", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "PI", "J", "s", "s", "d", "N", "y", "86", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581", "DY", "L", "pick", "le", "\u258113", ":", "\u2581\"", "\u2581What", "\u2581were", "\u2581the", "\u2581women", "\u2581even", "\u2581march", "ing", "\u2581for", "?", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "PI", "J", "s", "s", "d", "N", "y", "86", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "_", "\u2581", "DY", "L", "pick", "le", "\u258113", "</m>", ":", "\u2581\"", "\u2581What", "\u2581were", "\u2581the", "\u2581women", "\u2581even", "\u2581march", "ing", "\u2581for", "?", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "PI", "J", "s", "s", "d", "N", "y", "86", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_994", "sentence": ["\u2581How", "\u2581to", "\u2581Do", "\u2581", "a", "\u2581Great", "\u2581Man", "ic", "ure", "\u2581at", "\u2581Home", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "A", "l", "x", "d", "R", "9", "SW", "c", "3", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581to", "\u2581Do", "\u2581", "a", "\u2581Great", "\u2581Man", "ic", "ure", "\u2581at", "\u2581Home", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "A", "l", "x", "d", "R", "9", "SW", "c", "3", "</s>"], "target_sentence": ["\u2581How", "\u2581to", "\u2581Do", "\u2581", "a", "<m>", "\u2581Great", "\u2581Man", "ic", "ure", "</m>", "\u2581at", "\u2581Home", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "A", "l", "x", "d", "R", "9", "SW", "c", "3", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 5, 6, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_995", "sentence": ["\u258110", "\u2581Awesome", "\u2581Resources", "\u2581for", "\u2581Women", "\u2581in", "\u2581Tech", "\u2581https", "://", "t", ".", "co", "/", "Q", "Y", "p", "E", "A", "4", "a", "g", "LG", "\u2581via", "\u2581https", "://", "t", ".", "co", "/", "t", "B", "c", "d", "SK", "90", "s", "j", "\u2581#", "\u2581B", "OSS", "T", "IPS", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u258110", "\u2581Awesome", "\u2581Resources", "\u2581for", "\u2581Women", "\u2581in", "\u2581Tech", "\u2581https", "://", "t", ".", "co", "/", "Q", "Y", "p", "E", "A", "4", "a", "g", "LG", "\u2581via", "\u2581https", "://", "t", ".", "co", "/", "t", "B", "c", "d", "SK", "90", "s", "j", "\u2581#", "\u2581B", "OSS", "T", "IPS", "</s>"], "target_sentence": ["\u258110", "\u2581Awesome", "\u2581Resources", "\u2581for", "\u2581Women", "\u2581in", "\u2581Tech", "\u2581https", "://", "t", ".", "co", "/", "Q", "Y", "p", "E", "A", "4", "a", "g", "LG", "\u2581via", "\u2581https", "://", "t", ".", "co", "/", "t", "B", "c", "d", "SK", "90", "s", "j", "\u2581#", "<m>", "\u2581B", "OSS", "T", "IPS", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_996", "sentence": ["\u2581No", "\u2581brain", "er", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "Z", "MA", "pe", "g", "N", "5", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581No", "\u2581brain", "er", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "Z", "MA", "pe", "g", "N", "5", "M", "</s>"], "target_sentence": ["\u2581No", "\u2581brain", "er", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "Z", "MA", "pe", "g", "N", "5", "M", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_997", "sentence": ["\u2581If", "\u2581you", "\u2581prefer", "\u2581to", "\u2581", "eat", "\u2581food", "\u2581that", "\u2581", "\u2019", "\u2581", "s", "\u2581#", "\u2581organic", "ally", "grown", ",", "\u2581Chi", "quit", "a", "\u2581has", "\u2581", "a", "\u2581#", "\u2581banana", "\u2581for", "\u2581you", "!", "\u2581https", "://", "t", ".", "co", "/", "S", "1", "p", "o", "VE", "num", "r", "\u2581https", "://", "t", ".", "co", "/", "q", "TY", "b", "m", "A", "e", "0", "z", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581If", "\u2581you", "\u2581prefer", "\u2581to", "\u2581", "eat", "\u2581food", "\u2581that", "\u2581", "\u2019", "\u2581", "s", "\u2581#", "\u2581organic", "ally", "grown", ",", "\u2581Chi", "quit", "a", "\u2581has", "\u2581", "a", "\u2581#", "\u2581banana", "\u2581for", "\u2581you", "!", "\u2581https", "://", "t", ".", "co", "/", "S", "1", "p", "o", "VE", "num", "r", "\u2581https", "://", "t", ".", "co", "/", "q", "TY", "b", "m", "A", "e", "0", "z", "w", "</s>"], "target_sentence": ["\u2581If", "\u2581you", "\u2581prefer", "\u2581to", "\u2581", "eat", "\u2581food", "\u2581that", "\u2581", "\u2019", "\u2581", "s", "\u2581#", "\u2581organic", "ally", "grown", ",", "<m>", "\u2581Chi", "quit", "a", "</m>", "\u2581has", "\u2581", "a", "\u2581#", "\u2581banana", "\u2581for", "\u2581you", "!", "\u2581https", "://", "t", ".", "co", "/", "S", "1", "p", "o", "VE", "num", "r", "\u2581https", "://", "t", ".", "co", "/", "q", "TY", "b", "m", "A", "e", "0", "z", "w", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 7, 8, 8, 9, 10, 10, 10, 11, 12, 12, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_998", "sentence": ["\u2581A", "\u2581heart", "\u2581that", "\u2581trust", "s", "\u2581the", "\u2581", "lor", "d", "\u2581is", "\u2581", "a", "\u2581heart", "\u2581at", "\u2581peace", ".", "\u2581#", "\u2581Heart", "\u2581#", "\u2581Trust", "The", "L", "or", "d", "\u2581#", "\u2581Peace", "\u2581#", "\u2581Prayer", "\u2581#", "\u2581Faith", "\u2581#", "\u2581Zi", "gla", "r", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "M", "i", "q", "q", "6", "Z", "W", "Z", "R", "i", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "\u2581heart", "\u2581that", "\u2581trust", "s", "\u2581the", "\u2581", "lor", "d", "\u2581is", "\u2581", "a", "\u2581heart", "\u2581at", "\u2581peace", ".", "\u2581#", "\u2581Heart", "\u2581#", "\u2581Trust", "The", "L", "or", "d", "\u2581#", "\u2581Peace", "\u2581#", "\u2581Prayer", "\u2581#", "\u2581Faith", "\u2581#", "\u2581Zi", "gla", "r", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "M", "i", "q", "q", "6", "Z", "W", "Z", "R", "i", "</s>"], "target_sentence": ["\u2581A", "\u2581heart", "\u2581that", "\u2581trust", "s", "\u2581the", "\u2581", "lor", "d", "\u2581is", "\u2581", "a", "\u2581heart", "\u2581at", "\u2581peace", ".", "\u2581#", "\u2581Heart", "\u2581#", "\u2581Trust", "The", "L", "or", "d", "\u2581#", "\u2581Peace", "\u2581#", "\u2581Prayer", "\u2581#", "\u2581Faith", "\u2581#", "<m>", "\u2581Zi", "gla", "r", "</m>", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "M", "i", "q", "q", "6", "Z", "W", "Z", "R", "i", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_999", "sentence": ["\u2581@", "\u2581Ca", "s", "s", "Mon", "e", "y", "Live", "\u2581I", "'", "\u2581", "ll", "\u2581", "DM", "\u2581you", "\u2581lol", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Ca", "s", "s", "Mon", "e", "y", "Live", "\u2581I", "'", "\u2581", "ll", "\u2581", "DM", "\u2581you", "\u2581lol", "</s>"], "target_sentence": ["\u2581@", "\u2581Ca", "s", "s", "Mon", "e", "y", "Live", "\u2581I", "'", "\u2581", "ll", "\u2581", "DM", "\u2581you", "\u2581lol", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1000", "sentence": ["\u2581", "RT", "\u2581@", "\u2581paper", "beat", "s", "t", "we", "e", "t", ":", "\u2581", "if", "\u2581your", "\u2581", "feti", "s", "h", "\u2581is", "\u2581", "credited", "\u2581artwork", "\u2581you", "ll", "\u2581probably", "\u2581never", "\u2581get", "\u2581off", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581paper", "beat", "s", "t", "we", "e", "t", ":", "\u2581", "if", "\u2581your", "\u2581", "feti", "s", "h", "\u2581is", "\u2581", "credited", "\u2581artwork", "\u2581you", "ll", "\u2581probably", "\u2581never", "\u2581get", "\u2581off", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581paper", "beat", "s", "t", "we", "e", "t", ":", "\u2581", "if", "\u2581your", "\u2581", "feti", "s", "h", "\u2581is", "\u2581", "credited", "\u2581artwork", "\u2581you", "ll", "\u2581probably", "\u2581never", "\u2581get", "\u2581off", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 6, 6, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1001", "sentence": ["\u2581What", "\u2581happened", "\u2581last", "\u2581night", "\u2581can", "\u2581happen", "\u2581again", ".", "\u2581#", "\u2581Fortune", "Bot", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581What", "\u2581happened", "\u2581last", "\u2581night", "\u2581can", "\u2581happen", "\u2581again", ".", "\u2581#", "\u2581Fortune", "Bot", "</s>"], "target_sentence": ["\u2581What", "\u2581happened", "\u2581last", "\u2581night", "\u2581can", "\u2581happen", "\u2581again", ".", "\u2581#", "<m>", "\u2581Fortune", "Bot", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1]}, {"doc_id": "emerging.test_1002", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Lee", "l", "\u2581", "_", "\u2581", "hus", "s", "le", ":", "\u2581Get", "\u2581it", "\u2581how", "\u2581you", "\u2581live", ".", "\u2581https", "://", "t", ".", "co", "/", "d", "w", "LG", "w", "E", "s", "X", "6", "H", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Lee", "l", "\u2581", "_", "\u2581", "hus", "s", "le", ":", "\u2581Get", "\u2581it", "\u2581how", "\u2581you", "\u2581live", ".", "\u2581https", "://", "t", ".", "co", "/", "d", "w", "LG", "w", "E", "s", "X", "6", "H", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Lee", "l", "\u2581", "_", "\u2581", "hus", "s", "le", ":", "\u2581Get", "\u2581it", "\u2581how", "\u2581you", "\u2581live", ".", "\u2581https", "://", "t", ".", "co", "/", "d", "w", "LG", "w", "E", "s", "X", "6", "H", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1003", "sentence": ["\u2581", "RT", "\u2581@", "\u2581its", "d", "ou", "g", "the", "pu", "g", ":", "\u2581When", "\u2581", "ur", "\u2581friend", "\u2581buy", "s", "\u2581another", "\u2581pitcher", "\u2581https", "://", "t", ".", "co", "/", "UA", "5", "i", "J", "1", "g", "y", "K", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581its", "d", "ou", "g", "the", "pu", "g", ":", "\u2581When", "\u2581", "ur", "\u2581friend", "\u2581buy", "s", "\u2581another", "\u2581pitcher", "\u2581https", "://", "t", ".", "co", "/", "UA", "5", "i", "J", "1", "g", "y", "K", "w", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581its", "d", "ou", "g", "the", "pu", "g", ":", "\u2581When", "\u2581", "ur", "\u2581friend", "\u2581buy", "s", "\u2581another", "\u2581pitcher", "\u2581https", "://", "t", ".", "co", "/", "UA", "5", "i", "J", "1", "g", "y", "K", "w", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1004", "sentence": ["\u2581Questions", "\u2581Not", "\u2581Answer", "s", "\u2581|", "\u2581Box", "\u2581of", "\u2581C", "ray", "on", "s", "\u2581https", "://", "t", ".", "co", "/", "C", "X", "a", "f", "SH", "e", "W", "P", "V", "\u2581https", "://", "t", ".", "co", "/", "9", "k", "v", "P", "5", "s", "ok", "i", "j", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Questions", "\u2581Not", "\u2581Answer", "s", "\u2581|", "\u2581Box", "\u2581of", "\u2581C", "ray", "on", "s", "\u2581https", "://", "t", ".", "co", "/", "C", "X", "a", "f", "SH", "e", "W", "P", "V", "\u2581https", "://", "t", ".", "co", "/", "9", "k", "v", "P", "5", "s", "ok", "i", "j", "</s>"], "target_sentence": ["\u2581Questions", "\u2581Not", "\u2581Answer", "s", "\u2581|", "\u2581Box", "\u2581of", "\u2581C", "ray", "on", "s", "\u2581https", "://", "t", ".", "co", "/", "C", "X", "a", "f", "SH", "e", "W", "P", "V", "\u2581https", "://", "t", ".", "co", "/", "9", "k", "v", "P", "5", "s", "ok", "i", "j", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1005", "sentence": ["\u2581#", "\u2581adult", "\u2581al", "add", "in", "\u2581an", "al", "\u2581finger", "ing", "\u2581female", "\u2581https", "://", "t", ".", "co", "/", "z", "r", "IV", "y", "N", "f", "I", "9", "j", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581adult", "\u2581al", "add", "in", "\u2581an", "al", "\u2581finger", "ing", "\u2581female", "\u2581https", "://", "t", ".", "co", "/", "z", "r", "IV", "y", "N", "f", "I", "9", "j", "</s>"], "target_sentence": ["\u2581#", "\u2581adult", "<m>", "\u2581al", "add", "in", "</m>", "\u2581an", "al", "\u2581finger", "ing", "\u2581female", "\u2581https", "://", "t", ".", "co", "/", "z", "r", "IV", "y", "N", "f", "I", "9", "j", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 3, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1006", "sentence": ["\u2581Straight", "\u2581", "a", "\u2581altered", "\u2581logistic", "\u2581tac", "tic", "\u2581remedi", "al", "\u2581of", "\u2581", "erra", "tic", "\u2581", "mili", "t", "ancy", "\u2581organizations", ":", "\u2581", "e", "a", "g", "F", "c", "U", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Straight", "\u2581", "a", "\u2581altered", "\u2581logistic", "\u2581tac", "tic", "\u2581remedi", "al", "\u2581of", "\u2581", "erra", "tic", "\u2581", "mili", "t", "ancy", "\u2581organizations", ":", "\u2581", "e", "a", "g", "F", "c", "U", "a", "</s>"], "target_sentence": ["\u2581Straight", "\u2581", "a", "\u2581altered", "\u2581logistic", "\u2581tac", "tic", "\u2581remedi", "al", "\u2581of", "\u2581", "erra", "tic", "\u2581", "mili", "t", "ancy", "\u2581organizations", ":", "\u2581", "e", "a", "g", "F", "c", "U", "a", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 5, 5, 6, 7, 7, 7, 8, 8, 8, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1007", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ho", "bib", "f", ":", "\u2581", "i", "\u2581dar", "e", "\u2581you", "\u2581to", "\u2581tell", "\u2581me", "\u2581this", "\u2581is", "n", "'", "\u2581", "t", "\u2581", "t", "a", "e", "h", "y", "ung", "\u2581and", "\u2581", "jung", "k", "o", "ok", "\u2581https", "://", "t", ".", "co", "/", "Y", "M", "K", "H", "c", "R", "if", "TS", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ho", "bib", "f", ":", "\u2581", "i", "\u2581dar", "e", "\u2581you", "\u2581to", "\u2581tell", "\u2581me", "\u2581this", "\u2581is", "n", "'", "\u2581", "t", "\u2581", "t", "a", "e", "h", "y", "ung", "\u2581and", "\u2581", "jung", "k", "o", "ok", "\u2581https", "://", "t", ".", "co", "/", "Y", "M", "K", "H", "c", "R", "if", "TS", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581ho", "bib", "f", ":", "\u2581", "i", "\u2581dar", "e", "\u2581you", "\u2581to", "\u2581tell", "\u2581me", "\u2581this", "\u2581is", "n", "'", "\u2581", "t", "\u2581", "t", "a", "e", "h", "y", "ung", "\u2581and", "\u2581", "jung", "k", "o", "ok", "\u2581https", "://", "t", ".", "co", "/", "Y", "M", "K", "H", "c", "R", "if", "TS", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 4, 5, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1008", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Na", "z", "aire", "\u2581", "73", ":", "\u2581Trump", "\u2581", "\u2019", "\u2581", "s", "\u2581budget", "\u2581would", "\u2581cut", "\u2581funding", "\u2581for", "\u2581App", "al", "achi", "a", "\u2581", "\u2014", "\u2581and", "\u2581his", "\u2581all", "ies", "\u2581in", "\u2581coal", "\u2581country", "\u2581are", "\u2581", "l", "i", "vid", "\u2581https", "://", "t", ".", "co", "/", "BA", "t", "1", "W", "q", "q", "i", "ar", "\u2581via", "\u2581@", "\u2581", "vo", "x", "d", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Na", "z", "aire", "\u2581", "73", ":", "\u2581Trump", "\u2581", "\u2019", "\u2581", "s", "\u2581budget", "\u2581would", "\u2581cut", "\u2581funding", "\u2581for", "\u2581App", "al", "achi", "a", "\u2581", "\u2014", "\u2581and", "\u2581his", "\u2581all", "ies", "\u2581in", "\u2581coal", "\u2581country", "\u2581are", "\u2581", "l", "i", "vid", "\u2581https", "://", "t", ".", "co", "/", "BA", "t", "1", "W", "q", "q", "i", "ar", "\u2581via", "\u2581@", "\u2581", "vo", "x", "d", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "<m>", "\u2581@", "\u2581Na", "z", "aire", "\u2581", "73", "</m>", ":", "<m>", "\u2581Trump", "\u2581", "\u2019", "\u2581", "s", "</m>", "\u2581budget", "\u2581would", "\u2581cut", "\u2581funding", "\u2581for", "<m>", "\u2581App", "al", "achi", "a", "</m>", "\u2581", "\u2014", "\u2581and", "\u2581his", "<m>", "\u2581all", "ies", "</m>", "\u2581in", "\u2581coal", "\u2581country", "\u2581are", "\u2581", "l", "i", "vid", "\u2581https", "://", "t", ".", "co", "/", "BA", "t", "1", "W", "q", "q", "i", "ar", "\u2581via", "<m>", "\u2581@", "\u2581", "vo", "x", "d", "</m>", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 5, 6, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 14, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 25, 26, 26, 26, 26, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, 2, -1, -1, -1, -1, 3, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, 4, -1, -1, -1]}, {"doc_id": "emerging.test_1009", "sentence": ["\u2581#", "\u2581trap", "music", "\u2581#", "\u2581radio", "\u2581Instant", "\u2581Party", "!", "\u2581", "-", "\u2581Horizon", "s", "\u2581https", "://", "t", ".", "co", "/", "y", "j", "s", "U", "U", "a", "p", "T", "j", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581trap", "music", "\u2581#", "\u2581radio", "\u2581Instant", "\u2581Party", "!", "\u2581", "-", "\u2581Horizon", "s", "\u2581https", "://", "t", ".", "co", "/", "y", "j", "s", "U", "U", "a", "p", "T", "j", "X", "</s>"], "target_sentence": ["\u2581#", "\u2581trap", "music", "\u2581#", "\u2581radio", "\u2581Instant", "\u2581Party", "!", "\u2581", "-", "<m>", "\u2581Horizon", "s", "</m>", "\u2581https", "://", "t", ".", "co", "/", "y", "j", "s", "U", "U", "a", "p", "T", "j", "X", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1010", "sentence": ["\u2581@", "\u2581", "k", "o", "ok", "min", "\u2581", "_", "\u2581", "p", "h", ":", "\u25813", "\u2581thanks", "\u2581ha", "ha", "ha", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "k", "o", "ok", "min", "\u2581", "_", "\u2581", "p", "h", ":", "\u25813", "\u2581thanks", "\u2581ha", "ha", "ha", "</s>"], "target_sentence": ["\u2581@", "\u2581", "k", "o", "ok", "min", "\u2581", "_", "\u2581", "p", "h", ":", "\u25813", "\u2581thanks", "\u2581ha", "ha", "ha", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 4, 5, 6, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1011", "sentence": ["\u2581[", "\u2581", "ART", "I", "CLE", "]", "\u2581Top", "\u25815", "\u2581High", "est", "\u2581Pai", "d", "\u2581of", "\u2581Act", "or", "s", "\u2581Drama", "\u2581Syn", "ops", "is", "\u2581Lee", "\u2581Young", "\u2581A", "e", "\u2581(", "\u2581Sa", "im", "d", "ang", ",", "\u2581Light", "'", "\u2581", "s", "\u2581Di", "ary", ")", "\u2581", "-", "\u2581over", "\u2581", "a", "\u2581B", "illion", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "Q", "q", "J", "5", "Y", "E", "1", "RP", "1", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581[", "\u2581", "ART", "I", "CLE", "]", "\u2581Top", "\u25815", "\u2581High", "est", "\u2581Pai", "d", "\u2581of", "\u2581Act", "or", "s", "\u2581Drama", "\u2581Syn", "ops", "is", "\u2581Lee", "\u2581Young", "\u2581A", "e", "\u2581(", "\u2581Sa", "im", "d", "ang", ",", "\u2581Light", "'", "\u2581", "s", "\u2581Di", "ary", ")", "\u2581", "-", "\u2581over", "\u2581", "a", "\u2581B", "illion", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "Q", "q", "J", "5", "Y", "E", "1", "RP", "1", "</s>"], "target_sentence": ["\u2581[", "\u2581", "ART", "I", "CLE", "]", "<m>", "\u2581Top", "\u25815", "\u2581High", "est", "\u2581Pai", "d", "\u2581of", "\u2581Act", "or", "s", "\u2581Drama", "\u2581Syn", "ops", "is", "<m>", "\u2581Lee", "\u2581Young", "\u2581A", "e", "</m>", "</m>", "\u2581(", "<m>", "\u2581Sa", "im", "d", "ang", "</m>", ",", "<m>", "\u2581Light", "</m>", "'", "\u2581", "s", "<m>", "\u2581Di", "ary", "</m>", ")", "\u2581", "-", "\u2581over", "\u2581", "a", "\u2581B", "illion", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "Q", "q", "J", "5", "Y", "E", "1", "RP", "1", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 5, 6, 6, 7, 8, 8, 8, 9, 10, 10, 10, 11, 12, 13, 13, 14, 15, 15, 15, 15, 16, 17, 18, 19, 19, 20, 20, 21, 22, 22, 23, 24, 24, 25, 25, 26, 27, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 0, -1, 2, -1, -1, -1, -1, 2, -1, 3, -1, 3, -1, -1, -1, 4, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1012", "sentence": ["\u2581How", "\u2581to", "\u2581use", "\u2581data", "\u2581to", "\u2581enhance", "\u2581your", "\u2581#", "\u2581online", "s", "hopping", "\u2581#", "\u2581fulfillment", ".", "\u2581https", "://", "t", ".", "co", "/", "H", "nd", "A", "q", "3", "g", "WE", "1", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581to", "\u2581use", "\u2581data", "\u2581to", "\u2581enhance", "\u2581your", "\u2581#", "\u2581online", "s", "hopping", "\u2581#", "\u2581fulfillment", ".", "\u2581https", "://", "t", ".", "co", "/", "H", "nd", "A", "q", "3", "g", "WE", "1", "</s>"], "target_sentence": ["\u2581How", "\u2581to", "\u2581use", "\u2581data", "\u2581to", "\u2581enhance", "\u2581your", "\u2581#", "\u2581online", "s", "hopping", "\u2581#", "\u2581fulfillment", ".", "\u2581https", "://", "t", ".", "co", "/", "H", "nd", "A", "q", "3", "g", "WE", "1", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1013", "sentence": ["\u2581@", "\u2581", "borg", "\u2581", "_", "\u2581", "nic", "\u2581", "o", "i", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "borg", "\u2581", "_", "\u2581", "nic", "\u2581", "o", "i", "?", "</s>"], "target_sentence": ["\u2581@", "\u2581", "borg", "\u2581", "_", "\u2581", "nic", "\u2581", "o", "i", "?", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1014", "sentence": ["\u2581Good", "\u2581morning", ",", "\u2581beautiful", "!", "\u2581https", "://", "t", ".", "co", "/", "c", "v", "2", "99", "V", "l", "H", "5", "k", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Good", "\u2581morning", ",", "\u2581beautiful", "!", "\u2581https", "://", "t", ".", "co", "/", "c", "v", "2", "99", "V", "l", "H", "5", "k", "</s>"], "target_sentence": ["\u2581Good", "\u2581morning", ",", "\u2581beautiful", "!", "\u2581https", "://", "t", ".", "co", "/", "c", "v", "2", "99", "V", "l", "H", "5", "k", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1015", "sentence": ["\u2581Wow", "!", "\u2581Kid", "-", "in", "-", "the", "-", "c", "and", "y", "-", "store", "\u2581all", "-", "organ", "o", "i", "d", "\u2581issue", "\u2581of", "\u2581Development", "!", "\u2581https", "://", "t", ".", "co", "/", "Q", "Y", "m", "F", "X", "3", "Y", "F", "z", "J", "\u2581#", "\u2581stem", "cell", "s", "\u2581What", "\u2581to", "\u2581read", "\u25811", "\u2581", "s", "t", "?", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "j", "h", "c", "Z", "P", "p", "gu", "J", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Wow", "!", "\u2581Kid", "-", "in", "-", "the", "-", "c", "and", "y", "-", "store", "\u2581all", "-", "organ", "o", "i", "d", "\u2581issue", "\u2581of", "\u2581Development", "!", "\u2581https", "://", "t", ".", "co", "/", "Q", "Y", "m", "F", "X", "3", "Y", "F", "z", "J", "\u2581#", "\u2581stem", "cell", "s", "\u2581What", "\u2581to", "\u2581read", "\u25811", "\u2581", "s", "t", "?", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "j", "h", "c", "Z", "P", "p", "gu", "J", "7", "</s>"], "target_sentence": ["\u2581Wow", "!", "\u2581Kid", "-", "in", "-", "the", "-", "c", "and", "y", "-", "store", "\u2581all", "-", "organ", "o", "i", "d", "\u2581issue", "\u2581of", "\u2581Development", "!", "\u2581https", "://", "t", ".", "co", "/", "Q", "Y", "m", "F", "X", "3", "Y", "F", "z", "J", "\u2581#", "\u2581stem", "cell", "s", "\u2581What", "\u2581to", "\u2581read", "\u25811", "\u2581", "s", "t", "?", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "j", "h", "c", "Z", "P", "p", "gu", "J", "7", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10, 10, 11, 12, 13, 14, 15, 15, 15, 16, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1016", "sentence": ["\u2581@", "\u2581", "ka", "tari", "n", "a", "\u2581", "_", "\u2581", "n", "eko", "\u2581", "/", "\u2581", "/", "\u2581F", "ANG", "IR", "L", "ING", "\u2581SC", "RE", "a", "a", "MS", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "ka", "tari", "n", "a", "\u2581", "_", "\u2581", "n", "eko", "\u2581", "/", "\u2581", "/", "\u2581F", "ANG", "IR", "L", "ING", "\u2581SC", "RE", "a", "a", "MS", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "ka", "tari", "n", "a", "</m>", "\u2581", "_", "\u2581", "n", "eko", "\u2581", "/", "\u2581", "/", "<m>", "\u2581F", "ANG", "IR", "L", "ING", "\u2581SC", "RE", "a", "a", "MS", "</m>", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1]}, {"doc_id": "emerging.test_1017", "sentence": ["\u2581", "RT", "\u2581@", "\u2581da", "vid", "long", "ori", "a", "\u25817", "\u2581An", "\u2581obstacle", "\u2581is", "\u2581often", "\u2581an", "\u2581un", "re", "co", "g", "n", "ized", "\u2581opportunity", ".", "\u2581", "-", "\u2581Pet", "ter", "i", "\u2581Tar", "k", "kon", "en", "\u2581#", "\u2581quote", "\u2581https", "://", "t", ".", "co", "/", "k", "E", "d", "v", "4", "NL", "p", "O", "m", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581da", "vid", "long", "ori", "a", "\u25817", "\u2581An", "\u2581obstacle", "\u2581is", "\u2581often", "\u2581an", "\u2581un", "re", "co", "g", "n", "ized", "\u2581opportunity", ".", "\u2581", "-", "\u2581Pet", "ter", "i", "\u2581Tar", "k", "kon", "en", "\u2581#", "\u2581quote", "\u2581https", "://", "t", ".", "co", "/", "k", "E", "d", "v", "4", "NL", "p", "O", "m", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581da", "vid", "long", "ori", "a", "</m>", "\u25817", "\u2581An", "\u2581obstacle", "\u2581is", "\u2581often", "\u2581an", "\u2581un", "re", "co", "g", "n", "ized", "\u2581opportunity", ".", "\u2581", "-", "<m>", "\u2581Pet", "ter", "i", "\u2581Tar", "k", "kon", "en", "</m>", "\u2581#", "\u2581quote", "\u2581https", "://", "t", ".", "co", "/", "k", "E", "d", "v", "4", "NL", "p", "O", "m", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 10, 11, 12, 12, 13, 13, 13, 14, 14, 14, 14, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1018", "sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581done", "\u25813", "\u2581Collaboration", "s", "\u2581in", "\u2581the", "\u2581Sim", "s", "\u25814", "\u2581but", "\u2581more", "\u2581are", "\u2581to", "\u2581come", ",", "\u2581check", "\u2581out", "\u2581my", "\u2581Play", "list", "\u2581of", "\u2581the", "\u2581ones", "\u2581I", "\u2581already", "\u2581did", ":", "\u2581", "-", ")", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "q", "B", "J", "RF", "u", "2", "KB", "W", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "'", "\u2581", "ve", "\u2581done", "\u25813", "\u2581Collaboration", "s", "\u2581in", "\u2581the", "\u2581Sim", "s", "\u25814", "\u2581but", "\u2581more", "\u2581are", "\u2581to", "\u2581come", ",", "\u2581check", "\u2581out", "\u2581my", "\u2581Play", "list", "\u2581of", "\u2581the", "\u2581ones", "\u2581I", "\u2581already", "\u2581did", ":", "\u2581", "-", ")", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "q", "B", "J", "RF", "u", "2", "KB", "W", "</s>"], "target_sentence": ["\u2581I", "'", "\u2581", "ve", "\u2581done", "\u25813", "\u2581Collaboration", "s", "\u2581in", "\u2581the", "<m>", "<m>", "<m>", "\u2581Sim", "s", "</m>", "\u25814", "</m>", "</m>", "\u2581but", "\u2581more", "\u2581are", "\u2581to", "\u2581come", ",", "\u2581check", "\u2581out", "\u2581my", "\u2581Play", "list", "\u2581of", "\u2581the", "\u2581ones", "\u2581I", "\u2581already", "\u2581did", ":", "\u2581", "-", ")", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "q", "B", "J", "RF", "u", "2", "KB", "W", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 28, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 2, -1, -1, 0, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1019", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "u", "RS", "5", "UP", "a", "j", "7", "J", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "u", "RS", "5", "UP", "a", "j", "7", "J", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "u", "RS", "5", "UP", "a", "j", "7", "J", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1020", "sentence": ["\u2581Lay", "la", "\u2581Sa", "\u25813", "\u2581", "i", "d", "a", ".", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Lay", "la", "\u2581Sa", "\u25813", "\u2581", "i", "d", "a", ".", ".", ".", "</s>"], "target_sentence": ["\u2581Lay", "la", "\u2581Sa", "\u25813", "\u2581", "i", "d", "a", ".", ".", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1021", "sentence": ["\u2581U", "rox", "a", "tral", "\u258110", "\u2581mg", "\u2581", "x", "\u258190", "\u2581pills", "\u2581https", "://", "t", ".", "co", "/", "al", "N", "LM", "2", "j", "S", "s", "t", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581U", "rox", "a", "tral", "\u258110", "\u2581mg", "\u2581", "x", "\u258190", "\u2581pills", "\u2581https", "://", "t", ".", "co", "/", "al", "N", "LM", "2", "j", "S", "s", "t", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581U", "rox", "a", "tral", "</m>", "</m>", "\u258110", "\u2581mg", "\u2581", "x", "\u258190", "\u2581pills", "\u2581https", "://", "t", ".", "co", "/", "al", "N", "LM", "2", "j", "S", "s", "t", "</s>"], "subtoken_map": [0, 0, 0, 0, 1, 2, 3, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1022", "sentence": ["\u2581@", "\u2581Black", "\u2581", "_", "\u2581G", "and", "al", "f", "\u2581@", "\u2581", "s", "lick", "jack", "y", "\u2581I", "'", "\u2581", "ll", "\u2581miss", "\u2581you", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Black", "\u2581", "_", "\u2581G", "and", "al", "f", "\u2581@", "\u2581", "s", "lick", "jack", "y", "\u2581I", "'", "\u2581", "ll", "\u2581miss", "\u2581you", "</s>"], "target_sentence": ["\u2581@", "\u2581Black", "\u2581", "_", "\u2581G", "and", "al", "f", "\u2581@", "\u2581", "s", "lick", "jack", "y", "\u2581I", "'", "\u2581", "ll", "\u2581miss", "\u2581you", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 3, 3, 4, 5, 5, 5, 5, 5, 6, 7, 8, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1023", "sentence": ["\u2581", "RT", "\u2581@", "\u2581kit", "t", "ten", "que", "en", ":", "\u2581", "if", "\u2581you", "\u2581live", "\u2581in", "\u2581So", "Cal", "\u2581stay", "\u2581on", "\u2581the", "\u2581look", "\u2581out", "!", "\u2581pl", "s", "\u2581", "r", "t", "!", "!", "\u2581https", "://", "t", ".", "co", "/", "l", "4", "z", "n", "I", "q", "66", "RN", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581kit", "t", "ten", "que", "en", ":", "\u2581", "if", "\u2581you", "\u2581live", "\u2581in", "\u2581So", "Cal", "\u2581stay", "\u2581on", "\u2581the", "\u2581look", "\u2581out", "!", "\u2581pl", "s", "\u2581", "r", "t", "!", "!", "\u2581https", "://", "t", ".", "co", "/", "l", "4", "z", "n", "I", "q", "66", "RN", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581kit", "t", "ten", "que", "en", ":", "\u2581", "if", "\u2581you", "\u2581live", "\u2581in", "<m>", "\u2581So", "Cal", "</m>", "\u2581stay", "\u2581on", "\u2581the", "\u2581look", "\u2581out", "!", "\u2581pl", "s", "\u2581", "r", "t", "!", "!", "\u2581https", "://", "t", ".", "co", "/", "l", "4", "z", "n", "I", "q", "66", "RN", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 16, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1024", "sentence": ["\u2581@", "\u2581", "kin", "k", "s", "ham", "er", "\u2581where", "\u2581what", "\u2581the", "\u2581", "f", "uck", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "kin", "k", "s", "ham", "er", "\u2581where", "\u2581what", "\u2581the", "\u2581", "f", "uck", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "kin", "k", "s", "ham", "er", "</m>", "\u2581where", "\u2581what", "\u2581the", "\u2581", "f", "uck", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1025", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "Maur", "ici", "o", "The", "S", "one", ":", "\u2581Fa", "mili", "a", "\u2581Q", "i", "an", "\u2581Jung", "\u2581make", "\u2581you", "\u2581feel", "\u2581the", "\u2581heat", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "Maur", "ici", "o", "The", "S", "one", ":", "\u2581Fa", "mili", "a", "\u2581Q", "i", "an", "\u2581Jung", "\u2581make", "\u2581you", "\u2581feel", "\u2581the", "\u2581heat", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "Maur", "ici", "o", "The", "S", "one", ":", "<m>", "\u2581Fa", "mili", "a", "\u2581Q", "i", "an", "\u2581Jung", "</m>", "\u2581make", "\u2581you", "\u2581feel", "\u2581the", "\u2581heat", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1026", "sentence": ["\u2581I", "\u2581guess", "\u2581that", "\u2581is", "\u2581one", "\u2581way", "\u2581to", "\u2581handle", "\u2581being", "\u2581du", "mped", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/2", "s", "6", "U", "7", "CM", "W", "U", "r", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581guess", "\u2581that", "\u2581is", "\u2581one", "\u2581way", "\u2581to", "\u2581handle", "\u2581being", "\u2581du", "mped", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/2", "s", "6", "U", "7", "CM", "W", "U", "r", "</s>"], "target_sentence": ["\u2581I", "\u2581guess", "\u2581that", "\u2581is", "\u2581one", "\u2581way", "\u2581to", "\u2581handle", "\u2581being", "\u2581du", "mped", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/2", "s", "6", "U", "7", "CM", "W", "U", "r", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1027", "sentence": ["\u2581@", "\u2581CNN", "\u2581He", "'", "\u2581", "s", "\u2581an", "\u2581as", "s", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581CNN", "\u2581He", "'", "\u2581", "s", "\u2581an", "\u2581as", "s", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581CNN", "\u2581He", "'", "\u2581", "s", "\u2581an", "\u2581as", "s", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1028", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581time", "\u2581to", "\u2581bus", "t", "\u2581out", "\u2581some", "\u2581of", "\u2581those", "\u2581old", "\u2581classic", "\u2581games", "!", "\u2581https", "://", "t", ".", "co", "/", "B", "J", "NE", "Z", "f", "J", "b", "ge", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581time", "\u2581to", "\u2581bus", "t", "\u2581out", "\u2581some", "\u2581of", "\u2581those", "\u2581old", "\u2581classic", "\u2581games", "!", "\u2581https", "://", "t", ".", "co", "/", "B", "J", "NE", "Z", "f", "J", "b", "ge", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581time", "\u2581to", "\u2581bus", "t", "\u2581out", "\u2581some", "\u2581of", "\u2581those", "\u2581old", "\u2581classic", "\u2581games", "!", "\u2581https", "://", "t", ".", "co", "/", "B", "J", "NE", "Z", "f", "J", "b", "ge", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1029", "sentence": ["\u2581The", "n", "\u2581", "r", "a", "oul", "\u2581spoke", "\u2581", "m", ",", "\u2581her", "\u2581eyes", "\u2581in", "\u2581all", "\u2581their", "\u2581pain", "s", ",", "\u2581", "o", "h", "\u2581mad", "am", "\u2581min", "a", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "n", "\u2581", "r", "a", "oul", "\u2581spoke", "\u2581", "m", ",", "\u2581her", "\u2581eyes", "\u2581in", "\u2581all", "\u2581their", "\u2581pain", "s", ",", "\u2581", "o", "h", "\u2581mad", "am", "\u2581min", "a", ".", "</s>"], "target_sentence": ["\u2581The", "n", "<m>", "\u2581", "r", "a", "oul", "</m>", "\u2581spoke", "\u2581", "m", ",", "\u2581her", "\u2581eyes", "\u2581in", "\u2581all", "\u2581their", "\u2581pain", "s", ",", "\u2581", "o", "h", "\u2581mad", "am", "<m>", "\u2581min", "a", "</m>", ".", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 12, 12, 13, 13, 14, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1]}, {"doc_id": "emerging.test_1030", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "B", "J", "SV", "3", "u", "2", "B", "o", "1", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "B", "J", "SV", "3", "u", "2", "B", "o", "1", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "B", "J", "SV", "3", "u", "2", "B", "o", "1", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1031", "sentence": ["\u2581", "RT", "\u2581@", "\u2581me", "o", "s", "s", "\u258131", ":", "\u2581Ed", "'", "\u2581", "s", "\u2581", "-", "\u2581you", "\u2581are", "\u2581the", "\u2581one", "\u2581who", "\u2581makes", "\u2581me", "\u2581happy", "\u2581Always", "\u2581YOU", "\u2581I", "\u2581swear", "\u2581after", "\u2581five", "\u2581years", ",", "\u2581you", "\u2581are", "\u2581mine", "\u2581#", "\u2581MAY", "W", "ARD", "For", "Co", "ca", "Col", "a", "PH", "\u2581https", "://", "t", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581me", "o", "s", "s", "\u258131", ":", "\u2581Ed", "'", "\u2581", "s", "\u2581", "-", "\u2581you", "\u2581are", "\u2581the", "\u2581one", "\u2581who", "\u2581makes", "\u2581me", "\u2581happy", "\u2581Always", "\u2581YOU", "\u2581I", "\u2581swear", "\u2581after", "\u2581five", "\u2581years", ",", "\u2581you", "\u2581are", "\u2581mine", "\u2581#", "\u2581MAY", "W", "ARD", "For", "Co", "ca", "Col", "a", "PH", "\u2581https", "://", "t", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581me", "o", "s", "s", "\u258131", ":", "<m>", "\u2581Ed", "</m>", "'", "\u2581", "s", "\u2581", "-", "\u2581you", "\u2581are", "\u2581the", "\u2581one", "\u2581who", "\u2581makes", "\u2581me", "\u2581happy", "\u2581Always", "\u2581YOU", "\u2581I", "\u2581swear", "\u2581after", "\u2581five", "\u2581years", ",", "\u2581you", "\u2581are", "\u2581mine", "\u2581#", "<m>", "\u2581MAY", "W", "ARD", "For", "Co", "ca", "Col", "a", "PH", "</m>", "\u2581https", "://", "t", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1032", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Mario", "L", "o", "p", "ez", "Ex", "tra", ":", "\u2581Who", "a", ".", ".", ".", "\u2581Just", "\u2581saw", "\u2581the", "\u2581new", "\u2581#", "\u2581Mama", "J", "une", "!", "\u2581@", "\u2581WE", "t", "v", "\u2581#", "\u2581Jessica", "R", "abb", "it", "\u2581https", "://", "t", ".", "co", "/15", "F", "k", "p", "M", "p", "9", "g", "H", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Mario", "L", "o", "p", "ez", "Ex", "tra", ":", "\u2581Who", "a", ".", ".", ".", "\u2581Just", "\u2581saw", "\u2581the", "\u2581new", "\u2581#", "\u2581Mama", "J", "une", "!", "\u2581@", "\u2581WE", "t", "v", "\u2581#", "\u2581Jessica", "R", "abb", "it", "\u2581https", "://", "t", ".", "co", "/15", "F", "k", "p", "M", "p", "9", "g", "H", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Mario", "L", "o", "p", "ez", "Ex", "tra", "</m>", ":", "\u2581Who", "a", ".", ".", ".", "\u2581Just", "\u2581saw", "\u2581the", "\u2581new", "\u2581#", "<m>", "\u2581Mama", "J", "une", "</m>", "!", "\u2581@", "\u2581WE", "t", "v", "\u2581#", "<m>", "\u2581Jessica", "R", "abb", "it", "</m>", "\u2581https", "://", "t", ".", "co", "/15", "F", "k", "p", "M", "p", "9", "g", "H", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 16, 16, 17, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1033", "sentence": ["\u2581@", "\u2581Will", "power", "\u2581", "_", "\u25818", "\u2581Sorry", "\u2581for", "\u2581the", "\u2581delay", "\u2581but", "\u2581we", "'", "\u2581", "ve", "\u2581got", "\u2581your", "\u2581reply", "\u2581#", "\u2581How", "Do", "You", "F", "e", "e", "l", "C", "hall", "en", "ge", "\u2581https", "://", "t", ".", "co", "/6", "a", "x", "9", "V", "L", "j", "n", "Z", "P", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Will", "power", "\u2581", "_", "\u25818", "\u2581Sorry", "\u2581for", "\u2581the", "\u2581delay", "\u2581but", "\u2581we", "'", "\u2581", "ve", "\u2581got", "\u2581your", "\u2581reply", "\u2581#", "\u2581How", "Do", "You", "F", "e", "e", "l", "C", "hall", "en", "ge", "\u2581https", "://", "t", ".", "co", "/6", "a", "x", "9", "V", "L", "j", "n", "Z", "P", "</s>"], "target_sentence": ["\u2581@", "\u2581Will", "power", "\u2581", "_", "\u25818", "\u2581Sorry", "\u2581for", "\u2581the", "\u2581delay", "\u2581but", "\u2581we", "'", "\u2581", "ve", "\u2581got", "\u2581your", "\u2581reply", "\u2581#", "<m>", "\u2581How", "Do", "You", "F", "e", "e", "l", "C", "hall", "en", "ge", "</m>", "\u2581https", "://", "t", ".", "co", "/6", "a", "x", "9", "V", "L", "j", "n", "Z", "P", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1034", "sentence": ["\u2581Co", "e", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Co", "e", "</s>"], "target_sentence": ["\u2581Co", "e", "</s>"], "subtoken_map": [0, 0, 1], "ent_type_sequence": [-1, -1, -1], "ent_indices": [-1, -1, -1]}, {"doc_id": "emerging.test_1035", "sentence": ["\u2581Sat", "\u258118", "\u2581", "th", "\u2581Mar", "\u2581", "00", ":", "\u2581", "00", ":", "\u2581The", "\u2581#", "\u2581Weather", "\u2581in", "\u2581#", "\u2581Glasgow", "\u2581is", "\u2581currently", "\u2581Part", "ly", "\u2581cloud", "y", "\u2581and", "\u25819", "\u2581C", "\u2581|", "\u2581Max", ":", "\u258111", "\u2581C", "\u2581Min", ":", "\u25819", "\u2581C", "\u2581", "-", "\u2581#", "\u2581My", "We", "at", "her", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Sat", "\u258118", "\u2581", "th", "\u2581Mar", "\u2581", "00", ":", "\u2581", "00", ":", "\u2581The", "\u2581#", "\u2581Weather", "\u2581in", "\u2581#", "\u2581Glasgow", "\u2581is", "\u2581currently", "\u2581Part", "ly", "\u2581cloud", "y", "\u2581and", "\u25819", "\u2581C", "\u2581|", "\u2581Max", ":", "\u258111", "\u2581C", "\u2581Min", ":", "\u25819", "\u2581C", "\u2581", "-", "\u2581#", "\u2581My", "We", "at", "her", "</s>"], "target_sentence": ["\u2581Sat", "\u258118", "\u2581", "th", "\u2581Mar", "\u2581", "00", ":", "\u2581", "00", ":", "\u2581The", "\u2581#", "\u2581Weather", "\u2581in", "\u2581#", "<m>", "<m>", "\u2581Glasgow", "</m>", "</m>", "\u2581is", "\u2581currently", "\u2581Part", "ly", "\u2581cloud", "y", "\u2581and", "\u25819", "\u2581C", "\u2581|", "\u2581Max", ":", "\u258111", "\u2581C", "\u2581Min", ":", "\u25819", "\u2581C", "\u2581", "-", "\u2581#", "\u2581My", "We", "at", "her", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 32, 32, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1036", "sentence": ["\u2581@", "\u2581mari", "a", "\u2581", "_", "\u2581", "h", "t", "r", "za", "\u2581No", "pe", "\u2581the", "\u2581camera", "\u2581saw", "\u2581it", "\u2581first", "\u2581lucky", "\u2581", "phon", ":", "\u2581", "-", "\u2581(", "\u2581Maria", "\u2581I", "\u2581love", "\u2581every", "\u2581", "s", "ex", "y", "\u2581cur", "v", "\u2581of", "\u2581your", "\u2581body", "\u2581don", "'", "\u2581", "t", "\u2581stop", "\u2581showing", "\u2581that", "\u2581", "s", "ex", "y", "\u2581body", "\u2581of", "\u2581your", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581mari", "a", "\u2581", "_", "\u2581", "h", "t", "r", "za", "\u2581No", "pe", "\u2581the", "\u2581camera", "\u2581saw", "\u2581it", "\u2581first", "\u2581lucky", "\u2581", "phon", ":", "\u2581", "-", "\u2581(", "\u2581Maria", "\u2581I", "\u2581love", "\u2581every", "\u2581", "s", "ex", "y", "\u2581cur", "v", "\u2581of", "\u2581your", "\u2581body", "\u2581don", "'", "\u2581", "t", "\u2581stop", "\u2581showing", "\u2581that", "\u2581", "s", "ex", "y", "\u2581body", "\u2581of", "\u2581your", "s", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581mari", "a", "</m>", "\u2581", "_", "\u2581", "h", "t", "r", "za", "\u2581No", "pe", "\u2581the", "\u2581camera", "\u2581saw", "\u2581it", "\u2581first", "\u2581lucky", "\u2581", "phon", ":", "\u2581", "-", "\u2581(", "<m>", "\u2581Maria", "</m>", "\u2581I", "\u2581love", "\u2581every", "\u2581", "s", "ex", "y", "\u2581cur", "v", "\u2581of", "\u2581your", "\u2581body", "\u2581don", "'", "\u2581", "t", "\u2581stop", "\u2581showing", "\u2581that", "\u2581", "s", "ex", "y", "\u2581body", "\u2581of", "\u2581your", "s", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 20, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 30, 30, 30, 31, 32, 33, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1037", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Zen", "ki", "E", "d", "gar", ":", "\u2581@", "\u2581Lady", "Thr", "iller", "\u2581", "69", "\u2581@", "\u2581Diamond", "and", "S", "il", "k", "\u2581@", "\u2581real", "Don", "al", "d", "Tru", "mp", "\u2581Only", "\u2581", "a", "\u2581possibly", "\u2581because", "\u2581this", "\u2581do", "pe", "\u2581allowed", "\u2581test", "\u2581to", "\u2581happen", ".", "\u2581https", "://", "t", ".", "co", "/", "o", "Z", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Zen", "ki", "E", "d", "gar", ":", "\u2581@", "\u2581Lady", "Thr", "iller", "\u2581", "69", "\u2581@", "\u2581Diamond", "and", "S", "il", "k", "\u2581@", "\u2581real", "Don", "al", "d", "Tru", "mp", "\u2581Only", "\u2581", "a", "\u2581possibly", "\u2581because", "\u2581this", "\u2581do", "pe", "\u2581allowed", "\u2581test", "\u2581to", "\u2581happen", ".", "\u2581https", "://", "t", ".", "co", "/", "o", "Z", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Zen", "ki", "E", "d", "gar", ":", "\u2581@", "\u2581Lady", "Thr", "iller", "\u2581", "69", "\u2581@", "\u2581Diamond", "and", "S", "il", "k", "\u2581@", "\u2581real", "Don", "al", "d", "Tru", "mp", "\u2581Only", "\u2581", "a", "\u2581possibly", "\u2581because", "\u2581this", "\u2581do", "pe", "\u2581allowed", "<m>", "\u2581test", "</m>", "\u2581to", "\u2581happen", ".", "\u2581https", "://", "t", ".", "co", "/", "o", "Z", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 6, 6, 7, 8, 8, 8, 8, 8, 9, 10, 10, 10, 10, 10, 10, 11, 12, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1038", "sentence": ["\u2581Even", "ing", "\u2581Forecast", ":", "\u2581", "Increasing", "\u2581clouds", "\u2581with", "\u2581little", "\u2581temperature", "\u2581change", ".", "\u2581#", "\u2581cow", "x", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Even", "ing", "\u2581Forecast", ":", "\u2581", "Increasing", "\u2581clouds", "\u2581with", "\u2581little", "\u2581temperature", "\u2581change", ".", "\u2581#", "\u2581cow", "x", "</s>"], "target_sentence": ["\u2581Even", "ing", "\u2581Forecast", ":", "\u2581", "Increasing", "\u2581clouds", "\u2581with", "\u2581little", "\u2581temperature", "\u2581change", ".", "\u2581#", "\u2581cow", "x", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1039", "sentence": ["\u2581Se", "b", "ring", "\u2581Friday", "\u2581Notebook", "\u2581https", "://", "t", ".", "co", "/", "r", "N", "8", "l", "6", "W", "0", "LG", "Q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Se", "b", "ring", "\u2581Friday", "\u2581Notebook", "\u2581https", "://", "t", ".", "co", "/", "r", "N", "8", "l", "6", "W", "0", "LG", "Q", "</s>"], "target_sentence": ["\u2581Se", "b", "ring", "\u2581Friday", "<m>", "\u2581Notebook", "</m>", "\u2581https", "://", "t", ".", "co", "/", "r", "N", "8", "l", "6", "W", "0", "LG", "Q", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1040", "sentence": ["\u25812", "\u2581", "/", "\u25812", ":", "\u2581Feel", "s", "\u2581Like", ":", "\u258137", "\u2581F", "\u2581(", "\u25813", "\u2581C", ")", "\u2581Hu", "mid", "ity", ":", "\u258124", "\u2581", "%", "\u2581Local", "\u2581Forecast", ":", "\u2581https", "://", "t", ".", "co", "/", "h", "0", "f", "A", "k", "3", "m", "K", "w", "G", "\u2581#", "\u2581weather", "\u2581#", "\u2581news", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u25812", "\u2581", "/", "\u25812", ":", "\u2581Feel", "s", "\u2581Like", ":", "\u258137", "\u2581F", "\u2581(", "\u25813", "\u2581C", ")", "\u2581Hu", "mid", "ity", ":", "\u258124", "\u2581", "%", "\u2581Local", "\u2581Forecast", ":", "\u2581https", "://", "t", ".", "co", "/", "h", "0", "f", "A", "k", "3", "m", "K", "w", "G", "\u2581#", "\u2581weather", "\u2581#", "\u2581news", "</s>"], "target_sentence": ["\u25812", "\u2581", "/", "\u25812", ":", "\u2581Feel", "s", "\u2581Like", ":", "\u258137", "\u2581F", "\u2581(", "\u25813", "\u2581C", ")", "\u2581Hu", "mid", "ity", ":", "\u258124", "\u2581", "%", "\u2581Local", "\u2581Forecast", ":", "\u2581https", "://", "t", ".", "co", "/", "h", "0", "f", "A", "k", "3", "m", "K", "w", "G", "\u2581#", "\u2581weather", "\u2581#", "\u2581news", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1041", "sentence": ["\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581I", "\u2581", "\u2019", "\u2581", "d", "\u2581love", "\u2581to", "\u2581relax", "\u2581but", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581just", "\u2581not", "\u2581realistic", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581I", "\u2581", "\u2019", "\u2581", "d", "\u2581love", "\u2581to", "\u2581relax", "\u2581but", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581just", "\u2581not", "\u2581realistic", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "<m>", "\u2581mar", "I", "boro", "s", "</m>", "</m>", ":", "\u2581I", "\u2581", "\u2019", "\u2581", "d", "\u2581love", "\u2581to", "\u2581relax", "\u2581but", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581just", "\u2581not", "\u2581realistic", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1042", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Ka", "a", "a", "at", "i", "e", "\u25814", ":", "\u2581I", "\u2581just", "\u2581need", "\u2581", "a", "\u2581really", "\u2581close", "\u2581friend", "\u2581that", "\u2581has", "\u2581", "a", "\u2581baby", "\u2581so", "\u2581I", "\u2581can", "\u2581have", "\u2581one", "\u2581but", "\u2581not", "\u2581actually", "\u2581have", "\u2581one", ",", "\u2581", "y", "a", "\u2581know", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Ka", "a", "a", "at", "i", "e", "\u25814", ":", "\u2581I", "\u2581just", "\u2581need", "\u2581", "a", "\u2581really", "\u2581close", "\u2581friend", "\u2581that", "\u2581has", "\u2581", "a", "\u2581baby", "\u2581so", "\u2581I", "\u2581can", "\u2581have", "\u2581one", "\u2581but", "\u2581not", "\u2581actually", "\u2581have", "\u2581one", ",", "\u2581", "y", "a", "\u2581know", "?", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Ka", "a", "a", "at", "i", "e", "\u25814", ":", "\u2581I", "\u2581just", "\u2581need", "\u2581", "a", "\u2581really", "\u2581close", "\u2581friend", "\u2581that", "\u2581has", "\u2581", "a", "\u2581baby", "\u2581so", "\u2581I", "\u2581can", "\u2581have", "\u2581one", "\u2581but", "\u2581not", "\u2581actually", "\u2581have", "\u2581one", ",", "\u2581", "y", "a", "\u2581know", "?", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 27, 28, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1043", "sentence": ["\u2581Now", "\u2581playing", "\u2581Money", "\u2581A", "in", "'", "\u2581", "t", "\u2581A", "\u2581Problem", "\u2581Fe", "at", ".", "\u2581French", "\u2581Montana", "\u2581by", "\u2581Di", "ddy", "!", "\u2581Click", "\u2581link", "\u2581below", "\u2581https", "://", "t", ".", "co", "/", "M", "IU", "c", "pp", "R", "9", "OU", "\u2581https", "://", "t", ".", "co", "/", "Hu", "Y", "k", "s", "B", "a", "H", "k", "b", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Now", "\u2581playing", "\u2581Money", "\u2581A", "in", "'", "\u2581", "t", "\u2581A", "\u2581Problem", "\u2581Fe", "at", ".", "\u2581French", "\u2581Montana", "\u2581by", "\u2581Di", "ddy", "!", "\u2581Click", "\u2581link", "\u2581below", "\u2581https", "://", "t", ".", "co", "/", "M", "IU", "c", "pp", "R", "9", "OU", "\u2581https", "://", "t", ".", "co", "/", "Hu", "Y", "k", "s", "B", "a", "H", "k", "b", "</s>"], "target_sentence": ["\u2581Now", "\u2581playing", "<m>", "\u2581Money", "\u2581A", "in", "'", "\u2581", "t", "\u2581A", "\u2581Problem", "</m>", "\u2581Fe", "at", ".", "<m>", "\u2581French", "\u2581Montana", "</m>", "\u2581by", "<m>", "\u2581Di", "ddy", "</m>", "!", "\u2581Click", "\u2581link", "\u2581below", "\u2581https", "://", "t", ".", "co", "/", "M", "IU", "c", "pp", "R", "9", "OU", "\u2581https", "://", "t", ".", "co", "/", "Hu", "Y", "k", "s", "B", "a", "H", "k", "b", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, 1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1044", "sentence": ["\u2581", "RT", "\u2581@", "\u25812000", "\u2581", "s", "H", "its", ":", "\u258150", "\u2581Cent", "\u2581", "-", "\u258121", "\u2581Questions", "\u2581", "f", "t", ".", "\u2581Nat", "e", "\u2581Dog", "g", "\u2581https", "://", "t", ".", "co", "/", "v", "l", "Z", "i", "y", "v", "W", "U", "x", "G", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u25812000", "\u2581", "s", "H", "its", ":", "\u258150", "\u2581Cent", "\u2581", "-", "\u258121", "\u2581Questions", "\u2581", "f", "t", ".", "\u2581Nat", "e", "\u2581Dog", "g", "\u2581https", "://", "t", ".", "co", "/", "v", "l", "Z", "i", "y", "v", "W", "U", "x", "G", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u25812000", "\u2581", "s", "H", "its", ":", "<m>", "\u258150", "\u2581Cent", "</m>", "\u2581", "-", "\u258121", "\u2581Questions", "\u2581", "f", "t", ".", "<m>", "\u2581Nat", "e", "\u2581Dog", "g", "</m>", "\u2581https", "://", "t", ".", "co", "/", "v", "l", "Z", "i", "y", "v", "W", "U", "x", "G", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 10, 11, 12, 12, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1045", "sentence": ["\u2581@", "\u2581MI", "r", "and", "a", "Bru", "\u2581", "_", "\u2581https", "://", "t", ".", "co", "/", "NN", "b", "b", "NE", "8", "Y", "5", "E", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581MI", "r", "and", "a", "Bru", "\u2581", "_", "\u2581https", "://", "t", ".", "co", "/", "NN", "b", "b", "NE", "8", "Y", "5", "E", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581MI", "r", "and", "a", "Bru", "</m>", "\u2581", "_", "\u2581https", "://", "t", ".", "co", "/", "NN", "b", "b", "NE", "8", "Y", "5", "E", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1046", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Col", "i", "Du", "h", "h", ":", "\u2581It", "'", "\u2581", "s", "\u2581been", "\u2581too", "\u2581long", "\u2581", "\ud83d\ude14", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581https", "://", "t", ".", "co", "/", "P", "r", "F", "VE", "F", "l", "r", "12", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Col", "i", "Du", "h", "h", ":", "\u2581It", "'", "\u2581", "s", "\u2581been", "\u2581too", "\u2581long", "\u2581", "\ud83d\ude14", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581https", "://", "t", ".", "co", "/", "P", "r", "F", "VE", "F", "l", "r", "12", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Col", "i", "Du", "h", "h", ":", "\u2581It", "'", "\u2581", "s", "\u2581been", "\u2581too", "\u2581long", "\u2581", "\ud83d\ude14", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581#", "\u2581Ky", "S", "tate", "\u2581", "_", "\u2581", "RY", "S", "\u258117", "\u2581https", "://", "t", ".", "co", "/", "P", "r", "F", "VE", "F", "l", "r", "12", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 11, 12, 12, 12, 13, 13, 14, 14, 14, 15, 16, 17, 17, 17, 18, 18, 19, 19, 19, 20, 21, 22, 22, 22, 23, 23, 24, 24, 24, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1047", "sentence": ["\u2581#", "\u2581naked", "\u2581", "lind", "say", "\u2581", "s", "ex", "\u2581brutal", "\u2581in", "\u2581school", "\u2581girl", "\u2581https", "://", "t", ".", "co", "/", "m", "PP", "IM", "f", "6", "DS", "5", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581naked", "\u2581", "lind", "say", "\u2581", "s", "ex", "\u2581brutal", "\u2581in", "\u2581school", "\u2581girl", "\u2581https", "://", "t", ".", "co", "/", "m", "PP", "IM", "f", "6", "DS", "5", "</s>"], "target_sentence": ["\u2581#", "\u2581naked", "<m>", "\u2581", "lind", "say", "</m>", "\u2581", "s", "ex", "\u2581brutal", "\u2581in", "\u2581school", "\u2581girl", "\u2581https", "://", "t", ".", "co", "/", "m", "PP", "IM", "f", "6", "DS", "5", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 3, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1048", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ffy", "vi", "be", "s", ":", "\u2581", "a", "\u2581heart", "\u2581that", "'", "\u2581", "s", "\u2581broke", "\u2581is", "\u2581heart", "\u2581that", "'", "\u2581", "s", "\u2581been", "\u2581loved", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "ffy", "vi", "be", "s", ":", "\u2581", "a", "\u2581heart", "\u2581that", "'", "\u2581", "s", "\u2581broke", "\u2581is", "\u2581heart", "\u2581that", "'", "\u2581", "s", "\u2581been", "\u2581loved", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ffy", "vi", "be", "s", ":", "\u2581", "a", "\u2581heart", "\u2581that", "'", "\u2581", "s", "\u2581broke", "\u2581is", "\u2581heart", "\u2581that", "'", "\u2581", "s", "\u2581been", "\u2581loved", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1049", "sentence": ["\u2581Hey", "\u2581", "LO", "OK", "\u2581the", "\u2581weekend", "\u2581is", "\u2581here", "!", "\u2581https", "://", "t", ".", "co", "/", "L", "X", "N", "l", "Q", "p", "31", "h", "O", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Hey", "\u2581", "LO", "OK", "\u2581the", "\u2581weekend", "\u2581is", "\u2581here", "!", "\u2581https", "://", "t", ".", "co", "/", "L", "X", "N", "l", "Q", "p", "31", "h", "O", "</s>"], "target_sentence": ["\u2581Hey", "\u2581", "LO", "OK", "\u2581the", "\u2581weekend", "\u2581is", "\u2581here", "!", "\u2581https", "://", "t", ".", "co", "/", "L", "X", "N", "l", "Q", "p", "31", "h", "O", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1050", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "s", "s", "la", "h", "\u25817", "71", ":", "\u2581She", "'", "\u2581", "s", "\u2581Beautiful", "!", "\u2581(", "\u25818", "42", ")", "\u2581#", "\u2581S", "wall", "a", "Video", "\u2581https", "://", "t", ".", "co", "/", "gg", "b", "S", "2", "k", "ID", "p", "A", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "s", "s", "la", "h", "\u25817", "71", ":", "\u2581She", "'", "\u2581", "s", "\u2581Beautiful", "!", "\u2581(", "\u25818", "42", ")", "\u2581#", "\u2581S", "wall", "a", "Video", "\u2581https", "://", "t", ".", "co", "/", "gg", "b", "S", "2", "k", "ID", "p", "A", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "s", "s", "la", "h", "\u25817", "71", ":", "\u2581She", "'", "\u2581", "s", "\u2581Beautiful", "!", "\u2581(", "\u25818", "42", ")", "\u2581#", "\u2581S", "wall", "a", "Video", "\u2581https", "://", "t", ".", "co", "/", "gg", "b", "S", "2", "k", "ID", "p", "A", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1051", "sentence": ["\u2581", "brook", "e", "\u2581from", "\u2581candy", "\u2581girls", "\u2581nu", "de", "\u2581https", "://", "t", ".", "co", "/", "r", "MP", "2", "D", "X", "SL", "n", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "brook", "e", "\u2581from", "\u2581candy", "\u2581girls", "\u2581nu", "de", "\u2581https", "://", "t", ".", "co", "/", "r", "MP", "2", "D", "X", "SL", "n", "M", "</s>"], "target_sentence": ["<m>", "\u2581", "brook", "e", "</m>", "\u2581from", "<m>", "\u2581candy", "\u2581girls", "</m>", "\u2581nu", "de", "\u2581https", "://", "t", ".", "co", "/", "r", "MP", "2", "D", "X", "SL", "n", "M", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1052", "sentence": ["\u2581@", "\u2581coffee", "\u2581", "_", "\u2581bean", "\u25812016", "\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581have", "\u2581Bell", "ar", "mine", "\u2581money", "\u2581", "l", "m", "a", "o", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581coffee", "\u2581", "_", "\u2581bean", "\u25812016", "\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581have", "\u2581Bell", "ar", "mine", "\u2581money", "\u2581", "l", "m", "a", "o", "</s>"], "target_sentence": ["\u2581@", "\u2581coffee", "\u2581", "_", "\u2581bean", "\u25812016", "\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581have", "<m>", "\u2581Bell", "ar", "mine", "</m>", "\u2581money", "\u2581", "l", "m", "a", "o", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 10, 11, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1053", "sentence": ["\u2581You", "\u2581are", "\u2581not", "\u2581alone", ".", "\u2581https", "://", "t", ".", "co", "/", "g", "a", "NO", "3", "v", "U", "4", "I", "m", "\u2581#", "\u2581food", "related", "issue", "s", "e", "ating", "d", "is", "order", "s", "\u2581#", "\u2581general", "re", "cover", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581You", "\u2581are", "\u2581not", "\u2581alone", ".", "\u2581https", "://", "t", ".", "co", "/", "g", "a", "NO", "3", "v", "U", "4", "I", "m", "\u2581#", "\u2581food", "related", "issue", "s", "e", "ating", "d", "is", "order", "s", "\u2581#", "\u2581general", "re", "cover", "y", "</s>"], "target_sentence": ["\u2581You", "\u2581are", "\u2581not", "\u2581alone", ".", "\u2581https", "://", "t", ".", "co", "/", "g", "a", "NO", "3", "v", "U", "4", "I", "m", "\u2581#", "\u2581food", "related", "issue", "s", "e", "ating", "d", "is", "order", "s", "\u2581#", "\u2581general", "re", "cover", "y", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1054", "sentence": ["\u2581How", "'", "\u2581Up", "\u2581and", "\u2581Van", "ished", "'", "\u2581Podcast", "\u2581Help", "e", "d", "\u2581Sol", "ve", "\u2581Cold", "\u2581Mur", "der", "\u2581Case", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "P", "z", "Z", "PT", "Go", "G", "y", "4", "\u2581https", "://", "t", ".", "co", "/4", "WG", "x", "0", "t", "8", "y", "L", "q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "'", "\u2581Up", "\u2581and", "\u2581Van", "ished", "'", "\u2581Podcast", "\u2581Help", "e", "d", "\u2581Sol", "ve", "\u2581Cold", "\u2581Mur", "der", "\u2581Case", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "P", "z", "Z", "PT", "Go", "G", "y", "4", "\u2581https", "://", "t", ".", "co", "/4", "WG", "x", "0", "t", "8", "y", "L", "q", "</s>"], "target_sentence": ["\u2581How", "'", "<m>", "\u2581Up", "\u2581and", "\u2581Van", "ished", "</m>", "'", "\u2581Podcast", "\u2581Help", "e", "d", "\u2581Sol", "ve", "\u2581Cold", "\u2581Mur", "der", "\u2581Case", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "P", "z", "Z", "PT", "Go", "G", "y", "4", "\u2581https", "://", "t", ".", "co", "/4", "WG", "x", "0", "t", "8", "y", "L", "q", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 7, 7, 8, 8, 9, 10, 10, 11, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1055", "sentence": ["\u2581Auto", "\u2581DJ", "\u2581Show", "\u2581is", "\u2581starting", "\u2581now", "!", "\u2581Listen", "\u2581live", "\u2581here", ":", "\u2581https", "://", "t", ".", "co", "/", "q", "BE", "5", "T", "6", "al", "q", "l", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Auto", "\u2581DJ", "\u2581Show", "\u2581is", "\u2581starting", "\u2581now", "!", "\u2581Listen", "\u2581live", "\u2581here", ":", "\u2581https", "://", "t", ".", "co", "/", "q", "BE", "5", "T", "6", "al", "q", "l", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Auto", "\u2581DJ", "\u2581Show", "</m>", "</m>", "\u2581is", "\u2581starting", "\u2581now", "!", "\u2581Listen", "\u2581live", "\u2581here", ":", "\u2581https", "://", "t", ".", "co", "/", "q", "BE", "5", "T", "6", "al", "q", "l", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1056", "sentence": ["\u2581Jack", "\u2581Gil", "in", "sky", ",", "\u2581you", "\u2581mean", "\u2581the", "\u2581world", "\u2581to", "\u2581me", "\u2581thanks", "\u2581for", "\u2581everything", ",", "\u2581", "i", "\u2581love", "\u2581you", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Jack", "\u2581Gil", "in", "sky", ",", "\u2581you", "\u2581mean", "\u2581the", "\u2581world", "\u2581to", "\u2581me", "\u2581thanks", "\u2581for", "\u2581everything", ",", "\u2581", "i", "\u2581love", "\u2581you", ".", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Jack", "\u2581Gil", "in", "sky", "</m>", "</m>", ",", "\u2581you", "\u2581mean", "\u2581the", "\u2581world", "\u2581to", "\u2581me", "\u2581thanks", "\u2581for", "\u2581everything", ",", "\u2581", "i", "\u2581love", "\u2581you", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [1, 0, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1057", "sentence": ["\u25813", ":", "\u2581", "00", "\u2581AM", "\u2581https", "://", "t", ".", "co", "/", "A", "h", "K", "w", "va", "G", "0", "j", "T", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u25813", ":", "\u2581", "00", "\u2581AM", "\u2581https", "://", "t", ".", "co", "/", "A", "h", "K", "w", "va", "G", "0", "j", "T", "</s>"], "target_sentence": ["\u25813", ":", "\u2581", "00", "\u2581AM", "\u2581https", "://", "t", ".", "co", "/", "A", "h", "K", "w", "va", "G", "0", "j", "T", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1058", "sentence": ["\u2581", "RT", "\u2581@", "\u2581BC", "raft", "S", "to", "rage", ":", "\u2581Cast", "\u2581and", "\u2581Director", "\u2581of", "\u2581Moon", "light", "\u2581", "&", "\u2581amp", ";", "\u2581Magnolia", "s", "\u2581at", "\u2581the", "\u2581Fly", "\u2581Community", "\u2581Theater", "\u2581Friday", "\u2581and", "\u2581Saturday", "\u2581night", "\u25817", "\u2581pm", "\u2581and", ".", ".", ".", "\u2581https", "://", "t", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581BC", "raft", "S", "to", "rage", ":", "\u2581Cast", "\u2581and", "\u2581Director", "\u2581of", "\u2581Moon", "light", "\u2581", "&", "\u2581amp", ";", "\u2581Magnolia", "s", "\u2581at", "\u2581the", "\u2581Fly", "\u2581Community", "\u2581Theater", "\u2581Friday", "\u2581and", "\u2581Saturday", "\u2581night", "\u25817", "\u2581pm", "\u2581and", ".", ".", ".", "\u2581https", "://", "t", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581BC", "raft", "S", "to", "rage", ":", "\u2581Cast", "\u2581and", "\u2581Director", "\u2581of", "<m>", "\u2581Moon", "light", "\u2581", "&", "\u2581amp", ";", "\u2581Magnolia", "s", "</m>", "\u2581at", "\u2581the", "<m>", "\u2581Fly", "\u2581Community", "\u2581Theater", "</m>", "\u2581Friday", "\u2581and", "\u2581Saturday", "\u2581night", "\u25817", "\u2581pm", "\u2581and", ".", ".", ".", "\u2581https", "://", "t", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 28, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1059", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "t", "t", "uck", "\u2581", "_", "\u25815", ":", "\u2581Love", "\u2581the", "\u2581game", "\u2581like", "\u2581Mit", "ch", "\u2581", "\ud83d\udcb0", "\u2581https", "://", "t", ".", "co", "/3", "c", "we", "q", "w", "3", "y", "f", "V", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "t", "t", "uck", "\u2581", "_", "\u25815", ":", "\u2581Love", "\u2581the", "\u2581game", "\u2581like", "\u2581Mit", "ch", "\u2581", "\ud83d\udcb0", "\u2581https", "://", "t", ".", "co", "/3", "c", "we", "q", "w", "3", "y", "f", "V", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "t", "t", "uck", "\u2581", "_", "\u25815", "</m>", ":", "\u2581Love", "\u2581the", "\u2581game", "\u2581like", "<m>", "\u2581Mit", "ch", "</m>", "\u2581", "\ud83d\udcb0", "\u2581https", "://", "t", ".", "co", "/3", "c", "we", "q", "w", "3", "y", "f", "V", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1060", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Kon", "n", "an", "\u25815", "150", ":", "\u2581Just", "\u2581dropped", "\u2581two", "\u2581new", "\u2581videos", "\u2581for", "\u2581https", "://", "t", ".", "co", "/", "u", "y", "JS", "zog", "8", "K", "t", "\u2581members", "\u2581and", "\u2581later", "\u2581tonight", "\u2581", "a", "\u2581new", "\u258190", "\u2581minute", "\u2581+", "\u2581Keep", "in", "\u2581it", "\u2581100", "\u2581+", "\u2581", "e", "p", "\u2581for", "\u2581$", "\u25813", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Kon", "n", "an", "\u25815", "150", ":", "\u2581Just", "\u2581dropped", "\u2581two", "\u2581new", "\u2581videos", "\u2581for", "\u2581https", "://", "t", ".", "co", "/", "u", "y", "JS", "zog", "8", "K", "t", "\u2581members", "\u2581and", "\u2581later", "\u2581tonight", "\u2581", "a", "\u2581new", "\u258190", "\u2581minute", "\u2581+", "\u2581Keep", "in", "\u2581it", "\u2581100", "\u2581+", "\u2581", "e", "p", "\u2581for", "\u2581$", "\u25813", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Kon", "n", "an", "\u25815", "150", "</m>", ":", "\u2581Just", "\u2581dropped", "\u2581two", "\u2581new", "\u2581videos", "\u2581for", "\u2581https", "://", "t", ".", "co", "/", "u", "y", "JS", "zog", "8", "K", "t", "\u2581members", "\u2581and", "\u2581later", "\u2581tonight", "\u2581", "a", "\u2581new", "\u258190", "\u2581minute", "\u2581+", "\u2581Keep", "in", "\u2581it", "\u2581100", "\u2581+", "\u2581", "e", "p", "\u2581for", "\u2581$", "\u25813", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 25, 25, 26, 27, 28, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1061", "sentence": ["\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581know", "\u2581how", "\u2581it", "\u2581will", "\u2581look", "\u2581like", "\u2581", "if", "\u2581Leicester", "\u2581wins", "\u2581the", "\u2581champion", "s", "\u2581league", "\u2581and", "\u2581man", "\u2581", "u", "\u2581wins", "\u2581Europa", "\u2581league", "!", "!", "!", "!", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581know", "\u2581how", "\u2581it", "\u2581will", "\u2581look", "\u2581like", "\u2581", "if", "\u2581Leicester", "\u2581wins", "\u2581the", "\u2581champion", "s", "\u2581league", "\u2581and", "\u2581man", "\u2581", "u", "\u2581wins", "\u2581Europa", "\u2581league", "!", "!", "!", "!", "!", "</s>"], "target_sentence": ["\u2581I", "\u2581don", "'", "\u2581", "t", "\u2581know", "\u2581how", "\u2581it", "\u2581will", "\u2581look", "\u2581like", "\u2581", "if", "<m>", "<m>", "\u2581Leicester", "</m>", "</m>", "\u2581wins", "\u2581the", "\u2581champion", "s", "\u2581league", "\u2581and", "\u2581man", "\u2581", "u", "\u2581wins", "<m>", "\u2581Europa", "</m>", "\u2581league", "!", "!", "!", "!", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1062", "sentence": ["\u2581how", "\u2581come", "\u2581im", "\u2581just", "\u2581now", "\u2581see", "\u2581this", "\u2581", "th", "o", "\u2581", "\ud83d\udc40", "\u2581anyway", "s", "\u2581you", "\u2581look", "\u2581good", "\u2581ma", ",", "\u2581love", "\u2581the", "\u2581hair", "!", "\u2581https", "://", "t", ".", "co", "/", "b", "N", "c", "I", "3", "T", "g", "Q", "n", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581how", "\u2581come", "\u2581im", "\u2581just", "\u2581now", "\u2581see", "\u2581this", "\u2581", "th", "o", "\u2581", "\ud83d\udc40", "\u2581anyway", "s", "\u2581you", "\u2581look", "\u2581good", "\u2581ma", ",", "\u2581love", "\u2581the", "\u2581hair", "!", "\u2581https", "://", "t", ".", "co", "/", "b", "N", "c", "I", "3", "T", "g", "Q", "n", "w", "</s>"], "target_sentence": ["\u2581how", "\u2581come", "\u2581im", "\u2581just", "\u2581now", "\u2581see", "\u2581this", "\u2581", "th", "o", "\u2581", "\ud83d\udc40", "\u2581anyway", "s", "\u2581you", "\u2581look", "\u2581good", "\u2581ma", ",", "\u2581love", "\u2581the", "\u2581hair", "!", "\u2581https", "://", "t", ".", "co", "/", "b", "N", "c", "I", "3", "T", "g", "Q", "n", "w", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1063", "sentence": ["\u2581", "\ud83d\udd34", "\u2581L", "IVE", "\u2581on", "\u2581@", "\u2581You", "Now", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "e", "8", "G", "85", "h", "s", "I", "a", "g", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "\ud83d\udd34", "\u2581L", "IVE", "\u2581on", "\u2581@", "\u2581You", "Now", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "e", "8", "G", "85", "h", "s", "I", "a", "g", "</s>"], "target_sentence": ["\u2581", "\ud83d\udd34", "\u2581L", "IVE", "\u2581on", "\u2581@", "\u2581You", "Now", "\u2581", "-", "\u2581https", "://", "t", ".", "co", "/", "e", "8", "G", "85", "h", "s", "I", "a", "g", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 4, 4, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1064", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "k", "20", "j", "1", "B", "KW", "96", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "k", "20", "j", "1", "B", "KW", "96", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "k", "20", "j", "1", "B", "KW", "96", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1065", "sentence": ["\u2581The", "\u2581power", "\u2581of", "\u2581planning", "\u2581can", "\u2581be", "\u2581", "a", "\u2581blessing", "\u2581or", "\u2581", "a", "\u2581curse", "\u2581depending", "\u2581", "o", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Libra", "\u2581https", "://", "t", ".", "co", "/", "q", "BO", "9", "b", "R", "p", "t", "d", "Z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581power", "\u2581of", "\u2581planning", "\u2581can", "\u2581be", "\u2581", "a", "\u2581blessing", "\u2581or", "\u2581", "a", "\u2581curse", "\u2581depending", "\u2581", "o", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Libra", "\u2581https", "://", "t", ".", "co", "/", "q", "BO", "9", "b", "R", "p", "t", "d", "Z", "</s>"], "target_sentence": ["\u2581The", "\u2581power", "\u2581of", "\u2581planning", "\u2581can", "\u2581be", "\u2581", "a", "\u2581blessing", "\u2581or", "\u2581", "a", "\u2581curse", "\u2581depending", "\u2581", "o", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Libra", "\u2581https", "://", "t", ".", "co", "/", "q", "BO", "9", "b", "R", "p", "t", "d", "Z", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1066", "sentence": ["\u2581Not", "\u2581feeling", "\u2581Trial", "s", "\u2581tonight", "\u2581so", "\u2581I", "'", "\u2581", "ll", "\u2581more", "\u2581likely", "\u2581stream", "\u2581some", "\u2581H", "\u25811", "\u2581Z", "\u25811", "\u2581and", "\u2581Late", "\u2581Night", "\u2581Battle", "field", "\u25811", "\u2581with", "\u2581the", "\u2581", "hom", "ies", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Not", "\u2581feeling", "\u2581Trial", "s", "\u2581tonight", "\u2581so", "\u2581I", "'", "\u2581", "ll", "\u2581more", "\u2581likely", "\u2581stream", "\u2581some", "\u2581H", "\u25811", "\u2581Z", "\u25811", "\u2581and", "\u2581Late", "\u2581Night", "\u2581Battle", "field", "\u25811", "\u2581with", "\u2581the", "\u2581", "hom", "ies", "</s>"], "target_sentence": ["\u2581Not", "\u2581feeling", "\u2581Trial", "s", "\u2581tonight", "\u2581so", "\u2581I", "'", "\u2581", "ll", "\u2581more", "\u2581likely", "\u2581stream", "\u2581some", "<m>", "\u2581H", "\u25811", "\u2581Z", "\u25811", "</m>", "\u2581and", "\u2581Late", "\u2581Night", "<m>", "\u2581Battle", "field", "\u25811", "</m>", "\u2581with", "\u2581the", "\u2581", "hom", "ies", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 23, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1067", "sentence": ["\u2581and", "\u2581", "y", "'", "\u2581all", "\u2581were", "\u2581saying", "\u2581", "he", "\u2581didn", "'", "\u2581", "t", "\u2581care", "\u2581about", "\u2581iar", "my", "s", "\u2581", "\ud83d\ude24", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581and", "\u2581", "y", "'", "\u2581all", "\u2581were", "\u2581saying", "\u2581", "he", "\u2581didn", "'", "\u2581", "t", "\u2581care", "\u2581about", "\u2581iar", "my", "s", "\u2581", "\ud83d\ude24", "</s>"], "target_sentence": ["\u2581and", "\u2581", "y", "'", "\u2581all", "\u2581were", "\u2581saying", "\u2581", "he", "\u2581didn", "'", "\u2581", "t", "\u2581care", "\u2581about", "<m>", "\u2581iar", "my", "s", "</m>", "\u2581", "\ud83d\ude24", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 9, 10, 11, 12, 12, 12, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_1068", "sentence": ["\u2581and", "re", "w", "\u2581", "m", "cca", "be", "\u2581", "f", "uck", "\u2581fly", "n", "n", "\u2581then", "\u2581we", "\u2581", "f", "uck", "\u2581", "tru", "mp", "\u2581", "-", "\u2581Google", "\u2581Search", "\u2581@", "\u2581Stefan", "M", "o", "ly", "n", "eux", "\u2581@", "\u2581real", "Don", "al", "d", "Tru", "mp", "\u2581@", "\u2581Donald", "J", "Tru", "mp", "J", "r", "\u2581https", "://", "t", ".", "co", "/", "X", "GO", "EP", "s", "F", "0", "KB", ":", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581and", "re", "w", "\u2581", "m", "cca", "be", "\u2581", "f", "uck", "\u2581fly", "n", "n", "\u2581then", "\u2581we", "\u2581", "f", "uck", "\u2581", "tru", "mp", "\u2581", "-", "\u2581Google", "\u2581Search", "\u2581@", "\u2581Stefan", "M", "o", "ly", "n", "eux", "\u2581@", "\u2581real", "Don", "al", "d", "Tru", "mp", "\u2581@", "\u2581Donald", "J", "Tru", "mp", "J", "r", "\u2581https", "://", "t", ".", "co", "/", "X", "GO", "EP", "s", "F", "0", "KB", ":", "</s>"], "target_sentence": ["<m>", "\u2581and", "re", "w", "\u2581", "m", "cca", "be", "</m>", "\u2581", "f", "uck", "<m>", "\u2581fly", "n", "n", "</m>", "\u2581then", "\u2581we", "\u2581", "f", "uck", "<m>", "\u2581", "tru", "mp", "</m>", "\u2581", "-", "<m>", "\u2581Google", "</m>", "\u2581Search", "\u2581@", "<m>", "\u2581Stefan", "M", "o", "ly", "n", "eux", "</m>", "\u2581@", "<m>", "\u2581real", "Don", "al", "d", "Tru", "mp", "</m>", "\u2581@", "<m>", "\u2581Donald", "J", "Tru", "mp", "J", "r", "</m>", "\u2581https", "://", "t", ".", "co", "/", "X", "GO", "EP", "s", "F", "0", "KB", ":", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 7, 7, 8, 8, 9, 10, 11, 12, 12, 12, 12, 12, 12, 13, 14, 14, 14, 14, 14, 14, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, 3, -1, 3, -1, -1, 4, -1, -1, -1, -1, -1, -1, 4, -1, 5, -1, -1, -1, -1, -1, -1, 5, -1, 6, -1, -1, -1, -1, -1, -1, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1069", "sentence": ["\u2581", "RT", "\u2581@", "\u2581W", "ORI", "D", "STAR", "H", "l", "PH", "OP", ":", "\u2581me", "\u2581trying", "\u2581to", "\u2581get", "\u2581my", "\u2581life", "\u2581together", "\u2581https", "://", "t", ".", "co", "/", "T", "a", "s", "e", "5", "I", "e", "h", "RO", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581W", "ORI", "D", "STAR", "H", "l", "PH", "OP", ":", "\u2581me", "\u2581trying", "\u2581to", "\u2581get", "\u2581my", "\u2581life", "\u2581together", "\u2581https", "://", "t", ".", "co", "/", "T", "a", "s", "e", "5", "I", "e", "h", "RO", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581W", "ORI", "D", "STAR", "H", "l", "PH", "OP", ":", "\u2581me", "\u2581trying", "\u2581to", "\u2581get", "\u2581my", "\u2581life", "\u2581together", "\u2581https", "://", "t", ".", "co", "/", "T", "a", "s", "e", "5", "I", "e", "h", "RO", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1070", "sentence": ["\u2581I", "\u2581feel", "\u2581like", "\u2581Met", "s", "\u2581fans", "\u2581are", "\u2581the", "\u2581best", "\u2581with", "\u2581following", "\u2581their", "\u2581team", ",", "\u2581maybe", "\u2581im", "\u2581", "a", "\u2581", "l", "il", "\u2581bias", "\u2581", "th", "o", "\u2581lol", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581feel", "\u2581like", "\u2581Met", "s", "\u2581fans", "\u2581are", "\u2581the", "\u2581best", "\u2581with", "\u2581following", "\u2581their", "\u2581team", ",", "\u2581maybe", "\u2581im", "\u2581", "a", "\u2581", "l", "il", "\u2581bias", "\u2581", "th", "o", "\u2581lol", "</s>"], "target_sentence": ["\u2581I", "\u2581feel", "\u2581like", "<m>", "<m>", "<m>", "<m>", "\u2581Met", "s", "</m>", "</m>", "</m>", "</m>", "\u2581fans", "\u2581are", "\u2581the", "\u2581best", "\u2581with", "\u2581following", "\u2581their", "\u2581team", ",", "\u2581maybe", "\u2581im", "\u2581", "a", "\u2581", "l", "il", "\u2581bias", "\u2581", "th", "o", "\u2581lol", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 16, 16, 17, 18, 18, 18, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 3, 2, 1, 0, -1, -1, 3, 2, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1071", "sentence": ["\u2581", "RT", "\u2581@", "\u2581rate", "t", "ank", ":", "\u2581Anyone", "\u2581who", "\u2581would", "\u2581publicly", "\u2581celebrate", "\u2581someone", "\u2581else", "'", "\u2581", "s", "\u2581extreme", "\u2581invasion", "\u2581of", "\u2581privacy", "\u2581is", "\u2581someone", "\u2581who", "\u2581definitely", "\u2581has", "\u2581lost", "\u2581my", "\u2581respect", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581rate", "t", "ank", ":", "\u2581Anyone", "\u2581who", "\u2581would", "\u2581publicly", "\u2581celebrate", "\u2581someone", "\u2581else", "'", "\u2581", "s", "\u2581extreme", "\u2581invasion", "\u2581of", "\u2581privacy", "\u2581is", "\u2581someone", "\u2581who", "\u2581definitely", "\u2581has", "\u2581lost", "\u2581my", "\u2581respect", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581rate", "t", "ank", ":", "\u2581Anyone", "\u2581who", "\u2581would", "\u2581publicly", "\u2581celebrate", "\u2581someone", "\u2581else", "'", "\u2581", "s", "\u2581extreme", "\u2581invasion", "\u2581of", "\u2581privacy", "\u2581is", "\u2581someone", "\u2581who", "\u2581definitely", "\u2581has", "\u2581lost", "\u2581my", "\u2581respect", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1072", "sentence": ["\u2581Emil", "i", "a", "\u2581Clark", "e", "\u2581trying", "\u2581her", "\u2581best", "\u2581https", "://", "t", ".", "co", "/", "at", "3", "j", "P", "6", "p", "r", "A", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Emil", "i", "a", "\u2581Clark", "e", "\u2581trying", "\u2581her", "\u2581best", "\u2581https", "://", "t", ".", "co", "/", "at", "3", "j", "P", "6", "p", "r", "A", "z", "</s>"], "target_sentence": ["<m>", "\u2581Emil", "i", "a", "\u2581Clark", "e", "</m>", "\u2581trying", "\u2581her", "\u2581best", "\u2581https", "://", "t", ".", "co", "/", "at", "3", "j", "P", "6", "p", "r", "A", "z", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1073", "sentence": ["\u2581Development", "-", "ready", "\u2581land", "\u2581in", "\u2581town", ",", "\u2581", "surrounded", "\u2581by", "\u2581tall", "\u2581pine", "s", "\u2581", "-", "\u2581$", "\u2581", "129", ",", "\u2581000", "\u2581https", "://", "t", ".", "co", "/", "i", "r", "126", "r", "J", "r", "z", "O", "\u2581https", "://", "t", ".", "co", "/", "g", "X", "z", "f", "y", "v", "w", "i", "I", "c", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Development", "-", "ready", "\u2581land", "\u2581in", "\u2581town", ",", "\u2581", "surrounded", "\u2581by", "\u2581tall", "\u2581pine", "s", "\u2581", "-", "\u2581$", "\u2581", "129", ",", "\u2581000", "\u2581https", "://", "t", ".", "co", "/", "i", "r", "126", "r", "J", "r", "z", "O", "\u2581https", "://", "t", ".", "co", "/", "g", "X", "z", "f", "y", "v", "w", "i", "I", "c", "</s>"], "target_sentence": ["\u2581Development", "-", "ready", "\u2581land", "\u2581in", "\u2581town", ",", "\u2581", "surrounded", "\u2581by", "\u2581tall", "\u2581pine", "s", "\u2581", "-", "\u2581$", "\u2581", "129", ",", "\u2581000", "\u2581https", "://", "t", ".", "co", "/", "i", "r", "126", "r", "J", "r", "z", "O", "\u2581https", "://", "t", ".", "co", "/", "g", "X", "z", "f", "y", "v", "w", "i", "I", "c", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 9, 10, 11, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1074", "sentence": ["\u2581Building", "\u2581", "a", "\u2581Strategic", "\u2581Relation", "ship", "\u2581With", "\u2581Others", "\u2581is", "\u2581Hard", "\u2581Work", "\u2581https", "://", "t", ".", "co", "/", "P", "k", "7", "n", "p", "k", "Z", "5", "jo", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Building", "\u2581", "a", "\u2581Strategic", "\u2581Relation", "ship", "\u2581With", "\u2581Others", "\u2581is", "\u2581Hard", "\u2581Work", "\u2581https", "://", "t", ".", "co", "/", "P", "k", "7", "n", "p", "k", "Z", "5", "jo", "</s>"], "target_sentence": ["\u2581Building", "\u2581", "a", "<m>", "\u2581Strategic", "\u2581Relation", "ship", "</m>", "\u2581With", "\u2581Others", "\u2581is", "\u2581Hard", "\u2581Work", "\u2581https", "://", "t", ".", "co", "/", "P", "k", "7", "n", "p", "k", "Z", "5", "jo", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1075", "sentence": ["\u2581@", "\u2581micro", "grav", "ity", "lab", "\u2581I", "\u2581saw", "\u2581an", "\u2581actual", "\u2581child", "\u2581wearing", "\u2581", "a", "\u2581Fox", "y", "\u2581shirt", "\u2581during", "\u2581my", "\u2581last", "\u2581overnight", "\u2581shift", "\u2581I", "\u2581start", "led", "\u2581my", "\u2581co", "work", "er", "\u2581with", "\u2581how", "\u2581hard", "\u2581I", "\u2581laughed", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581micro", "grav", "ity", "lab", "\u2581I", "\u2581saw", "\u2581an", "\u2581actual", "\u2581child", "\u2581wearing", "\u2581", "a", "\u2581Fox", "y", "\u2581shirt", "\u2581during", "\u2581my", "\u2581last", "\u2581overnight", "\u2581shift", "\u2581I", "\u2581start", "led", "\u2581my", "\u2581co", "work", "er", "\u2581with", "\u2581how", "\u2581hard", "\u2581I", "\u2581laughed", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581micro", "grav", "ity", "lab", "</m>", "\u2581I", "\u2581saw", "\u2581an", "\u2581actual", "\u2581child", "\u2581wearing", "\u2581", "a", "<m>", "<m>", "<m>", "\u2581Fox", "y", "</m>", "</m>", "</m>", "\u2581shirt", "\u2581during", "\u2581my", "\u2581last", "\u2581overnight", "\u2581shift", "\u2581I", "\u2581start", "led", "\u2581my", "\u2581co", "work", "er", "\u2581with", "\u2581how", "\u2581hard", "\u2581I", "\u2581laughed", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 19, 19, 20, 21, 22, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 3, 1, 2, -1, -1, 3, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1076", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Up", "or", "n", "T", "u", "be", "\u25812", ":", "\u2581", "h", "d", "\u2581por", "n", "\u2581videos", "\u2581for", "\u2581the", "\u2581full", "\u2581clips", "\u2581visit", "\u2581our", "\u2581site", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581https", "://", "t", ".", "co", "/", "k", "j", "X", "X", "k", "mit", "t", "w", "\u2581https", "://", "t", ".", "co", "/", "S", "j", "9", "m", "g", "i", "p", "Z", "d", "j", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Up", "or", "n", "T", "u", "be", "\u25812", ":", "\u2581", "h", "d", "\u2581por", "n", "\u2581videos", "\u2581for", "\u2581the", "\u2581full", "\u2581clips", "\u2581visit", "\u2581our", "\u2581site", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581https", "://", "t", ".", "co", "/", "k", "j", "X", "X", "k", "mit", "t", "w", "\u2581https", "://", "t", ".", "co", "/", "S", "j", "9", "m", "g", "i", "p", "Z", "d", "j", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Up", "or", "n", "T", "u", "be", "\u25812", "</m>", ":", "\u2581", "h", "d", "\u2581por", "n", "\u2581videos", "\u2581for", "\u2581the", "\u2581full", "\u2581clips", "\u2581visit", "\u2581our", "\u2581site", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581", "&", "\u2581", "g", "t", ";", "\u2581https", "://", "t", ".", "co", "/", "k", "j", "X", "X", "k", "mit", "t", "w", "\u2581https", "://", "t", ".", "co", "/", "S", "j", "9", "m", "g", "i", "p", "Z", "d", "j", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 16, 16, 17, 18, 18, 19, 19, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1077", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "m", "d", "\u2581", "_", "\u2581add", "am", ":", "\u2581Typ", "ing", "'", "\u2581ha", "ha", "'", "\u2581when", "\u2581you", "\u2581can", "'", "\u2581", "t", "\u2581even", "\u2581smile", ".", "\u2581Act", "ing", "\u2581like", "\u2581you", "'", "\u2581", "re", "\u2581happy", "\u2581when", "\u2581all", "\u2581you", "\u2581want", "\u2581to", "\u2581do", "\u2581is", "\u2581cry", ".", "\u2581Tell", "\u2581everyone", "\u2581you", "'", "\u2581", "re", "\u2581okay", "\u2581", "w", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "m", "d", "\u2581", "_", "\u2581add", "am", ":", "\u2581Typ", "ing", "'", "\u2581ha", "ha", "'", "\u2581when", "\u2581you", "\u2581can", "'", "\u2581", "t", "\u2581even", "\u2581smile", ".", "\u2581Act", "ing", "\u2581like", "\u2581you", "'", "\u2581", "re", "\u2581happy", "\u2581when", "\u2581all", "\u2581you", "\u2581want", "\u2581to", "\u2581do", "\u2581is", "\u2581cry", ".", "\u2581Tell", "\u2581everyone", "\u2581you", "'", "\u2581", "re", "\u2581okay", "\u2581", "w", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "m", "d", "\u2581", "_", "<m>", "\u2581add", "am", "</m>", ":", "\u2581Typ", "ing", "'", "\u2581ha", "ha", "'", "\u2581when", "\u2581you", "\u2581can", "'", "\u2581", "t", "\u2581even", "\u2581smile", ".", "\u2581Act", "ing", "\u2581like", "\u2581you", "'", "\u2581", "re", "\u2581happy", "\u2581when", "\u2581all", "\u2581you", "\u2581want", "\u2581to", "\u2581do", "\u2581is", "\u2581cry", ".", "\u2581Tell", "\u2581everyone", "\u2581you", "'", "\u2581", "re", "\u2581okay", "\u2581", "w", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 37, 38, 39, 39, 40, 40, 41], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1078", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Fre", "ddy", "Am", "a", "zin", ":", "\u2581this", "\u2581is", "\u2581", "a", "\u2581no", "\u2581from", "\u2581me", ",", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581no", "\u2581amount", "\u2581of", "\u2581money", "\u2581in", "\u2581the", "\u2581world", "\u2581getting", "\u2581me", "\u2581on", "\u2581it", "\u2581either", "\u2581https", "://", "t", ".", "co", "/", "zi", "v", "8", "n", "A", "s", "1", "kk", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Fre", "ddy", "Am", "a", "zin", ":", "\u2581this", "\u2581is", "\u2581", "a", "\u2581no", "\u2581from", "\u2581me", ",", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581no", "\u2581amount", "\u2581of", "\u2581money", "\u2581in", "\u2581the", "\u2581world", "\u2581getting", "\u2581me", "\u2581on", "\u2581it", "\u2581either", "\u2581https", "://", "t", ".", "co", "/", "zi", "v", "8", "n", "A", "s", "1", "kk", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Fre", "ddy", "Am", "a", "zin", "</m>", ":", "\u2581this", "\u2581is", "\u2581", "a", "\u2581no", "\u2581from", "\u2581me", ",", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581no", "\u2581amount", "\u2581of", "\u2581money", "\u2581in", "\u2581the", "\u2581world", "\u2581getting", "\u2581me", "\u2581on", "\u2581it", "\u2581either", "\u2581https", "://", "t", ".", "co", "/", "zi", "v", "8", "n", "A", "s", "1", "kk", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1079", "sentence": ["\u2581@", "\u2581Scho", "f", "e", "\u2581@", "\u2581C", "\u25814", "\u2581Go", "g", "gle", "box", "\u2581would", "\u2581love", "\u2581", "if", "\u2581@", "\u2581I", "TV", "\u2581could", "\u2581arrange", "\u2581for", "\u2581you", "\u2581and", "\u2581@", "\u2581", "hol", "ly", "will", "s", "\u2581to", "\u2581film", "\u2581the", "\u2581W", "ha", "\u2581wh", "a", "\u2581tribe", ".", "\u2581I", "'", "\u2581", "d", "\u2581watch", "\u2581that", "\u2581so", "o", "o", "\u2581funny", "\u2581", "\ud83d\ude02", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Scho", "f", "e", "\u2581@", "\u2581C", "\u25814", "\u2581Go", "g", "gle", "box", "\u2581would", "\u2581love", "\u2581", "if", "\u2581@", "\u2581I", "TV", "\u2581could", "\u2581arrange", "\u2581for", "\u2581you", "\u2581and", "\u2581@", "\u2581", "hol", "ly", "will", "s", "\u2581to", "\u2581film", "\u2581the", "\u2581W", "ha", "\u2581wh", "a", "\u2581tribe", ".", "\u2581I", "'", "\u2581", "d", "\u2581watch", "\u2581that", "\u2581so", "o", "o", "\u2581funny", "\u2581", "\ud83d\ude02", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Scho", "f", "e", "</m>", "\u2581@", "\u2581C", "\u25814", "\u2581Go", "g", "gle", "box", "\u2581would", "\u2581love", "\u2581", "if", "\u2581@", "\u2581I", "TV", "\u2581could", "\u2581arrange", "\u2581for", "\u2581you", "\u2581and", "\u2581@", "\u2581", "hol", "ly", "will", "s", "\u2581to", "\u2581film", "\u2581the", "\u2581W", "ha", "\u2581wh", "a", "\u2581tribe", ".", "\u2581I", "'", "\u2581", "d", "\u2581watch", "\u2581that", "\u2581so", "o", "o", "\u2581funny", "\u2581", "\ud83d\ude02", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 5, 5, 5, 5, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 17, 17, 18, 19, 20, 21, 21, 22, 22, 23, 24, 25, 26, 27, 27, 28, 29, 30, 30, 30, 31, 32, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1080", "sentence": ["\u2581@", "\u2581Kam", "m", "Be", "\u2581that", "s", "\u2581no", "\u2581help", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Kam", "m", "Be", "\u2581that", "s", "\u2581no", "\u2581help", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Kam", "m", "Be", "</m>", "\u2581that", "s", "\u2581no", "\u2581help", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 2, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1081", "sentence": ["\u2581@", "\u2581Tony", "T", "Good", "man", "\u2581@", "\u2581Whole", "Food", "s", "\u2581@", "\u2581Nor", "a", "h", "R", "a", "b", "\u2581We", "\u2581just", "\u2581missed", "\u2581you", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Tony", "T", "Good", "man", "\u2581@", "\u2581Whole", "Food", "s", "\u2581@", "\u2581Nor", "a", "h", "R", "a", "b", "\u2581We", "\u2581just", "\u2581missed", "\u2581you", "!", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Tony", "T", "Good", "man", "</m>", "\u2581@", "<m>", "\u2581Whole", "Food", "s", "</m>", "\u2581@", "<m>", "\u2581Nor", "a", "h", "R", "a", "b", "</m>", "\u2581We", "\u2581just", "\u2581missed", "\u2581you", "!", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 3, 3, 4, 5, 5, 5, 5, 5, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, 1, -1, 2, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1082", "sentence": ["\u2581Tonight", "\u2581at", "\u258110", "\u2581on", "\u2581", "KO", "DE", "\u2581Action", "\u258112", "\u2581News", ".", "\u2581#", "\u2581", "k", "o", "de", "\u258112", "\u2581https", "://", "t", ".", "co", "/", "A", "d", "6", "r", "u", "I", "y", "r", "5", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Tonight", "\u2581at", "\u258110", "\u2581on", "\u2581", "KO", "DE", "\u2581Action", "\u258112", "\u2581News", ".", "\u2581#", "\u2581", "k", "o", "de", "\u258112", "\u2581https", "://", "t", ".", "co", "/", "A", "d", "6", "r", "u", "I", "y", "r", "5", "M", "</s>"], "target_sentence": ["\u2581Tonight", "\u2581at", "\u258110", "\u2581on", "<m>", "\u2581", "KO", "DE", "</m>", "\u2581Action", "\u258112", "\u2581News", ".", "\u2581#", "\u2581", "k", "o", "de", "\u258112", "\u2581https", "://", "t", ".", "co", "/", "A", "d", "6", "r", "u", "I", "y", "r", "5", "M", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1083", "sentence": ["\u2581Help", "\u2581to", "\u2581Stop", "\u2581Cru", "e", "l", "\u2581Treatment", "\u2581of", "\u2581Mon", "key", "s", "\u2581at", "\u2581Bio", "med", "ical", "\u2581Labor", "ator", "ies", "!", "\u2581Pl", "z", "\u2581sign", ":", "\u2581https", "://", "t", ".", "co", "/", "c", "55", "GE", "1", "e", "c", "f", "z", "\u2581https", "://", "t", ".", "co", "/", "d", "7", "T", "y", "B", "0", "b", "I", "b", "m", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Help", "\u2581to", "\u2581Stop", "\u2581Cru", "e", "l", "\u2581Treatment", "\u2581of", "\u2581Mon", "key", "s", "\u2581at", "\u2581Bio", "med", "ical", "\u2581Labor", "ator", "ies", "!", "\u2581Pl", "z", "\u2581sign", ":", "\u2581https", "://", "t", ".", "co", "/", "c", "55", "GE", "1", "e", "c", "f", "z", "\u2581https", "://", "t", ".", "co", "/", "d", "7", "T", "y", "B", "0", "b", "I", "b", "m", "</s>"], "target_sentence": ["\u2581Help", "\u2581to", "\u2581Stop", "\u2581Cru", "e", "l", "\u2581Treatment", "\u2581of", "\u2581Mon", "key", "s", "\u2581at", "\u2581Bio", "med", "ical", "\u2581Labor", "ator", "ies", "!", "\u2581Pl", "z", "\u2581sign", ":", "\u2581https", "://", "t", ".", "co", "/", "c", "55", "GE", "1", "e", "c", "f", "z", "\u2581https", "://", "t", ".", "co", "/", "d", "7", "T", "y", "B", "0", "b", "I", "b", "m", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 8, 8, 8, 9, 9, 9, 10, 11, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1084", "sentence": ["\u2581Ireland", "'", "\u2581", "s", "\u2581clinical", "\u2581trials", "\u2581capacity", "\u2581is", "\u2581", "advancing", ".", "\u2581We", "\u2581look", "\u2581at", "\u2581Ireland", "'", "\u2581", "s", "\u2581progress", "\u2581in", "\u2581this", "\u2581article", "\u2581https", "://", "t", ".", "co", "/", "Q", "ZA", "k", "A", "x", "LB", "1", "d", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ireland", "'", "\u2581", "s", "\u2581clinical", "\u2581trials", "\u2581capacity", "\u2581is", "\u2581", "advancing", ".", "\u2581We", "\u2581look", "\u2581at", "\u2581Ireland", "'", "\u2581", "s", "\u2581progress", "\u2581in", "\u2581this", "\u2581article", "\u2581https", "://", "t", ".", "co", "/", "Q", "ZA", "k", "A", "x", "LB", "1", "d", "</s>"], "target_sentence": ["<m>", "\u2581Ireland", "</m>", "'", "\u2581", "s", "\u2581clinical", "\u2581trials", "\u2581capacity", "\u2581is", "\u2581", "advancing", ".", "\u2581We", "\u2581look", "\u2581at", "<m>", "\u2581Ireland", "</m>", "'", "\u2581", "s", "\u2581progress", "\u2581in", "\u2581this", "\u2581article", "\u2581https", "://", "t", ".", "co", "/", "Q", "ZA", "k", "A", "x", "LB", "1", "d", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1085", "sentence": ["\u2581S", "UN", "NN", "NN", "NN", "NN", "NA", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581S", "UN", "NN", "NN", "NN", "NN", "NA", "</s>"], "target_sentence": ["<m>", "\u2581S", "UN", "NN", "NN", "NN", "NN", "NA", "</m>", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_1086", "sentence": ["\u2581#", "\u2581", "UC", "\u2581perfect", "\u25817", "\u2581", "-", "\u25817", "\u2581from", "\u2581the", "\u2581field", ".", "\u2581Would", "\u2581be", "\u25818", "\u2581", "if", "\u2581that", "\u2581Ca", "up", "a", "in", "\u25813", "\u2581count", "e", "d", ".", "\u2581@", "\u2581", "WC", "PO", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581", "UC", "\u2581perfect", "\u25817", "\u2581", "-", "\u25817", "\u2581from", "\u2581the", "\u2581field", ".", "\u2581Would", "\u2581be", "\u25818", "\u2581", "if", "\u2581that", "\u2581Ca", "up", "a", "in", "\u25813", "\u2581count", "e", "d", ".", "\u2581@", "\u2581", "WC", "PO", "</s>"], "target_sentence": ["\u2581#", "\u2581", "UC", "\u2581perfect", "\u25817", "\u2581", "-", "\u25817", "\u2581from", "\u2581the", "\u2581field", ".", "\u2581Would", "\u2581be", "\u25818", "\u2581", "if", "\u2581that", "\u2581Ca", "up", "a", "in", "\u25813", "\u2581count", "e", "d", ".", "\u2581@", "\u2581", "WC", "PO", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 15, 15, 15, 16, 17, 17, 17, 18, 19, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1087", "sentence": ["\u25812017", ",", "\u258103", ",", "\u258118", "\u258106", ":", "\u258130", ":", "\u2581", "05", "\u2581ja", "y", "\u2581", "d", "m", "b", "\u2581test", "\u25818", "\u2581", "-", "\u258111", "\u2581", "-", "\u25812016", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u25812017", ",", "\u258103", ",", "\u258118", "\u258106", ":", "\u258130", ":", "\u2581", "05", "\u2581ja", "y", "\u2581", "d", "m", "b", "\u2581test", "\u25818", "\u2581", "-", "\u258111", "\u2581", "-", "\u25812016", "</s>"], "target_sentence": ["\u25812017", ",", "\u258103", ",", "\u258118", "\u258106", ":", "\u258130", ":", "\u2581", "05", "\u2581ja", "y", "\u2581", "d", "m", "b", "\u2581test", "\u25818", "\u2581", "-", "\u258111", "\u2581", "-", "\u25812016", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 11, 11, 11, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1088", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "EL", "VI", "cloth", "ing", ":", "\u2581To", "\u2581celebrate", "\u2581the", "\u2581launch", "\u2581of", "\u2581our", "'", "\u2581", "Into", "\u2581the", "\u2581Wild", "'", "\u2581collection", "\u2581", "RT", "\u2581and", "\u2581Follow", "\u2581to", "\u2581#", "\u2581win", "\u2581our", "\u2581tropical", "\u2581print", "\u2581cu", "lotte", "s", "!", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "EL", "VI", "cloth", "ing", ":", "\u2581To", "\u2581celebrate", "\u2581the", "\u2581launch", "\u2581of", "\u2581our", "'", "\u2581", "Into", "\u2581the", "\u2581Wild", "'", "\u2581collection", "\u2581", "RT", "\u2581and", "\u2581Follow", "\u2581to", "\u2581#", "\u2581win", "\u2581our", "\u2581tropical", "\u2581print", "\u2581cu", "lotte", "s", "!", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "EL", "VI", "cloth", "ing", "</m>", ":", "\u2581To", "\u2581celebrate", "\u2581the", "\u2581launch", "\u2581of", "\u2581our", "<m>", "'", "\u2581", "Into", "\u2581the", "\u2581Wild", "'", "</m>", "\u2581collection", "<m>", "\u2581", "RT", "</m>", "\u2581and", "\u2581Follow", "\u2581to", "\u2581#", "\u2581win", "\u2581our", "\u2581tropical", "\u2581print", "\u2581cu", "lotte", "s", "!", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 25, 26, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1089", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Wor", "I", "d", "Star", "Laugh", ":", "\u2581https", "://", "t", ".", "co", "/", "f", "C", "q", "G", "q", "m", "E", "s", "v", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Wor", "I", "d", "Star", "Laugh", ":", "\u2581https", "://", "t", ".", "co", "/", "f", "C", "q", "G", "q", "m", "E", "s", "v", "z", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Wor", "I", "d", "Star", "Laugh", ":", "\u2581https", "://", "t", ".", "co", "/", "f", "C", "q", "G", "q", "m", "E", "s", "v", "z", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1090", "sentence": ["\u2581Race", "\u2581Re", "cap", ":", "\u2581Run", "\u2581@", "\u2581the", "\u2581Ridge", "\u25815", "\u2581K", "\u2581(", "\u25812012", ")", "\u2581", "-", "\u2581", "{", "\u2581from", "\u2581my", "\u2581blog", "\u2581archives", "}", "\u2581#", "\u2581healthy", "bal", "ance", "\u2581https", "://", "t", ".", "co", "/", "b", "j", "ZA", "s", "v", "c", "x", "c", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Race", "\u2581Re", "cap", ":", "\u2581Run", "\u2581@", "\u2581the", "\u2581Ridge", "\u25815", "\u2581K", "\u2581(", "\u25812012", ")", "\u2581", "-", "\u2581", "{", "\u2581from", "\u2581my", "\u2581blog", "\u2581archives", "}", "\u2581#", "\u2581healthy", "bal", "ance", "\u2581https", "://", "t", ".", "co", "/", "b", "j", "ZA", "s", "v", "c", "x", "c", "s", "</s>"], "target_sentence": ["<m>", "\u2581Race", "\u2581Re", "cap", "</m>", ":", "\u2581Run", "\u2581@", "\u2581the", "\u2581Ridge", "\u25815", "\u2581K", "\u2581(", "\u25812012", ")", "\u2581", "-", "\u2581", "{", "\u2581from", "\u2581my", "\u2581blog", "\u2581archives", "}", "\u2581#", "\u2581healthy", "bal", "ance", "\u2581https", "://", "t", ".", "co", "/", "b", "j", "ZA", "s", "v", "c", "x", "c", "s", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1091", "sentence": ["\u2581Wow", "\u2581", "m", "b", "n", "\u2581https", "://", "t", ".", "co", "/", "V", "Q", "t", "87", "V", "w", "z", "4", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Wow", "\u2581", "m", "b", "n", "\u2581https", "://", "t", ".", "co", "/", "V", "Q", "t", "87", "V", "w", "z", "4", "X", "</s>"], "target_sentence": ["\u2581Wow", "\u2581", "m", "b", "n", "\u2581https", "://", "t", ".", "co", "/", "V", "Q", "t", "87", "V", "w", "z", "4", "X", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1092", "sentence": ["\u2581", "RT", "\u2581@", "\u2581C", "rap", "T", "axi", "der", "my", ":", "\u2581\"", "\u2581I", "\u2581told", "\u2581you", "\u2581it", "\u2581was", "\u2581", "f", "uck", "ing", "\u2581hunting", "\u2581season", "\u2581Do", "re", "en", "\u2581but", "\u2581No", "oooo", ",", "\u2581we", "\u2581had", "\u2581to", "\u2581visit", "\u2581your", "\u2581sisters", "\u2581new", "\u2581place", "\u2581by", "\u2581the", "\u2581lake", "!", "\u2581\"", "\u2581https", ":", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581C", "rap", "T", "axi", "der", "my", ":", "\u2581\"", "\u2581I", "\u2581told", "\u2581you", "\u2581it", "\u2581was", "\u2581", "f", "uck", "ing", "\u2581hunting", "\u2581season", "\u2581Do", "re", "en", "\u2581but", "\u2581No", "oooo", ",", "\u2581we", "\u2581had", "\u2581to", "\u2581visit", "\u2581your", "\u2581sisters", "\u2581new", "\u2581place", "\u2581by", "\u2581the", "\u2581lake", "!", "\u2581\"", "\u2581https", ":", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581C", "rap", "T", "axi", "der", "my", "</m>", ":", "\u2581\"", "\u2581I", "\u2581told", "\u2581you", "\u2581it", "\u2581was", "\u2581", "f", "uck", "ing", "\u2581hunting", "\u2581season", "<m>", "\u2581Do", "re", "en", "</m>", "\u2581but", "\u2581No", "oooo", ",", "\u2581we", "\u2581had", "\u2581to", "\u2581visit", "\u2581your", "\u2581sisters", "\u2581new", "\u2581place", "\u2581by", "\u2581the", "\u2581lake", "!", "\u2581\"", "\u2581https", ":", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 13, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1093", "sentence": ["\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581I", "\u2581love", "\u2581when", "\u2581people", "\u2581open", "\u2581up", "\u2581to", "\u2581me", "\u2581and", "\u2581call", "\u2581me", "\u2581nickname", "s", "\u2581on", "\u2581their", "\u2581own", "\u2581and", "\u2581just", "\u2581like", "\u2581me", "\u2581and", "\u2581trust", "\u2581me", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581such", "\u2581", "a", "\u2581nice", "\u2581feeling", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581I", "\u2581love", "\u2581when", "\u2581people", "\u2581open", "\u2581up", "\u2581to", "\u2581me", "\u2581and", "\u2581call", "\u2581me", "\u2581nickname", "s", "\u2581on", "\u2581their", "\u2581own", "\u2581and", "\u2581just", "\u2581like", "\u2581me", "\u2581and", "\u2581trust", "\u2581me", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581such", "\u2581", "a", "\u2581nice", "\u2581feeling", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581mar", "I", "boro", "s", "</m>", ":", "\u2581I", "\u2581love", "\u2581when", "\u2581people", "\u2581open", "\u2581up", "\u2581to", "\u2581me", "\u2581and", "\u2581call", "\u2581me", "\u2581nickname", "s", "\u2581on", "\u2581their", "\u2581own", "\u2581and", "\u2581just", "\u2581like", "\u2581me", "\u2581and", "\u2581trust", "\u2581me", "\u2581it", "\u2581", "\u2019", "\u2581", "s", "\u2581such", "\u2581", "a", "\u2581nice", "\u2581feeling", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 28, 28, 29, 30, 30, 31, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1094", "sentence": ["\u2581", "ATA", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "ATA", ".", "</s>"], "target_sentence": ["\u2581", "ATA", ".", "</s>"], "subtoken_map": [0, 0, 1, 2], "ent_type_sequence": [-1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1]}, {"doc_id": "emerging.test_1095", "sentence": ["\u258120", "\u2581Un", "us", "ual", "\u2581Baby", "\u2581Name", "s", "\u2581You", "\u2581Haven", "t", "\u2581He", "ard", "\u2581Of", "\u2581But", "\u2581Should", "\u2581Consider", "\u2581https", "://", "t", ".", "co", "/", "y", "p", "A", "8", "on", "SV", "0", "Y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u258120", "\u2581Un", "us", "ual", "\u2581Baby", "\u2581Name", "s", "\u2581You", "\u2581Haven", "t", "\u2581He", "ard", "\u2581Of", "\u2581But", "\u2581Should", "\u2581Consider", "\u2581https", "://", "t", ".", "co", "/", "y", "p", "A", "8", "on", "SV", "0", "Y", "</s>"], "target_sentence": ["\u258120", "\u2581Un", "us", "ual", "\u2581Baby", "\u2581Name", "s", "\u2581You", "\u2581Haven", "t", "\u2581He", "ard", "\u2581Of", "\u2581But", "\u2581Should", "\u2581Consider", "\u2581https", "://", "t", ".", "co", "/", "y", "p", "A", "8", "on", "SV", "0", "Y", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 3, 4, 5, 5, 6, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1096", "sentence": ["\u2581", "81", "\u2581", "%", "\u2581done", "\u2581with", "\u2581Re", "born", ",", "\u2581by", "\u2581Jane", "\u2581E", "der", "ly", "n", "\u2581https", "://", "t", ".", "co", "/", "c", "y", "E", "zu", "c", "Z", "WH", "5", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "81", "\u2581", "%", "\u2581done", "\u2581with", "\u2581Re", "born", ",", "\u2581by", "\u2581Jane", "\u2581E", "der", "ly", "n", "\u2581https", "://", "t", ".", "co", "/", "c", "y", "E", "zu", "c", "Z", "WH", "5", "</s>"], "target_sentence": ["\u2581", "81", "\u2581", "%", "\u2581done", "\u2581with", "<m>", "<m>", "\u2581Re", "born", "</m>", "</m>", ",", "\u2581by", "<m>", "\u2581Jane", "\u2581E", "der", "ly", "n", "</m>", "\u2581https", "://", "t", ".", "co", "/", "c", "y", "E", "zu", "c", "Z", "WH", "5", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, 1, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1097", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ab", "hik", "\u25813", "23", "51", ":", "\u2581why", "\u2581Woman", "\u2581", "\u2019", "\u2581", "s", "\u2581interview", "\u2581gets", "\u2581cancelled", "?", "?", "?", "?", "\u2581https", "://", "t", ".", "co", "/", "KI", "1", "W", "UR", "Q", "5", "G", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ab", "hik", "\u25813", "23", "51", ":", "\u2581why", "\u2581Woman", "\u2581", "\u2019", "\u2581", "s", "\u2581interview", "\u2581gets", "\u2581cancelled", "?", "?", "?", "?", "\u2581https", "://", "t", ".", "co", "/", "KI", "1", "W", "UR", "Q", "5", "G", "w", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581ab", "hik", "\u25813", "23", "51", ":", "\u2581why", "\u2581Woman", "\u2581", "\u2019", "\u2581", "s", "\u2581interview", "\u2581gets", "\u2581cancelled", "?", "?", "?", "?", "\u2581https", "://", "t", ".", "co", "/", "KI", "1", "W", "UR", "Q", "5", "G", "w", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 4, 5, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1098", "sentence": ["\u258115", "\u2581Mind", "\u2581Bo", "ggling", "\u2581Fact", "s", "\u2581That", "\u2581Will", "\u2581Serve", "\u2581Up", "\u2581", "a", "\u2581Plate", "\u2581of", "\u2581Food", "\u2581for", "\u2581Though", "t", "\u2581https", "://", "t", ".", "co", "/", "o", "i", "H", "j", "6", "IQ", "Gu", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u258115", "\u2581Mind", "\u2581Bo", "ggling", "\u2581Fact", "s", "\u2581That", "\u2581Will", "\u2581Serve", "\u2581Up", "\u2581", "a", "\u2581Plate", "\u2581of", "\u2581Food", "\u2581for", "\u2581Though", "t", "\u2581https", "://", "t", ".", "co", "/", "o", "i", "H", "j", "6", "IQ", "Gu", "X", "</s>"], "target_sentence": ["\u258115", "\u2581Mind", "\u2581Bo", "ggling", "\u2581Fact", "s", "\u2581That", "\u2581Will", "\u2581Serve", "\u2581Up", "\u2581", "a", "\u2581Plate", "\u2581of", "\u2581Food", "\u2581for", "\u2581Though", "t", "\u2581https", "://", "t", ".", "co", "/", "o", "i", "H", "j", "6", "IQ", "Gu", "X", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1099", "sentence": ["\u2581@", "\u2581De", "p", "C", "rus", "a", "der", "z", "\u2581For", "\u2581free", "?", "\u2581I", "\u2581have", "\u2581cotton", "\u2581that", "\u2581needs", "\u2581picking", ".", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581De", "p", "C", "rus", "a", "der", "z", "\u2581For", "\u2581free", "?", "\u2581I", "\u2581have", "\u2581cotton", "\u2581that", "\u2581needs", "\u2581picking", ".", ".", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "<m>", "\u2581De", "p", "C", "rus", "a", "der", "z", "</m>", "</m>", "\u2581For", "\u2581free", "?", "\u2581I", "\u2581have", "\u2581cotton", "\u2581that", "\u2581needs", "\u2581picking", ".", ".", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1100", "sentence": ["\u2581I", "\u2581dream", "\u2581of", "\u2581", "a", "\u2581day", "\u2581#", "\u2581Birmingham", "\u2581is", "\u2581#", "\u2581Birmingham", "ist", "an", "\u2581an", "\u2581", "islam", "ic", "\u2581state", "\u2581with", "\u2581no", "\u2581", "ku", "f", "r", "\u2581Police", "\u2581https", "://", "t", ".", "co", "/", "q", "2", "X", "T", "j", "d", "6", "x", "0", "m", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581dream", "\u2581of", "\u2581", "a", "\u2581day", "\u2581#", "\u2581Birmingham", "\u2581is", "\u2581#", "\u2581Birmingham", "ist", "an", "\u2581an", "\u2581", "islam", "ic", "\u2581state", "\u2581with", "\u2581no", "\u2581", "ku", "f", "r", "\u2581Police", "\u2581https", "://", "t", ".", "co", "/", "q", "2", "X", "T", "j", "d", "6", "x", "0", "m", "</s>"], "target_sentence": ["\u2581I", "\u2581dream", "\u2581of", "\u2581", "a", "\u2581day", "\u2581#", "<m>", "\u2581Birmingham", "</m>", "\u2581is", "\u2581#", "\u2581Birmingham", "ist", "an", "\u2581an", "\u2581", "islam", "ic", "\u2581state", "\u2581with", "\u2581no", "\u2581", "ku", "f", "r", "\u2581Police", "\u2581https", "://", "t", ".", "co", "/", "q", "2", "X", "T", "j", "d", "6", "x", "0", "m", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10, 11, 11, 11, 12, 13, 14, 15, 15, 15, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1101", "sentence": ["\u2581O", "MG", "!", "\u2581Why", "?", "\u2581https", "://", "t", ".", "co", "/", "K", "FA", "E", "j", "7", "I", "kk", "1", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581O", "MG", "!", "\u2581Why", "?", "\u2581https", "://", "t", ".", "co", "/", "K", "FA", "E", "j", "7", "I", "kk", "1", "</s>"], "target_sentence": ["\u2581O", "MG", "!", "\u2581Why", "?", "\u2581https", "://", "t", ".", "co", "/", "K", "FA", "E", "j", "7", "I", "kk", "1", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1102", "sentence": ["\u2581", "RT", "\u2581@", "\u2581yes", "I", "m", "that", "d", "o", "pe", ":", "\u2581Mind", "\u2581your", "\u2581business", "\u2581https", "://", "t", ".", "co", "/", "MB", "b", "VG", "UB", "9", "h", "2", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581yes", "I", "m", "that", "d", "o", "pe", ":", "\u2581Mind", "\u2581your", "\u2581business", "\u2581https", "://", "t", ".", "co", "/", "MB", "b", "VG", "UB", "9", "h", "2", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581yes", "I", "m", "that", "d", "o", "pe", ":", "\u2581Mind", "\u2581your", "\u2581business", "\u2581https", "://", "t", ".", "co", "/", "MB", "b", "VG", "UB", "9", "h", "2", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1103", "sentence": ["\u2581Harry", "\u2581Potter", "\u2581Hum", "our", "\u2581", "-", "\u2581Write", "r", "s", "\u2581Write", "\u2581Creative", "\u2581Blog", "\u2581https", "://", "t", ".", "co", "/", "U", "7", "L", "q", "BN", "g", "v", "3", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Harry", "\u2581Potter", "\u2581Hum", "our", "\u2581", "-", "\u2581Write", "r", "s", "\u2581Write", "\u2581Creative", "\u2581Blog", "\u2581https", "://", "t", ".", "co", "/", "U", "7", "L", "q", "BN", "g", "v", "3", "z", "</s>"], "target_sentence": ["<m>", "<m>", "\u2581Harry", "\u2581Potter", "</m>", "</m>", "\u2581Hum", "our", "\u2581", "-", "\u2581Write", "r", "s", "\u2581Write", "\u2581Creative", "\u2581Blog", "\u2581https", "://", "t", ".", "co", "/", "U", "7", "L", "q", "BN", "g", "v", "3", "z", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1104", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "i", "L", "GD", "a", "ily", ":", "\u2581https", "://", "t", ".", "co", "/", "y", "m", "h", "W", "f", "DR", "o", "K", "m", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "i", "L", "GD", "a", "ily", ":", "\u2581https", "://", "t", ".", "co", "/", "y", "m", "h", "W", "f", "DR", "o", "K", "m", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "<m>", "\u2581", "i", "L", "GD", "a", "ily", "</m>", "</m>", ":", "\u2581https", "://", "t", ".", "co", "/", "y", "m", "h", "W", "f", "DR", "o", "K", "m", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1105", "sentence": ["\u2581#", "\u2581Positive", "\u2581#", "\u2581P", "unk", "\u2581#", "\u2581rock", "\u2581#", "\u2581music", "\u2581https", "://", "t", ".", "co", "/3", "U", "6", "e", "U", "au", "S", "OR", "\u2581@", "\u2581Bas", "z", "MM", "\u2581#", "\u2581sport", "\u2581#", "\u2581in", "die", "dev", "\u2581#", "\u2581game", "dev", "\u2581#", "\u2581Now", "Play", "ing", "\u2581#", "\u2581guitar", "\u2581#", "\u2581pun", "k", "rock", "\u2581https", "://", "t", ".", "co", "/", "BA", "E", "qu", "7", "o", "l", "PJ", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581Positive", "\u2581#", "\u2581P", "unk", "\u2581#", "\u2581rock", "\u2581#", "\u2581music", "\u2581https", "://", "t", ".", "co", "/3", "U", "6", "e", "U", "au", "S", "OR", "\u2581@", "\u2581Bas", "z", "MM", "\u2581#", "\u2581sport", "\u2581#", "\u2581in", "die", "dev", "\u2581#", "\u2581game", "dev", "\u2581#", "\u2581Now", "Play", "ing", "\u2581#", "\u2581guitar", "\u2581#", "\u2581pun", "k", "rock", "\u2581https", "://", "t", ".", "co", "/", "BA", "E", "qu", "7", "o", "l", "PJ", "</s>"], "target_sentence": ["\u2581#", "\u2581Positive", "\u2581#", "\u2581P", "unk", "\u2581#", "\u2581rock", "\u2581#", "\u2581music", "\u2581https", "://", "t", ".", "co", "/3", "U", "6", "e", "U", "au", "S", "OR", "\u2581@", "<m>", "\u2581Bas", "z", "MM", "</m>", "\u2581#", "\u2581sport", "\u2581#", "\u2581in", "die", "dev", "\u2581#", "\u2581game", "dev", "\u2581#", "\u2581Now", "Play", "ing", "\u2581#", "\u2581guitar", "\u2581#", "\u2581pun", "k", "rock", "\u2581https", "://", "t", ".", "co", "/", "BA", "E", "qu", "7", "o", "l", "PJ", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10, 10, 11, 12, 13, 14, 14, 14, 15, 16, 16, 17, 18, 18, 18, 19, 20, 21, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1106", "sentence": ["\u2581I", "\u2581won", "\u25817", "\u2581achievements", "\u2581in", "\u25812", "\u2581games", "\u2581for", "\u25812", "20", "\u2581#", "\u2581True", "A", "chie", "ve", "ment", "\u2581points", "\u2581https", "://", "t", ".", "co", "/", "HQ", "81", "x", "m", "j", "BG", "2", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581won", "\u25817", "\u2581achievements", "\u2581in", "\u25812", "\u2581games", "\u2581for", "\u25812", "20", "\u2581#", "\u2581True", "A", "chie", "ve", "ment", "\u2581points", "\u2581https", "://", "t", ".", "co", "/", "HQ", "81", "x", "m", "j", "BG", "2", "</s>"], "target_sentence": ["\u2581I", "\u2581won", "\u25817", "\u2581achievements", "\u2581in", "\u25812", "\u2581games", "\u2581for", "\u25812", "20", "\u2581#", "\u2581True", "A", "chie", "ve", "ment", "\u2581points", "\u2581https", "://", "t", ".", "co", "/", "HQ", "81", "x", "m", "j", "BG", "2", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 10, 10, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1107", "sentence": ["\u2581", "Intensiv", "e", "\u2581speech", "\u2581therapy", "\u2581helps", "\u2581months", "\u2581after", "\u2581stroke", "\u2581https", "://", "t", ".", "co", "/", "o", "p", "S", "c", "L", "X", "t", "i", "C", "3", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Intensiv", "e", "\u2581speech", "\u2581therapy", "\u2581helps", "\u2581months", "\u2581after", "\u2581stroke", "\u2581https", "://", "t", ".", "co", "/", "o", "p", "S", "c", "L", "X", "t", "i", "C", "3", "</s>"], "target_sentence": ["\u2581", "Intensiv", "e", "\u2581speech", "\u2581therapy", "\u2581helps", "\u2581months", "\u2581after", "\u2581stroke", "\u2581https", "://", "t", ".", "co", "/", "o", "p", "S", "c", "L", "X", "t", "i", "C", "3", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1108", "sentence": ["\u2581I", "\u2581will", "\u2581never", "\u2581regret", "\u2581on", "\u2581my", "\u2581decision", "\u2581to", "\u2581support", "\u2581Ni", "all", "\u2581Hor", "an", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581will", "\u2581never", "\u2581regret", "\u2581on", "\u2581my", "\u2581decision", "\u2581to", "\u2581support", "\u2581Ni", "all", "\u2581Hor", "an", "</s>"], "target_sentence": ["\u2581I", "\u2581will", "\u2581never", "\u2581regret", "\u2581on", "\u2581my", "\u2581decision", "\u2581to", "\u2581support", "<m>", "\u2581Ni", "all", "\u2581Hor", "an", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_1109", "sentence": ["\u2581Tri", "o", "\u2581@", "\u2581", "phro", "nes", "is", "music", "\u2581collaborate", "s", "\u2581with", "\u2581the", "\u2581Frankfurt", "\u2581Radio", "\u2581Big", "\u2581Band", "\u2581", "&", "\u2581amp", ";", "\u2581@", "\u2581Jul", "Arg", "J", "a", "zz", "\u2581for", "\u2581The", "\u2581Be", "hem", "o", "th", "\u2581@", "\u2581Edition", "Re", "cord", "s", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "UV", "5", "UG", "6", "e", "c", "2", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Tri", "o", "\u2581@", "\u2581", "phro", "nes", "is", "music", "\u2581collaborate", "s", "\u2581with", "\u2581the", "\u2581Frankfurt", "\u2581Radio", "\u2581Big", "\u2581Band", "\u2581", "&", "\u2581amp", ";", "\u2581@", "\u2581Jul", "Arg", "J", "a", "zz", "\u2581for", "\u2581The", "\u2581Be", "hem", "o", "th", "\u2581@", "\u2581Edition", "Re", "cord", "s", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "UV", "5", "UG", "6", "e", "c", "2", "w", "</s>"], "target_sentence": ["\u2581Tri", "o", "\u2581@", "<m>", "\u2581", "phro", "nes", "is", "music", "</m>", "\u2581collaborate", "s", "\u2581with", "\u2581the", "<m>", "\u2581Frankfurt", "\u2581Radio", "\u2581Big", "\u2581Band", "</m>", "\u2581", "&", "\u2581amp", ";", "\u2581@", "\u2581Jul", "Arg", "J", "a", "zz", "\u2581for", "<m>", "\u2581The", "\u2581Be", "hem", "o", "th", "</m>", "\u2581@", "<m>", "<m>", "\u2581Edition", "Re", "cord", "s", "</m>", "</m>", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "UV", "5", "UG", "6", "e", "c", "2", "w", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 14, 14, 14, 14, 15, 16, 17, 17, 17, 17, 18, 19, 19, 19, 19, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1, 4, 3, -1, -1, -1, -1, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1110", "sentence": ["\u2581@", "\u2581real", "J", "o", "s", "e", "p", "h", "EG", "\u2581https", "://", "t", ".", "co", "/", "v", "65", "Q", "o", "A", "0", "U", "y", "x", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581real", "J", "o", "s", "e", "p", "h", "EG", "\u2581https", "://", "t", ".", "co", "/", "v", "65", "Q", "o", "A", "0", "U", "y", "x", "</s>"], "target_sentence": ["\u2581@", "\u2581real", "J", "o", "s", "e", "p", "h", "EG", "\u2581https", "://", "t", ".", "co", "/", "v", "65", "Q", "o", "A", "0", "U", "y", "x", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1111", "sentence": ["\u2581@", "\u2581Corp", "oral", "M", "um", "\u2581", "Y", "ES", "\u2581", "\ud83d\ude29", ".", ".", ".", "\u2581that", "'", "\u2581", "ll", "\u2581teach", "\u2581me", "\u2581for", "\u2581doing", "\u2581the", "\u2581laundry", "\u2581", "&", "\u2581amp", ";", "\u2581playing", "\u2581with", "\u2581the", "\u2581dog", "\u2581lol", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Corp", "oral", "M", "um", "\u2581", "Y", "ES", "\u2581", "\ud83d\ude29", ".", ".", ".", "\u2581that", "'", "\u2581", "ll", "\u2581teach", "\u2581me", "\u2581for", "\u2581doing", "\u2581the", "\u2581laundry", "\u2581", "&", "\u2581amp", ";", "\u2581playing", "\u2581with", "\u2581the", "\u2581dog", "\u2581lol", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Corp", "oral", "M", "um", "</m>", "\u2581", "Y", "ES", "\u2581", "\ud83d\ude29", ".", ".", ".", "\u2581that", "'", "\u2581", "ll", "\u2581teach", "\u2581me", "\u2581for", "\u2581doing", "\u2581the", "\u2581laundry", "\u2581", "&", "\u2581amp", ";", "\u2581playing", "\u2581with", "\u2581the", "\u2581dog", "\u2581lol", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1112", "sentence": ["\u2581", "RT", "\u2581@", "\u2581C", "rink", "le", "W", "u", "sky", "Cu", "b", ":", "\u2581#", "\u2581Dia", "per", "art", "\u2581For", "\u2581@", "\u2581Winston", "B", "un", "\u2581I", "\u2581guess", "\u2581", "he", "\u2581couldn", "t", "\u2581bring", "\u2581his", "\u2581work", "\u2581pants", "\u2581to", "\u2581work", "\u2581cu", "z", "\u2581it", "\u2581was", "\u2581still", "\u2581we", "t", ":", "\u25813", "\u2581", "c", "!", "\u2581https", "://", "t", ".", "co", "/6", "o", "Z", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581C", "rink", "le", "W", "u", "sky", "Cu", "b", ":", "\u2581#", "\u2581Dia", "per", "art", "\u2581For", "\u2581@", "\u2581Winston", "B", "un", "\u2581I", "\u2581guess", "\u2581", "he", "\u2581couldn", "t", "\u2581bring", "\u2581his", "\u2581work", "\u2581pants", "\u2581to", "\u2581work", "\u2581cu", "z", "\u2581it", "\u2581was", "\u2581still", "\u2581we", "t", ":", "\u25813", "\u2581", "c", "!", "\u2581https", "://", "t", ".", "co", "/6", "o", "Z", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581C", "rink", "le", "W", "u", "sky", "Cu", "b", ":", "\u2581#", "\u2581Dia", "per", "art", "\u2581For", "\u2581@", "\u2581Winston", "B", "un", "\u2581I", "\u2581guess", "\u2581", "he", "\u2581couldn", "t", "\u2581bring", "\u2581his", "\u2581work", "\u2581pants", "\u2581to", "\u2581work", "\u2581cu", "z", "\u2581it", "\u2581was", "\u2581still", "\u2581we", "t", ":", "\u25813", "\u2581", "c", "!", "\u2581https", "://", "t", ".", "co", "/6", "o", "Z", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 6, 7, 8, 8, 8, 9, 10, 11, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 23, 24, 25, 26, 26, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1113", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Lan", "a", "De", "l", "Re", "y", ":", "\u2581Music", "\u2581To", "\u2581Watch", "\u2581Boys", "\u2581To", "\u2581http", "://", "t", ".", "co", "/", "FL", "d", "v", "km", "k", "w", "j", "H", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Lan", "a", "De", "l", "Re", "y", ":", "\u2581Music", "\u2581To", "\u2581Watch", "\u2581Boys", "\u2581To", "\u2581http", "://", "t", ".", "co", "/", "FL", "d", "v", "km", "k", "w", "j", "H", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "<m>", "\u2581Lan", "a", "De", "l", "Re", "y", "</m>", "</m>", ":", "<m>", "\u2581Music", "\u2581To", "\u2581Watch", "\u2581Boys", "\u2581To", "</m>", "\u2581http", "://", "t", ".", "co", "/", "FL", "d", "v", "km", "k", "w", "j", "H", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, 1, 0, -1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1114", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Ya", "s", "min", "Y", "on", "is", ":", "\u2581How", "\u2581to", "\u2581deal", "\u2581with", "\u2581all", "\u2581your", "\u2581trauma", "\u2581", "&", "\u2581amp", ";", "\u2581baggage", ".", "\u2581How", "\u2581to", "\u2581date", ".", "\u2581How", "\u2581to", "\u2581say", "\u2581no", ".", "\u2581How", "\u2581to", "\u2581save", ".", "\u2581How", "\u2581to", "\u2581cook", ".", "\u2581How", "\u2581", "s", "uff", "o", "c", "ating", "\u2581", "a", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Ya", "s", "min", "Y", "on", "is", ":", "\u2581How", "\u2581to", "\u2581deal", "\u2581with", "\u2581all", "\u2581your", "\u2581trauma", "\u2581", "&", "\u2581amp", ";", "\u2581baggage", ".", "\u2581How", "\u2581to", "\u2581date", ".", "\u2581How", "\u2581to", "\u2581say", "\u2581no", ".", "\u2581How", "\u2581to", "\u2581save", ".", "\u2581How", "\u2581to", "\u2581cook", ".", "\u2581How", "\u2581", "s", "uff", "o", "c", "ating", "\u2581", "a", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Ya", "s", "min", "Y", "on", "is", ":", "\u2581How", "\u2581to", "\u2581deal", "\u2581with", "\u2581all", "\u2581your", "\u2581trauma", "\u2581", "&", "\u2581amp", ";", "\u2581baggage", ".", "\u2581How", "\u2581to", "\u2581date", ".", "\u2581How", "\u2581to", "\u2581say", "\u2581no", ".", "\u2581How", "\u2581to", "\u2581save", ".", "\u2581How", "\u2581to", "\u2581cook", ".", "\u2581How", "\u2581", "s", "uff", "o", "c", "ating", "\u2581", "a", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 34, 34, 34, 34, 34, 35, 35, 36, 36, 37], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1115", "sentence": ["\u2581", "Temp", "\u2581", "66", ".", "\u2581", "0", "\u2581", "\u00b0", "\u2581F", "\u2581Fall", "ing", ",", "\u2581De", "w", "\u2581point", "\u258153", ".", "\u25819", "\u2581", "\u00b0", "\u2581Pressure", "\u258130", ".", "\u2581101", "\u2581in", "\u2581Rising", "\u2581slowly", "\u2581Wind", "\u2581N", "\u2581", "0", "\u2581", "mph", "\u2581Rain", "\u2581today", "\u2581", "0", ".", "\u2581", "00", "\u2581in", "\u2581https", "://", "t", ".", "co", "/", "g", "P", "t", "n", "r", "2", "d", "D", "t", "V", "\u2581#", "\u2581", "s", "t", "l", "w", "x", "\u2581#", "\u2581mo", "w", "x", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "Temp", "\u2581", "66", ".", "\u2581", "0", "\u2581", "\u00b0", "\u2581F", "\u2581Fall", "ing", ",", "\u2581De", "w", "\u2581point", "\u258153", ".", "\u25819", "\u2581", "\u00b0", "\u2581Pressure", "\u258130", ".", "\u2581101", "\u2581in", "\u2581Rising", "\u2581slowly", "\u2581Wind", "\u2581N", "\u2581", "0", "\u2581", "mph", "\u2581Rain", "\u2581today", "\u2581", "0", ".", "\u2581", "00", "\u2581in", "\u2581https", "://", "t", ".", "co", "/", "g", "P", "t", "n", "r", "2", "d", "D", "t", "V", "\u2581#", "\u2581", "s", "t", "l", "w", "x", "\u2581#", "\u2581mo", "w", "x", "</s>"], "target_sentence": ["\u2581", "Temp", "\u2581", "66", ".", "\u2581", "0", "\u2581", "\u00b0", "\u2581F", "\u2581Fall", "ing", ",", "\u2581De", "w", "\u2581point", "\u258153", ".", "\u25819", "\u2581", "\u00b0", "\u2581Pressure", "\u258130", ".", "\u2581101", "\u2581in", "\u2581Rising", "\u2581slowly", "\u2581Wind", "\u2581N", "\u2581", "0", "\u2581", "mph", "\u2581Rain", "\u2581today", "\u2581", "0", ".", "\u2581", "00", "\u2581in", "\u2581https", "://", "t", ".", "co", "/", "g", "P", "t", "n", "r", "2", "d", "D", "t", "V", "\u2581#", "\u2581", "s", "t", "l", "w", "x", "\u2581#", "\u2581mo", "w", "x", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 3, 4, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 24, 25, 26, 27, 27, 28, 29, 29, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 33, 33, 33, 33, 33, 33, 34, 35, 35, 35, 36], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1116", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ani", "s", "a", "s", "x", ":", "\u2581", "116", ")", "\u2581this", "\u2581is", "\u2581so", "\u2581", "triggering", "\u2581for", "\u2581anyone", "\u2581who", "\u2581watches", "\u2581", "a", "h", "s", "\u2581https", "://", "t", ".", "co", "/", "g", "5", "g", "9", "L", "X", "7", "f", "A", "5", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ani", "s", "a", "s", "x", ":", "\u2581", "116", ")", "\u2581this", "\u2581is", "\u2581so", "\u2581", "triggering", "\u2581for", "\u2581anyone", "\u2581who", "\u2581watches", "\u2581", "a", "h", "s", "\u2581https", "://", "t", ".", "co", "/", "g", "5", "g", "9", "L", "X", "7", "f", "A", "5", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581ani", "s", "a", "s", "x", "</m>", ":", "\u2581", "116", ")", "\u2581this", "\u2581is", "\u2581so", "\u2581", "triggering", "\u2581for", "\u2581anyone", "\u2581who", "\u2581watches", "\u2581", "a", "h", "s", "\u2581https", "://", "t", ".", "co", "/", "g", "5", "g", "9", "L", "X", "7", "f", "A", "5", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1117", "sentence": ["\u2581", "RT", "\u2581@", "\u2581P", "au", "D", "y", "bala", "\u2581", "_", "\u2581J", "R", ":", "\u2581#", "\u2581", "d", "y", "bala", "mas", "k", "\u2581could", "\u2581be", "\u2581", "/", "\u2581pod", "r", "\u00ec", "a", "\u2581ser", "\u2581", "/", "\u2581pot", "re", "b", "be", "\u2581", "esse", "re", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "V", "r", "8", "n", "6", "CL", "J", "G", "Y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581P", "au", "D", "y", "bala", "\u2581", "_", "\u2581J", "R", ":", "\u2581#", "\u2581", "d", "y", "bala", "mas", "k", "\u2581could", "\u2581be", "\u2581", "/", "\u2581pod", "r", "\u00ec", "a", "\u2581ser", "\u2581", "/", "\u2581pot", "re", "b", "be", "\u2581", "esse", "re", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "V", "r", "8", "n", "6", "CL", "J", "G", "Y", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581P", "au", "D", "y", "bala", "</m>", "\u2581", "_", "\u2581J", "R", ":", "\u2581#", "\u2581", "d", "y", "bala", "mas", "k", "\u2581could", "\u2581be", "\u2581", "/", "\u2581pod", "r", "\u00ec", "a", "\u2581ser", "\u2581", "/", "\u2581pot", "re", "b", "be", "\u2581", "esse", "re", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "V", "r", "8", "n", "6", "CL", "J", "G", "Y", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 5, 6, 7, 7, 7, 7, 7, 7, 8, 9, 10, 10, 11, 11, 11, 11, 12, 13, 13, 14, 14, 14, 14, 15, 15, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1118", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "rick", "y", "ger", "va", "is", ":", "\u2581If", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581have", "\u2581empathy", "\u2581with", "\u2581animals", ",", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581have", "\u2581empathy", "\u2581at", "\u2581all", ".", "\u2581Have", "\u2581", "a", "\u2581peaceful", "\u2581night", ".", "\u2581https", "://", "t", ".", "co", "/", "z", "0", "g", "9", "b", "ID", "ul", "B", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "rick", "y", "ger", "va", "is", ":", "\u2581If", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581have", "\u2581empathy", "\u2581with", "\u2581animals", ",", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581have", "\u2581empathy", "\u2581at", "\u2581all", ".", "\u2581Have", "\u2581", "a", "\u2581peaceful", "\u2581night", ".", "\u2581https", "://", "t", ".", "co", "/", "z", "0", "g", "9", "b", "ID", "ul", "B", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "rick", "y", "ger", "va", "is", "</m>", ":", "\u2581If", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581have", "\u2581empathy", "\u2581with", "\u2581animals", ",", "\u2581you", "\u2581don", "'", "\u2581", "t", "\u2581have", "\u2581empathy", "\u2581at", "\u2581all", ".", "\u2581Have", "\u2581", "a", "\u2581peaceful", "\u2581night", ".", "\u2581https", "://", "t", ".", "co", "/", "z", "0", "g", "9", "b", "ID", "ul", "B", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1119", "sentence": ["\u2581", "RT", "\u2581@", "\u2581pi", "p", "i", "i", "xx", ":", "\u2581https", "://", "t", ".", "co", "/", "84", "t", "R", "v", "F", "1", "Q", "ow", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581pi", "p", "i", "i", "xx", ":", "\u2581https", "://", "t", ".", "co", "/", "84", "t", "R", "v", "F", "1", "Q", "ow", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581pi", "p", "i", "i", "xx", ":", "\u2581https", "://", "t", ".", "co", "/", "84", "t", "R", "v", "F", "1", "Q", "ow", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1120", "sentence": ["\u2581", "RT", "\u2581@", "\u2581L", "one", "some", "G", "host", "s", ":", "\u2581I", "'", "\u2581", "ve", "\u2581had", "\u2581enough", "\u2581of", "\u2581the", "\u2581world", "\u2581and", "\u2581its", "\u2581people", "'", "\u2581", "s", "\u2581mind", "less", "\u2581games", ",", "\u2581so", "\u2581par", "don", "\u2581me", "\u2581while", "\u2581I", "\u2581bur", "s", "t", "\u2581and", "\u2581rise", "\u2581above", "\u2581the", "\u2581flame", "\u2581", "\ud83d\udd25", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581L", "one", "some", "G", "host", "s", ":", "\u2581I", "'", "\u2581", "ve", "\u2581had", "\u2581enough", "\u2581of", "\u2581the", "\u2581world", "\u2581and", "\u2581its", "\u2581people", "'", "\u2581", "s", "\u2581mind", "less", "\u2581games", ",", "\u2581so", "\u2581par", "don", "\u2581me", "\u2581while", "\u2581I", "\u2581bur", "s", "t", "\u2581and", "\u2581rise", "\u2581above", "\u2581the", "\u2581flame", "\u2581", "\ud83d\udd25", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581L", "one", "some", "G", "host", "s", ":", "\u2581I", "'", "\u2581", "ve", "\u2581had", "\u2581enough", "\u2581of", "\u2581the", "<m>", "\u2581world", "</m>", "\u2581and", "\u2581its", "\u2581people", "'", "\u2581", "s", "\u2581mind", "less", "\u2581games", ",", "\u2581so", "\u2581par", "don", "\u2581me", "\u2581while", "\u2581I", "\u2581bur", "s", "t", "\u2581and", "\u2581rise", "\u2581above", "\u2581the", "\u2581flame", "\u2581", "\ud83d\udd25", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 17, 18, 19, 20, 21, 21, 22, 23, 24, 25, 25, 25, 26, 27, 28, 29, 30, 31, 31, 32], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1121", "sentence": ["\u2581How", "\u2581Miami", "\u2581Dolphin", "s", "\u2581defensive", "\u2581end", "\u2581spot", "\u2581stack", "s", "\u2581up", ",", "\u2581what", "\u2581that", "\u2581means", "\u2581for", "\u2581Di", "on", "\u2581Jordan", "\u2581https", "://", "t", ".", "co", "/", "41", "Y", "BT", "4", "P", "n", "VC", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581Miami", "\u2581Dolphin", "s", "\u2581defensive", "\u2581end", "\u2581spot", "\u2581stack", "s", "\u2581up", ",", "\u2581what", "\u2581that", "\u2581means", "\u2581for", "\u2581Di", "on", "\u2581Jordan", "\u2581https", "://", "t", ".", "co", "/", "41", "Y", "BT", "4", "P", "n", "VC", "</s>"], "target_sentence": ["\u2581How", "<m>", "<m>", "\u2581Miami", "</m>", "\u2581Dolphin", "s", "</m>", "\u2581defensive", "\u2581end", "<m>", "\u2581spot", "\u2581stack", "s", "\u2581up", "</m>", ",", "\u2581what", "\u2581that", "\u2581means", "\u2581for", "<m>", "\u2581Di", "on", "\u2581Jordan", "</m>", "\u2581https", "://", "t", ".", "co", "/", "41", "Y", "BT", "4", "P", "n", "VC", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, 1, -1, 0, -1, -1, 1, -1, -1, 2, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 3, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1122", "sentence": ["\u2581", "RT", "\u2581@", "\u2581praise", "s", ":", "\u2581\"", "\u2581you", "\u2581", "gonna", "\u2581hate", "\u2581yourself", "\u2581in", "\u2581the", "\u2581morning", "\u2581", "if", "\u2581you", "\u2581stay", "\u2581up", "\u2581late", "\u2581\"", "\u2581joke", "s", "\u2581on", "\u2581you", "\u2581I", "'", "\u2581", "m", "\u2581", "gonna", "\u2581hate", "\u2581myself", "\u2581in", "\u2581the", "\u2581morning", "\u2581no", "\u2581matter", "\u2581what", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581praise", "s", ":", "\u2581\"", "\u2581you", "\u2581", "gonna", "\u2581hate", "\u2581yourself", "\u2581in", "\u2581the", "\u2581morning", "\u2581", "if", "\u2581you", "\u2581stay", "\u2581up", "\u2581late", "\u2581\"", "\u2581joke", "s", "\u2581on", "\u2581you", "\u2581I", "'", "\u2581", "m", "\u2581", "gonna", "\u2581hate", "\u2581myself", "\u2581in", "\u2581the", "\u2581morning", "\u2581no", "\u2581matter", "\u2581what", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581praise", "s", ":", "\u2581\"", "\u2581you", "\u2581", "gonna", "\u2581hate", "\u2581yourself", "\u2581in", "\u2581the", "\u2581morning", "\u2581", "if", "\u2581you", "\u2581stay", "\u2581up", "\u2581late", "\u2581\"", "\u2581joke", "s", "\u2581on", "\u2581you", "\u2581I", "'", "\u2581", "m", "\u2581", "gonna", "\u2581hate", "\u2581myself", "\u2581in", "\u2581the", "\u2581morning", "\u2581no", "\u2581matter", "\u2581what", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1123", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "HS", "5", "IV", "l", "s", "t", "Q", "j", "\u2581https", "://", "t", ".", "co", "/", "r", "9", "Er", "Q", "BS", "b", "f", "V", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "HS", "5", "IV", "l", "s", "t", "Q", "j", "\u2581https", "://", "t", ".", "co", "/", "r", "9", "Er", "Q", "BS", "b", "f", "V", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "HS", "5", "IV", "l", "s", "t", "Q", "j", "\u2581https", "://", "t", ".", "co", "/", "r", "9", "Er", "Q", "BS", "b", "f", "V", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1124", "sentence": ["\u2581Jimmy", "\u2581Fall", "on", "\u2581Make", "s", "\u2581Blake", "\u2581She", "lton", "\u2581Try", "\u2581Su", "shi", "\u2581#", "\u2581", "uga", "nd", "a", "\u2581business", "\u2581https", "://", "t", ".", "co", "/", "s", "2", "Y", "e", "AW", "y", "FS", "5", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Jimmy", "\u2581Fall", "on", "\u2581Make", "s", "\u2581Blake", "\u2581She", "lton", "\u2581Try", "\u2581Su", "shi", "\u2581#", "\u2581", "uga", "nd", "a", "\u2581business", "\u2581https", "://", "t", ".", "co", "/", "s", "2", "Y", "e", "AW", "y", "FS", "5", "</s>"], "target_sentence": ["<m>", "\u2581Jimmy", "\u2581Fall", "on", "</m>", "\u2581Make", "s", "<m>", "\u2581Blake", "\u2581She", "lton", "</m>", "\u2581Try", "\u2581Su", "shi", "\u2581#", "<m>", "\u2581", "uga", "nd", "a", "</m>", "\u2581business", "\u2581https", "://", "t", ".", "co", "/", "s", "2", "Y", "e", "AW", "y", "FS", "5", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 8, 8, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 2, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1125", "sentence": ["\u2581A", "w", "\u2581@", "\u2581ab", "by", "kos", "ic", "\u2581I", "\u2581can", "\u2581share", "\u2581with", "\u2581you", "\u2581", "\u2764", "\u2581https", "://", "t", ".", "co", "/", "J", "0", "I", "b", "S", "u", "8", "FL", "h", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "w", "\u2581@", "\u2581ab", "by", "kos", "ic", "\u2581I", "\u2581can", "\u2581share", "\u2581with", "\u2581you", "\u2581", "\u2764", "\u2581https", "://", "t", ".", "co", "/", "J", "0", "I", "b", "S", "u", "8", "FL", "h", "</s>"], "target_sentence": ["\u2581A", "w", "\u2581@", "\u2581ab", "by", "kos", "ic", "\u2581I", "\u2581can", "\u2581share", "\u2581with", "\u2581you", "\u2581", "\u2764", "\u2581https", "://", "t", ".", "co", "/", "J", "0", "I", "b", "S", "u", "8", "FL", "h", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1126", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Hil", "ar", "ious", "\u2581", "_", "\u2581I", "d", "i", "o", "t", ":", "\u2581A", "\u2581relationship", "\u2581is", "\u2581not", "\u2581", "based", "\u2581on", "\u2581the", "\u2581length", "\u2581of", "\u2581time", "\u2581you", "\u2581spent", "\u2581together", ",", "\u2581it", "'", "\u2581", "s", "\u2581", "based", "\u2581on", "\u2581the", "\u2581foundation", "\u2581you", "\u2581built", "\u2581together", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Hil", "ar", "ious", "\u2581", "_", "\u2581I", "d", "i", "o", "t", ":", "\u2581A", "\u2581relationship", "\u2581is", "\u2581not", "\u2581", "based", "\u2581on", "\u2581the", "\u2581length", "\u2581of", "\u2581time", "\u2581you", "\u2581spent", "\u2581together", ",", "\u2581it", "'", "\u2581", "s", "\u2581", "based", "\u2581on", "\u2581the", "\u2581foundation", "\u2581you", "\u2581built", "\u2581together", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Hil", "ar", "ious", "\u2581", "_", "\u2581I", "d", "i", "o", "t", ":", "\u2581A", "\u2581relationship", "\u2581is", "\u2581not", "\u2581", "based", "\u2581on", "\u2581the", "\u2581length", "\u2581of", "\u2581time", "\u2581you", "\u2581spent", "\u2581together", ",", "\u2581it", "'", "\u2581", "s", "\u2581", "based", "\u2581on", "\u2581the", "\u2581foundation", "\u2581you", "\u2581built", "\u2581together", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1127", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Je", "s", "sie", "Be", "l", "n", "a", "p", ":", "\u2581the", "\u2581feeling", "\u2581when", "\u2581spring", "\u2581break", "\u2581has", "\u2581begun", "\u2581and", "\u2581is", "\u2581two", "oooo", "\u2581we", "e", "e", "eek", "s", "\u2581long", "gg", "gg", "!", "!", "!", "!", "!", "\u2581https", "://", "t", ".", "co", "/", "P", "p", "L", "p", "7", "a", "LY", "H", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Je", "s", "sie", "Be", "l", "n", "a", "p", ":", "\u2581the", "\u2581feeling", "\u2581when", "\u2581spring", "\u2581break", "\u2581has", "\u2581begun", "\u2581and", "\u2581is", "\u2581two", "oooo", "\u2581we", "e", "e", "eek", "s", "\u2581long", "gg", "gg", "!", "!", "!", "!", "!", "\u2581https", "://", "t", ".", "co", "/", "P", "p", "L", "p", "7", "a", "LY", "H", "7", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Je", "s", "sie", "Be", "l", "n", "a", "p", "</m>", ":", "\u2581the", "\u2581feeling", "\u2581when", "\u2581spring", "\u2581break", "\u2581has", "\u2581begun", "\u2581and", "\u2581is", "\u2581two", "oooo", "\u2581we", "e", "e", "eek", "s", "\u2581long", "gg", "gg", "!", "!", "!", "!", "!", "\u2581https", "://", "t", ".", "co", "/", "P", "p", "L", "p", "7", "a", "LY", "H", "7", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 16, 17, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1128", "sentence": ["\u2581The", "n", "\u2581realized", "\u2581", "i", "\u2581wasn", "t", "\u2581going", "\u2581", "\ud83d\ude29", "\u2581https", "://", "t", ".", "co", "/", "V", "4", "h", "h", "1", "L", "Z", "u", "t", "n", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "n", "\u2581realized", "\u2581", "i", "\u2581wasn", "t", "\u2581going", "\u2581", "\ud83d\ude29", "\u2581https", "://", "t", ".", "co", "/", "V", "4", "h", "h", "1", "L", "Z", "u", "t", "n", "</s>"], "target_sentence": ["\u2581The", "n", "\u2581realized", "\u2581", "i", "\u2581wasn", "t", "\u2581going", "\u2581", "\ud83d\ude29", "\u2581https", "://", "t", ".", "co", "/", "V", "4", "h", "h", "1", "L", "Z", "u", "t", "n", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1129", "sentence": ["\u2581", "-", "\u2581", "l", "c", "\u2581https", "://", "t", ".", "co", "/", "I", "A", "p", "s", "PP", "ID", "J", "x", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "-", "\u2581", "l", "c", "\u2581https", "://", "t", ".", "co", "/", "I", "A", "p", "s", "PP", "ID", "J", "x", "</s>"], "target_sentence": ["\u2581", "-", "\u2581", "l", "c", "\u2581https", "://", "t", ".", "co", "/", "I", "A", "p", "s", "PP", "ID", "J", "x", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1130", "sentence": ["\u2581Park", "West", "\u2581Staff", "ing", "\u2581Services", "\u2581is", "\u2581hiring", ":", "\u2581Hotel", "\u2581House", "keeper", "s", "\u2581Need", "e", "d", "\u2581in", "\u2581Spring", ",", "\u2581T", "X", "\u2581https", "://", "t", ".", "co", "/5", "d", "U", "h", "Y", "D", "7", "OA", "t", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Park", "West", "\u2581Staff", "ing", "\u2581Services", "\u2581is", "\u2581hiring", ":", "\u2581Hotel", "\u2581House", "keeper", "s", "\u2581Need", "e", "d", "\u2581in", "\u2581Spring", ",", "\u2581T", "X", "\u2581https", "://", "t", ".", "co", "/5", "d", "U", "h", "Y", "D", "7", "OA", "t", "</s>"], "target_sentence": ["<m>", "\u2581Park", "West", "</m>", "\u2581Staff", "ing", "\u2581Services", "\u2581is", "\u2581hiring", ":", "\u2581Hotel", "\u2581House", "keeper", "s", "\u2581Need", "e", "d", "\u2581in", "<m>", "\u2581Spring", "</m>", ",", "<m>", "\u2581T", "X", "</m>", "\u2581https", "://", "t", ".", "co", "/5", "d", "U", "h", "Y", "D", "7", "OA", "t", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 8, 8, 9, 10, 11, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1131", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ho", "b", "x", "o", ":", "\u2581when", "\u2581your", "\u2581girl", "\u2581doesn", "'", "\u2581", "t", "\u2581go", "\u2581shopping", "\u2581with", "\u2581you", "\u2581but", "\u2581your", "\u2581ho", "mie", "\u2581does", "\u2581https", "://", "t", ".", "co", "/", "Y", "h", "y", "3", "H", "W", "0", "zy", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ho", "b", "x", "o", ":", "\u2581when", "\u2581your", "\u2581girl", "\u2581doesn", "'", "\u2581", "t", "\u2581go", "\u2581shopping", "\u2581with", "\u2581you", "\u2581but", "\u2581your", "\u2581ho", "mie", "\u2581does", "\u2581https", "://", "t", ".", "co", "/", "Y", "h", "y", "3", "H", "W", "0", "zy", "X", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581ho", "b", "x", "o", ":", "\u2581when", "\u2581your", "\u2581girl", "\u2581doesn", "'", "\u2581", "t", "\u2581go", "\u2581shopping", "\u2581with", "\u2581you", "\u2581but", "\u2581your", "\u2581ho", "mie", "\u2581does", "\u2581https", "://", "t", ".", "co", "/", "Y", "h", "y", "3", "H", "W", "0", "zy", "X", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1132", "sentence": ["\u2581school", "\u2581girls", "\u2581abortion", "\u2581https", "://", "t", ".", "co", "/", "j", "P", "l", "m", "RO", "K", "39", "M", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581school", "\u2581girls", "\u2581abortion", "\u2581https", "://", "t", ".", "co", "/", "j", "P", "l", "m", "RO", "K", "39", "M", "</s>"], "target_sentence": ["\u2581school", "\u2581girls", "\u2581abortion", "\u2581https", "://", "t", ".", "co", "/", "j", "P", "l", "m", "RO", "K", "39", "M", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1133", "sentence": ["\u2581", "RT", "\u2581@", "\u2581curs", "curs", ":", "\u2581your", "\u2581standards", "\u2581began", "\u2581to", "\u2581be", "\u2581ignored", "\u2581when", "\u2581", "u", "\u2581let", "\u2581", "m", "f", "s", "\u2581get", "\u2581comfortable", "\u2581in", "\u2581knowing", "\u2581that", "\u2581another", "\u2581chance", "\u2581will", "\u2581always", "\u2581exist", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581curs", "curs", ":", "\u2581your", "\u2581standards", "\u2581began", "\u2581to", "\u2581be", "\u2581ignored", "\u2581when", "\u2581", "u", "\u2581let", "\u2581", "m", "f", "s", "\u2581get", "\u2581comfortable", "\u2581in", "\u2581knowing", "\u2581that", "\u2581another", "\u2581chance", "\u2581will", "\u2581always", "\u2581exist", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581curs", "curs", ":", "\u2581your", "\u2581standards", "\u2581began", "\u2581to", "\u2581be", "\u2581ignored", "\u2581when", "\u2581", "u", "\u2581let", "\u2581", "m", "f", "s", "\u2581get", "\u2581comfortable", "\u2581in", "\u2581knowing", "\u2581that", "\u2581another", "\u2581chance", "\u2581will", "\u2581always", "\u2581exist", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1134", "sentence": ["\u2581Listen", "\u2581to", "\u2581Pre", "T", "a", "pe", "\u2581by", "\u2581Rich", "i", "D", "en", "z", "\u2581#", "\u2581", "n", "p", "\u2581on", "\u2581#", "\u2581Sound", "Cloud", "\u2581https", "://", "t", ".", "co", "/5", "x", "6", "w", "c", "5", "s", "R", "q", "A", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Listen", "\u2581to", "\u2581Pre", "T", "a", "pe", "\u2581by", "\u2581Rich", "i", "D", "en", "z", "\u2581#", "\u2581", "n", "p", "\u2581on", "\u2581#", "\u2581Sound", "Cloud", "\u2581https", "://", "t", ".", "co", "/5", "x", "6", "w", "c", "5", "s", "R", "q", "A", "</s>"], "target_sentence": ["\u2581Listen", "\u2581to", "<m>", "\u2581Pre", "T", "a", "pe", "</m>", "\u2581by", "<m>", "<m>", "<m>", "\u2581Rich", "i", "D", "en", "z", "</m>", "</m>", "</m>", "\u2581#", "\u2581", "n", "p", "\u2581on", "\u2581#", "<m>", "\u2581Sound", "Cloud", "</m>", "\u2581https", "://", "t", ".", "co", "/5", "x", "6", "w", "c", "5", "s", "R", "q", "A", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 5, 6, 6, 6, 7, 8, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, 0, -1, 3, 2, 1, -1, -1, -1, -1, -1, 3, 2, 1, -1, -1, -1, -1, -1, -1, 4, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1135", "sentence": ["\u2581", "RT", "\u2581@", "\u2581pale", "of", "u", "ture", ":", "\u2581Seriously", ",", "\u2581why", "\u2581is", "\u2581I", "van", "ka", "\u2581in", "\u2581these", "\u2581meetings", "\u2581with", "\u2581world", "\u2581leaders", "?", "\u2581Has", "\u2581she", "\u2581been", "\u2581given", "\u2581", "a", "\u2581title", "\u2581yet", "\u2581because", "\u2581this", "\u2581is", "\u2581just", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581pale", "of", "u", "ture", ":", "\u2581Seriously", ",", "\u2581why", "\u2581is", "\u2581I", "van", "ka", "\u2581in", "\u2581these", "\u2581meetings", "\u2581with", "\u2581world", "\u2581leaders", "?", "\u2581Has", "\u2581she", "\u2581been", "\u2581given", "\u2581", "a", "\u2581title", "\u2581yet", "\u2581because", "\u2581this", "\u2581is", "\u2581just", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581pale", "of", "u", "ture", ":", "\u2581Seriously", ",", "\u2581why", "\u2581is", "<m>", "\u2581I", "van", "ka", "</m>", "\u2581in", "\u2581these", "\u2581meetings", "\u2581with", "\u2581world", "\u2581leaders", "?", "\u2581Has", "\u2581she", "\u2581been", "\u2581given", "\u2581", "a", "\u2581title", "\u2581yet", "\u2581because", "\u2581this", "\u2581is", "\u2581just", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 22, 23, 24, 25, 26, 27, 27, 28], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1136", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "l", "t", "s", "G", "RE", "Y", "S", "quot", "e", "s", ":", "\u2581me", "\u258124", "\u2581", "/", "\u25817", "\u2581lol", "\u2581https", "://", "t", ".", "co", "/", "25", "il", "X", "m", "L", "go", "j", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "l", "t", "s", "G", "RE", "Y", "S", "quot", "e", "s", ":", "\u2581me", "\u258124", "\u2581", "/", "\u25817", "\u2581lol", "\u2581https", "://", "t", ".", "co", "/", "25", "il", "X", "m", "L", "go", "j", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "l", "t", "s", "G", "RE", "Y", "S", "quot", "e", "s", ":", "\u2581me", "\u258124", "\u2581", "/", "\u25817", "\u2581lol", "\u2581https", "://", "t", ".", "co", "/", "25", "il", "X", "m", "L", "go", "j", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1137", "sentence": ["\u2581", "RT", "\u2581@", "\u2581soft", "p", "aste", "I", "s", ":", "\u2581Lost", "\u2581in", "\u2581", "a", "\u2581field", "\u2581of", "\u2581flowers", "\u2581https", "://", "t", ".", "co", "/", "H", "x", "l", "DL", "in", "f", "t", "t", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581soft", "p", "aste", "I", "s", ":", "\u2581Lost", "\u2581in", "\u2581", "a", "\u2581field", "\u2581of", "\u2581flowers", "\u2581https", "://", "t", ".", "co", "/", "H", "x", "l", "DL", "in", "f", "t", "t", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581soft", "p", "aste", "I", "s", ":", "\u2581Lost", "\u2581in", "\u2581", "a", "<m>", "\u2581field", "\u2581of", "\u2581flowers", "</m>", "\u2581https", "://", "t", ".", "co", "/", "H", "x", "l", "DL", "in", "f", "t", "t", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1138", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "x", "a", "y", "tar", "ak", "\u2581", "_", "\u2581va", "hak", ":", "\u2581sometimes", "\u2581", "i", "\u2581wish", "\u2581certain", "\u2581people", "\u2581were", "\u2581never", "\u2581", "a", "\u2581part", "\u2581of", "\u2581my", "\u2581life", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "x", "a", "y", "tar", "ak", "\u2581", "_", "\u2581va", "hak", ":", "\u2581sometimes", "\u2581", "i", "\u2581wish", "\u2581certain", "\u2581people", "\u2581were", "\u2581never", "\u2581", "a", "\u2581part", "\u2581of", "\u2581my", "\u2581life", "</s>"], "target_sentence": ["\u2581", "RT", "<m>", "\u2581@", "\u2581", "x", "a", "y", "tar", "ak", "\u2581", "_", "\u2581va", "hak", "</m>", ":", "\u2581sometimes", "\u2581", "i", "\u2581wish", "\u2581certain", "\u2581people", "\u2581were", "\u2581never", "\u2581", "a", "\u2581part", "\u2581of", "\u2581my", "\u2581life", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1139", "sentence": ["\u2581How", "\u2581little", "\u2581respect", "\u2581do", "\u2581you", "\u2581have", "\u2581to", "\u2581have", "\u2581for", "\u2581the", "\u2581role", "\u2581of", "\u2581MP", "\u2581to", "\u2581spend", "\u2581so", "\u2581much", "\u2581time", "\u2581doing", "\u2581other", "\u2581work", "?", "\u2581#", "\u2581O", "s", "borne", "Re", "sign", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "EQ", "I", "b", "Z", "M", "9", "k", "B", "b", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", "\u2581little", "\u2581respect", "\u2581do", "\u2581you", "\u2581have", "\u2581to", "\u2581have", "\u2581for", "\u2581the", "\u2581role", "\u2581of", "\u2581MP", "\u2581to", "\u2581spend", "\u2581so", "\u2581much", "\u2581time", "\u2581doing", "\u2581other", "\u2581work", "?", "\u2581#", "\u2581O", "s", "borne", "Re", "sign", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "EQ", "I", "b", "Z", "M", "9", "k", "B", "b", "</s>"], "target_sentence": ["\u2581How", "\u2581little", "\u2581respect", "\u2581do", "\u2581you", "\u2581have", "\u2581to", "\u2581have", "\u2581for", "\u2581the", "\u2581role", "\u2581of", "\u2581MP", "\u2581to", "\u2581spend", "\u2581so", "\u2581much", "\u2581time", "\u2581doing", "\u2581other", "\u2581work", "?", "\u2581#", "\u2581O", "s", "borne", "Re", "sign", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "EQ", "I", "b", "Z", "M", "9", "k", "B", "b", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 23, 23, 23, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1140", "sentence": ["\u2581", "RT", "\u2581@", "\u2581art", "ific", "a", "I", "ly", ":", "\u2581D", "rained", "\u2581of", "\u2581blood", ",", "\u2581the", "\u2581heart", "\u2581is", "\u2581white", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "4", "Y", "z", "G", "kWh", "s", "m", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581art", "ific", "a", "I", "ly", ":", "\u2581D", "rained", "\u2581of", "\u2581blood", ",", "\u2581the", "\u2581heart", "\u2581is", "\u2581white", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "4", "Y", "z", "G", "kWh", "s", "m", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581art", "ific", "a", "I", "ly", ":", "\u2581D", "rained", "\u2581of", "\u2581blood", ",", "\u2581the", "\u2581heart", "\u2581is", "\u2581white", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "4", "Y", "z", "G", "kWh", "s", "m", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1141", "sentence": ["\u258114", ".", "\u2581Ly", "la", "\u2581", "-", "\u2581", "MAN", "TAN", "\u2581", "KE", "K", "AS", "I", "H", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u258114", ".", "\u2581Ly", "la", "\u2581", "-", "\u2581", "MAN", "TAN", "\u2581", "KE", "K", "AS", "I", "H", "</s>"], "target_sentence": ["\u258114", ".", "\u2581Ly", "la", "\u2581", "-", "<m>", "\u2581", "MAN", "TAN", "\u2581", "KE", "K", "AS", "I", "H", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_1142", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Leaf", "y", "I", "s", "Her", "e", ":", "\u2581https", "://", "t", ".", "co", "/", "NM", "d", "s", "G", "p", "k", "q", "M", "t", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Leaf", "y", "I", "s", "Her", "e", ":", "\u2581https", "://", "t", ".", "co", "/", "NM", "d", "s", "G", "p", "k", "q", "M", "t", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Leaf", "y", "I", "s", "Her", "e", ":", "\u2581https", "://", "t", ".", "co", "/", "NM", "d", "s", "G", "p", "k", "q", "M", "t", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1143", "sentence": ["\u2581Sha", "Q", "\u2581on", "\u2581the", "\u2581phone", "\u2581I", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581hear", "\u2581this", "\u2581", "nig", "g", "a", "\u2581voice", "\u2581in", "\u2581years", "s", "s", "\u2581", "\u2764", "\u2581", "\ufe0f", "\u2581#", "\u2581free", "there", "al", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Sha", "Q", "\u2581on", "\u2581the", "\u2581phone", "\u2581I", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581hear", "\u2581this", "\u2581", "nig", "g", "a", "\u2581voice", "\u2581in", "\u2581years", "s", "s", "\u2581", "\u2764", "\u2581", "\ufe0f", "\u2581#", "\u2581free", "there", "al", "</s>"], "target_sentence": ["<m>", "\u2581Sha", "Q", "</m>", "\u2581on", "\u2581the", "\u2581phone", "\u2581I", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581hear", "\u2581this", "\u2581", "nig", "g", "a", "\u2581voice", "\u2581in", "\u2581years", "s", "s", "\u2581", "\u2764", "\u2581", "\ufe0f", "\u2581#", "\u2581free", "there", "al", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 7, 8, 9, 10, 10, 10, 10, 11, 12, 13, 13, 13, 14, 14, 15, 15, 16, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1144", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "j", "in", "j", "jar", "e", "vil", ":", "\u2581", "i", "\u2581can", "t", "\u2581stop", "\u2581laughing", "\u2581", "HE", "LP", "\u2581https", "://", "t", ".", "co", "/", "05", "KB", "18", "B", "2", "w", "f", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "j", "in", "j", "jar", "e", "vil", ":", "\u2581", "i", "\u2581can", "t", "\u2581stop", "\u2581laughing", "\u2581", "HE", "LP", "\u2581https", "://", "t", ".", "co", "/", "05", "KB", "18", "B", "2", "w", "f", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "<m>", "\u2581", "j", "in", "j", "jar", "e", "vil", "</m>", "</m>", ":", "\u2581", "i", "\u2581can", "t", "\u2581stop", "\u2581laughing", "\u2581", "HE", "LP", "\u2581https", "://", "t", ".", "co", "/", "05", "KB", "18", "B", "2", "w", "f", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 5, 6, 7, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1145", "sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "Best", "O", "f", "G", "if", "s", "\u25811", ":", "\u2581T", "W", "ENT", "Y", "-", "S", "I", "X", "\u2581YEAR", "S", "\u2581A", "GO", "!", "\u2581", "/", "\u2581", "/", "\u2581Beauty", "\u2581and", "\u2581the", "\u2581Beast", "\u2581https", "://", "t", ".", "co", "/", "q", "s", "y", "37", "d", "Q", "g", "R", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581The", "Best", "O", "f", "G", "if", "s", "\u25811", ":", "\u2581T", "W", "ENT", "Y", "-", "S", "I", "X", "\u2581YEAR", "S", "\u2581A", "GO", "!", "\u2581", "/", "\u2581", "/", "\u2581Beauty", "\u2581and", "\u2581the", "\u2581Beast", "\u2581https", "://", "t", ".", "co", "/", "q", "s", "y", "37", "d", "Q", "g", "R", "a", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "Best", "O", "f", "G", "if", "s", "\u25811", ":", "\u2581T", "W", "ENT", "Y", "-", "S", "I", "X", "\u2581YEAR", "S", "\u2581A", "GO", "!", "\u2581", "/", "\u2581", "/", "<m>", "<m>", "<m>", "\u2581Beauty", "</m>", "\u2581and", "\u2581the", "<m>", "\u2581Beast", "</m>", "</m>", "</m>", "\u2581https", "://", "t", ".", "co", "/", "q", "s", "y", "37", "d", "Q", "g", "R", "a", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 8, 9, 9, 10, 10, 11, 12, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 0, 1, -1, 0, -1, -1, 3, -1, 2, 3, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1146", "sentence": ["\u2581", "RT", "\u2581@", "\u2581This", "Food", "Th", "o", ":", "\u2581Um", ",", "\u2581Yes", "\u2581https", "://", "t", ".", "co", "/", "Q", "LB", "NS", "f", "P", "m", "4", "u", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581This", "Food", "Th", "o", ":", "\u2581Um", ",", "\u2581Yes", "\u2581https", "://", "t", ".", "co", "/", "Q", "LB", "NS", "f", "P", "m", "4", "u", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581This", "Food", "Th", "o", ":", "\u2581Um", ",", "\u2581Yes", "\u2581https", "://", "t", ".", "co", "/", "Q", "LB", "NS", "f", "P", "m", "4", "u", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1147", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Dr", "J", "im", "my", "Star", ":", "\u2581Have", "\u2581", "a", "\u2581great", "\u2581night", "\u2581@", "\u2581je", "b", "o", "ve", "\u25812", "\u2581@", "\u2581fri", "u", "typ", "i", "e", "\u25811", "\u2581@", "\u2581hope", "\u258122", "59", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Dr", "J", "im", "my", "Star", ":", "\u2581Have", "\u2581", "a", "\u2581great", "\u2581night", "\u2581@", "\u2581je", "b", "o", "ve", "\u25812", "\u2581@", "\u2581fri", "u", "typ", "i", "e", "\u25811", "\u2581@", "\u2581hope", "\u258122", "59", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Dr", "J", "im", "my", "Star", "</m>", ":", "\u2581Have", "\u2581", "a", "\u2581great", "\u2581night", "\u2581@", "\u2581je", "b", "o", "ve", "\u25812", "\u2581@", "\u2581fri", "u", "typ", "i", "e", "\u25811", "\u2581@", "\u2581hope", "\u258122", "59", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 9, 9, 10, 11, 12, 12, 12, 12, 12, 13, 14, 15, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1148", "sentence": ["\u2581Listen", "\u2581to", "\u2581rock", "\u2581station", "\u2581old", "ies", "\u2581for", "\u2581Free", "!", ":", "\u2581https", "://", "t", ".", "co", "/", "t", "s", "zy", "9", "z", "HR", "61", ":", "\u2581your", "\u2581listen", "\u2581Ple", "a", "sure", ",", "\u2581avec", "\u2581le", "\u2581titre", ":", "\u2581Joy", "ous", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Listen", "\u2581to", "\u2581rock", "\u2581station", "\u2581old", "ies", "\u2581for", "\u2581Free", "!", ":", "\u2581https", "://", "t", ".", "co", "/", "t", "s", "zy", "9", "z", "HR", "61", ":", "\u2581your", "\u2581listen", "\u2581Ple", "a", "sure", ",", "\u2581avec", "\u2581le", "\u2581titre", ":", "\u2581Joy", "ous", "</s>"], "target_sentence": ["\u2581Listen", "\u2581to", "\u2581rock", "\u2581station", "\u2581old", "ies", "\u2581for", "\u2581Free", "!", ":", "\u2581https", "://", "t", ".", "co", "/", "t", "s", "zy", "9", "z", "HR", "61", ":", "\u2581your", "\u2581listen", "\u2581Ple", "a", "sure", ",", "\u2581avec", "\u2581le", "\u2581titre", ":", "<m>", "\u2581Joy", "ous", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 17, 18, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1]}, {"doc_id": "emerging.test_1149", "sentence": ["\u2581The", "\u2581waters", "\u2581of", "\u2581doubt", "\u2581can", "\u2581", "corro", "de", "\u2581even", "\u2581the", "\u2581strongest", "\u2581of", "\u2581iron", "\u2581", "w", "il", ".", ".", ".", "\u2581More", "\u2581for", "\u2581A", "ries", "\u2581https", "://", "t", ".", "co", "/", "V", "H", "r", "N", "k", "v", "Q", "Z", "i", "U", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581The", "\u2581waters", "\u2581of", "\u2581doubt", "\u2581can", "\u2581", "corro", "de", "\u2581even", "\u2581the", "\u2581strongest", "\u2581of", "\u2581iron", "\u2581", "w", "il", ".", ".", ".", "\u2581More", "\u2581for", "\u2581A", "ries", "\u2581https", "://", "t", ".", "co", "/", "V", "H", "r", "N", "k", "v", "Q", "Z", "i", "U", "</s>"], "target_sentence": ["\u2581The", "\u2581waters", "\u2581of", "\u2581doubt", "\u2581can", "\u2581", "corro", "de", "\u2581even", "\u2581the", "\u2581strongest", "\u2581of", "\u2581iron", "\u2581", "w", "il", ".", ".", ".", "\u2581More", "\u2581for", "\u2581A", "ries", "\u2581https", "://", "t", ".", "co", "/", "V", "H", "r", "N", "k", "v", "Q", "Z", "i", "U", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 5, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1150", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "tre", "s", "\u2581", "_", "\u2581", "e", "qui", "s", "\u2581", "_", ":", "\u2581", "s", "m", "h", "\u2581", "y", "'", "\u2581all", "\u2581made", "\u2581them", "\u2581stay", "\u2581in", "\u2581the", "\u2581trunk", "\u2581for", "\u2581the", "\u2581pic", "?", "\u2581https", "://", "t", ".", "co", "/2", "v", "Q", "Y", "NK", "1", "n", "91", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "tre", "s", "\u2581", "_", "\u2581", "e", "qui", "s", "\u2581", "_", ":", "\u2581", "s", "m", "h", "\u2581", "y", "'", "\u2581all", "\u2581made", "\u2581them", "\u2581stay", "\u2581in", "\u2581the", "\u2581trunk", "\u2581for", "\u2581the", "\u2581pic", "?", "\u2581https", "://", "t", ".", "co", "/2", "v", "Q", "Y", "NK", "1", "n", "91", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "tre", "s", "\u2581", "_", "\u2581", "e", "qui", "s", "\u2581", "_", ":", "\u2581", "s", "m", "h", "\u2581", "y", "'", "\u2581all", "\u2581made", "\u2581them", "\u2581stay", "\u2581in", "\u2581the", "\u2581trunk", "\u2581for", "\u2581the", "\u2581pic", "?", "\u2581https", "://", "t", ".", "co", "/2", "v", "Q", "Y", "NK", "1", "n", "91", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 6, 7, 7, 7, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1151", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Mad", "am", "M", "e", "lan", "in", ":", "\u2581Sk", "a", "i", "\u2581Jackson", "\u2581for", "\u2581Un", "titled", "\u2581Magazine", "\u2581https", "://", "t", ".", "co", "/", "s", "O", "24", "Z", "L", "f", "3", "MA", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Mad", "am", "M", "e", "lan", "in", ":", "\u2581Sk", "a", "i", "\u2581Jackson", "\u2581for", "\u2581Un", "titled", "\u2581Magazine", "\u2581https", "://", "t", ".", "co", "/", "s", "O", "24", "Z", "L", "f", "3", "MA", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Mad", "am", "M", "e", "lan", "in", ":", "<m>", "\u2581Sk", "a", "i", "\u2581Jackson", "</m>", "\u2581for", "<m>", "\u2581Un", "titled", "\u2581Magazine", "</m>", "\u2581https", "://", "t", ".", "co", "/", "s", "O", "24", "Z", "L", "f", "3", "MA", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 5, 6, 7, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1152", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "X", "X", "N", "p", "J", "41", "o", "B", "m", "\u2581https", "://", "t", ".", "co", "/", "pm", "w", "J", "a", "dry", "a", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "X", "X", "N", "p", "J", "41", "o", "B", "m", "\u2581https", "://", "t", ".", "co", "/", "pm", "w", "J", "a", "dry", "a", "7", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "X", "X", "N", "p", "J", "41", "o", "B", "m", "\u2581https", "://", "t", ".", "co", "/", "pm", "w", "J", "a", "dry", "a", "7", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1153", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "kk", "J", "1", "EV", "pu", "N", "f", "\u2581https", "://", "t", ".", "co", "/", "DU", "6", "u", "O", "g", "M", "q", "VO", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "kk", "J", "1", "EV", "pu", "N", "f", "\u2581https", "://", "t", ".", "co", "/", "DU", "6", "u", "O", "g", "M", "q", "VO", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "kk", "J", "1", "EV", "pu", "N", "f", "\u2581https", "://", "t", ".", "co", "/", "DU", "6", "u", "O", "g", "M", "q", "VO", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1154", "sentence": ["\u2581", "i", "\u2581can", "\u2581smell", "\u2581money", "\u2581already", "\u2581https", "://", "t", ".", "co", "/", "O", "w", "b", "g", "x", "5", "pe", "CE", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "i", "\u2581can", "\u2581smell", "\u2581money", "\u2581already", "\u2581https", "://", "t", ".", "co", "/", "O", "w", "b", "g", "x", "5", "pe", "CE", "</s>"], "target_sentence": ["\u2581", "i", "\u2581can", "\u2581smell", "\u2581money", "\u2581already", "\u2581https", "://", "t", ".", "co", "/", "O", "w", "b", "g", "x", "5", "pe", "CE", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1155", "sentence": ["\u2581Now", "\u2581Play", "ing", ":", "\u2581Ap", "n", "a", "\u2581San", "ge", "e", "t", "\u2581", "-", "\u2581Va", "let", "i", "\u2581Bh", "abi", "y", "an", "\u2581https", "://", "t", ".", "co", "/", "R", "p", "legi", "07", "v", "b", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Now", "\u2581Play", "ing", ":", "\u2581Ap", "n", "a", "\u2581San", "ge", "e", "t", "\u2581", "-", "\u2581Va", "let", "i", "\u2581Bh", "abi", "y", "an", "\u2581https", "://", "t", ".", "co", "/", "R", "p", "legi", "07", "v", "b", "</s>"], "target_sentence": ["\u2581Now", "\u2581Play", "ing", ":", "<m>", "\u2581Ap", "n", "a", "\u2581San", "ge", "e", "t", "</m>", "\u2581", "-", "<m>", "<m>", "\u2581Va", "let", "i", "\u2581Bh", "abi", "y", "an", "</m>", "</m>", "\u2581https", "://", "t", ".", "co", "/", "R", "p", "legi", "07", "v", "b", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1156", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Alt", "Y", "ello", "N", "at", "Park", ":", "\u2581https", "://", "t", ".", "co", "/", "To", "1", "Q", "c", "X", "H", "8", "V", "D", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Alt", "Y", "ello", "N", "at", "Park", ":", "\u2581https", "://", "t", ".", "co", "/", "To", "1", "Q", "c", "X", "H", "8", "V", "D", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Alt", "Y", "ello", "N", "at", "Park", "</m>", ":", "\u2581https", "://", "t", ".", "co", "/", "To", "1", "Q", "c", "X", "H", "8", "V", "D", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1157", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Ge", "nius", ":", "\u2581DJ", "s", "\u2581and", "\u2581producers", "\u2581can", "\u2581now", "\u2581get", "\u2581paid", "\u2581for", "\u2581their", "\u2581Sound", "Cloud", "\u2581mixes", "\u2581", "\ud83d\ude4f", "\u2581https", "://", "t", ".", "co", "/", "o", "v", "R", "7", "79", "r", "V", "V", "r", "\u2581https", "://", "t", ".", "co", "/", "V", "i", "W", "U", "QU", "Y", "RC", "v", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Ge", "nius", ":", "\u2581DJ", "s", "\u2581and", "\u2581producers", "\u2581can", "\u2581now", "\u2581get", "\u2581paid", "\u2581for", "\u2581their", "\u2581Sound", "Cloud", "\u2581mixes", "\u2581", "\ud83d\ude4f", "\u2581https", "://", "t", ".", "co", "/", "o", "v", "R", "7", "79", "r", "V", "V", "r", "\u2581https", "://", "t", ".", "co", "/", "V", "i", "W", "U", "QU", "Y", "RC", "v", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Ge", "nius", ":", "<m>", "\u2581DJ", "s", "</m>", "\u2581and", "\u2581producers", "\u2581can", "\u2581now", "\u2581get", "\u2581paid", "\u2581for", "\u2581their", "<m>", "<m>", "<m>", "\u2581Sound", "Cloud", "</m>", "</m>", "\u2581mixes", "</m>", "\u2581", "\ud83d\ude4f", "\u2581https", "://", "t", ".", "co", "/", "o", "v", "R", "7", "79", "r", "V", "V", "r", "\u2581https", "://", "t", ".", "co", "/", "V", "i", "W", "U", "QU", "Y", "RC", "v", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, 3, -1, -1, 1, 2, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1158", "sentence": ["\u2581#", "\u2581floral", "\u2581#", "\u2581", "ka", "leid", "o", "scope", "\u2581by", "\u2581#", "\u2581Kay", "e", "\u2581", "_", "\u2581Men", "ner", "\u2581#", "\u2581photography", "\u2581quality", "\u2581prints", "\u2581cards", "\u2581and", "\u2581more", "\u2581at", ":", "\u2581https", "://", "t", ".", "co", "/1", "g", "j", "X", "Z", "d", "9", "M", "g", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581floral", "\u2581#", "\u2581", "ka", "leid", "o", "scope", "\u2581by", "\u2581#", "\u2581Kay", "e", "\u2581", "_", "\u2581Men", "ner", "\u2581#", "\u2581photography", "\u2581quality", "\u2581prints", "\u2581cards", "\u2581and", "\u2581more", "\u2581at", ":", "\u2581https", "://", "t", ".", "co", "/1", "g", "j", "X", "Z", "d", "9", "M", "g", "7", "</s>"], "target_sentence": ["\u2581#", "<m>", "\u2581floral", "</m>", "\u2581#", "<m>", "\u2581", "ka", "leid", "o", "scope", "</m>", "\u2581by", "\u2581#", "<m>", "\u2581Kay", "e", "</m>", "\u2581", "_", "<m>", "\u2581Men", "ner", "</m>", "\u2581#", "\u2581photography", "\u2581quality", "\u2581prints", "\u2581cards", "\u2581and", "\u2581more", "\u2581at", ":", "\u2581https", "://", "t", ".", "co", "/1", "g", "j", "X", "Z", "d", "9", "M", "g", "7", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 3, 4, 5, 6, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 2, -1, -1, 2, -1, -1, 3, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1159", "sentence": ["\u2581@", "\u2581Jacob", "R", "h", "ines", "\u2581that", "\u2581or", "\u2581", "s", "hit", "\u2581on", "\u2581them", "\u2581lol", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Jacob", "R", "h", "ines", "\u2581that", "\u2581or", "\u2581", "s", "hit", "\u2581on", "\u2581them", "\u2581lol", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Jacob", "R", "h", "ines", "</m>", "\u2581that", "\u2581or", "\u2581", "s", "hit", "\u2581on", "\u2581them", "\u2581lol", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1160", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Jacob", "White", "side", "s", ":", "\u2581", "i", "\u2581would", "\u2581as", "\u2581well", "\u2581https", "://", "t", ".", "co", "/1", "R", "c", "E", "A", "l", "x", "W", "m", "5", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Jacob", "White", "side", "s", ":", "\u2581", "i", "\u2581would", "\u2581as", "\u2581well", "\u2581https", "://", "t", ".", "co", "/1", "R", "c", "E", "A", "l", "x", "W", "m", "5", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Jacob", "White", "side", "s", "</m>", ":", "\u2581", "i", "\u2581would", "\u2581as", "\u2581well", "\u2581https", "://", "t", ".", "co", "/1", "R", "c", "E", "A", "l", "x", "W", "m", "5", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1161", "sentence": ["\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581how", "\u2581do", "\u2581you", "\u2581un", "install", "\u2581school", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581how", "\u2581do", "\u2581you", "\u2581un", "install", "\u2581school", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "<m>", "\u2581mar", "I", "boro", "s", "</m>", "</m>", ":", "\u2581how", "\u2581do", "\u2581you", "\u2581un", "install", "\u2581school", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1162", "sentence": ["\u2581Could", "\u2581someone", "\u2581explain", "\u2581to", "\u2581me", ".", "\u2581How", "\u2581people", "\u2581can", "\u2581hate", "\u2581@", "\u2581", "e", "d", "s", "he", "er", "an", "?", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Could", "\u2581someone", "\u2581explain", "\u2581to", "\u2581me", ".", "\u2581How", "\u2581people", "\u2581can", "\u2581hate", "\u2581@", "\u2581", "e", "d", "s", "he", "er", "an", "?", "</s>"], "target_sentence": ["\u2581Could", "\u2581someone", "\u2581explain", "\u2581to", "\u2581me", ".", "\u2581How", "\u2581people", "\u2581can", "\u2581hate", "\u2581@", "<m>", "\u2581", "e", "d", "s", "he", "er", "an", "</m>", "?", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_1163", "sentence": ["\u2581", "RT", "\u2581@", "\u2581It", "s", "Tra", "vel", "V", "i", "be", "s", ":", "\u2581Birmingham", ",", "\u2581United", "\u2581Kingdom", "\u2581https", "://", "t", ".", "co", "/", "W", "c", "G", "f", "0", "C", "68", "V", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581It", "s", "Tra", "vel", "V", "i", "be", "s", ":", "\u2581Birmingham", ",", "\u2581United", "\u2581Kingdom", "\u2581https", "://", "t", ".", "co", "/", "W", "c", "G", "f", "0", "C", "68", "V", "z", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581It", "s", "Tra", "vel", "V", "i", "be", "s", "</m>", ":", "<m>", "\u2581Birmingham", "</m>", ",", "<m>", "\u2581United", "\u2581Kingdom", "</m>", "\u2581https", "://", "t", ".", "co", "/", "W", "c", "G", "f", "0", "C", "68", "V", "z", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, 1, -1, 2, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1164", "sentence": ["\u2581", "RT", "\u2581@", "\u2581A", "\u2581", "_", "\u2581S", "ul", "try", "\u2581", "_", "\u2581Mir", "age", ":", "\u2581\"", "\u2581There", "'", "\u2581", "s", "\u2581always", "\u2581room", "\u2581at", "\u2581our", "\u2581base", "\u2581for", "\u2581another", ",", "\u2581Helen", ".", ".", "\u2581you", "\u2581know", "\u2581you", "'", "\u2581", "re", "\u2581welcome", "\u2581here", "\u2581", "~", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "T", "J", "b", "t", "k", "gg", "DS", "Y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581A", "\u2581", "_", "\u2581S", "ul", "try", "\u2581", "_", "\u2581Mir", "age", ":", "\u2581\"", "\u2581There", "'", "\u2581", "s", "\u2581always", "\u2581room", "\u2581at", "\u2581our", "\u2581base", "\u2581for", "\u2581another", ",", "\u2581Helen", ".", ".", "\u2581you", "\u2581know", "\u2581you", "'", "\u2581", "re", "\u2581welcome", "\u2581here", "\u2581", "~", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "T", "J", "b", "t", "k", "gg", "DS", "Y", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581A", "\u2581", "_", "\u2581S", "ul", "try", "\u2581", "_", "\u2581Mir", "age", ":", "\u2581\"", "\u2581There", "'", "\u2581", "s", "\u2581always", "\u2581room", "\u2581at", "\u2581our", "\u2581base", "\u2581for", "\u2581another", ",", "\u2581Helen", ".", ".", "\u2581you", "\u2581know", "\u2581you", "'", "\u2581", "re", "\u2581welcome", "\u2581here", "\u2581", "~", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "T", "J", "b", "t", "k", "gg", "DS", "Y", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 28, 29, 30, 30, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1165", "sentence": ["\u2581#", "\u2581", "152", "\u2581Chi", "kor", "it", "a", "\u2581(", "\u2581Ta", "ckle", "\u2581", "/", "\u2581", "Gra", "s", "s", "\u2581Kno", "t", "\u25818", "\u2581", "/", "\u258112", "\u2581", "/", "\u2581", "0", "\u2581", "-", "\u258144", ".", "\u258144", "\u2581", "%", ")", "\u2581None", "\u2581Para", "mount", "\u2581Dr", "\u2581L", "\u25818", "\u2581J", "\u25812", "\u2581M", "\u25817", ",", "\u258108", ":", "\u258130", ":", "\u2581", "00", "\u2581pm", "\u2581(", "\u258129", "\u2581", "m", "\u258145", "\u2581", "s", "\u2581left", ")", "\u2581https", "://", "t", ".", "co", "/", "t", "Q", "H", "w", "b", "j", "z", "X", "i", "b", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581", "152", "\u2581Chi", "kor", "it", "a", "\u2581(", "\u2581Ta", "ckle", "\u2581", "/", "\u2581", "Gra", "s", "s", "\u2581Kno", "t", "\u25818", "\u2581", "/", "\u258112", "\u2581", "/", "\u2581", "0", "\u2581", "-", "\u258144", ".", "\u258144", "\u2581", "%", ")", "\u2581None", "\u2581Para", "mount", "\u2581Dr", "\u2581L", "\u25818", "\u2581J", "\u25812", "\u2581M", "\u25817", ",", "\u258108", ":", "\u258130", ":", "\u2581", "00", "\u2581pm", "\u2581(", "\u258129", "\u2581", "m", "\u258145", "\u2581", "s", "\u2581left", ")", "\u2581https", "://", "t", ".", "co", "/", "t", "Q", "H", "w", "b", "j", "z", "X", "i", "b", "</s>"], "target_sentence": ["\u2581#", "\u2581", "152", "\u2581Chi", "kor", "it", "a", "\u2581(", "\u2581Ta", "ckle", "\u2581", "/", "\u2581", "Gra", "s", "s", "\u2581Kno", "t", "\u25818", "\u2581", "/", "\u258112", "\u2581", "/", "\u2581", "0", "\u2581", "-", "\u258144", ".", "\u258144", "\u2581", "%", ")", "\u2581None", "<m>", "\u2581Para", "mount", "</m>", "\u2581Dr", "\u2581L", "\u25818", "\u2581J", "\u25812", "\u2581M", "\u25817", ",", "\u258108", ":", "\u258130", ":", "\u2581", "00", "\u2581pm", "\u2581(", "\u258129", "\u2581", "m", "\u258145", "\u2581", "s", "\u2581left", ")", "\u2581https", "://", "t", ".", "co", "/", "t", "Q", "H", "w", "b", "j", "z", "X", "i", "b", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 2, 2, 3, 4, 4, 5, 5, 6, 6, 6, 6, 7, 7, 8, 9, 9, 10, 11, 11, 12, 12, 13, 13, 14, 15, 16, 17, 17, 18, 19, 20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 33, 34, 35, 36, 37, 37, 38, 39, 39, 40, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1166", "sentence": ["\u2581", "RT", "\u2581@", "\u2581may", "ward", "Un", ":", "\u2581Good", "\u2581morning", "\u2581@", "\u2581Coca", "Col", "a", "PH", "\u25817", "21", "\u2581K", "\u2581tweet", "s", "\u2581Fresh", "\u2581and", "\u2581Organic", ".", "\u2581#", "\u2581MAY", "W", "ARD", "For", "Co", "ca", "Col", "a", "PH", "\u2581https", "://", "t", ".", "co", "/18", "p", "6", "Y", "8", "C", "s", "7", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581may", "ward", "Un", ":", "\u2581Good", "\u2581morning", "\u2581@", "\u2581Coca", "Col", "a", "PH", "\u25817", "21", "\u2581K", "\u2581tweet", "s", "\u2581Fresh", "\u2581and", "\u2581Organic", ".", "\u2581#", "\u2581MAY", "W", "ARD", "For", "Co", "ca", "Col", "a", "PH", "\u2581https", "://", "t", ".", "co", "/18", "p", "6", "Y", "8", "C", "s", "7", "X", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581may", "ward", "Un", ":", "\u2581Good", "\u2581morning", "\u2581@", "<m>", "\u2581Coca", "Col", "a", "PH", "</m>", "\u25817", "21", "\u2581K", "\u2581tweet", "s", "<m>", "\u2581Fresh", "\u2581and", "\u2581Organic", "</m>", ".", "\u2581#", "\u2581MAY", "W", "ARD", "For", "Co", "ca", "Col", "a", "PH", "\u2581https", "://", "t", ".", "co", "/18", "p", "6", "Y", "8", "C", "s", "7", "X", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 7, 7, 7, 8, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1167", "sentence": ["\u2581@", "\u2581H", "uff", "Post", "We", "i", "r", "d", "\u2581There", "'", "\u2581", "s", "\u2581nothing", "\u2581\"", "\u2581hilarious", "\u2581\"", "\u2581about", "\u2581it", ".", "\u2581Try", "\u2581doing", "\u2581some", "\u2581actual", "\u2581research", "\u2581on", "\u2581the", "\u2581subject", ".", "\u2581https", "://", "t", ".", "co", "/", "S", "km", "r", "s", "u", "z", "98", "e", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581H", "uff", "Post", "We", "i", "r", "d", "\u2581There", "'", "\u2581", "s", "\u2581nothing", "\u2581\"", "\u2581hilarious", "\u2581\"", "\u2581about", "\u2581it", ".", "\u2581Try", "\u2581doing", "\u2581some", "\u2581actual", "\u2581research", "\u2581on", "\u2581the", "\u2581subject", ".", "\u2581https", "://", "t", ".", "co", "/", "S", "km", "r", "s", "u", "z", "98", "e", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581H", "uff", "Post", "We", "i", "r", "d", "</m>", "\u2581There", "'", "\u2581", "s", "\u2581nothing", "\u2581\"", "\u2581hilarious", "\u2581\"", "\u2581about", "\u2581it", ".", "\u2581Try", "\u2581doing", "\u2581some", "\u2581actual", "\u2581research", "\u2581on", "\u2581the", "\u2581subject", ".", "\u2581https", "://", "t", ".", "co", "/", "S", "km", "r", "s", "u", "z", "98", "e", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1168", "sentence": ["\u2581", "RT", "\u2581@", "\u2581co", "I", "e", "activity", ":", "\u2581this", "\u2581picture", "\u2581", "s", "cream", "s", "\u2581perfection", "\u2581https", "://", "t", ".", "co", "/", "0", "X", "U", "u", "f", "2", "88", "j", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581co", "I", "e", "activity", ":", "\u2581this", "\u2581picture", "\u2581", "s", "cream", "s", "\u2581perfection", "\u2581https", "://", "t", ".", "co", "/", "0", "X", "U", "u", "f", "2", "88", "j", "7", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581co", "I", "e", "activity", ":", "\u2581this", "\u2581picture", "\u2581", "s", "cream", "s", "\u2581perfection", "\u2581https", "://", "t", ".", "co", "/", "0", "X", "U", "u", "f", "2", "88", "j", "7", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1169", "sentence": ["\u2581I", "\u2581S", "TO", "PP", "ED", "\u2581", "BRE", "ATH", "ING", "\u2581https", "://", "t", ".", "co", "/", "AU", "ZE", "m", "r", "RI", "n", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581S", "TO", "PP", "ED", "\u2581", "BRE", "ATH", "ING", "\u2581https", "://", "t", ".", "co", "/", "AU", "ZE", "m", "r", "RI", "n", "X", "</s>"], "target_sentence": ["\u2581I", "\u2581S", "TO", "PP", "ED", "\u2581", "BRE", "ATH", "ING", "\u2581https", "://", "t", ".", "co", "/", "AU", "ZE", "m", "r", "RI", "n", "X", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1170", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "RM", "F", "v", "g", "IO", "CD", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "RM", "F", "v", "g", "IO", "CD", "a", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "RM", "F", "v", "g", "IO", "CD", "a", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1171", "sentence": ["\u2581your", "\u2581smile", "\u2581makes", "\u2581my", "\u2581day", "\u2581stay", "\u2581always", "\u2581better", "\u2581Jack", "\u2581Gil", "in", "sky", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581your", "\u2581smile", "\u2581makes", "\u2581my", "\u2581day", "\u2581stay", "\u2581always", "\u2581better", "\u2581Jack", "\u2581Gil", "in", "sky", "</s>"], "target_sentence": ["\u2581your", "\u2581smile", "\u2581makes", "\u2581my", "\u2581day", "\u2581stay", "\u2581always", "\u2581better", "<m>", "\u2581Jack", "\u2581Gil", "in", "sky", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1]}, {"doc_id": "emerging.test_1172", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Mars", "up", "il", "ami", "\u2581", "_", "\u2581", "X", "X", "I", ":", "\u2581https", "://", "t", ".", "co", "/", "U", "k", "J", "r", "P", "la", "q", "9", "t", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Mars", "up", "il", "ami", "\u2581", "_", "\u2581", "X", "X", "I", ":", "\u2581https", "://", "t", ".", "co", "/", "U", "k", "J", "r", "P", "la", "q", "9", "t", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Mars", "up", "il", "ami", "\u2581", "_", "\u2581", "X", "X", "I", ":", "\u2581https", "://", "t", ".", "co", "/", "U", "k", "J", "r", "P", "la", "q", "9", "t", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1173", "sentence": ["\u2581#", "\u2581", "x", "xx", "\u2581naked", "\u2581picture", "\u2581", "s", "ex", "\u2581beach", "\u2581movies", "\u2581https", "://", "t", ".", "co", "/", "l", "Q", "s", "m", "C", "d", "9", "AO", "u", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581", "x", "xx", "\u2581naked", "\u2581picture", "\u2581", "s", "ex", "\u2581beach", "\u2581movies", "\u2581https", "://", "t", ".", "co", "/", "l", "Q", "s", "m", "C", "d", "9", "AO", "u", "</s>"], "target_sentence": ["\u2581#", "\u2581", "x", "xx", "\u2581naked", "\u2581picture", "\u2581", "s", "ex", "\u2581beach", "\u2581movies", "\u2581https", "://", "t", ".", "co", "/", "l", "Q", "s", "m", "C", "d", "9", "AO", "u", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 4, 4, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1174", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Dear", "You", "From", "We", ":", "\u2581stop", "\u2581", "rushing", "\u2581your", "\u2581life", ".", "\u2581just", "\u2581live", ".", "\u2581just", "\u2581breathe", ".", "\u2581just", "\u2581be", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Dear", "You", "From", "We", ":", "\u2581stop", "\u2581", "rushing", "\u2581your", "\u2581life", ".", "\u2581just", "\u2581live", ".", "\u2581just", "\u2581breathe", ".", "\u2581just", "\u2581be", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Dear", "You", "From", "We", ":", "\u2581stop", "\u2581", "rushing", "\u2581your", "\u2581life", ".", "\u2581just", "\u2581live", ".", "\u2581just", "\u2581breathe", ".", "\u2581just", "\u2581be", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1175", "sentence": ["\u2581Your", "\u2581natural", "\u2581awareness", "\u2581of", "\u2581social", "\u2581justice", "\u2581makes", "\u2581it", "\u2581hard", "\u2581to", "\u2581just", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Aqua", "rius", "\u2581https", "://", "t", ".", "co", "/", "u", "be", "E", "2", "Z", "D", "4", "ow", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Your", "\u2581natural", "\u2581awareness", "\u2581of", "\u2581social", "\u2581justice", "\u2581makes", "\u2581it", "\u2581hard", "\u2581to", "\u2581just", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Aqua", "rius", "\u2581https", "://", "t", ".", "co", "/", "u", "be", "E", "2", "Z", "D", "4", "ow", "</s>"], "target_sentence": ["\u2581Your", "\u2581natural", "\u2581awareness", "\u2581of", "\u2581social", "\u2581justice", "\u2581makes", "\u2581it", "\u2581hard", "\u2581to", "\u2581just", ".", ".", ".", "\u2581More", "\u2581for", "\u2581Aqua", "rius", "\u2581https", "://", "t", ".", "co", "/", "u", "be", "E", "2", "Z", "D", "4", "ow", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1176", "sentence": ["\u2581Wind", "\u2581", "0", ",", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581E", ".", "\u2581Bar", "ometer", "\u25811000", ",", "\u25812", "\u2581", "h", "P", "a", ",", "\u2581Fall", "ing", "\u2581slowly", ".", "\u2581Temperatur", "e", "\u258112", ",", "\u25814", "\u2581", "\u00b0", "\u2581C", ".", "\u2581Rain", "\u2581today", "\u2581", "0", ",", "\u2581", "0", "\u2581", "mm", ".", "\u2581Hu", "mid", "ity", "\u2581", "71", "\u2581", "%", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Wind", "\u2581", "0", ",", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581E", ".", "\u2581Bar", "ometer", "\u25811000", ",", "\u25812", "\u2581", "h", "P", "a", ",", "\u2581Fall", "ing", "\u2581slowly", ".", "\u2581Temperatur", "e", "\u258112", ",", "\u25814", "\u2581", "\u00b0", "\u2581C", ".", "\u2581Rain", "\u2581today", "\u2581", "0", ",", "\u2581", "0", "\u2581", "mm", ".", "\u2581Hu", "mid", "ity", "\u2581", "71", "\u2581", "%", "</s>"], "target_sentence": ["\u2581Wind", "\u2581", "0", ",", "\u2581", "0", "\u2581km", "\u2581", "/", "\u2581", "h", "\u2581E", ".", "\u2581Bar", "ometer", "\u25811000", ",", "\u25812", "\u2581", "h", "P", "a", ",", "\u2581Fall", "ing", "\u2581slowly", ".", "\u2581Temperatur", "e", "\u258112", ",", "\u25814", "\u2581", "\u00b0", "\u2581C", ".", "\u2581Rain", "\u2581today", "\u2581", "0", ",", "\u2581", "0", "\u2581", "mm", ".", "\u2581Hu", "mid", "ity", "\u2581", "71", "\u2581", "%", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 5, 6, 6, 7, 8, 9, 9, 10, 11, 12, 13, 13, 13, 13, 14, 15, 15, 16, 17, 18, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 27, 28, 29, 29, 30, 30, 31, 32, 32, 32, 33, 33, 34, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1177", "sentence": ["\u2581Free", "\u2581on", "\u2581eBook", "\u2581B", "litz", ":", "\u2581The", "\u2581Es", "lite", "s", "\u2581by", "\u2581", "CM", "\u2581Do", "port", "o", "\u2581https", "://", "t", ".", "co", "/", "l", "S", "m", "K", "w", "x", "0", "q", "4", "g", "\u2581#", "\u2581", "e", "b", "b", "litz", "\u2581https", "://", "t", ".", "co", "/", "H", "7", "q", "D", "z", "6", "E", "2", "F", "v", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Free", "\u2581on", "\u2581eBook", "\u2581B", "litz", ":", "\u2581The", "\u2581Es", "lite", "s", "\u2581by", "\u2581", "CM", "\u2581Do", "port", "o", "\u2581https", "://", "t", ".", "co", "/", "l", "S", "m", "K", "w", "x", "0", "q", "4", "g", "\u2581#", "\u2581", "e", "b", "b", "litz", "\u2581https", "://", "t", ".", "co", "/", "H", "7", "q", "D", "z", "6", "E", "2", "F", "v", "</s>"], "target_sentence": ["\u2581Free", "\u2581on", "<m>", "\u2581eBook", "<m>", "\u2581B", "litz", "</m>", "</m>", ":", "<m>", "<m>", "\u2581The", "\u2581Es", "lite", "s", "</m>", "</m>", "\u2581by", "<m>", "<m>", "\u2581", "CM", "\u2581Do", "port", "o", "</m>", "</m>", "\u2581https", "://", "t", ".", "co", "/", "l", "S", "m", "K", "w", "x", "0", "q", "4", "g", "\u2581#", "<m>", "\u2581", "e", "b", "b", "litz", "</m>", "\u2581https", "://", "t", ".", "co", "/", "H", "7", "q", "D", "z", "6", "E", "2", "F", "v", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 6, 6, 7, 8, 8, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, 1, -1, -1, 1, 0, -1, 2, 3, -1, -1, -1, -1, 2, 3, -1, 4, 5, -1, -1, -1, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 6, -1, -1, -1, -1, -1, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1178", "sentence": ["\u2581Shadow", "s", ".", "\u2581We", "\u2581had", "\u2581to", "\u2581get", "\u2581out", "\u2581and", "\u2581enjoy", "\u2581the", "\u2581snow", "\u2581before", "\u2581this", "\u2581gorgeous", "\u2581sunshine", "\u2581", "melted", "\u2581it", "\u2581all", "!", ".", ".", ".", ".", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "650", "u", "E", "K", "3", "D", "z", "q", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Shadow", "s", ".", "\u2581We", "\u2581had", "\u2581to", "\u2581get", "\u2581out", "\u2581and", "\u2581enjoy", "\u2581the", "\u2581snow", "\u2581before", "\u2581this", "\u2581gorgeous", "\u2581sunshine", "\u2581", "melted", "\u2581it", "\u2581all", "!", ".", ".", ".", ".", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "650", "u", "E", "K", "3", "D", "z", "q", "</s>"], "target_sentence": ["\u2581Shadow", "s", ".", "\u2581We", "\u2581had", "\u2581to", "\u2581get", "\u2581out", "\u2581and", "\u2581enjoy", "\u2581the", "\u2581snow", "\u2581before", "\u2581this", "\u2581gorgeous", "\u2581sunshine", "\u2581", "melted", "\u2581it", "\u2581all", "!", ".", ".", ".", ".", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "650", "u", "E", "K", "3", "D", "z", "q", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1179", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "TC", "q", "5", "a", "J", "G", "6", "R", "x", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "TC", "q", "5", "a", "J", "G", "6", "R", "x", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "TC", "q", "5", "a", "J", "G", "6", "R", "x", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1180", "sentence": ["\u2581Saw", "\u2581", "a", "\u2581turtle", "\u2581https", "://", "t", ".", "co", "/", "89", "G", "Y", "X", "K", "Q", "H", "X", "9", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Saw", "\u2581", "a", "\u2581turtle", "\u2581https", "://", "t", ".", "co", "/", "89", "G", "Y", "X", "K", "Q", "H", "X", "9", "</s>"], "target_sentence": ["\u2581Saw", "\u2581", "a", "\u2581turtle", "\u2581https", "://", "t", ".", "co", "/", "89", "G", "Y", "X", "K", "Q", "H", "X", "9", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1181", "sentence": ["\u2581", "RT", "\u2581@", "\u2581am", "y", "right", "side", ":", "\u2581Age", "\u2581of", "\u2581Defender", "s", "\u2581", "-", "\u2581Multi", "player", "\u2581Tower", "\u2581Defense", "\u2581and", "\u2581Off", "ense", "\u2581post", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "kW", "p", "Z", "l", "q", "HH", "k", "\u2581#", "\u2581", "i", "pad", "\u2581#", "\u2581games", "\u2581#", "\u2581strategy", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581am", "y", "right", "side", ":", "\u2581Age", "\u2581of", "\u2581Defender", "s", "\u2581", "-", "\u2581Multi", "player", "\u2581Tower", "\u2581Defense", "\u2581and", "\u2581Off", "ense", "\u2581post", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "kW", "p", "Z", "l", "q", "HH", "k", "\u2581#", "\u2581", "i", "pad", "\u2581#", "\u2581games", "\u2581#", "\u2581strategy", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581am", "y", "right", "side", ":", "<m>", "\u2581Age", "\u2581of", "\u2581Defender", "s", "</m>", "\u2581", "-", "\u2581Multi", "player", "\u2581Tower", "\u2581Defense", "\u2581and", "\u2581Off", "ense", "\u2581post", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "k", "kW", "p", "Z", "l", "q", "HH", "k", "\u2581#", "\u2581", "i", "pad", "\u2581#", "\u2581games", "\u2581#", "\u2581strategy", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 7, 8, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 19, 19, 19, 20, 21, 22, 23, 24], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1182", "sentence": ["\u2581", "i", "'", "\u2581", "m", "\u2581leaving", "\u2581for", "\u2581#", "\u2581Beauty", "And", "The", "B", "east", ":", "\u2581D", "\u2581", "i", "'", "\u2581", "m", "\u2581so", "\u2581excited", "\u2581", "i", "\u2581have", "\u2581", "waited", "\u2581so", "\u2581long", "\u2581for", "\u2581this", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "i", "'", "\u2581", "m", "\u2581leaving", "\u2581for", "\u2581#", "\u2581Beauty", "And", "The", "B", "east", ":", "\u2581D", "\u2581", "i", "'", "\u2581", "m", "\u2581so", "\u2581excited", "\u2581", "i", "\u2581have", "\u2581", "waited", "\u2581so", "\u2581long", "\u2581for", "\u2581this", "</s>"], "target_sentence": ["\u2581", "i", "'", "\u2581", "m", "\u2581leaving", "\u2581for", "\u2581#", "<m>", "\u2581Beauty", "And", "The", "B", "east", "</m>", ":", "\u2581D", "\u2581", "i", "'", "\u2581", "m", "\u2581so", "\u2581excited", "\u2581", "i", "\u2581have", "\u2581", "waited", "\u2581so", "\u2581long", "\u2581for", "\u2581this", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1183", "sentence": ["\u2581We", "\u2581love", "\u2581that", "\u2581we", "\u2581have", "\u2581friends", "\u2581all", "\u2581over", "\u2581the", "\u2581world", "!", "\u2581Here", "\u2581is", "\u2581friend", "\u2581Isabel", "la", "\u2581proud", "ly", "\u2581wearing", "\u2581her", "\u2581C", "IM", "\u2581", "t", "-", "shirt", "\u2581today", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "a", "E", "J", "0", "ow", "L", "b", "CU", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581We", "\u2581love", "\u2581that", "\u2581we", "\u2581have", "\u2581friends", "\u2581all", "\u2581over", "\u2581the", "\u2581world", "!", "\u2581Here", "\u2581is", "\u2581friend", "\u2581Isabel", "la", "\u2581proud", "ly", "\u2581wearing", "\u2581her", "\u2581C", "IM", "\u2581", "t", "-", "shirt", "\u2581today", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "a", "E", "J", "0", "ow", "L", "b", "CU", "</s>"], "target_sentence": ["\u2581We", "\u2581love", "\u2581that", "\u2581we", "\u2581have", "\u2581friends", "\u2581all", "\u2581over", "\u2581the", "\u2581world", "!", "\u2581Here", "\u2581is", "\u2581friend", "<m>", "\u2581Isabel", "la", "</m>", "\u2581proud", "ly", "\u2581wearing", "\u2581her", "\u2581C", "IM", "\u2581", "t", "-", "shirt", "\u2581today", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "a", "E", "J", "0", "ow", "L", "b", "CU", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 15, 16, 17, 18, 18, 19, 19, 19, 19, 20, 21, 22, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1184", "sentence": ["\u2581", "RT", "\u2581@", "\u2581climb", "\u2581", "_", "\u2581chairman", ":", "\u2581Part", "\u25812", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "m", "P", "p", "w", "N", "s", "OM", "h", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581climb", "\u2581", "_", "\u2581chairman", ":", "\u2581Part", "\u25812", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "m", "P", "p", "w", "N", "s", "OM", "h", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581climb", "\u2581", "_", "\u2581chairman", "</m>", ":", "\u2581Part", "\u25812", ".", "\u2581https", "://", "t", ".", "co", "/", "b", "m", "P", "p", "w", "N", "s", "OM", "h", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1185", "sentence": ["\u2581@", "\u2581", "cha", "bot", "\u2581", "_", "\u2581came", "r", "on", "\u2581well", "\u2581", "if", "\u2581you", "\u2581", "stayed", "\u2581you", "\u2581wouldn", "'", "\u2581", "t", "\u2581go", "\u2581back", "\u2581for", "\u2581another", "\u2581week", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581", "cha", "bot", "\u2581", "_", "\u2581came", "r", "on", "\u2581well", "\u2581", "if", "\u2581you", "\u2581", "stayed", "\u2581you", "\u2581wouldn", "'", "\u2581", "t", "\u2581go", "\u2581back", "\u2581for", "\u2581another", "\u2581week", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581", "cha", "bot", "</m>", "\u2581", "_", "<m>", "\u2581came", "r", "on", "</m>", "\u2581well", "\u2581", "if", "\u2581you", "\u2581", "stayed", "\u2581you", "\u2581wouldn", "'", "\u2581", "t", "\u2581go", "\u2581back", "\u2581for", "\u2581another", "\u2581week", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 6, 7, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1186", "sentence": [".", "\u2581@", "\u2581", "k", "esel", "owski", "\u2581currently", "\u2581", "p", "\u25815", "\u2581after", "\u2581his", "\u2581first", "\u2581run", ".", "\u2581|", "\u2581@", "\u2581alliance", "part", "s", "\u2581@", "\u2581Ford", "Per", "form", "ance", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", ".", "\u2581@", "\u2581", "k", "esel", "owski", "\u2581currently", "\u2581", "p", "\u25815", "\u2581after", "\u2581his", "\u2581first", "\u2581run", ".", "\u2581|", "\u2581@", "\u2581alliance", "part", "s", "\u2581@", "\u2581Ford", "Per", "form", "ance", "</s>"], "target_sentence": [".", "\u2581@", "<m>", "\u2581", "k", "esel", "owski", "</m>", "\u2581currently", "\u2581", "p", "\u25815", "\u2581after", "\u2581his", "\u2581first", "\u2581run", ".", "\u2581|", "\u2581@", "\u2581alliance", "part", "s", "\u2581@", "<m>", "<m>", "\u2581Ford", "Per", "form", "ance", "</m>", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, 1, 2, -1]}, {"doc_id": "emerging.test_1187", "sentence": ["\u2581I", "\u2581got", "\u2581rear", "\u2581ended", "\u2581today", ".", "\u2581", "Luckily", ",", "\u2581this", "\u2581is", "\u2581all", "\u2581the", "\u2581work", "\u2581my", "\u2581car", "\u2581needed", ".", "\u2581https", "://", "t", ".", "co", "/4", "B", "EO", "t", "m", "o", "o", "o", "9", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581got", "\u2581rear", "\u2581ended", "\u2581today", ".", "\u2581", "Luckily", ",", "\u2581this", "\u2581is", "\u2581all", "\u2581the", "\u2581work", "\u2581my", "\u2581car", "\u2581needed", ".", "\u2581https", "://", "t", ".", "co", "/4", "B", "EO", "t", "m", "o", "o", "o", "9", "</s>"], "target_sentence": ["\u2581I", "\u2581got", "\u2581rear", "\u2581ended", "\u2581today", ".", "\u2581", "Luckily", ",", "\u2581this", "\u2581is", "\u2581all", "\u2581the", "\u2581work", "\u2581my", "\u2581car", "\u2581needed", ".", "\u2581https", "://", "t", ".", "co", "/4", "B", "EO", "t", "m", "o", "o", "o", "9", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1188", "sentence": ["\u2581", "teen", "\u2581", "wolf", "\u2581", "s", "a", "i", "\u2581logo", "\u2581do", "\u2581hi", "at", "us", "\u2581", "e", "u", "\u2581", "t", "e", "\u2581imp", "lor", "o", "o", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "teen", "\u2581", "wolf", "\u2581", "s", "a", "i", "\u2581logo", "\u2581do", "\u2581hi", "at", "us", "\u2581", "e", "u", "\u2581", "t", "e", "\u2581imp", "lor", "o", "o", "</s>"], "target_sentence": ["\u2581", "teen", "\u2581", "wolf", "\u2581", "s", "a", "i", "\u2581logo", "\u2581do", "\u2581hi", "at", "us", "\u2581", "e", "u", "\u2581", "t", "e", "\u2581imp", "lor", "o", "o", "</s>"], "subtoken_map": [0, 0, 1, 1, 2, 2, 2, 2, 3, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1189", "sentence": ["\u2581", "RT", "\u2581@", "\u2581the", "mov", "ing", "road", ":", "\u2581Do", "\u2581all", "\u2581things", "\u2581with", "\u2581love", ".", "\u2581O", "g", "\u2581Man", "din", "o", "\u2581#", "\u2581quote", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581the", "mov", "ing", "road", ":", "\u2581Do", "\u2581all", "\u2581things", "\u2581with", "\u2581love", ".", "\u2581O", "g", "\u2581Man", "din", "o", "\u2581#", "\u2581quote", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581the", "mov", "ing", "road", ":", "\u2581Do", "\u2581all", "\u2581things", "\u2581with", "\u2581love", ".", "<m>", "\u2581O", "g", "\u2581Man", "din", "o", "</m>", "\u2581#", "\u2581quote", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1]}, {"doc_id": "emerging.test_1190", "sentence": ["\u2581#", "\u2581", "gro", "o", "v", "y", "\u2581hot", "\u2581", "s", "ex", "\u2581videos", "\u2581brutal", "\u2581in", "terra", "cial", "\u2581", "s", "ex", "\u2581https", "://", "t", ".", "co", "/", "s", "v", "h", "i", "O", "ka", "c", "2", "D", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581", "gro", "o", "v", "y", "\u2581hot", "\u2581", "s", "ex", "\u2581videos", "\u2581brutal", "\u2581in", "terra", "cial", "\u2581", "s", "ex", "\u2581https", "://", "t", ".", "co", "/", "s", "v", "h", "i", "O", "ka", "c", "2", "D", "</s>"], "target_sentence": ["\u2581#", "\u2581", "gro", "o", "v", "y", "\u2581hot", "\u2581", "s", "ex", "\u2581videos", "\u2581brutal", "\u2581in", "terra", "cial", "\u2581", "s", "ex", "\u2581https", "://", "t", ".", "co", "/", "s", "v", "h", "i", "O", "ka", "c", "2", "D", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1191", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Beauty", "O", "f", "A", "n", "A", "ries", ":", "\u2581AR", "IES", ".", ".", ".", ".", ".", ".", ".", ".", "\u2581our", "\u2581season", "\u2581starts", "\u2581in", "\u25814", "\u2581days", "\u2581", "\ud83d\ude08", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Beauty", "O", "f", "A", "n", "A", "ries", ":", "\u2581AR", "IES", ".", ".", ".", ".", ".", ".", ".", ".", "\u2581our", "\u2581season", "\u2581starts", "\u2581in", "\u25814", "\u2581days", "\u2581", "\ud83d\ude08", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Beauty", "O", "f", "A", "n", "A", "ries", ":", "<m>", "\u2581AR", "IES", "</m>", ".", ".", ".", ".", ".", ".", ".", ".", "\u2581our", "\u2581season", "\u2581starts", "\u2581in", "\u25814", "\u2581days", "\u2581", "\ud83d\ude08", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1192", "sentence": ["\u2581@", "\u2581Junior", "C", "y", "c", "ling", "M", "Y", "\u2581N", "\u25819", "\u2581Under", "\u25819", "\u2581cat", "\u2581just", "\u2581started", "!", "\u2581#", "\u2581", "crit", "\u2581@", "\u2581", "k", "hair", "y", "k", "j", "\u2581https", "://", "t", ".", "co", "/", "X", "A", "s", "X", "G", "i", "P", "c", "f", "G", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Junior", "C", "y", "c", "ling", "M", "Y", "\u2581N", "\u25819", "\u2581Under", "\u25819", "\u2581cat", "\u2581just", "\u2581started", "!", "\u2581#", "\u2581", "crit", "\u2581@", "\u2581", "k", "hair", "y", "k", "j", "\u2581https", "://", "t", ".", "co", "/", "X", "A", "s", "X", "G", "i", "P", "c", "f", "G", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Junior", "C", "y", "c", "ling", "M", "Y", "</m>", "\u2581N", "\u25819", "\u2581Under", "\u25819", "\u2581cat", "\u2581just", "\u2581started", "!", "\u2581#", "\u2581", "crit", "\u2581@", "\u2581", "k", "hair", "y", "k", "j", "\u2581https", "://", "t", ".", "co", "/", "X", "A", "s", "X", "G", "i", "P", "c", "f", "G", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1193", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "NBC", "Gri", "mm", ":", "\u2581Get", "\u2581ready", "\u2581to", "\u2581wo", "ge", ".", "\u2581A", "\u2581new", "\u2581#", "\u2581Grim", "m", "\u2581starts", "\u2581", "NOW", "\u2581on", "\u2581@", "\u2581", "NBC", ".", "\u2581https", "://", "t", ".", "co", "/", "l", "M", "QA", "8", "a", "J", "w", "z", "L", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "NBC", "Gri", "mm", ":", "\u2581Get", "\u2581ready", "\u2581to", "\u2581wo", "ge", ".", "\u2581A", "\u2581new", "\u2581#", "\u2581Grim", "m", "\u2581starts", "\u2581", "NOW", "\u2581on", "\u2581@", "\u2581", "NBC", ".", "\u2581https", "://", "t", ".", "co", "/", "l", "M", "QA", "8", "a", "J", "w", "z", "L", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "NBC", "Gri", "mm", ":", "\u2581Get", "\u2581ready", "\u2581to", "\u2581wo", "ge", ".", "\u2581A", "\u2581new", "\u2581#", "<m>", "\u2581Grim", "m", "</m>", "\u2581starts", "\u2581", "NOW", "\u2581on", "\u2581@", "<m>", "\u2581", "NBC", "</m>", ".", "\u2581https", "://", "t", ".", "co", "/", "l", "M", "QA", "8", "a", "J", "w", "z", "L", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 12, 13, 14, 14, 15, 16, 17, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1194", "sentence": ["\u2581Tire", "d", "\u2581of", "\u2581fake", "\u2581as", "s", "\u2581love", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Tire", "d", "\u2581of", "\u2581fake", "\u2581as", "s", "\u2581love", "</s>"], "target_sentence": ["\u2581Tire", "d", "\u2581of", "\u2581fake", "\u2581as", "s", "\u2581love", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1195", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ste", "fond", "i", "gg", "s", ":", "\u2581Throw", "\u2581some", "\u2581more", "\u2581dirt", "\u2581on", "\u2581me", "\u2581but", "\u2581Im", "a", "\u2581never", "\u2581give", "\u2581up", ".", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "ste", "fond", "i", "gg", "s", ":", "\u2581Throw", "\u2581some", "\u2581more", "\u2581dirt", "\u2581on", "\u2581me", "\u2581but", "\u2581Im", "a", "\u2581never", "\u2581give", "\u2581up", ".", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ste", "fond", "i", "gg", "s", ":", "\u2581Throw", "\u2581some", "\u2581more", "\u2581dirt", "\u2581on", "\u2581me", "\u2581but", "\u2581Im", "a", "\u2581never", "\u2581give", "\u2581up", ".", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1196", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Independent", ":", "\u2581Cutting", "\u2581food", "\u2581for", "\u2581elderly", "'", "\u2581most", "\u2581compassionate", "\u2581thing", "\u2581we", "\u2581can", "\u2581do", "'", ",", "\u2581Trump", "\u2581team", "\u2581says", "\u2581https", "://", "t", ".", "co", "/", "w", "a", "a", "W", "h", "n", "Q", "07", "i", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Independent", ":", "\u2581Cutting", "\u2581food", "\u2581for", "\u2581elderly", "'", "\u2581most", "\u2581compassionate", "\u2581thing", "\u2581we", "\u2581can", "\u2581do", "'", ",", "\u2581Trump", "\u2581team", "\u2581says", "\u2581https", "://", "t", ".", "co", "/", "w", "a", "a", "W", "h", "n", "Q", "07", "i", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Independent", ":", "\u2581Cutting", "\u2581food", "\u2581for", "\u2581elderly", "'", "\u2581most", "\u2581compassionate", "\u2581thing", "\u2581we", "\u2581can", "\u2581do", "'", ",", "<m>", "\u2581Trump", "</m>", "\u2581team", "\u2581says", "\u2581https", "://", "t", ".", "co", "/", "w", "a", "a", "W", "h", "n", "Q", "07", "i", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1197", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "C", "9", "r", "i", "D", "z", "s", "J", "u", "v", "\u2581#", "\u2581Gan", "a", "Con", "Who", "o", "list", "\u2581#", "\u2581Con", "curs", "o", "Who", "o", "list", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "C", "9", "r", "i", "D", "z", "s", "J", "u", "v", "\u2581#", "\u2581Gan", "a", "Con", "Who", "o", "list", "\u2581#", "\u2581Con", "curs", "o", "Who", "o", "list", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "C", "9", "r", "i", "D", "z", "s", "J", "u", "v", "\u2581#", "<m>", "\u2581Gan", "a", "Con", "Who", "o", "list", "</m>", "\u2581#", "\u2581Con", "curs", "o", "Who", "o", "list", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1198", "sentence": ["\u2581@", "\u2581Omni", "D", "est", "in", "y", "\u2581I", "'", "\u2581", "m", "\u2581all", "\u2581for", "\u2581freedom", "\u2581of", "\u2581speech", "\u2581and", "\u2581", "expressing", "\u2581your", "\u2581opinion", ",", "\u2581but", "\u2581there", "\u2581is", "\u2581such", "\u2581thing", "\u2581as", "\u2581doing", "\u2581so", "\u2581respectful", "ly", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Omni", "D", "est", "in", "y", "\u2581I", "'", "\u2581", "m", "\u2581all", "\u2581for", "\u2581freedom", "\u2581of", "\u2581speech", "\u2581and", "\u2581", "expressing", "\u2581your", "\u2581opinion", ",", "\u2581but", "\u2581there", "\u2581is", "\u2581such", "\u2581thing", "\u2581as", "\u2581doing", "\u2581so", "\u2581respectful", "ly", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Omni", "D", "est", "in", "y", "\u2581I", "'", "\u2581", "m", "\u2581all", "\u2581for", "\u2581freedom", "\u2581of", "\u2581speech", "\u2581and", "\u2581", "expressing", "\u2581your", "\u2581opinion", ",", "\u2581but", "\u2581there", "\u2581is", "\u2581such", "\u2581thing", "\u2581as", "\u2581doing", "\u2581so", "\u2581respectful", "ly", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1199", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Ho", "za", "y", "\u2581", "_", "\u2581", "_", ":", "\u2581Just", "\u2581cancelled", "\u2581going", "\u2581to", "\u2581Italy", ",", "\u2581decided", "\u2581just", "\u2581to", "\u2581have", "\u2581dinner", "\u2581at", "\u2581Olive", "\u2581Garden", "\u2581instead", "\u2581https", "://", "t", ".", "co", "/", "o", "h", "A", "1", "B", "Y", "z", "Z", "s", "K", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Ho", "za", "y", "\u2581", "_", "\u2581", "_", ":", "\u2581Just", "\u2581cancelled", "\u2581going", "\u2581to", "\u2581Italy", ",", "\u2581decided", "\u2581just", "\u2581to", "\u2581have", "\u2581dinner", "\u2581at", "\u2581Olive", "\u2581Garden", "\u2581instead", "\u2581https", "://", "t", ".", "co", "/", "o", "h", "A", "1", "B", "Y", "z", "Z", "s", "K", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Ho", "za", "y", "</m>", "\u2581", "_", "\u2581", "_", ":", "\u2581Just", "\u2581cancelled", "\u2581going", "\u2581to", "\u2581Italy", ",", "\u2581decided", "\u2581just", "\u2581to", "\u2581have", "\u2581dinner", "\u2581at", "<m>", "\u2581Olive", "\u2581Garden", "</m>", "\u2581instead", "\u2581https", "://", "t", ".", "co", "/", "o", "h", "A", "1", "B", "Y", "z", "Z", "s", "K", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1200", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ki", "i", "ing", "pin", "\u25811997", ":", "\u2581I", "\u2581want", "\u2581to", "\u2581be", "\u2581someone", "'", "\u2581", "s", "\u2581favorite", "\u2581person", "\u2581to", "\u2581talk", "\u2581to", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "ki", "i", "ing", "pin", "\u25811997", ":", "\u2581I", "\u2581want", "\u2581to", "\u2581be", "\u2581someone", "'", "\u2581", "s", "\u2581favorite", "\u2581person", "\u2581to", "\u2581talk", "\u2581to", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ki", "i", "ing", "pin", "\u25811997", ":", "\u2581I", "\u2581want", "\u2581to", "\u2581be", "\u2581someone", "'", "\u2581", "s", "\u2581favorite", "\u2581person", "\u2581to", "\u2581talk", "\u2581to", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1201", "sentence": ["\u2581Dear", "\u2581Am", "i", "tab", "h", "!", "\u2581Happy", "\u2581Birthday", "\u2581to", "\u2581your", "\u2581daughter", "\u2581Sh", "we", "t", "a", "!", "\u2581Happi", "ness", ",", "\u2581love", ",", "\u2581joy", "\u2581and", "\u2581life", "\u2581for", "\u2581many", "\u2581years", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Dear", "\u2581Am", "i", "tab", "h", "!", "\u2581Happy", "\u2581Birthday", "\u2581to", "\u2581your", "\u2581daughter", "\u2581Sh", "we", "t", "a", "!", "\u2581Happi", "ness", ",", "\u2581love", ",", "\u2581joy", "\u2581and", "\u2581life", "\u2581for", "\u2581many", "\u2581years", "!", "</s>"], "target_sentence": ["\u2581Dear", "<m>", "\u2581Am", "i", "tab", "h", "</m>", "!", "\u2581Happy", "\u2581Birthday", "\u2581to", "\u2581your", "\u2581daughter", "<m>", "\u2581Sh", "we", "t", "a", "</m>", "!", "\u2581Happi", "ness", ",", "\u2581love", ",", "\u2581joy", "\u2581and", "\u2581life", "\u2581for", "\u2581many", "\u2581years", "!", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1202", "sentence": ["\u2581naked", "\u2581city", "\u2581", "t", "v", "\u2581series", "\u2581#", "\u2581nu", "de", "\u2581google", "\u2581videos", "\u2581https", "://", "t", ".", "co", "/", "c", "F", "IQ", "G", "0", "z", "1", "t", "V", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581naked", "\u2581city", "\u2581", "t", "v", "\u2581series", "\u2581#", "\u2581nu", "de", "\u2581google", "\u2581videos", "\u2581https", "://", "t", ".", "co", "/", "c", "F", "IQ", "G", "0", "z", "1", "t", "V", "</s>"], "target_sentence": ["<m>", "\u2581naked", "\u2581city", "\u2581", "t", "v", "\u2581series", "</m>", "\u2581#", "\u2581nu", "de", "\u2581google", "\u2581videos", "\u2581https", "://", "t", ".", "co", "/", "c", "F", "IQ", "G", "0", "z", "1", "t", "V", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1203", "sentence": ["\u2581@", "\u2581Triple", "U", "rus", "a", "i", "\u2581+", "\u2581mind", ".", "\u2581Just", "\u2581don", "'", "\u2581", "t", "\u2581tell", "\u2581him", ",", "\u2581", "ok", "?", "\u2581\"", "\u2581A", "\u2581playful", "\u2581laugh", "\u2581left", "\u2581his", "\u2581mouth", "\u2581as", "\u2581", "he", "\u2581held", "\u2581", "a", "\u2581finger", "\u2581to", "\u2581it", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Triple", "U", "rus", "a", "i", "\u2581+", "\u2581mind", ".", "\u2581Just", "\u2581don", "'", "\u2581", "t", "\u2581tell", "\u2581him", ",", "\u2581", "ok", "?", "\u2581\"", "\u2581A", "\u2581playful", "\u2581laugh", "\u2581left", "\u2581his", "\u2581mouth", "\u2581as", "\u2581", "he", "\u2581held", "\u2581", "a", "\u2581finger", "\u2581to", "\u2581it", ".", "</s>"], "target_sentence": ["\u2581@", "\u2581Triple", "U", "rus", "a", "i", "\u2581+", "\u2581mind", ".", "\u2581Just", "\u2581don", "'", "\u2581", "t", "\u2581tell", "\u2581him", ",", "\u2581", "ok", "?", "\u2581\"", "\u2581A", "\u2581playful", "\u2581laugh", "\u2581left", "\u2581his", "\u2581mouth", "\u2581as", "\u2581", "he", "\u2581held", "\u2581", "a", "\u2581finger", "\u2581to", "\u2581it", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1204", "sentence": ["\u2581Me", "\u2581reading", "\u2581really", "\u2581sad", "\u2581manga", ".", "\u2581https", "://", "t", ".", "co", "/", "u", "B", "z", "9", "C", "m", "WS", "I", "0", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Me", "\u2581reading", "\u2581really", "\u2581sad", "\u2581manga", ".", "\u2581https", "://", "t", ".", "co", "/", "u", "B", "z", "9", "C", "m", "WS", "I", "0", "</s>"], "target_sentence": ["\u2581Me", "\u2581reading", "\u2581really", "\u2581sad", "\u2581manga", ".", "\u2581https", "://", "t", ".", "co", "/", "u", "B", "z", "9", "C", "m", "WS", "I", "0", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1205", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Kind", "ness", "O", "f", "M", "en", ":", "\u2581Except", "\u2581for", "\u2581Bitte", "r", ".", "\u2581He", "'", "\u2581", "s", "\u2581always", "\u2581pi", "s", "sed", "\u2581off", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Kind", "ness", "O", "f", "M", "en", ":", "\u2581Except", "\u2581for", "\u2581Bitte", "r", ".", "\u2581He", "'", "\u2581", "s", "\u2581always", "\u2581pi", "s", "sed", "\u2581off", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Kind", "ness", "O", "f", "M", "en", ":", "\u2581Except", "\u2581for", "<m>", "\u2581Bitte", "r", "</m>", ".", "\u2581He", "'", "\u2581", "s", "\u2581always", "\u2581pi", "s", "sed", "\u2581off", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 10, 11, 12, 12, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1206", "sentence": ["\u2581S", "\u2581A", "\u2581I", "\u2581L", "\u2581O", "\u2581R", ".", ".", ".", "\u2581#", "\u2581Photo", "\u2581by", "\u2581Din", "k", "o", "\u2581#", "\u2581Dream", "\u2581#", "\u2581Love", "\u2581#", "\u2581Hope", "\u2581#", "\u2581Health", "\u2581#", "\u2581Peace", "\u2581", "&", "\u2581amp", ";", "\u2581#", "\u2581Art", "\u2581https", "://", "t", ".", "co", "/", "a", "K", "v", "s", "WS", "5", "y", "O", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581S", "\u2581A", "\u2581I", "\u2581L", "\u2581O", "\u2581R", ".", ".", ".", "\u2581#", "\u2581Photo", "\u2581by", "\u2581Din", "k", "o", "\u2581#", "\u2581Dream", "\u2581#", "\u2581Love", "\u2581#", "\u2581Hope", "\u2581#", "\u2581Health", "\u2581#", "\u2581Peace", "\u2581", "&", "\u2581amp", ";", "\u2581#", "\u2581Art", "\u2581https", "://", "t", ".", "co", "/", "a", "K", "v", "s", "WS", "5", "y", "O", "a", "</s>"], "target_sentence": ["\u2581S", "\u2581A", "\u2581I", "\u2581L", "\u2581O", "\u2581R", ".", ".", ".", "\u2581#", "\u2581Photo", "\u2581by", "\u2581Din", "k", "o", "\u2581#", "\u2581Dream", "\u2581#", "\u2581Love", "\u2581#", "\u2581Hope", "\u2581#", "\u2581Health", "\u2581#", "\u2581Peace", "\u2581", "&", "\u2581amp", ";", "\u2581#", "\u2581Art", "\u2581https", "://", "t", ".", "co", "/", "a", "K", "v", "s", "WS", "5", "y", "O", "a", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1207", "sentence": ["\u2581Daily", "\u2581question", "\u258115", "23", ":", "\u2581See", "\u2581", "if", "\u2581you", "\u2581won", "!", "\u2581https", "://", "t", ".", "co", "/", "b", "FI", "g", "z", "5", "q", "P", "n", "X", "\u2581#", "\u2581win", "\u2581#", "\u2581winners", "\u2581https", "://", "t", ".", "co", "/", "p", "4", "a", "9", "c", "if", "6", "O", "j", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Daily", "\u2581question", "\u258115", "23", ":", "\u2581See", "\u2581", "if", "\u2581you", "\u2581won", "!", "\u2581https", "://", "t", ".", "co", "/", "b", "FI", "g", "z", "5", "q", "P", "n", "X", "\u2581#", "\u2581win", "\u2581#", "\u2581winners", "\u2581https", "://", "t", ".", "co", "/", "p", "4", "a", "9", "c", "if", "6", "O", "j", "</s>"], "target_sentence": ["\u2581Daily", "\u2581question", "\u258115", "23", ":", "\u2581See", "\u2581", "if", "\u2581you", "\u2581won", "!", "\u2581https", "://", "t", ".", "co", "/", "b", "FI", "g", "z", "5", "q", "P", "n", "X", "\u2581#", "\u2581win", "\u2581#", "\u2581winners", "\u2581https", "://", "t", ".", "co", "/", "p", "4", "a", "9", "c", "if", "6", "O", "j", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1208", "sentence": ["\u2581Mad", "am", "a", "\u2581butterfly", "\u2581in", "\u2581the", "\u2581English", "\u2581pub", ":", "\u2581for", "\u2581those", "\u2581who", "\u2581loves", "\u2581opera", "\u2581with", "\u2581their", "\u2581pin", "t", ".", "\u2581", "\u2014", "\u2581feeling", "\u2581intrigued", "\u2581at", "\u2581King", "'", "\u2581", "s", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "Z", "Y", "q", "g", "h", "g", "Q", "B", "Y", "p", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Mad", "am", "a", "\u2581butterfly", "\u2581in", "\u2581the", "\u2581English", "\u2581pub", ":", "\u2581for", "\u2581those", "\u2581who", "\u2581loves", "\u2581opera", "\u2581with", "\u2581their", "\u2581pin", "t", ".", "\u2581", "\u2014", "\u2581feeling", "\u2581intrigued", "\u2581at", "\u2581King", "'", "\u2581", "s", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "Z", "Y", "q", "g", "h", "g", "Q", "B", "Y", "p", "</s>"], "target_sentence": ["<m>", "\u2581Mad", "am", "a", "\u2581butterfly", "</m>", "\u2581in", "\u2581the", "\u2581English", "\u2581pub", ":", "\u2581for", "\u2581those", "\u2581who", "\u2581loves", "\u2581opera", "\u2581with", "\u2581their", "\u2581pin", "t", ".", "\u2581", "\u2014", "\u2581feeling", "\u2581intrigued", "\u2581at", "\u2581King", "'", "\u2581", "s", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "Z", "Y", "q", "g", "h", "g", "Q", "B", "Y", "p", "</s>"], "subtoken_map": [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1209", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ric", "ard", "o", "j", "kay", ":", "\u2581someone", ":", "\u2581", "ur", "\u2581crush", "\u2581is", "\u2581coming", "\u2581act", "\u2581natural", "\u2581me", ":", "\u2581https", "://", "t", ".", "co", "/", "G", "k", "H", "J", "o", "Y", "T", "g", "R", "W", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "ric", "ard", "o", "j", "kay", ":", "\u2581someone", ":", "\u2581", "ur", "\u2581crush", "\u2581is", "\u2581coming", "\u2581act", "\u2581natural", "\u2581me", ":", "\u2581https", "://", "t", ".", "co", "/", "G", "k", "H", "J", "o", "Y", "T", "g", "R", "W", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "ric", "ard", "o", "j", "kay", ":", "\u2581someone", ":", "\u2581", "ur", "\u2581crush", "\u2581is", "\u2581coming", "\u2581act", "\u2581natural", "\u2581me", ":", "\u2581https", "://", "t", ".", "co", "/", "G", "k", "H", "J", "o", "Y", "T", "g", "R", "W", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1210", "sentence": ["\u2581Do", "\u2581You", "\u2581Have", "\u2581News", "\u2581to", "\u2581Share", "?", "\u2581Get", "\u2581It", "\u2581Published", ".", "\u2581https", "://", "t", ".", "co", "/", "K", "X", "f", "F", "d", "D", "c", "PE", "6", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Do", "\u2581You", "\u2581Have", "\u2581News", "\u2581to", "\u2581Share", "?", "\u2581Get", "\u2581It", "\u2581Published", ".", "\u2581https", "://", "t", ".", "co", "/", "K", "X", "f", "F", "d", "D", "c", "PE", "6", "</s>"], "target_sentence": ["\u2581Do", "\u2581You", "\u2581Have", "\u2581News", "\u2581to", "\u2581Share", "?", "\u2581Get", "\u2581It", "\u2581Published", ".", "\u2581https", "://", "t", ".", "co", "/", "K", "X", "f", "F", "d", "D", "c", "PE", "6", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1211", "sentence": ["\u2581People", "\u2581Say", "\u2581I", "\u2581Sound", "\u2581Crazy", "\u2581When", "\u2581I", "\u2581Say", "\u2581This", ",", "\u2581But", "\u2581I", "\u2581Can", "\u2581Not", "t", "t", "t", "t", "t", "\u2581Hang", "\u2581With", "\u2581People", "\u2581Who", "\u2581Don", "'", "\u2581", "t", "\u2581Smok", "e", "!", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581People", "\u2581Say", "\u2581I", "\u2581Sound", "\u2581Crazy", "\u2581When", "\u2581I", "\u2581Say", "\u2581This", ",", "\u2581But", "\u2581I", "\u2581Can", "\u2581Not", "t", "t", "t", "t", "t", "\u2581Hang", "\u2581With", "\u2581People", "\u2581Who", "\u2581Don", "'", "\u2581", "t", "\u2581Smok", "e", "!", "</s>"], "target_sentence": ["\u2581People", "\u2581Say", "\u2581I", "\u2581Sound", "\u2581Crazy", "\u2581When", "\u2581I", "\u2581Say", "\u2581This", ",", "\u2581But", "\u2581I", "\u2581Can", "\u2581Not", "t", "t", "t", "t", "t", "\u2581Hang", "\u2581With", "\u2581People", "\u2581Who", "\u2581Don", "'", "\u2581", "t", "\u2581Smok", "e", "!", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21, 22, 23], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1212", "sentence": ["\u2581", "RT", "\u2581@", "\u2581am", "ber", "\u2581", "_", "\u2581", "e", "ly", "xx", ":", "\u2581Everything", "\u2581happens", "\u2581for", "\u2581", "a", "\u2581reason", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581am", "ber", "\u2581", "_", "\u2581", "e", "ly", "xx", ":", "\u2581Everything", "\u2581happens", "\u2581for", "\u2581", "a", "\u2581reason", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581am", "ber", "</m>", "\u2581", "_", "<m>", "\u2581", "e", "ly", "xx", "</m>", ":", "\u2581Everything", "\u2581happens", "\u2581for", "\u2581", "a", "\u2581reason", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1213", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "kla", "the", "ly", "ric", "ist", ":", "\u2581I", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581fin", "n", "a", "\u2581bull", "s", "hit", "\u2581with", "\u2581you", ".", ".", ".", "\u2581Grow", "\u2581or", "\u2581go", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "kla", "the", "ly", "ric", "ist", ":", "\u2581I", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581fin", "n", "a", "\u2581bull", "s", "hit", "\u2581with", "\u2581you", ".", ".", ".", "\u2581Grow", "\u2581or", "\u2581go", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "kla", "the", "ly", "ric", "ist", "</m>", ":", "\u2581I", "\u2581", "a", "in", "'", "\u2581", "t", "\u2581fin", "n", "a", "\u2581bull", "s", "hit", "\u2581with", "\u2581you", ".", ".", ".", "\u2581Grow", "\u2581or", "\u2581go", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7, 8, 8, 8, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1214", "sentence": ["\u2581", "RT", "\u2581@", "\u2581L", "l", "TF", "RE", "EST", "Y", "LES", ":", "\u2581Fan", "\u2581", "s", "pit", "s", "\u2581some", "\u2581bars", "\u2581for", "\u2581Li", "l", "\u2581Yacht", "y", "\u2581https", "://", "t", ".", "co", "/", "Q", "9", "I", "h", "FE", "d", "q", "5", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581L", "l", "TF", "RE", "EST", "Y", "LES", ":", "\u2581Fan", "\u2581", "s", "pit", "s", "\u2581some", "\u2581bars", "\u2581for", "\u2581Li", "l", "\u2581Yacht", "y", "\u2581https", "://", "t", ".", "co", "/", "Q", "9", "I", "h", "FE", "d", "q", "5", "X", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581L", "l", "TF", "RE", "EST", "Y", "LES", ":", "\u2581Fan", "\u2581", "s", "pit", "s", "\u2581some", "\u2581bars", "\u2581for", "<m>", "<m>", "\u2581Li", "l", "\u2581Yacht", "y", "</m>", "</m>", "\u2581https", "://", "t", ".", "co", "/", "Q", "9", "I", "h", "FE", "d", "q", "5", "X", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 5, 6, 7, 8, 9, 9, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1215", "sentence": ["\u2581Not", "\u2581in", "\u2581his", "\u2581wheel", "\u2581house", "!", "\u2581Trump", "i", "e", "\u2581is", "\u2581so", "o", "\u2581dump", "\u2581", "he", "\u2581don", "'", "\u2581", "t", "\u2581know", "\u2581what", "\u2581", "he", "\u2581don", "'", "\u2581", "t", "\u2581know", "!", "\u2581To", "\u2581stupid", "\u2581to", "\u2581ask", "\u2581for", "\u2581help", "\u2581or", "\u2581advice", "\u2581", "f", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "a", "b", "UL", "F", "w", "u", "v", "W", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Not", "\u2581in", "\u2581his", "\u2581wheel", "\u2581house", "!", "\u2581Trump", "i", "e", "\u2581is", "\u2581so", "o", "\u2581dump", "\u2581", "he", "\u2581don", "'", "\u2581", "t", "\u2581know", "\u2581what", "\u2581", "he", "\u2581don", "'", "\u2581", "t", "\u2581know", "!", "\u2581To", "\u2581stupid", "\u2581to", "\u2581ask", "\u2581for", "\u2581help", "\u2581or", "\u2581advice", "\u2581", "f", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "a", "b", "UL", "F", "w", "u", "v", "W", "w", "</s>"], "target_sentence": ["\u2581Not", "\u2581in", "\u2581his", "\u2581wheel", "\u2581house", "!", "<m>", "\u2581Trump", "i", "e", "</m>", "\u2581is", "\u2581so", "o", "\u2581dump", "\u2581", "he", "\u2581don", "'", "\u2581", "t", "\u2581know", "\u2581what", "\u2581", "he", "\u2581don", "'", "\u2581", "t", "\u2581know", "!", "\u2581To", "\u2581stupid", "\u2581to", "\u2581ask", "\u2581for", "\u2581help", "\u2581or", "\u2581advice", "\u2581", "f", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/", "a", "b", "UL", "F", "w", "u", "v", "W", "w", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 6, 6, 7, 8, 8, 9, 10, 10, 11, 12, 13, 13, 14, 15, 16, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1216", "sentence": ["\u2581stunning", "\u2581earrings", "\u2581https", "://", "t", ".", "co", "/", "I", "r", "U", "c", "g", "Y", "x", "k", "26", "\u2581https", "://", "t", ".", "co", "/", "Y", "er", "X", "g", "De", "L", "f", "P", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581stunning", "\u2581earrings", "\u2581https", "://", "t", ".", "co", "/", "I", "r", "U", "c", "g", "Y", "x", "k", "26", "\u2581https", "://", "t", ".", "co", "/", "Y", "er", "X", "g", "De", "L", "f", "P", "</s>"], "target_sentence": ["\u2581stunning", "\u2581earrings", "\u2581https", "://", "t", ".", "co", "/", "I", "r", "U", "c", "g", "Y", "x", "k", "26", "\u2581https", "://", "t", ".", "co", "/", "Y", "er", "X", "g", "De", "L", "f", "P", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1217", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "n", "ak", "be", "bel", ":", "\u2581https", "://", "t", ".", "co", "/", "n", "v", "v", "C", "11", "J", "f", "e", "9", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "n", "ak", "be", "bel", ":", "\u2581https", "://", "t", ".", "co", "/", "n", "v", "v", "C", "11", "J", "f", "e", "9", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "n", "ak", "be", "bel", ":", "\u2581https", "://", "t", ".", "co", "/", "n", "v", "v", "C", "11", "J", "f", "e", "9", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1218", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "n", "p", "r", "music", ":", "\u2581Watch", "\u2581@", "\u2581Chic", "an", "o", "B", "at", "man", ",", "\u2581@", "\u2581spoon", "the", "band", "\u2581and", "\u2581@", "\u2581The", "Val", "erie", "J", "une", "\u2581live", "\u2581from", "\u2581#", "\u2581S", "X", "SW", "\u2581beginning", "\u2581at", "\u25811", "\u2581", "p", ".", "\u2581", "m", ".", "\u2581ET", "\u2581via", "\u2581@", "\u2581V", "u", "H", "aus", ".", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "n", "p", "r", "music", ":", "\u2581Watch", "\u2581@", "\u2581Chic", "an", "o", "B", "at", "man", ",", "\u2581@", "\u2581spoon", "the", "band", "\u2581and", "\u2581@", "\u2581The", "Val", "erie", "J", "une", "\u2581live", "\u2581from", "\u2581#", "\u2581S", "X", "SW", "\u2581beginning", "\u2581at", "\u25811", "\u2581", "p", ".", "\u2581", "m", ".", "\u2581ET", "\u2581via", "\u2581@", "\u2581V", "u", "H", "aus", ".", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "n", "p", "r", "music", ":", "\u2581Watch", "\u2581@", "<m>", "\u2581Chic", "an", "o", "B", "at", "man", "</m>", ",", "\u2581@", "<m>", "\u2581spoon", "the", "band", "</m>", "\u2581and", "\u2581@", "<m>", "\u2581The", "Val", "erie", "J", "une", "</m>", "\u2581live", "\u2581from", "\u2581#", "<m>", "\u2581S", "X", "SW", "</m>", "\u2581beginning", "\u2581at", "\u25811", "\u2581", "p", ".", "\u2581", "m", ".", "\u2581ET", "\u2581via", "\u2581@", "\u2581V", "u", "H", "aus", ".", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 7, 8, 9, 9, 9, 10, 11, 12, 12, 12, 12, 12, 13, 14, 15, 16, 16, 16, 17, 18, 19, 20, 20, 21, 22, 22, 23, 24, 25, 26, 27, 27, 27, 27, 28, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, 3, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1219", "sentence": ["\u2581\"", "\u2581[", "\u2581W", "]", "\u2581", "hen", "\u2581the", "\u2581bad", "\u2581people", "\u2581are", "\u2581right", "\u2581here", "\u2581under", "\u2581our", "\u2581nose", "s", ".", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "J", "9", "l", "F", "c", "R", "p", "2", "x", "j", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581\"", "\u2581[", "\u2581W", "]", "\u2581", "hen", "\u2581the", "\u2581bad", "\u2581people", "\u2581are", "\u2581right", "\u2581here", "\u2581under", "\u2581our", "\u2581nose", "s", ".", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "J", "9", "l", "F", "c", "R", "p", "2", "x", "j", "</s>"], "target_sentence": ["\u2581\"", "\u2581[", "\u2581W", "]", "\u2581", "hen", "\u2581the", "\u2581bad", "\u2581people", "\u2581are", "\u2581right", "\u2581here", "\u2581under", "\u2581our", "\u2581nose", "s", ".", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "J", "9", "l", "F", "c", "R", "p", "2", "x", "j", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1220", "sentence": ["\u2581", "RT", "\u2581@", "\u2581W", "TF", "\u2581", "_", "\u2581E", "h", ":", "\u2581@", "\u2581She", "il", "a", "G", "un", "n", "Re", "i", "d", "\u2581@", "\u2581The", "Re", "bel", "TV", "\u2581You", "\u2581", "n", "ailed", "\u2581it", ".", "\u2581#", "\u2581N", "DP", "\u2581#", "\u2581ab", "poli", "\u2581#", "\u2581Not", "ley", "\u2581https", "://", "t", ".", "co", "/", "x", "b", "G", "X", "A", "l", "z", "2", "q", "9", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581W", "TF", "\u2581", "_", "\u2581E", "h", ":", "\u2581@", "\u2581She", "il", "a", "G", "un", "n", "Re", "i", "d", "\u2581@", "\u2581The", "Re", "bel", "TV", "\u2581You", "\u2581", "n", "ailed", "\u2581it", ".", "\u2581#", "\u2581N", "DP", "\u2581#", "\u2581ab", "poli", "\u2581#", "\u2581Not", "ley", "\u2581https", "://", "t", ".", "co", "/", "x", "b", "G", "X", "A", "l", "z", "2", "q", "9", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581W", "TF", "\u2581", "_", "\u2581E", "h", ":", "\u2581@", "<m>", "\u2581She", "il", "a", "G", "un", "n", "Re", "i", "d", "</m>", "\u2581@", "\u2581The", "Re", "bel", "TV", "\u2581You", "\u2581", "n", "ailed", "\u2581it", ".", "\u2581#", "\u2581N", "DP", "\u2581#", "\u2581ab", "poli", "\u2581#", "\u2581Not", "ley", "\u2581https", "://", "t", ".", "co", "/", "x", "b", "G", "X", "A", "l", "z", "2", "q", "9", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 9, 9, 9, 10, 11, 11, 11, 12, 13, 14, 15, 15, 16, 17, 17, 18, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1221", "sentence": ["\u2581#", "\u2581resist", "\u2581#", "\u2581respect", "\u2581https", "://", "t", ".", "co", "/", "S", "33", "A", "q", "n", "z", "c", "2", "r", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581resist", "\u2581#", "\u2581respect", "\u2581https", "://", "t", ".", "co", "/", "S", "33", "A", "q", "n", "z", "c", "2", "r", "</s>"], "target_sentence": ["\u2581#", "\u2581resist", "\u2581#", "\u2581respect", "\u2581https", "://", "t", ".", "co", "/", "S", "33", "A", "q", "n", "z", "c", "2", "r", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1222", "sentence": ["\u2581I", "\u2581just", "\u2581want", "\u2581", "a", "\u2581man", "\u2581that", "\u2581loves", "\u2581me", "\u2581the", "\u2581way", "\u2581Jack", "\u2581Pearson", "\u2581loves", "\u2581Rebecca", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581I", "\u2581just", "\u2581want", "\u2581", "a", "\u2581man", "\u2581that", "\u2581loves", "\u2581me", "\u2581the", "\u2581way", "\u2581Jack", "\u2581Pearson", "\u2581loves", "\u2581Rebecca", ".", "</s>"], "target_sentence": ["\u2581I", "\u2581just", "\u2581want", "\u2581", "a", "\u2581man", "\u2581that", "\u2581loves", "\u2581me", "\u2581the", "\u2581way", "<m>", "<m>", "\u2581Jack", "\u2581Pearson", "</m>", "\u2581loves", "<m>", "\u2581Rebecca", "</m>", "</m>", ".", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, 3, 4, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, 0, -1, 2, -1, 2, 1, -1, -1]}, {"doc_id": "emerging.test_1223", "sentence": ["\u2581", "RT", "\u2581@", "\u2581twenty", "one", "pilot", "s", ":", "\u2581", "f", "e", "b", "\u258126", "\u2581", "n", "\u2581", "char", "le", "ston", "\u2581#", "\u2581", "ERS", "\u25812017", "\u2581photos", "\u2581are", "\u2581up", ":", "\u2581https", "://", "t", ".", "co", "/", "d", "X", "f", "5", "v", "t", "i", "3", "RU", "\u2581https", "://", "t", ".", "co", "/", "e", "c", "L", "y", "pm", "n", "xx", "u", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581twenty", "one", "pilot", "s", ":", "\u2581", "f", "e", "b", "\u258126", "\u2581", "n", "\u2581", "char", "le", "ston", "\u2581#", "\u2581", "ERS", "\u25812017", "\u2581photos", "\u2581are", "\u2581up", ":", "\u2581https", "://", "t", ".", "co", "/", "d", "X", "f", "5", "v", "t", "i", "3", "RU", "\u2581https", "://", "t", ".", "co", "/", "e", "c", "L", "y", "pm", "n", "xx", "u", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581twenty", "one", "pilot", "s", ":", "\u2581", "f", "e", "b", "\u258126", "\u2581", "n", "<m>", "\u2581", "char", "le", "ston", "</m>", "\u2581#", "<m>", "\u2581", "ERS", "\u25812017", "</m>", "\u2581photos", "\u2581are", "\u2581up", ":", "\u2581https", "://", "t", ".", "co", "/", "d", "X", "f", "5", "v", "t", "i", "3", "RU", "\u2581https", "://", "t", ".", "co", "/", "e", "c", "L", "y", "pm", "n", "xx", "u", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 4, 4, 5, 6, 6, 7, 7, 7, 7, 8, 9, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1224", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "y", "U", "v", "Y", "v", "j", "L", "h", "N", "i", "\u2581Listen", "\u2581to", "\u2581your", "\u2581body", ",", "\u2581your", "\u2581doctor", "\u2581and", "\u2581your", "\u2581common", "\u2581sense", "\u2581about", "\u2581work", "-", "related", "\u2581injuries", ".", "\u2581https", "://", "t", ".", "co", "/", "zz", "1", "w", "n", "f", "m", "Q", "Q", "R", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "y", "U", "v", "Y", "v", "j", "L", "h", "N", "i", "\u2581Listen", "\u2581to", "\u2581your", "\u2581body", ",", "\u2581your", "\u2581doctor", "\u2581and", "\u2581your", "\u2581common", "\u2581sense", "\u2581about", "\u2581work", "-", "related", "\u2581injuries", ".", "\u2581https", "://", "t", ".", "co", "/", "zz", "1", "w", "n", "f", "m", "Q", "Q", "R", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "y", "U", "v", "Y", "v", "j", "L", "h", "N", "i", "\u2581Listen", "\u2581to", "\u2581your", "\u2581body", ",", "\u2581your", "\u2581doctor", "\u2581and", "\u2581your", "\u2581common", "\u2581sense", "\u2581about", "\u2581work", "-", "related", "\u2581injuries", ".", "\u2581https", "://", "t", ".", "co", "/", "zz", "1", "w", "n", "f", "m", "Q", "Q", "R", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1225", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Fl", "i", "r", "t", "y", "Not", "e", "s", ":", "\u2581You", "\u2581never", "\u2581really", "\u2581stop", "\u2581loving", "\u2581someone", ".", "\u2581You", "\u2581just", "\u2581learn", "\u2581to", "\u2581live", "\u2581without", "\u2581them", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Fl", "i", "r", "t", "y", "Not", "e", "s", ":", "\u2581You", "\u2581never", "\u2581really", "\u2581stop", "\u2581loving", "\u2581someone", ".", "\u2581You", "\u2581just", "\u2581learn", "\u2581to", "\u2581live", "\u2581without", "\u2581them", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Fl", "i", "r", "t", "y", "Not", "e", "s", "</m>", ":", "\u2581You", "\u2581never", "\u2581really", "\u2581stop", "\u2581loving", "\u2581someone", ".", "\u2581You", "\u2581just", "\u2581learn", "\u2581to", "\u2581live", "\u2581without", "\u2581them", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1226", "sentence": ["\u2581@", "\u2581CBS", "Sport", "s", "\u2581@", "\u2581Prime", "Le", "Bro", "n", "\u2581I", "\u2581hate", "\u2581that", "\u2581family", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581CBS", "Sport", "s", "\u2581@", "\u2581Prime", "Le", "Bro", "n", "\u2581I", "\u2581hate", "\u2581that", "\u2581family", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "<m>", "\u2581CBS", "Sport", "s", "</m>", "</m>", "\u2581@", "\u2581Prime", "Le", "Bro", "n", "\u2581I", "\u2581hate", "\u2581that", "\u2581family", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1227", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "bou", "je", "e", "t", "u", "an", ":", "\u2581mark", ":", "\u2581", "-", "\u2581\"", "\u2581", "i", "\u2581was", "\u2581in", "\u2581boy", "\u2581", "s", "cou", "t", "s", "\u2581", "i", "\u2581know", "\u2581what", "\u2581im", "\u2581doing", "!", "\u2581\"", "\u2581", "-", "\u2581", "he", "\u2581dont", "\u2581know", "\u2581what", "\u2581", "he", "\u2581doing", "\u2581", "-", "\u2581already", "\u2581started", "\u2581growing", "\u2581", "weed", "\u2581", "-", "\u2581", "s", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "bou", "je", "e", "t", "u", "an", ":", "\u2581mark", ":", "\u2581", "-", "\u2581\"", "\u2581", "i", "\u2581was", "\u2581in", "\u2581boy", "\u2581", "s", "cou", "t", "s", "\u2581", "i", "\u2581know", "\u2581what", "\u2581im", "\u2581doing", "!", "\u2581\"", "\u2581", "-", "\u2581", "he", "\u2581dont", "\u2581know", "\u2581what", "\u2581", "he", "\u2581doing", "\u2581", "-", "\u2581already", "\u2581started", "\u2581growing", "\u2581", "weed", "\u2581", "-", "\u2581", "s", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "bou", "je", "e", "t", "u", "an", ":", "<m>", "\u2581mark", "</m>", ":", "\u2581", "-", "\u2581\"", "\u2581", "i", "\u2581was", "\u2581in", "<m>", "\u2581boy", "\u2581", "s", "cou", "t", "s", "</m>", "\u2581", "i", "\u2581know", "\u2581what", "\u2581im", "\u2581doing", "!", "\u2581\"", "\u2581", "-", "\u2581", "he", "\u2581dont", "\u2581know", "\u2581what", "\u2581", "he", "\u2581doing", "\u2581", "-", "\u2581already", "\u2581started", "\u2581growing", "\u2581", "weed", "\u2581", "-", "\u2581", "s", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 8, 9, 10, 11, 12, 12, 12, 12, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21, 22, 23, 24, 25, 25, 26, 27, 27, 28, 29, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1228", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Who", "a", "die", "B", "re", "e", "s", ":", "\u2581Tat", "um", "\u2581really", "\u2581Prime", "\u2581Mel", "o", "\u2581in", "\u2581the", "\u2581is", "o", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Who", "a", "die", "B", "re", "e", "s", ":", "\u2581Tat", "um", "\u2581really", "\u2581Prime", "\u2581Mel", "o", "\u2581in", "\u2581the", "\u2581is", "o", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Who", "a", "die", "B", "re", "e", "s", ":", "<m>", "\u2581Tat", "um", "</m>", "\u2581really", "\u2581Prime", "\u2581Mel", "o", "\u2581in", "\u2581the", "<m>", "\u2581is", "o", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1]}, {"doc_id": "emerging.test_1229", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Female", "K", "now", "s", ":", "\u2581@", "\u2581anyone", "\u2581who", "'", "\u2581", "s", "\u2581ever", "\u2581tried", "\u2581to", "\u2581", "d", "m", "\u2581or", "\u2581text", "\u2581me", "\u2581https", "://", "t", ".", "co", "/", "0", "z", "I", "1", "d", "5", "m", "x", "f", "G", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Female", "K", "now", "s", ":", "\u2581@", "\u2581anyone", "\u2581who", "'", "\u2581", "s", "\u2581ever", "\u2581tried", "\u2581to", "\u2581", "d", "m", "\u2581or", "\u2581text", "\u2581me", "\u2581https", "://", "t", ".", "co", "/", "0", "z", "I", "1", "d", "5", "m", "x", "f", "G", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Female", "K", "now", "s", ":", "\u2581@", "\u2581anyone", "\u2581who", "'", "\u2581", "s", "\u2581ever", "\u2581tried", "\u2581to", "\u2581", "d", "m", "\u2581or", "\u2581text", "\u2581me", "\u2581https", "://", "t", ".", "co", "/", "0", "z", "I", "1", "d", "5", "m", "x", "f", "G", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1230", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "jack", "i", "e", "dom", "ing", "ez", ":", "\u2581the", "\u2581lo", "m", "l", "\u2581picked", "\u2581this", "\u2581https", "://", "t", ".", "co", "/", "j", "PB", "e", "i", "J", "n", "D", "i", "p", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "jack", "i", "e", "dom", "ing", "ez", ":", "\u2581the", "\u2581lo", "m", "l", "\u2581picked", "\u2581this", "\u2581https", "://", "t", ".", "co", "/", "j", "PB", "e", "i", "J", "n", "D", "i", "p", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "jack", "i", "e", "dom", "ing", "ez", "</m>", ":", "\u2581the", "\u2581lo", "m", "l", "\u2581picked", "\u2581this", "\u2581https", "://", "t", ".", "co", "/", "j", "PB", "e", "i", "J", "n", "D", "i", "p", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1231", "sentence": ["\u2581@", "\u2581Hug", "o", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581Hug", "o", "\u2581check", "\u2581it", "\u2581https", "://", "t", ".", "co", "/8", "79", "v", "3", "g", "O", "y", "t", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Hug", "o", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581Hug", "o", "\u2581check", "\u2581it", "\u2581https", "://", "t", ".", "co", "/8", "79", "v", "3", "g", "O", "y", "t", "y", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Hug", "o", "</m>", "\u2581", "_", "\u2581", "_", "\u2581", "_", "\u2581", "_", "<m>", "\u2581Hug", "o", "</m>", "\u2581check", "\u2581it", "\u2581https", "://", "t", ".", "co", "/8", "79", "v", "3", "g", "O", "y", "t", "y", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1232", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Marsh", "m", "allow", "Do", "of", ":", "\u2581I", "\u2581did", "\u2581drawn", "\u2581the", "\u2581Tiger", "\u2581Mama", "\u2581", "\u2605", "\u2581", "\u2605", "\u2581", "\u2605", "\u2581@", "\u2581B", "ux", "b", "i", "Art", "s", "\u2581https", "://", "t", ".", "co", "/", "j", "j", "v", "S", "2", "a", "L", "y", "H", "b", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Marsh", "m", "allow", "Do", "of", ":", "\u2581I", "\u2581did", "\u2581drawn", "\u2581the", "\u2581Tiger", "\u2581Mama", "\u2581", "\u2605", "\u2581", "\u2605", "\u2581", "\u2605", "\u2581@", "\u2581B", "ux", "b", "i", "Art", "s", "\u2581https", "://", "t", ".", "co", "/", "j", "j", "v", "S", "2", "a", "L", "y", "H", "b", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Marsh", "m", "allow", "Do", "of", ":", "\u2581I", "\u2581did", "\u2581drawn", "\u2581the", "<m>", "\u2581Tiger", "\u2581Mama", "</m>", "\u2581", "\u2605", "\u2581", "\u2605", "\u2581", "\u2605", "\u2581@", "\u2581B", "ux", "b", "i", "Art", "s", "\u2581https", "://", "t", ".", "co", "/", "j", "j", "v", "S", "2", "a", "L", "y", "H", "b", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 11, 12, 12, 13, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1233", "sentence": ["\u2581", "RT", "\u2581@", "\u2581de", "f", "e", "i", "to", "s", "la", "ur", "en", "\u2581", "_", ":", "\u2581error", "\u2581", "404", "\u2581could", "\u2581not", "\u2581found", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581de", "f", "e", "i", "to", "s", "la", "ur", "en", "\u2581", "_", ":", "\u2581error", "\u2581", "404", "\u2581could", "\u2581not", "\u2581found", "</s>"], "target_sentence": ["\u2581", "RT", "<m>", "\u2581@", "\u2581de", "f", "e", "i", "to", "s", "la", "ur", "en", "</m>", "\u2581", "_", ":", "\u2581error", "\u2581", "404", "\u2581could", "\u2581not", "\u2581found", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 4, 5, 6, 6, 7, 8, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1234", "sentence": ["\u2581Nex", "us", "\u25816", "\u2581P", "\u2581|", "\u2581Nex", "us", "\u25816", "\u2581Sleeve", "\u2581Shop", ":", "\u2581https", "://", "t", ".", "co", "/", "R", "g", "2", "e", "o", "p", "R", "p", "W", "B", "\u2581|", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581P", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581PS", "le", "e", "ve", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581PC", "over", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581", "PL", "eat", "her", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581PC", "a", "s", "e", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Nex", "us", "\u25816", "\u2581P", "\u2581|", "\u2581Nex", "us", "\u25816", "\u2581Sleeve", "\u2581Shop", ":", "\u2581https", "://", "t", ".", "co", "/", "R", "g", "2", "e", "o", "p", "R", "p", "W", "B", "\u2581|", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581P", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581PS", "le", "e", "ve", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581PC", "over", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581", "PL", "eat", "her", "\u2581#", "\u2581Nex", "us", "\u25816", "\u2581PC", "a", "s", "e", "</s>"], "target_sentence": ["<m>", "\u2581Nex", "us", "\u25816", "\u2581P", "</m>", "\u2581|", "<m>", "<m>", "\u2581Nex", "us", "\u25816", "</m>", "\u2581Sleeve", "</m>", "\u2581Shop", ":", "\u2581https", "://", "t", ".", "co", "/", "R", "g", "2", "e", "o", "p", "R", "p", "W", "B", "\u2581|", "\u2581#", "<m>", "\u2581Nex", "us", "\u25816", "</m>", "\u2581P", "\u2581#", "<m>", "<m>", "\u2581Nex", "us", "\u25816", "</m>", "</m>", "\u2581#", "<m>", "\u2581Nex", "us", "\u25816", "\u2581PS", "le", "e", "ve", "</m>", "\u2581#", "<m>", "<m>", "\u2581Nex", "us", "\u25816", "\u2581PC", "over", "</m>", "</m>", "\u2581#", "<m>", "<m>", "\u2581Nex", "us", "\u25816", "</m>", "\u2581", "PL", "eat", "her", "</m>", "\u2581#", "<m>", "\u2581Nex", "us", "\u25816", "\u2581PC", "a", "s", "e", "</m>", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 11, 12, 12, 13, 14, 15, 16, 16, 17, 18, 19, 19, 20, 21, 21, 21, 21, 22, 23, 23, 24, 25, 25, 26, 27, 27, 28, 29, 29, 29, 29, 30, 31, 31, 32, 33, 33, 33, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, 1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, 1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, 1, 5, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1], "ent_indices": [0, -1, -1, -1, -1, 0, -1, 1, 2, -1, -1, -1, 1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, 3, -1, -1, 5, 4, -1, -1, -1, 5, 4, -1, 6, -1, -1, -1, -1, -1, -1, -1, 6, -1, 8, 7, -1, -1, -1, -1, -1, 8, 7, -1, 9, 10, -1, -1, -1, 9, -1, -1, -1, -1, 10, -1, 11, -1, -1, -1, -1, -1, -1, -1, 11, -1]}, {"doc_id": "emerging.test_1235", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581Go", "G", "etta", "V", "e", "e", ":", "\u2581Mental", "ly", ",", "\u2581none", "\u2581of", "\u2581this", "\u2581", "s", "hit", "\u2581can", "\u2581phase", "\u2581me", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581Go", "G", "etta", "V", "e", "e", ":", "\u2581Mental", "ly", ",", "\u2581none", "\u2581of", "\u2581this", "\u2581", "s", "hit", "\u2581can", "\u2581phase", "\u2581me", ".", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "_", "\u2581Go", "G", "etta", "V", "e", "e", ":", "\u2581Mental", "ly", ",", "\u2581none", "\u2581of", "\u2581this", "\u2581", "s", "hit", "\u2581can", "\u2581phase", "\u2581me", ".", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 3, 3, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1236", "sentence": ["\u2581", "/", ".", "\u2581Trump", "\u2581administration", "\u2581rolls", "\u2581back", "\u2581protection", "s", "\u2581for", "\u2581people", "\u2581in", "\u2581default", "\u2581on", "\u2581student", "\u2581loans", "\u2581https", "://", "t", ".", "co", "/", "Y", "P", "e", "2", "DR", "s", "j", "Le", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "/", ".", "\u2581Trump", "\u2581administration", "\u2581rolls", "\u2581back", "\u2581protection", "s", "\u2581for", "\u2581people", "\u2581in", "\u2581default", "\u2581on", "\u2581student", "\u2581loans", "\u2581https", "://", "t", ".", "co", "/", "Y", "P", "e", "2", "DR", "s", "j", "Le", "</s>"], "target_sentence": ["\u2581", "/", ".", "<m>", "\u2581Trump", "\u2581administration", "</m>", "\u2581rolls", "\u2581back", "\u2581protection", "s", "\u2581for", "\u2581people", "\u2581in", "\u2581default", "\u2581on", "\u2581student", "\u2581loans", "\u2581https", "://", "t", ".", "co", "/", "Y", "P", "e", "2", "DR", "s", "j", "Le", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1237", "sentence": ["\u2581How", ",", "\u2581Ru", "s", "s", "?", "\u2581#", "\u2581Thunder", "Up", "\u2581#", "\u2581As", "s", "ist", "O", "f", "The", "N", "ight", "\u2581https", "://", "t", ".", "co", "/", "RP", "OP", "m", "3", "M", "d", "up", "\u2581#", "\u2581Rhode", "I", "s", "l", "and", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581How", ",", "\u2581Ru", "s", "s", "?", "\u2581#", "\u2581Thunder", "Up", "\u2581#", "\u2581As", "s", "ist", "O", "f", "The", "N", "ight", "\u2581https", "://", "t", ".", "co", "/", "RP", "OP", "m", "3", "M", "d", "up", "\u2581#", "\u2581Rhode", "I", "s", "l", "and", "</s>"], "target_sentence": ["\u2581How", ",", "<m>", "\u2581Ru", "s", "s", "</m>", "?", "\u2581#", "\u2581Thunder", "Up", "\u2581#", "<m>", "\u2581As", "s", "ist", "O", "f", "The", "N", "ight", "</m>", "\u2581https", "://", "t", ".", "co", "/", "RP", "OP", "m", "3", "M", "d", "up", "\u2581#", "<m>", "\u2581Rhode", "I", "s", "l", "and", "</m>", "</s>"], "subtoken_map": [0, 1, 2, 2, 2, 3, 4, 5, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1]}, {"doc_id": "emerging.test_1238", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ho", "bu", "ing", ":", "\u2581\"", "\u2581anyway", "\u2581the", "\u2581members", "\u2581are", "\u2581all", "\u2581doing", "\u2581well", "\u2581\"", "\u2581\"", "\u2581We", "\u2581are", "\u2581not", "\u2581hurt", "\u2581and", "\u2581we", "\u2581are", "\u2581eating", "\u2581well", "\u2581so", "\u2581don", "'", "\u2581", "t", "\u2581worry", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "O", "7", "w", "RP", "y", "Z", "S", "J", "6", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ho", "bu", "ing", ":", "\u2581\"", "\u2581anyway", "\u2581the", "\u2581members", "\u2581are", "\u2581all", "\u2581doing", "\u2581well", "\u2581\"", "\u2581\"", "\u2581We", "\u2581are", "\u2581not", "\u2581hurt", "\u2581and", "\u2581we", "\u2581are", "\u2581eating", "\u2581well", "\u2581so", "\u2581don", "'", "\u2581", "t", "\u2581worry", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "O", "7", "w", "RP", "y", "Z", "S", "J", "6", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581ho", "bu", "ing", ":", "\u2581\"", "\u2581anyway", "\u2581the", "\u2581members", "\u2581are", "\u2581all", "\u2581doing", "\u2581well", "\u2581\"", "\u2581\"", "\u2581We", "\u2581are", "\u2581not", "\u2581hurt", "\u2581and", "\u2581we", "\u2581are", "\u2581eating", "\u2581well", "\u2581so", "\u2581don", "'", "\u2581", "t", "\u2581worry", "\u2581\"", "\u2581https", "://", "t", ".", "co", "/", "O", "7", "w", "RP", "y", "Z", "S", "J", "6", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1239", "sentence": ["\u2581#", "\u2581Voice", "O", "f", "W", "i", "pro", "\u2581#", "\u2581C", "X", "\u2581#", "\u2581Car", "go", "In", "dus", "try", "\u2581#", "\u2581U", "X", "\u2581https", "://", "t", ".", "co", "/", "02", "V", "zy", "4", "m", "D", "q", "c", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581Voice", "O", "f", "W", "i", "pro", "\u2581#", "\u2581C", "X", "\u2581#", "\u2581Car", "go", "In", "dus", "try", "\u2581#", "\u2581U", "X", "\u2581https", "://", "t", ".", "co", "/", "02", "V", "zy", "4", "m", "D", "q", "c", "</s>"], "target_sentence": ["\u2581#", "\u2581Voice", "O", "f", "W", "i", "pro", "\u2581#", "\u2581C", "X", "\u2581#", "<m>", "\u2581Car", "go", "In", "dus", "try", "</m>", "\u2581#", "\u2581U", "X", "\u2581https", "://", "t", ".", "co", "/", "02", "V", "zy", "4", "m", "D", "q", "c", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 5, 5, 5, 6, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1240", "sentence": ["\u2581Perspective", "\u2581is", "\u2581everything", ".", "\u2581https", "://", "t", ".", "co", "/", "z", "3", "t", "0", "P", "o", "9", "k", "n", "b", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Perspective", "\u2581is", "\u2581everything", ".", "\u2581https", "://", "t", ".", "co", "/", "z", "3", "t", "0", "P", "o", "9", "k", "n", "b", "</s>"], "target_sentence": ["\u2581Perspective", "\u2581is", "\u2581everything", ".", "\u2581https", "://", "t", ".", "co", "/", "z", "3", "t", "0", "P", "o", "9", "k", "n", "b", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1241", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "r", "f", "H", "n", "z", "q", "M", "p", "2", "x", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "r", "f", "H", "n", "z", "q", "M", "p", "2", "x", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "r", "f", "H", "n", "z", "q", "M", "p", "2", "x", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1242", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Sal", "Her", "n", "and", "ez", ":", "\u2581Brett", "\u2581Bai", "er", "\u2581says", "\u2581Fox", "\u2581News", "\u2581\"", "\u2581loves", "\u2581\"", "\u2581Judge", "\u2581Andrew", "\u2581Na", "polita", "n", "o", ",", "\u2581but", "\u2581that", "\u2581Fox", "\u2581News", "\u2581was", "\u2581not", "\u2581", "able", "\u2581to", "\u2581verify", "\u2581his", "'", "\u2581report", "'", "\u2581https", "://", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Sal", "Her", "n", "and", "ez", ":", "\u2581Brett", "\u2581Bai", "er", "\u2581says", "\u2581Fox", "\u2581News", "\u2581\"", "\u2581loves", "\u2581\"", "\u2581Judge", "\u2581Andrew", "\u2581Na", "polita", "n", "o", ",", "\u2581but", "\u2581that", "\u2581Fox", "\u2581News", "\u2581was", "\u2581not", "\u2581", "able", "\u2581to", "\u2581verify", "\u2581his", "'", "\u2581report", "'", "\u2581https", "://", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Sal", "Her", "n", "and", "ez", "</m>", ":", "<m>", "\u2581Brett", "\u2581Bai", "er", "</m>", "\u2581says", "\u2581Fox", "\u2581News", "\u2581\"", "\u2581loves", "\u2581\"", "\u2581Judge", "<m>", "\u2581Andrew", "\u2581Na", "polita", "n", "o", "</m>", ",", "\u2581but", "\u2581that", "\u2581Fox", "\u2581News", "\u2581was", "\u2581not", "\u2581", "able", "\u2581to", "\u2581verify", "\u2581his", "'", "\u2581report", "'", "\u2581https", "://", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 29, 29, 30], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1243", "sentence": ["\u2581", "RT", "\u2581@", "\u2581World", "Star", "F", "un", "n", "y", ":", "\u2581Ag", "re", "e", "d", "\u2581https", "://", "t", ".", "co", "/", "g", "x", "HG", "u", "H", "0", "MR", "4", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581World", "Star", "F", "un", "n", "y", ":", "\u2581Ag", "re", "e", "d", "\u2581https", "://", "t", ".", "co", "/", "g", "x", "HG", "u", "H", "0", "MR", "4", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581World", "Star", "F", "un", "n", "y", ":", "\u2581Ag", "re", "e", "d", "\u2581https", "://", "t", ".", "co", "/", "g", "x", "HG", "u", "H", "0", "MR", "4", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1244", "sentence": ["\u2581", "RT", "\u2581@", "\u2581ani", "s", "a", "s", "x", ":", "\u258141", ")", "\u2581Her", "\u2581voice", "\u2581is", "\u2581so", "\u2581monoton", "e", "\u2581lo", "o", "l", "\u2581https", "://", "t", ".", "co", "/", "B", "d", "9", "C", "y", "8", "B", "CF", "v", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581ani", "s", "a", "s", "x", ":", "\u258141", ")", "\u2581Her", "\u2581voice", "\u2581is", "\u2581so", "\u2581monoton", "e", "\u2581lo", "o", "l", "\u2581https", "://", "t", ".", "co", "/", "B", "d", "9", "C", "y", "8", "B", "CF", "v", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581ani", "s", "a", "s", "x", ":", "\u258141", ")", "\u2581Her", "\u2581voice", "\u2581is", "\u2581so", "\u2581monoton", "e", "\u2581lo", "o", "l", "\u2581https", "://", "t", ".", "co", "/", "B", "d", "9", "C", "y", "8", "B", "CF", "v", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1245", "sentence": ["\u2581Al", "a", "in", "\u258133", "78", "\u2581played", "\u2581Pla", "gue", "\u2581Inc", ":", "\u2581E", "vol", "ve", "d", "\u2581(", "\u2581PS", "\u25814", ")", "\u2581in", "\u2581the", "\u2581last", "\u258124", "\u2581hours", "\u2581https", "://", "t", ".", "co", "/6", "T", "m", "2", "Z", "B", "NK", "i", "p", "\u2581#", "\u2581ex", "o", "phase", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Al", "a", "in", "\u258133", "78", "\u2581played", "\u2581Pla", "gue", "\u2581Inc", ":", "\u2581E", "vol", "ve", "d", "\u2581(", "\u2581PS", "\u25814", ")", "\u2581in", "\u2581the", "\u2581last", "\u258124", "\u2581hours", "\u2581https", "://", "t", ".", "co", "/6", "T", "m", "2", "Z", "B", "NK", "i", "p", "\u2581#", "\u2581ex", "o", "phase", "</s>"], "target_sentence": ["<m>", "\u2581Al", "a", "in", "</m>", "\u258133", "78", "\u2581played", "<m>", "<m>", "\u2581Pla", "gue", "\u2581Inc", "</m>", ":", "<m>", "\u2581E", "vol", "ve", "d", "</m>", "</m>", "\u2581(", "<m>", "<m>", "\u2581PS", "\u25814", "</m>", "</m>", ")", "\u2581in", "\u2581the", "\u2581last", "\u258124", "\u2581hours", "\u2581https", "://", "t", ".", "co", "/6", "T", "m", "2", "Z", "B", "NK", "i", "p", "\u2581#", "\u2581ex", "o", "phase", "</s>"], "subtoken_map": [0, 0, 0, 1, 1, 2, 3, 3, 4, 5, 6, 6, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, 2, 4, -1, -1, -1, -1, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, 0, -1, -1, -1, 1, 2, -1, -1, -1, 1, -1, 3, -1, -1, -1, -1, 3, 2, -1, 4, 5, -1, -1, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1246", "sentence": ["\u2581", "RT", "\u2581@", "\u2581bubble", "s", "t", "b", "h", ":", "\u2581do", "\u2581", "u", "\u2581ever", "\u2581meet", "\u2581someone", "\u2581for", "\u2581the", "\u2581first", "\u2581time", "\u2581and", "\u2581pretend", "\u2581", "u", "\u2581have", "\u2581never", "\u2581met", "\u2581them", "\u2581but", "\u2581in", "\u2581", "ur", "\u2581head", "\u2581", "ur", "\u2581like", "\u2581\"", "\u2581", "i", "'", "\u2581", "ve", "\u2581stalk", "e", "d", "\u2581", "ur", "\u2581In", "s", "tag", "r", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581bubble", "s", "t", "b", "h", ":", "\u2581do", "\u2581", "u", "\u2581ever", "\u2581meet", "\u2581someone", "\u2581for", "\u2581the", "\u2581first", "\u2581time", "\u2581and", "\u2581pretend", "\u2581", "u", "\u2581have", "\u2581never", "\u2581met", "\u2581them", "\u2581but", "\u2581in", "\u2581", "ur", "\u2581head", "\u2581", "ur", "\u2581like", "\u2581\"", "\u2581", "i", "'", "\u2581", "ve", "\u2581stalk", "e", "d", "\u2581", "ur", "\u2581In", "s", "tag", "r", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581bubble", "s", "t", "b", "h", "</m>", ":", "\u2581do", "\u2581", "u", "\u2581ever", "\u2581meet", "\u2581someone", "\u2581for", "\u2581the", "\u2581first", "\u2581time", "\u2581and", "\u2581pretend", "\u2581", "u", "\u2581have", "\u2581never", "\u2581met", "\u2581them", "\u2581but", "\u2581in", "\u2581", "ur", "\u2581head", "\u2581", "ur", "\u2581like", "\u2581\"", "\u2581", "i", "'", "\u2581", "ve", "\u2581stalk", "e", "d", "\u2581", "ur", "\u2581In", "s", "tag", "r", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 24, 25, 26, 27, 27, 28, 29, 29, 30, 30, 30, 31, 31, 32, 32, 32, 32, 33, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1247", "sentence": ["\u2581grave", "\u2581https", "://", "t", ".", "co", "/", "J", "n", "L", "gla", "v", "S", "4", "c", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581grave", "\u2581https", "://", "t", ".", "co", "/", "J", "n", "L", "gla", "v", "S", "4", "c", "</s>"], "target_sentence": ["\u2581grave", "\u2581https", "://", "t", ".", "co", "/", "J", "n", "L", "gla", "v", "S", "4", "c", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1248", "sentence": ["\u2581Cur", "ious", "\u2581George", "\u2581really", "\u2581is", "\u2581the", "\u2581", "GO", "AT", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Cur", "ious", "\u2581George", "\u2581really", "\u2581is", "\u2581the", "\u2581", "GO", "AT", "</s>"], "target_sentence": ["\u2581Cur", "ious", "\u2581George", "\u2581really", "\u2581is", "\u2581the", "\u2581", "GO", "AT", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 4, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1249", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Jacob", "S", "i", "S", "Life", ":", "\u2581You", "'", "\u2581", "re", "\u2581way", "\u2581more", "\u2581important", "\u2581than", "\u2581you", "\u2581actually", "\u2581realize", ",", "\u2581stay", "\u2581strong", "\u2581", "\ud83d\udc93", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Jacob", "S", "i", "S", "Life", ":", "\u2581You", "'", "\u2581", "re", "\u2581way", "\u2581more", "\u2581important", "\u2581than", "\u2581you", "\u2581actually", "\u2581realize", ",", "\u2581stay", "\u2581strong", "\u2581", "\ud83d\udc93", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Jacob", "S", "i", "S", "Life", ":", "\u2581You", "'", "\u2581", "re", "\u2581way", "\u2581more", "\u2581important", "\u2581than", "\u2581you", "\u2581actually", "\u2581realize", ",", "\u2581stay", "\u2581strong", "\u2581", "\ud83d\udc93", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1250", "sentence": ["\u2581", "RT", "\u2581@", "\u2581for", "d", "m", ":", "\u2581Kelly", "anne", "\u2581Con", "way", "'", "\u2581", "s", "\u2581husband", ".", "\u2581https", "://", "t", ".", "co", "/", "Z", "b", "j", "G", "3", "o", "a", "i", "b", "k", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581for", "d", "m", ":", "\u2581Kelly", "anne", "\u2581Con", "way", "'", "\u2581", "s", "\u2581husband", ".", "\u2581https", "://", "t", ".", "co", "/", "Z", "b", "j", "G", "3", "o", "a", "i", "b", "k", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581for", "d", "m", "</m>", ":", "<m>", "<m>", "\u2581Kelly", "anne", "\u2581Con", "way", "</m>", "</m>", "'", "\u2581", "s", "\u2581husband", ".", "\u2581https", "://", "t", ".", "co", "/", "Z", "b", "j", "G", "3", "o", "a", "i", "b", "k", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 4, 5, 5, 6, 7, 7, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, 0, -1, 2, 1, -1, -1, -1, -1, 2, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1251", "sentence": ["\u2581A", "\u2581massive", "\u2581happy", "\u2581birthday", "\u2581to", "\u2581one", "\u2581of", "\u2581the", "\u2581love", "liest", "\u2581of", "\u2581people", "\u2581@", "\u2581Emma", "W", "ill", "is", "!", "\u2581I", "\u2581hope", "\u2581you", "\u2581have", "\u2581the", "\u2581best", "\u2581day", ",", "\u2581you", "\u2581deserve", "\u2581", "i", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/3", "F", "2", "y", "HS", "i", "d", "p", "y", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "\u2581massive", "\u2581happy", "\u2581birthday", "\u2581to", "\u2581one", "\u2581of", "\u2581the", "\u2581love", "liest", "\u2581of", "\u2581people", "\u2581@", "\u2581Emma", "W", "ill", "is", "!", "\u2581I", "\u2581hope", "\u2581you", "\u2581have", "\u2581the", "\u2581best", "\u2581day", ",", "\u2581you", "\u2581deserve", "\u2581", "i", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/3", "F", "2", "y", "HS", "i", "d", "p", "y", "</s>"], "target_sentence": ["\u2581A", "\u2581massive", "\u2581happy", "\u2581birthday", "\u2581to", "\u2581one", "\u2581of", "\u2581the", "\u2581love", "liest", "\u2581of", "\u2581people", "\u2581@", "<m>", "\u2581Emma", "W", "ill", "is", "</m>", "!", "\u2581I", "\u2581hope", "\u2581you", "\u2581have", "\u2581the", "\u2581best", "\u2581day", ",", "\u2581you", "\u2581deserve", "\u2581", "i", "\u2581", "...", "\u2581https", "://", "t", ".", "co", "/3", "F", "2", "y", "HS", "i", "d", "p", "y", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 12, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1252", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "eat", "my", "pe", "p", "i", ":", "\u2581guys", "\u2581", "i", "\u2581made", "\u2581", "a", "\u2581compilation", "\u2581of", "\u2581got", "\u25816", "\u2581dancing", "\u2581the", "\u2581", "s", "ex", "i", "est", "\u2581part", "\u2581in", "\u2581never", "\u2581ever", "\u2581", "&", "\u2581amp", ";", "\u2581", "i", "\u2581think", "\u2581", "i", "\u2581want", "\u2581to", "\u2581die", ".", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "q", "r", "n", "N", "c", "O", "lbs", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "eat", "my", "pe", "p", "i", ":", "\u2581guys", "\u2581", "i", "\u2581made", "\u2581", "a", "\u2581compilation", "\u2581of", "\u2581got", "\u25816", "\u2581dancing", "\u2581the", "\u2581", "s", "ex", "i", "est", "\u2581part", "\u2581in", "\u2581never", "\u2581ever", "\u2581", "&", "\u2581amp", ";", "\u2581", "i", "\u2581think", "\u2581", "i", "\u2581want", "\u2581to", "\u2581die", ".", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "q", "r", "n", "N", "c", "O", "lbs", "s", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "eat", "my", "pe", "p", "i", ":", "\u2581guys", "\u2581", "i", "\u2581made", "\u2581", "a", "\u2581compilation", "\u2581of", "\u2581got", "\u25816", "\u2581dancing", "\u2581the", "\u2581", "s", "ex", "i", "est", "\u2581part", "\u2581in", "\u2581never", "\u2581ever", "\u2581", "&", "\u2581amp", ";", "\u2581", "i", "\u2581think", "\u2581", "i", "\u2581want", "\u2581to", "\u2581die", ".", ".", ".", ".", ".", "\u2581https", "://", "t", ".", "co", "/", "q", "r", "n", "N", "c", "O", "lbs", "s", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 14, 14, 14, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1253", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Les", "s", "Go", "v", "M", "or", "e", "F", "un", ":", ".", "\u2581Sounds", "\u2581like", "\u2581that", "\u2581outfit", "\u2581that", "\u2581left", "\u2581the", "\u2581White", "\u2581House", "\u2581on", "\u2581January", "\u258120", ".", ".", ".", ".", "\u2581#", "\u2581Wir", "e", "tap", "\u2581#", "\u2581Wir", "e", "G", "ate", "\u2581https", "://", "t", ".", "co", "/", "g", "FW", "J", "J", "5", "L", "l", "x", "0", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Les", "s", "Go", "v", "M", "or", "e", "F", "un", ":", ".", "\u2581Sounds", "\u2581like", "\u2581that", "\u2581outfit", "\u2581that", "\u2581left", "\u2581the", "\u2581White", "\u2581House", "\u2581on", "\u2581January", "\u258120", ".", ".", ".", ".", "\u2581#", "\u2581Wir", "e", "tap", "\u2581#", "\u2581Wir", "e", "G", "ate", "\u2581https", "://", "t", ".", "co", "/", "g", "FW", "J", "J", "5", "L", "l", "x", "0", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Les", "s", "Go", "v", "M", "or", "e", "F", "un", ":", ".", "\u2581Sounds", "\u2581like", "\u2581that", "\u2581outfit", "\u2581that", "\u2581left", "\u2581the", "<m>", "\u2581White", "\u2581House", "</m>", "\u2581on", "\u2581January", "\u258120", ".", ".", ".", ".", "\u2581#", "\u2581Wir", "e", "tap", "\u2581#", "\u2581Wir", "e", "G", "ate", "\u2581https", "://", "t", ".", "co", "/", "g", "FW", "J", "J", "5", "L", "l", "x", "0", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 22, 23, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1254", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581easy", "\u2581now", "\u2581cause", "\u2581you", "\u2581earned", "\u2581it", "\u2581along", "\u2581the", "\u2581way", ",", "\u2581get", "\u2581paid", "\u2581young", "\u2581", "nig", "g", "a", "!", "\u2581https", "://", "t", ".", "co", "/", "J", "U", "m", "MF", "HK", "IC", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581easy", "\u2581now", "\u2581cause", "\u2581you", "\u2581earned", "\u2581it", "\u2581along", "\u2581the", "\u2581way", ",", "\u2581get", "\u2581paid", "\u2581young", "\u2581", "nig", "g", "a", "!", "\u2581https", "://", "t", ".", "co", "/", "J", "U", "m", "MF", "HK", "IC", "z", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581easy", "\u2581now", "\u2581cause", "\u2581you", "\u2581earned", "\u2581it", "\u2581along", "\u2581the", "\u2581way", ",", "\u2581get", "\u2581paid", "\u2581young", "\u2581", "nig", "g", "a", "!", "\u2581https", "://", "t", ".", "co", "/", "J", "U", "m", "MF", "HK", "IC", "z", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1255", "sentence": ["\u2581Simple", "\u2581Strategy", "\u2581to", "\u2581build", "\u2581#", "\u2581wealth", "\u2581and", "\u2581protect", "\u2581yourself", "\u2581from", "\u2581the", "\u2581evil", "s", "\u2581of", "\u2581inflation", "\u2581https", "://", "t", ".", "co", "/", "B", "o", "d", "TL", "8", "r", "1", "p", "U", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Simple", "\u2581Strategy", "\u2581to", "\u2581build", "\u2581#", "\u2581wealth", "\u2581and", "\u2581protect", "\u2581yourself", "\u2581from", "\u2581the", "\u2581evil", "s", "\u2581of", "\u2581inflation", "\u2581https", "://", "t", ".", "co", "/", "B", "o", "d", "TL", "8", "r", "1", "p", "U", "</s>"], "target_sentence": ["\u2581Simple", "\u2581Strategy", "\u2581to", "\u2581build", "\u2581#", "\u2581wealth", "\u2581and", "\u2581protect", "\u2581yourself", "\u2581from", "\u2581the", "\u2581evil", "s", "\u2581of", "\u2581inflation", "\u2581https", "://", "t", ".", "co", "/", "B", "o", "d", "TL", "8", "r", "1", "p", "U", "</s>"], "subtoken_map": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1256", "sentence": ["\u2581#", "\u2581Fa", "ke", "\u2581news", "\u2581trend", "\u2581gathering", "\u2581momentum", "-", "\u2581", "a", "\u2581little", "\u2581common", "\u2581sense", "\u2581is", "\u2581all", "\u2581you", "\u2581need", "\u2581to", "\u2581spot", "\u2581#", "\u2581fake", "\u2581#", "\u2581news", "\u2581https", "://", "t", ".", "co", "/", "x", "I", "o", "m", "a", "T", "e", "VG", "X", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581#", "\u2581Fa", "ke", "\u2581news", "\u2581trend", "\u2581gathering", "\u2581momentum", "-", "\u2581", "a", "\u2581little", "\u2581common", "\u2581sense", "\u2581is", "\u2581all", "\u2581you", "\u2581need", "\u2581to", "\u2581spot", "\u2581#", "\u2581fake", "\u2581#", "\u2581news", "\u2581https", "://", "t", ".", "co", "/", "x", "I", "o", "m", "a", "T", "e", "VG", "X", "</s>"], "target_sentence": ["\u2581#", "\u2581Fa", "ke", "\u2581news", "\u2581trend", "\u2581gathering", "\u2581momentum", "-", "\u2581", "a", "\u2581little", "\u2581common", "\u2581sense", "\u2581is", "\u2581all", "\u2581you", "\u2581need", "\u2581to", "\u2581spot", "\u2581#", "\u2581fake", "\u2581#", "\u2581news", "\u2581https", "://", "t", ".", "co", "/", "x", "I", "o", "m", "a", "T", "e", "VG", "X", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 4, 5, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1257", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "D", "d", "J", "p", "i", "i", "e", "e", "ak", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "D", "d", "J", "p", "i", "i", "e", "e", "ak", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "D", "d", "J", "p", "i", "i", "e", "e", "ak", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1258", "sentence": ["\u2581", "RT", "\u2581@", "\u2581V", "\u2581", "_", "\u2581of", "\u2581", "_", "\u2581Europe", ":", "\u2581Europe", "'", "\u2581", "s", "\u2581most", "\u2581horrible", "\u2581person", "\u2581is", "\u2581in", "\u2581the", "\u2581White", "\u2581House", ".", "\u2581The", "\u2581damage", "\u2581she", "'", "\u2581", "s", "\u2581done", "\u2581to", "\u2581her", "\u2581country", "\u2581and", "\u2581our", "\u2581continent", "\u2581is", "\u2581un", "p", "r", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581V", "\u2581", "_", "\u2581of", "\u2581", "_", "\u2581Europe", ":", "\u2581Europe", "'", "\u2581", "s", "\u2581most", "\u2581horrible", "\u2581person", "\u2581is", "\u2581in", "\u2581the", "\u2581White", "\u2581House", ".", "\u2581The", "\u2581damage", "\u2581she", "'", "\u2581", "s", "\u2581done", "\u2581to", "\u2581her", "\u2581country", "\u2581and", "\u2581our", "\u2581continent", "\u2581is", "\u2581un", "p", "r", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581V", "\u2581", "_", "\u2581of", "\u2581", "_", "\u2581Europe", ":", "<m>", "\u2581Europe", "</m>", "'", "\u2581", "s", "\u2581most", "\u2581horrible", "\u2581person", "\u2581is", "\u2581in", "\u2581the", "\u2581White", "\u2581House", ".", "\u2581The", "\u2581damage", "\u2581she", "'", "\u2581", "s", "\u2581done", "\u2581to", "\u2581her", "\u2581country", "\u2581and", "\u2581our", "\u2581continent", "\u2581is", "\u2581un", "p", "r", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 33, 33, 34, 34, 35], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1259", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "e", "l", "kli", "en", ":", "\u2581I", "\u2581actually", "\u2581miss", "\u2581primary", "\u2581school", "\u2581I", "\u2581was", "\u2581always", "\u2581moving", "\u2581like", "\u2581one", "\u2581", "s", "la", "ggy", "\u2581Kat", "\u2581S", "late", "r", "\u2581having", "\u2581like", "\u25813", "\u2581relationships", "\u2581at", "\u2581", "a", "\u2581time", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "e", "l", "kli", "en", ":", "\u2581I", "\u2581actually", "\u2581miss", "\u2581primary", "\u2581school", "\u2581I", "\u2581was", "\u2581always", "\u2581moving", "\u2581like", "\u2581one", "\u2581", "s", "la", "ggy", "\u2581Kat", "\u2581S", "late", "r", "\u2581having", "\u2581like", "\u25813", "\u2581relationships", "\u2581at", "\u2581", "a", "\u2581time", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "e", "l", "kli", "en", "</m>", ":", "\u2581I", "\u2581actually", "\u2581miss", "\u2581primary", "\u2581school", "\u2581I", "\u2581was", "\u2581always", "\u2581moving", "\u2581like", "\u2581one", "\u2581", "s", "la", "ggy", "<m>", "<m>", "\u2581Kat", "\u2581S", "late", "r", "</m>", "</m>", "\u2581having", "\u2581like", "\u25813", "\u2581relationships", "\u2581at", "\u2581", "a", "\u2581time", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 15, 15, 16, 17, 17, 17, 18, 19, 20, 21, 22, 23, 23, 24, 25], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1260", "sentence": ["\u2581Ever", "\u2581get", "\u2581", "a", "\u2581chill", "\u2581and", "\u2581get", "\u2581", "ting", "ly", "\u2581", "n", "i", "pp", "les", "\u2581for", "\u258110", "\u2581minutes", "\u2581afterwards", "?", "\u2581Ask", "ing", "\u2581for", "\u2581me", ".", "\u2581Je", "al", "ous", "?", "\u2581#", "\u2581unlike", "able", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Ever", "\u2581get", "\u2581", "a", "\u2581chill", "\u2581and", "\u2581get", "\u2581", "ting", "ly", "\u2581", "n", "i", "pp", "les", "\u2581for", "\u258110", "\u2581minutes", "\u2581afterwards", "?", "\u2581Ask", "ing", "\u2581for", "\u2581me", ".", "\u2581Je", "al", "ous", "?", "\u2581#", "\u2581unlike", "able", "</s>"], "target_sentence": ["\u2581Ever", "\u2581get", "\u2581", "a", "\u2581chill", "\u2581and", "\u2581get", "\u2581", "ting", "ly", "\u2581", "n", "i", "pp", "les", "\u2581for", "\u258110", "\u2581minutes", "\u2581afterwards", "?", "\u2581Ask", "ing", "\u2581for", "\u2581me", ".", "\u2581Je", "al", "ous", "?", "\u2581#", "\u2581unlike", "able", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 5, 6, 6, 6, 7, 7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 13, 14, 15, 16, 17, 17, 17, 18, 19, 20, 20, 21], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1261", "sentence": ["\u2581@", "\u2581Yo", "s", "h", "ku", "mar", "\u2581Happen", "s", "\u2581", "\u2639", "\u2581", "\ufe0f", "\u2581that", "'", "\u2581", "s", "\u2581E", "sport", "s", "\u2581for", "\u2581", "y", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Yo", "s", "h", "ku", "mar", "\u2581Happen", "s", "\u2581", "\u2639", "\u2581", "\ufe0f", "\u2581that", "'", "\u2581", "s", "\u2581E", "sport", "s", "\u2581for", "\u2581", "y", "a", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Yo", "s", "h", "ku", "mar", "</m>", "\u2581Happen", "s", "\u2581", "\u2639", "\u2581", "\ufe0f", "\u2581that", "'", "\u2581", "s", "<m>", "\u2581E", "sport", "s", "</m>", "\u2581for", "\u2581", "y", "a", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 6, 7, 7, 8, 8, 8, 9, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1262", "sentence": ["\u2581", "kim", "\u2581bur", "re", "l", "\u2581", "-", "\u2581hold", "\u25812", "\u2581", "ur", "\u2581faith", "\u2581https", "://", "t", ".", "co", "/5", "S", "X", "w", "x", "5", "n", "h", "Y", "a", "\u2581#", "\u2581Now", "Play", "ing", "\u2581#", "\u2581Listen", "Live", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "kim", "\u2581bur", "re", "l", "\u2581", "-", "\u2581hold", "\u25812", "\u2581", "ur", "\u2581faith", "\u2581https", "://", "t", ".", "co", "/5", "S", "X", "w", "x", "5", "n", "h", "Y", "a", "\u2581#", "\u2581Now", "Play", "ing", "\u2581#", "\u2581Listen", "Live", "</s>"], "target_sentence": ["<m>", "\u2581", "kim", "\u2581bur", "re", "l", "</m>", "\u2581", "-", "\u2581hold", "\u25812", "\u2581", "ur", "\u2581faith", "\u2581https", "://", "t", ".", "co", "/5", "S", "X", "w", "x", "5", "n", "h", "Y", "a", "\u2581#", "\u2581Now", "Play", "ing", "\u2581#", "\u2581Listen", "Live", "</s>"], "subtoken_map": [0, 0, 1, 1, 1, 2, 2, 3, 4, 5, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 9, 9, 10, 11, 11, 12], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1263", "sentence": ["\u2581", "RT", "\u2581@", "\u2581sens", "ual", "g", "if", "s", ":", "\u2581When", "\u2581", "he", "\u2581tell", "s", "\u2581you", "\u2581no", ",", "\u2581but", "\u2581then", "\u2581comes", "\u2581to", "\u2581his", "\u2581sense", "s", "\u2581and", "\u2581says", "\u2581yes", "\u2581https", "://", "t", ".", "co", "/", "RY", "s", "r", "t", "Z", "t", "b", "TD", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581sens", "ual", "g", "if", "s", ":", "\u2581When", "\u2581", "he", "\u2581tell", "s", "\u2581you", "\u2581no", ",", "\u2581but", "\u2581then", "\u2581comes", "\u2581to", "\u2581his", "\u2581sense", "s", "\u2581and", "\u2581says", "\u2581yes", "\u2581https", "://", "t", ".", "co", "/", "RY", "s", "r", "t", "Z", "t", "b", "TD", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581sens", "ual", "g", "if", "s", ":", "\u2581When", "\u2581", "he", "\u2581tell", "s", "\u2581you", "\u2581no", ",", "\u2581but", "\u2581then", "\u2581comes", "\u2581to", "\u2581his", "\u2581sense", "s", "\u2581and", "\u2581says", "\u2581yes", "\u2581https", "://", "t", ".", "co", "/", "RY", "s", "r", "t", "Z", "t", "b", "TD", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1264", "sentence": ["\u2581", "RT", "\u2581@", "\u2581boy", "band", "\u2581", "_", "\u2581", "jo", "a", "o", ":", "\u2581Happy", "\u2581Six", "\u2581Month", "s", "\u2581To", "\u2581All", "\u2581Of", "\u2581The", "\u2581Other", "\u2581Jo", "\u00e3", "o", "'", "\u2581", "s", "\u2581Support", "ers", "\u2581Out", "\u2581There", "!", "\u2581I", "\u2581Love", "\u2581You", "\u2581All", "!", "\u2581More", "\u2581B", "less", "ing", "s", "\u2581For", "\u2581Everyone", "!", "\u2581", "\u2764", "\u2581Team", "JO", "A", "\u2581", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581boy", "band", "\u2581", "_", "\u2581", "jo", "a", "o", ":", "\u2581Happy", "\u2581Six", "\u2581Month", "s", "\u2581To", "\u2581All", "\u2581Of", "\u2581The", "\u2581Other", "\u2581Jo", "\u00e3", "o", "'", "\u2581", "s", "\u2581Support", "ers", "\u2581Out", "\u2581There", "!", "\u2581I", "\u2581Love", "\u2581You", "\u2581All", "!", "\u2581More", "\u2581B", "less", "ing", "s", "\u2581For", "\u2581Everyone", "!", "\u2581", "\u2764", "\u2581Team", "JO", "A", "\u2581", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581boy", "band", "\u2581", "_", "\u2581", "jo", "a", "o", ":", "\u2581Happy", "\u2581Six", "\u2581Month", "s", "\u2581To", "\u2581All", "\u2581Of", "\u2581The", "\u2581Other", "\u2581Jo", "\u00e3", "o", "'", "\u2581", "s", "\u2581Support", "ers", "\u2581Out", "\u2581There", "!", "\u2581I", "\u2581Love", "\u2581You", "\u2581All", "!", "\u2581More", "\u2581B", "less", "ing", "s", "\u2581For", "\u2581Everyone", "!", "\u2581", "\u2764", "\u2581Team", "JO", "A", "\u2581", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 14, 14, 15, 16, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 27, 27, 27, 28, 29, 30, 31, 31, 32, 32, 32, 33, 33, 34], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1265", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Daily", "S", "ex", "S", "up", "p", "ly", "\u25817", ":", "\u2581https", "://", "t", ".", "co", "/", "q", "8", "AS", "k", "h", "E", "I", "J", "l", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Daily", "S", "ex", "S", "up", "p", "ly", "\u25817", ":", "\u2581https", "://", "t", ".", "co", "/", "q", "8", "AS", "k", "h", "E", "I", "J", "l", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Daily", "S", "ex", "S", "up", "p", "ly", "\u25817", ":", "\u2581https", "://", "t", ".", "co", "/", "q", "8", "AS", "k", "h", "E", "I", "J", "l", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1266", "sentence": ["\u2581Here", "\u2581", "\u2019", "\u2581", "s", "\u2581$", "\u2581100", "\u2581in", "\u2581FREE", "\u2581Post", "mates", "\u2581delivery", "\u2581credit", "\u2581(", "\u2581good", "\u2581for", "\u25817", "\u2581days", ")", ".", "\u2581Sign", "\u2581up", "\u2581with", "\u2581my", "\u2581code", "\u2581E", "J", "\u25813", "\u2581A", "\u2581or", "\u2581this", "\u2581link", "\u2581https", "://", "t", ".", "co", "/", "On", "1", "v", "y", "7", "v", "w", "z", "P", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Here", "\u2581", "\u2019", "\u2581", "s", "\u2581$", "\u2581100", "\u2581in", "\u2581FREE", "\u2581Post", "mates", "\u2581delivery", "\u2581credit", "\u2581(", "\u2581good", "\u2581for", "\u25817", "\u2581days", ")", ".", "\u2581Sign", "\u2581up", "\u2581with", "\u2581my", "\u2581code", "\u2581E", "J", "\u25813", "\u2581A", "\u2581or", "\u2581this", "\u2581link", "\u2581https", "://", "t", ".", "co", "/", "On", "1", "v", "y", "7", "v", "w", "z", "P", "</s>"], "target_sentence": ["\u2581Here", "\u2581", "\u2019", "\u2581", "s", "\u2581$", "\u2581100", "\u2581in", "\u2581FREE", "<m>", "\u2581Post", "mates", "</m>", "\u2581delivery", "\u2581credit", "\u2581(", "\u2581good", "\u2581for", "\u25817", "\u2581days", ")", ".", "\u2581Sign", "\u2581up", "\u2581with", "\u2581my", "\u2581code", "\u2581E", "J", "\u25813", "\u2581A", "\u2581or", "\u2581this", "\u2581link", "\u2581https", "://", "t", ".", "co", "/", "On", "1", "v", "y", "7", "v", "w", "z", "P", "</s>"], "subtoken_map": [0, 1, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1267", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Dr", "e", "b", "a", "e", "\u2581", "_", ":", "\u2581If", "\u2581somebody", "\u2581ever", "\u2581try", "\u2581to", "\u2581use", "\u2581you", "\u2581tell", "\u2581your", "\u2581", "hood", "\u2581boyfriend", "\u2581to", "\u2581have", "\u2581they", "\u2581as", "s", "\u2581handled", ".", "\u2581Bet", "\u2581they", "\u2581cut", "\u2581that", "\u2581", "s", "hit", "\u2581out", "\u2581https", "://", "t", ".", "co", "/", "ND", "W", "...", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Dr", "e", "b", "a", "e", "\u2581", "_", ":", "\u2581If", "\u2581somebody", "\u2581ever", "\u2581try", "\u2581to", "\u2581use", "\u2581you", "\u2581tell", "\u2581your", "\u2581", "hood", "\u2581boyfriend", "\u2581to", "\u2581have", "\u2581they", "\u2581as", "s", "\u2581handled", ".", "\u2581Bet", "\u2581they", "\u2581cut", "\u2581that", "\u2581", "s", "hit", "\u2581out", "\u2581https", "://", "t", ".", "co", "/", "ND", "W", "...", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581Dr", "e", "b", "a", "e", "</m>", "\u2581", "_", ":", "\u2581If", "\u2581somebody", "\u2581ever", "\u2581try", "\u2581to", "\u2581use", "\u2581you", "\u2581tell", "\u2581your", "\u2581", "hood", "\u2581boyfriend", "\u2581to", "\u2581have", "\u2581they", "\u2581as", "s", "\u2581handled", ".", "\u2581Bet", "\u2581they", "\u2581cut", "\u2581that", "\u2581", "s", "hit", "\u2581out", "\u2581https", "://", "t", ".", "co", "/", "ND", "W", "...", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1268", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Greater", "Th", "n", ":", "\u2581Me", ":", "\u2581\"", "\u2581its", "\u2581fine", ".", "\u2581\"", "\u2581Me", ":", "\u2581https", "://", "t", ".", "co", "/", "B", "q", "y", "8", "z", "0", "F", "u", "us", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Greater", "Th", "n", ":", "\u2581Me", ":", "\u2581\"", "\u2581its", "\u2581fine", ".", "\u2581\"", "\u2581Me", ":", "\u2581https", "://", "t", ".", "co", "/", "B", "q", "y", "8", "z", "0", "F", "u", "us", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Greater", "Th", "n", ":", "\u2581Me", ":", "\u2581\"", "\u2581its", "\u2581fine", ".", "\u2581\"", "\u2581Me", ":", "\u2581https", "://", "t", ".", "co", "/", "B", "q", "y", "8", "z", "0", "F", "u", "us", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1269", "sentence": ["\u2581Latest", "\u2581level", ":", "\u2581", "0", ".", "\u25812", "87", "\u2581", "m", "\u2581at", "\u258117", "\u2581", "/", "\u258103", "\u2581", "/", "\u25812017", "\u258122", ":", "\u258145", ":", "\u2581", "00", "\u2581(", "\u2581GMT", ")", ".", "\u2581Further", "\u2581information", "\u2581available", "\u2581at", "\u2581https", "://", "t", ".", "co", "/4", "y", "V", "o", "b", "HQ", "8", "m", "L", "\u2581#", "\u2581river", "level", "s", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Latest", "\u2581level", ":", "\u2581", "0", ".", "\u25812", "87", "\u2581", "m", "\u2581at", "\u258117", "\u2581", "/", "\u258103", "\u2581", "/", "\u25812017", "\u258122", ":", "\u258145", ":", "\u2581", "00", "\u2581(", "\u2581GMT", ")", ".", "\u2581Further", "\u2581information", "\u2581available", "\u2581at", "\u2581https", "://", "t", ".", "co", "/4", "y", "V", "o", "b", "HQ", "8", "m", "L", "\u2581#", "\u2581river", "level", "s", "</s>"], "target_sentence": ["\u2581Latest", "\u2581level", ":", "\u2581", "0", ".", "\u25812", "87", "\u2581", "m", "\u2581at", "\u258117", "\u2581", "/", "\u258103", "\u2581", "/", "\u25812017", "\u258122", ":", "\u258145", ":", "\u2581", "00", "\u2581(", "\u2581GMT", ")", ".", "\u2581Further", "\u2581information", "\u2581available", "\u2581at", "\u2581https", "://", "t", ".", "co", "/4", "y", "V", "o", "b", "HQ", "8", "m", "L", "\u2581#", "\u2581river", "level", "s", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 4, 5, 5, 6, 6, 7, 8, 9, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 28, 28, 28, 29], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1270", "sentence": ["\u2581", "RT", "\u2581@", "\u2581an", "th", "on", "y", "u", "J", "R", ":", "\u2581When", "\u2581I", "\u2581believe", "\u2581in", "\u2581myself", "\u2581https", "://", "t", ".", "co", "/", "F", "s", "G", "r", "GS", "1", "p", "z", "7", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581an", "th", "on", "y", "u", "J", "R", ":", "\u2581When", "\u2581I", "\u2581believe", "\u2581in", "\u2581myself", "\u2581https", "://", "t", ".", "co", "/", "F", "s", "G", "r", "GS", "1", "p", "z", "7", "</s>"], "target_sentence": ["\u2581", "RT", "<m>", "\u2581@", "\u2581an", "th", "on", "y", "u", "J", "R", "</m>", ":", "\u2581When", "\u2581I", "\u2581believe", "\u2581in", "\u2581myself", "\u2581https", "://", "t", ".", "co", "/", "F", "s", "G", "r", "GS", "1", "p", "z", "7", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1271", "sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "C", "our", "t", "K", "im", ":", "\u2581you", "'", "\u2581", "re", "\u2581single", "\u2581until", "\u2581you", "'", "\u2581", "re", "\u2581officially", "\u2581", "c", "uffed", "\u2581so", "\u2581the", "\u2581limit", "\u2581does", "\u2581not", "\u2581exist", "\u2581", "\u2728", "\u2581https", "://", "t", ".", "co", "/", "We", "V", "SET", "s", "3", "K", "H", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581The", "C", "our", "t", "K", "im", ":", "\u2581you", "'", "\u2581", "re", "\u2581single", "\u2581until", "\u2581you", "'", "\u2581", "re", "\u2581officially", "\u2581", "c", "uffed", "\u2581so", "\u2581the", "\u2581limit", "\u2581does", "\u2581not", "\u2581exist", "\u2581", "\u2728", "\u2581https", "://", "t", ".", "co", "/", "We", "V", "SET", "s", "3", "K", "H", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581The", "C", "our", "t", "K", "im", ":", "\u2581you", "'", "\u2581", "re", "\u2581single", "\u2581until", "\u2581you", "'", "\u2581", "re", "\u2581officially", "\u2581", "c", "uffed", "\u2581so", "\u2581the", "\u2581limit", "\u2581does", "\u2581not", "\u2581exist", "\u2581", "\u2728", "\u2581https", "://", "t", ".", "co", "/", "We", "V", "SET", "s", "3", "K", "H", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 11, 12, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1272", "sentence": ["\u2581Now", "\u2581Play", "ing", ":", "\u2581Wild", "fire", "\u2581by", "\u2581@", "\u2581", "LF", "DH", "com", "\u2581Listen", "\u2581at", "\u2581https", "://", "t", ".", "co", "/3", "O", "Z", "c", "f", "8", "i", "D", "Z", "J", "\u2581https", "://", "t", ".", "co", "/", "t", "kk", "X", "MA", "h", "z", "s", "n", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Now", "\u2581Play", "ing", ":", "\u2581Wild", "fire", "\u2581by", "\u2581@", "\u2581", "LF", "DH", "com", "\u2581Listen", "\u2581at", "\u2581https", "://", "t", ".", "co", "/3", "O", "Z", "c", "f", "8", "i", "D", "Z", "J", "\u2581https", "://", "t", ".", "co", "/", "t", "kk", "X", "MA", "h", "z", "s", "n", "</s>"], "target_sentence": ["\u2581Now", "\u2581Play", "ing", ":", "<m>", "\u2581Wild", "fire", "</m>", "\u2581by", "\u2581@", "<m>", "\u2581", "LF", "DH", "com", "</m>", "\u2581Listen", "\u2581at", "\u2581https", "://", "t", ".", "co", "/3", "O", "Z", "c", "f", "8", "i", "D", "Z", "J", "\u2581https", "://", "t", ".", "co", "/", "t", "kk", "X", "MA", "h", "z", "s", "n", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5, 6, 6, 6, 6, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1273", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "r", "he", "t", "t", "and", "link", ":", "\u2581Once", "\u2581you", "\u2581start", "\u2581", "dipping", ",", "\u2581the", "\u2581vom", "it", "\u2581starts", "\u2581", "slipping", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "r", "he", "t", "t", "and", "link", ":", "\u2581Once", "\u2581you", "\u2581start", "\u2581", "dipping", ",", "\u2581the", "\u2581vom", "it", "\u2581starts", "\u2581", "slipping", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "<m>", "\u2581", "r", "he", "t", "t", "and", "link", "</m>", ":", "\u2581Once", "\u2581you", "\u2581start", "\u2581", "dipping", ",", "\u2581the", "\u2581vom", "it", "\u2581starts", "\u2581", "slipping", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 10, 11, 12, 12, 13], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1274", "sentence": ["\u2581@", "\u2581Richmond", "Do", "c", "\u2581", "TY", "\u2581for", "\u2581continuing", "\u2581to", "\u2581respond", ".", "\u2581That", "\u2581was", "\u2581A", "-", "\u2581all", "\u2581right", "\u2581of", "\u2581you", ".", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Richmond", "Do", "c", "\u2581", "TY", "\u2581for", "\u2581continuing", "\u2581to", "\u2581respond", ".", "\u2581That", "\u2581was", "\u2581A", "-", "\u2581all", "\u2581right", "\u2581of", "\u2581you", ".", "</s>"], "target_sentence": ["\u2581@", "<m>", "\u2581Richmond", "Do", "c", "\u2581", "TY", "</m>", "\u2581for", "\u2581continuing", "\u2581to", "\u2581respond", ".", "\u2581That", "\u2581was", "\u2581A", "-", "\u2581all", "\u2581right", "\u2581of", "\u2581you", ".", "</s>"], "subtoken_map": [0, 1, 1, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1275", "sentence": ["\u2581", "RT", "\u2581@", "\u2581the", "girl", "z", "aki", "y", "yah", ":", "\u2581close", "\u2581", "minded", ",", "\u2581no", "\u2581moral", "s", ",", "\u2581selfish", ",", "\u2581fake", "\u2581spiritual", ",", "\u2581no", "\u2581goals", ".", ".", "\u2581str", "\u25818", "\u2581", "d", "ummy", "'", "\u2581", "s", "\u2581for", "\u2581", "u", "\u2581https", "://", "t", ".", "co", "/", "vo", "D", "J", "g", "X", "T", "q", "s", "z", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581the", "girl", "z", "aki", "y", "yah", ":", "\u2581close", "\u2581", "minded", ",", "\u2581no", "\u2581moral", "s", ",", "\u2581selfish", ",", "\u2581fake", "\u2581spiritual", ",", "\u2581no", "\u2581goals", ".", ".", "\u2581str", "\u25818", "\u2581", "d", "ummy", "'", "\u2581", "s", "\u2581for", "\u2581", "u", "\u2581https", "://", "t", ".", "co", "/", "vo", "D", "J", "g", "X", "T", "q", "s", "z", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581the", "girl", "z", "aki", "y", "yah", ":", "\u2581close", "\u2581", "minded", ",", "\u2581no", "\u2581moral", "s", ",", "\u2581selfish", ",", "\u2581fake", "\u2581spiritual", ",", "\u2581no", "\u2581goals", ".", ".", "\u2581str", "\u25818", "\u2581", "d", "ummy", "'", "\u2581", "s", "\u2581for", "\u2581", "u", "\u2581https", "://", "t", ".", "co", "/", "vo", "D", "J", "g", "X", "T", "q", "s", "z", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 21, 21, 22, 23, 23, 24, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1276", "sentence": ["\u2581", "RT", "\u2581@", "\u2581lit", "gri", "mes", ":", "\u2581ar", "chie", "\u2581and", "\u2581", "bla", "i", "r", "\u2581", "\u2014", "\u2581", "i", "\u2581know", "\u2581she", "\u2581like", "\u2581me", "\u2581https", "://", "t", ".", "co", "/", "g", "J", "H", "2", "WC", "G", "Y", "I", "u", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581lit", "gri", "mes", ":", "\u2581ar", "chie", "\u2581and", "\u2581", "bla", "i", "r", "\u2581", "\u2014", "\u2581", "i", "\u2581know", "\u2581she", "\u2581like", "\u2581me", "\u2581https", "://", "t", ".", "co", "/", "g", "J", "H", "2", "WC", "G", "Y", "I", "u", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581lit", "gri", "mes", ":", "\u2581ar", "chie", "\u2581and", "\u2581", "bla", "i", "r", "\u2581", "\u2014", "\u2581", "i", "\u2581know", "\u2581she", "\u2581like", "\u2581me", "\u2581https", "://", "t", ".", "co", "/", "g", "J", "H", "2", "WC", "G", "Y", "I", "u", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 3, 4, 4, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1277", "sentence": ["\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581short", "\u2581girls", "\u2581were", "\u2581born", "\u2581with", "\u2581attitudes", "\u2581lol", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581short", "\u2581girls", "\u2581were", "\u2581born", "\u2581with", "\u2581attitudes", "\u2581lol", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581mar", "I", "boro", "s", ":", "\u2581short", "\u2581girls", "\u2581were", "\u2581born", "\u2581with", "\u2581attitudes", "\u2581lol", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1278", "sentence": ["\u2581A", "\u2581proper", "\u2581#", "\u2581St", "Patri", "ck", "s", "Day", "\u2581drink", "\u2581https", "://", "t", ".", "co", "/", "c", "4", "V", "c", "UF", "EQ", "X", "w", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581A", "\u2581proper", "\u2581#", "\u2581St", "Patri", "ck", "s", "Day", "\u2581drink", "\u2581https", "://", "t", ".", "co", "/", "c", "4", "V", "c", "UF", "EQ", "X", "w", "</s>"], "target_sentence": ["\u2581A", "\u2581proper", "\u2581#", "\u2581St", "Patri", "ck", "s", "Day", "\u2581drink", "\u2581https", "://", "t", ".", "co", "/", "c", "4", "V", "c", "UF", "EQ", "X", "w", "</s>"], "subtoken_map": [0, 1, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1279", "sentence": ["\u2581", "RT", "\u2581@", "\u2581Pain", "ful", "Tex", "t", ":", "\u2581", "i", "\u2581do", "\u2581really", "\u2581hate", "\u2581how", "\u2581my", "\u2581brain", "\u2581over", "think", "s", "\u2581literally", "\u2581everything", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581Pain", "ful", "Tex", "t", ":", "\u2581", "i", "\u2581do", "\u2581really", "\u2581hate", "\u2581how", "\u2581my", "\u2581brain", "\u2581over", "think", "s", "\u2581literally", "\u2581everything", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581Pain", "ful", "Tex", "t", ":", "\u2581", "i", "\u2581do", "\u2581really", "\u2581hate", "\u2581how", "\u2581my", "\u2581brain", "\u2581over", "think", "s", "\u2581literally", "\u2581everything", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1280", "sentence": ["\u2581Never", "\u2581Be", "en", "\u2581To", "\u2581Sha", "kers", "\u2581Before", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581Never", "\u2581Be", "en", "\u2581To", "\u2581Sha", "kers", "\u2581Before", "</s>"], "target_sentence": ["\u2581Never", "\u2581Be", "en", "\u2581To", "<m>", "\u2581Sha", "kers", "</m>", "\u2581Before", "</s>"], "subtoken_map": [0, 1, 1, 2, 3, 3, 4, 5], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, 2, -1, -1], "ent_indices": [-1, -1, -1, -1, 0, -1, -1, 0, -1, -1]}, {"doc_id": "emerging.test_1281", "sentence": ["\u2581https", "://", "t", ".", "co", "/", "h", "h", "3", "P", "V", "Q", "5", "L", "0", "a", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581https", "://", "t", ".", "co", "/", "h", "h", "3", "P", "V", "Q", "5", "L", "0", "a", "</s>"], "target_sentence": ["\u2581https", "://", "t", ".", "co", "/", "h", "h", "3", "P", "V", "Q", "5", "L", "0", "a", "</s>"], "subtoken_map": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1282", "sentence": ["\u2581", "RT", "\u2581@", "\u2581I", "over", "though", "t", "s", ":", "\u2581", "i", "\u2581like", "\u2581looking", "\u2581cute", "\u2581but", "\u2581", "i", "\u2581like", "\u2581wearing", "\u2581", "X", "L", "\u2581", "t", "shirts", "\u2581more", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581I", "over", "though", "t", "s", ":", "\u2581", "i", "\u2581like", "\u2581looking", "\u2581cute", "\u2581but", "\u2581", "i", "\u2581like", "\u2581wearing", "\u2581", "X", "L", "\u2581", "t", "shirts", "\u2581more", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581I", "over", "though", "t", "s", ":", "\u2581", "i", "\u2581like", "\u2581looking", "\u2581cute", "\u2581but", "\u2581", "i", "\u2581like", "\u2581wearing", "\u2581", "X", "L", "\u2581", "t", "shirts", "\u2581more", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9, 9, 10, 11, 12, 12, 12, 13, 13, 13, 14, 15], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1283", "sentence": ["\u2581", "RT", "\u2581@", "\u2581", "t", "y", "bro", "ke", "sign", ":", "\u2581talk", "\u2581about", "\u2581", "a", "\u2581plot", "\u2581twist", "\u2581L", "MA", "OO", "OO", "\u2581https", "://", "t", ".", "co", "/", "9", "y", "t", "V", "OP", "v", "u", "8", "D", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581", "RT", "\u2581@", "\u2581", "t", "y", "bro", "ke", "sign", ":", "\u2581talk", "\u2581about", "\u2581", "a", "\u2581plot", "\u2581twist", "\u2581L", "MA", "OO", "OO", "\u2581https", "://", "t", ".", "co", "/", "9", "y", "t", "V", "OP", "v", "u", "8", "D", "</s>"], "target_sentence": ["\u2581", "RT", "\u2581@", "\u2581", "t", "y", "bro", "ke", "sign", ":", "\u2581talk", "\u2581about", "\u2581", "a", "\u2581plot", "\u2581twist", "\u2581L", "MA", "OO", "OO", "\u2581https", "://", "t", ".", "co", "/", "9", "y", "t", "V", "OP", "v", "u", "8", "D", "</s>"], "subtoken_map": [0, 0, 1, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 7, 8, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1284", "sentence": ["\u2581It", "'", "\u2581", "s", "\u2581#", "\u2581", "FF", "\u2581add", "\u2581us", "\u2581https", "://", "t", ".", "co", "/1", "W", "0", "AC", "W", "f", "r", "10", "\u2581repos", "t", "\u2581and", "\u2581I", "'", "\u2581", "ll", "\u2581add", "\u2581you", "\u2581too", "\u2581", "\u270c", "\u2581#", "\u2581AT", "CC", "food", "i", "e", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581It", "'", "\u2581", "s", "\u2581#", "\u2581", "FF", "\u2581add", "\u2581us", "\u2581https", "://", "t", ".", "co", "/1", "W", "0", "AC", "W", "f", "r", "10", "\u2581repos", "t", "\u2581and", "\u2581I", "'", "\u2581", "ll", "\u2581add", "\u2581you", "\u2581too", "\u2581", "\u270c", "\u2581#", "\u2581AT", "CC", "food", "i", "e", "</s>"], "target_sentence": ["\u2581It", "'", "\u2581", "s", "\u2581#", "\u2581", "FF", "\u2581add", "\u2581us", "\u2581https", "://", "t", ".", "co", "/1", "W", "0", "AC", "W", "f", "r", "10", "\u2581repos", "t", "\u2581and", "\u2581I", "'", "\u2581", "ll", "\u2581add", "\u2581you", "\u2581too", "\u2581", "\u270c", "\u2581#", "\u2581AT", "CC", "food", "i", "e", "</s>"], "subtoken_map": [0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 10, 11, 12, 12, 13, 14, 15, 16, 16, 17, 18, 18, 18, 18, 18, 19], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1285", "sentence": ["\u2581No", "\u2581Cou", "s", "in", "s", "\u2581today", ".", ".", ".", "\u2581Pe", "lic", "ans", "\u2581off", "ence", "\u2581could", "\u2581be", "\u2581horrible", "\u2581today", "\u2581", "unless", "\u2581Holiday", "\u2581has", "\u2581", "a", "\u2581big", "\u2581game", "\u2581and", "\u2581we", "\u2581hit", "\u2581jump", "ers", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581No", "\u2581Cou", "s", "in", "s", "\u2581today", ".", ".", ".", "\u2581Pe", "lic", "ans", "\u2581off", "ence", "\u2581could", "\u2581be", "\u2581horrible", "\u2581today", "\u2581", "unless", "\u2581Holiday", "\u2581has", "\u2581", "a", "\u2581big", "\u2581game", "\u2581and", "\u2581we", "\u2581hit", "\u2581jump", "ers", "</s>"], "target_sentence": ["\u2581No", "<m>", "\u2581Cou", "s", "in", "s", "</m>", "\u2581today", ".", ".", ".", "<m>", "\u2581Pe", "lic", "ans", "</m>", "\u2581off", "ence", "\u2581could", "\u2581be", "\u2581horrible", "\u2581today", "\u2581", "unless", "<m>", "\u2581Holiday", "</m>", "\u2581has", "\u2581", "a", "\u2581big", "\u2581game", "\u2581and", "\u2581we", "\u2581hit", "\u2581jump", "ers", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 8, 9, 10, 11, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21, 21, 22], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [-1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1286", "sentence": ["\u2581@", "\u2581Ken", "y", "e", "a", "h", "Mon", "a", "e", "\u2581It", "'", "\u2581", "s", "\u2581my", "\u2581school", "\u2581fault", ",", "\u2581girl", "\u2581they", "\u2581cutting", "\u2581up", "\u2581with", "\u2581this", "\u2581dress", "\u2581code", "\u2581", "\ud83d\ude02", "</s>"], "input_sentence": ["\u2581named", "\u2581entity", "\u2581recognition", ":", "\u2581@", "\u2581Ken", "y", "e", "a", "h", "Mon", "a", "e", "\u2581It", "'", "\u2581", "s", "\u2581my", "\u2581school", "\u2581fault", ",", "\u2581girl", "\u2581they", "\u2581cutting", "\u2581up", "\u2581with", "\u2581this", "\u2581dress", "\u2581code", "\u2581", "\ud83d\ude02", "</s>"], "target_sentence": ["<m>", "\u2581@", "\u2581Ken", "y", "e", "a", "h", "Mon", "a", "e", "</m>", "\u2581It", "'", "\u2581", "s", "\u2581my", "\u2581school", "\u2581fault", ",", "\u2581girl", "\u2581they", "\u2581cutting", "\u2581up", "\u2581with", "\u2581this", "\u2581dress", "\u2581code", "\u2581", "\ud83d\ude02", "</s>"], "subtoken_map": [0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 17, 18], "ent_type_sequence": [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], "ent_indices": [0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]}, {"doc_id": "emerging.test_1287", "sentence": ["</s>"], "input_sentence": ["</s>"], "target_sentence": ["</s>"], "subtoken_map": [0], "ent_type_sequence": [-1], "ent_indices": [-1]}]