{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Build ASR pipeline\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation error:  datasets/wnut/emerging.test.conll 18828 ['Advertise', 'I-creative-work']\n",
      "Annotation error:  datasets/wnut/emerging.test.conll 18829 ['Anything', 'I-creative-work']\n"
     ]
    }
   ],
   "source": [
    "from data_preparation.wnut import wnut_to_json\n",
    "\n",
    "wnut_to_json(\"datasets/wnut/wnut17train.conll\", \n",
    "                  \"datasets/wnut/emerging.dev.conll\",\n",
    "                  \"datasets/wnut/emerging.test.conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': {'short': 'location'},\n",
       " 'group': {'short': 'group'},\n",
       " 'corporation': {'short': 'corporation'},\n",
       " 'person': {'short': 'person'},\n",
       " 'creative-work': {'short': 'creative-work'},\n",
       " 'product': {'short': 'product'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['For',\n",
       "  'more',\n",
       "  'info',\n",
       "  'about',\n",
       "  'this',\n",
       "  'and',\n",
       "  'local',\n",
       "  'views',\n",
       "  'on',\n",
       "  'the',\n",
       "  'matter',\n",
       "  'check',\n",
       "  'out',\n",
       "  'where',\n",
       "  'OP',\n",
       "  'took',\n",
       "  'this',\n",
       "  'from',\n",
       "  '.'],\n",
       " 'extended': ['For',\n",
       "  'more',\n",
       "  'info',\n",
       "  'about',\n",
       "  'this',\n",
       "  'and',\n",
       "  'local',\n",
       "  'views',\n",
       "  'on',\n",
       "  'the',\n",
       "  'matter',\n",
       "  'check',\n",
       "  'out',\n",
       "  'where',\n",
       "  'OP',\n",
       "  'took',\n",
       "  'this',\n",
       "  'from',\n",
       "  '.'],\n",
       " 'entities': [Entity(type='creative-work', start=6, end=8)]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinloebbert/opt/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing.tokenize import tokenize_json\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "\n",
    "tokenize_json(tokenizer,\n",
    "              \"datasets/wnut/wnut17train.json\",\n",
    "              \"datasets/wnut/emerging.dev.json\",\n",
    "              \"datasets/wnut/emerging.test.json\",\n",
    "              \"datasets/wnut/wnut_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels can have multiple values concatenated via commas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinloebbert/opt/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing.tensorize import NERDataProcessor\n",
    "from data_preprocessing.tokenize import MENTION_START, MENTION_END\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "tokenizer.add_tokens(MENTION_START)\n",
    "tokenizer.add_tokens(MENTION_END)\n",
    "\n",
    "processor = NERDataProcessor({}, tokenizer, \n",
    "                             MENTION_START, MENTION_END,\n",
    "                             \"datasets/wnut/wnut17train.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/emerging.dev.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/emerging.test.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/wnut_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, _, _ = processor.get_tensor_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wnut17train_395',\n",
       " {'input_ids': tensor([ 2650, 10409,  5786,    10,     3,  5934,  3320,   439,  8399,    23,\n",
       "           1191,   107,   254,     3,  5934,  3320,   134,  2295,     9, 13286,\n",
       "          13714,    17,   109,    51,    29,  3337,   116,  3320,     7,   994,\n",
       "             77,    77,    23,    19,     3,  5307,     3,    40,    17,   140,\n",
       "            474,     8,   505,  2423,  2423,  2423,  2423,  3274,   308,    30,\n",
       "            160,    58,     3,   184,    40,    17,   117,     3,    40,    51,\n",
       "             89,     9,    32,     3, 14952, 16780,  2381,    41,     3,    29,\n",
       "             77,    23,     3,   157,    29,   210,     7,     3,   210,     7,\n",
       "            413,  4244,     3,    76,   416, 16497,    61,     1]),\n",
       "  'input_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'to_copy_ids': tensor([    3,  5934,  3320,   439,  8399,    23,  1191,   107,   254,     3,\n",
       "           5934,  3320,   134,  2295,     9, 13286, 13714,    17,   109,    51,\n",
       "             29,  3337,   116,  3320,     7,   994,    77,    77,    23,    19,\n",
       "              3,  5307,     3,    40,    17,   140,   474,     8,   505,  2423,\n",
       "           2423,  2423,  2423,  3274,   308,    30,   160,    58,     3,   184,\n",
       "             40,    17,   117,     3,    40,    51,    89,     9,    32,     3,\n",
       "          14952, 16780,  2381,    41,     3,    29,    77,    23,     3,   157,\n",
       "             29,   210,     7,     3,   210,     7,   413,  4244,     3,    76,\n",
       "            416, 16497,    61,     1]),\n",
       "  'target_ids': tensor([    3,  5934,  3320,   439,  8399,    23,  1191,   107,   254,     3,\n",
       "           5934,  3320,   134,  2295,     9, 13286, 13714,    17,   109,    51,\n",
       "             29,  3337,   116,  3320,     7,   994,    77,    77,    23,    19,\n",
       "              3,  5307,     3,    40,    17,   140,   474,     8,   505,  2423,\n",
       "           2423,  2423,  2423,  3274,   308,    30,   160,    58,     3,   184,\n",
       "             40,    17,   117,     3,    40,    51,    89,     9,    32,     3,\n",
       "          14952, 16780,  2381,    41, 32100,     3,    29,    77,    23, 32101,\n",
       "              3,   157,    29,   210,     7,     3,   210,     7,   413,  4244,\n",
       "              3,    76,   416, 16497,    61,     1]),\n",
       "  'target_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'action_labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'ent_indices': tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
       "  'ent_types': tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  3, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
       "  'lr_pair_flag': tensor([[[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False,  True, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]],\n",
       "  \n",
       "          [[False, False, False, False, False, False]]]),\n",
       "  'is_training': tensor(True)})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
