{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Build ASR pipeline\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/envs/haystack/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from pipelines.evaluation import get_or_filter_from_list, setup_database\n",
    "import json\n",
    "\n",
    "error_database_size = 0.5\n",
    "filters = {\n",
    "    \"train\": [\"train\"],\n",
    "    \"dev\": [\"train\", \"dev\"],\n",
    "    \"test\": [\"train\", \"dev\", \"test\"]\n",
    "}\n",
    "seed = 42\n",
    "error_document_id_filter = defaultdict(list)\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "error_document_store, error_search = setup_database(\n",
    "    \"ann_10_gazetteers_error_dataset_868514705\", \"ann\", 10)\n",
    "\n",
    "with open(\"/home/loebbert/projects/thesis/evaluations/false_positives.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    false_positives = json.load(file)\n",
    "\n",
    "for part in filters:\n",
    "    current_filter = get_or_filter_from_list(\"dataset\", filters[part])\n",
    "    current_filter[\"$not\"] = {  # type: ignore\n",
    "        \"doc_id\": [doc_id for doc_id in false_positives[part]]\n",
    "    }\n",
    "    doc_count = error_document_store.get_document_count(\n",
    "        current_filter)  # type: ignore\n",
    "    filter_mask = rng.choice(doc_count,\n",
    "                                int(doc_count * error_database_size),\n",
    "                                replace=False).tolist()\n",
    "    docs = error_document_store.get_all_documents(\n",
    "        filters=current_filter)  # type: ignore\n",
    "    for search_mask, doc in enumerate(docs):\n",
    "        if search_mask in filter_mask and doc.id not in error_document_id_filter[\n",
    "                part]:\n",
    "            error_document_id_filter[part].append(doc.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 706\n",
      "dev 1040\n",
      "test 1498\n"
     ]
    }
   ],
   "source": [
    "for key, values in error_document_id_filter.items():\n",
    "    print(key, len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = {\n",
    "    \"tokens\": [\n",
    "        \"@paulwalk\", \"It\", \"'s\", \"the\", \"view\", \"from\", \"where\", \"I\", \"'m\",\n",
    "        \"living\", \"for\", \"two\", \"weeks\", \".\", \"Empire\", \"State\", \"Building\",\n",
    "        \"=\", \"ESB\", \".\", \"Pretty\", \"bad\", \"storm\", \"here\", \"last\", \"evening\",\n",
    "        \".\"\n",
    "    ],\n",
    "    \"extended\": [\n",
    "        \"@paulwalk\", \"It\", \"'s\", \"the\", \"view\", \"from\", \"where\", \"I\", \"'m\",\n",
    "        \"living\", \"for\", \"two\", \"weeks\", \".\", \"Empire\", \"State\", \"Building\",\n",
    "        \"=\", \"ESB\", \".\", \"Pretty\", \"bad\", \"storm\", \"here\", \"last\", \"evening\",\n",
    "        \".\"\n",
    "    ],\n",
    "    \"entities\": [{\n",
    "        \"type\": \"location\",\n",
    "        \"start\": 14,\n",
    "        \"end\": 17\n",
    "    }, {\n",
    "        \"type\": \"location\",\n",
    "        \"start\": 18,\n",
    "        \"end\": 19\n",
    "    }],\n",
    "    \"doc_id\":\n",
    "    \"wnut_train_0\"\n",
    "}\n",
    "sentence = \" \".join(doc[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "results = error_search.run(query=sentence,\n",
    "                           params={\n",
    "                               \"filters\": {\n",
    "                                   \"$and\": {\n",
    "                                       \"$not\": {\n",
    "                                           \"doc_id\": [doc[\"doc_id\"]],\n",
    "                                           \"content\": sentence,\n",
    "                                           \"_id\":\n",
    "                                           error_document_id_filter[\"train\"]\n",
    "                                       },\n",
    "                                       **{\n",
    "                                           \"$or\": [{\n",
    "                                               \"dataset\": [\"train\"]\n",
    "                                           }]\n",
    "                                       }\n",
    "                                   }\n",
    "                               }\n",
    "                           })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = error_document_store.get_all_documents(\n",
    "    filters={\n",
    "        \"$and\": {\n",
    "            \"$not\": {\n",
    "                \"doc_id\": [doc[\"doc_id\"]],\n",
    "                \"content\": sentence,\n",
    "                \"_id\": error_document_id_filter[\"dev\"]\n",
    "            },\n",
    "            **get_or_filter_from_list(\"dataset\", filters[\"dev\"])\n",
    "        }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3190"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_document_store.get_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document: {'content': 'NYC', 'content_type': 'text', 'score': 0.5011589979241876, 'meta': {'data_type': 'gazetteers', 'type': 'location', 'doc_id': ['wnut_train_442', 'wnut_train_473', 'wnut_train_1830', 'wnut_train_2098', 'wnut_train_2248', 'wnut_train_2478'], 'dataset': ['train']}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3e40989e0035845aed63ad3b9989e9ac'}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation error:  datasets/wnut/emerging.test.conll 18828 ['Advertise', 'I-creative-work']\n",
      "Annotation error:  datasets/wnut/emerging.test.conll 18829 ['Anything', 'I-creative-work']\n"
     ]
    }
   ],
   "source": [
    "from data_preparation.wnut import wnut_to_json\n",
    "\n",
    "wnut_to_json(\"datasets/wnut/wnut17train.conll\", \n",
    "                  \"datasets/wnut/emerging.dev.conll\",\n",
    "                  \"datasets/wnut/emerging.test.conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation.conll03 import conll03_to_json\n",
    "\n",
    "conll03_to_json(\"data/conll03/mine/train.txt\",\n",
    "                \"data/conll03/mine/dev.txt\",\n",
    "                \"data/conll03/mine/test.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': {'short': 'location'},\n",
       " 'group': {'short': 'group'},\n",
       " 'corporation': {'short': 'corporation'},\n",
       " 'person': {'short': 'person'},\n",
       " 'creative-work': {'short': 'creative-work'},\n",
       " 'product': {'short': 'product'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['For',\n",
       "  'more',\n",
       "  'info',\n",
       "  'about',\n",
       "  'this',\n",
       "  'and',\n",
       "  'local',\n",
       "  'views',\n",
       "  'on',\n",
       "  'the',\n",
       "  'matter',\n",
       "  'check',\n",
       "  'out',\n",
       "  'where',\n",
       "  'OP',\n",
       "  'took',\n",
       "  'this',\n",
       "  'from',\n",
       "  '.'],\n",
       " 'extended': ['For',\n",
       "  'more',\n",
       "  'info',\n",
       "  'about',\n",
       "  'this',\n",
       "  'and',\n",
       "  'local',\n",
       "  'views',\n",
       "  'on',\n",
       "  'the',\n",
       "  'matter',\n",
       "  'check',\n",
       "  'out',\n",
       "  'where',\n",
       "  'OP',\n",
       "  'took',\n",
       "  'this',\n",
       "  'from',\n",
       "  '.'],\n",
       " 'entities': [Entity(type='creative-work', start=6, end=8)]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinloebbert/opt/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing.tokenize import tokenize_json\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "\n",
    "tokenize_json(tokenizer,\n",
    "              \"datasets/wnut/wnut17train.json\",\n",
    "              \"datasets/wnut/emerging.dev.json\",\n",
    "              \"datasets/wnut/emerging.test.json\",\n",
    "              \"datasets/wnut/wnut_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conll03_train: dropped 5 inst_ids: 8884 10279 13068 13234 13672\n",
      "conll03_dev: dropped 8 inst_ids: 1055 2184 2185 2594 2595 2616 2617 2903\n",
      "conll03_test: dropped 8 inst_ids: 33 46 47 202 203 1841 3198 3199\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing.tokenize import tokenize_json\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "\n",
    "tokenize_json(tokenizer, \"datasets/conll03/conll03_train.json\",\n",
    "              \"datasets/conll03/conll03_dev.json\",\n",
    "              \"datasets/conll03/conll03_test.json\",\n",
    "              \"datasets/conll03/conll03_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels can have multiple values concatenated via commas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing.tensorize import NERDataProcessor\n",
    "from data_preprocessing.tokenize import MENTION_START, MENTION_END\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "tokenizer.add_tokens(MENTION_START)\n",
    "tokenizer.add_tokens(MENTION_END)\n",
    "\n",
    "config = {\n",
    "    \"mention_start_token\": MENTION_START,\n",
    "    \"mention_end_token\": MENTION_END\n",
    "}\n",
    "\n",
    "processor = NERDataProcessor(config, tokenizer,\n",
    "                             \"datasets/wnut/wnut17train.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/emerging.dev.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/emerging.test.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/wnut_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/wnut/cached.tensors.t5-small.bin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.get_cache_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = processor.get_tensor_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': 'emerging.test_22',\n",
       " 'sentence': ['▁Rep',\n",
       "  'ly',\n",
       "  'ing',\n",
       "  '▁to',\n",
       "  '▁another',\n",
       "  '▁question',\n",
       "  ',',\n",
       "  '▁B',\n",
       "  'ham',\n",
       "  're',\n",
       "  '▁said',\n",
       "  '▁the',\n",
       "  '▁jaw',\n",
       "  'ans',\n",
       "  '▁deployed',\n",
       "  '▁at',\n",
       "  '▁places',\n",
       "  '▁such',\n",
       "  '▁as',\n",
       "  '▁Si',\n",
       "  'a',\n",
       "  'chen',\n",
       "  '▁Gla',\n",
       "  'cier',\n",
       "  '▁are',\n",
       "  '▁provided',\n",
       "  '▁with',\n",
       "  '▁the',\n",
       "  '▁best',\n",
       "  '-',\n",
       "  'quality',\n",
       "  '▁winter',\n",
       "  '▁clothing',\n",
       "  '.',\n",
       "  '</s>'],\n",
       " 'input_sentence': ['▁named',\n",
       "  '▁entity',\n",
       "  '▁recognition',\n",
       "  ':',\n",
       "  '▁Rep',\n",
       "  'ly',\n",
       "  'ing',\n",
       "  '▁to',\n",
       "  '▁another',\n",
       "  '▁question',\n",
       "  ',',\n",
       "  '▁B',\n",
       "  'ham',\n",
       "  're',\n",
       "  '▁said',\n",
       "  '▁the',\n",
       "  '▁jaw',\n",
       "  'ans',\n",
       "  '▁deployed',\n",
       "  '▁at',\n",
       "  '▁places',\n",
       "  '▁such',\n",
       "  '▁as',\n",
       "  '▁Si',\n",
       "  'a',\n",
       "  'chen',\n",
       "  '▁Gla',\n",
       "  'cier',\n",
       "  '▁are',\n",
       "  '▁provided',\n",
       "  '▁with',\n",
       "  '▁the',\n",
       "  '▁best',\n",
       "  '-',\n",
       "  'quality',\n",
       "  '▁winter',\n",
       "  '▁clothing',\n",
       "  '.',\n",
       "  '</s>'],\n",
       " 'target_sentence': ['▁Rep',\n",
       "  'ly',\n",
       "  'ing',\n",
       "  '▁to',\n",
       "  '▁another',\n",
       "  '▁question',\n",
       "  ',',\n",
       "  '<m>',\n",
       "  '<m>',\n",
       "  '▁B',\n",
       "  'ham',\n",
       "  're',\n",
       "  '</m>',\n",
       "  '</m>',\n",
       "  '▁said',\n",
       "  '▁the',\n",
       "  '<m>',\n",
       "  '▁jaw',\n",
       "  'ans',\n",
       "  '</m>',\n",
       "  '▁deployed',\n",
       "  '▁at',\n",
       "  '▁places',\n",
       "  '▁such',\n",
       "  '▁as',\n",
       "  '<m>',\n",
       "  '<m>',\n",
       "  '<m>',\n",
       "  '▁Si',\n",
       "  'a',\n",
       "  'chen',\n",
       "  '▁Gla',\n",
       "  'cier',\n",
       "  '</m>',\n",
       "  '</m>',\n",
       "  '</m>',\n",
       "  '▁are',\n",
       "  '▁provided',\n",
       "  '▁with',\n",
       "  '▁the',\n",
       "  '▁best',\n",
       "  '-',\n",
       "  'quality',\n",
       "  '▁winter',\n",
       "  '▁clothing',\n",
       "  '.',\n",
       "  '</s>'],\n",
       " 'subtoken_map': [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24],\n",
       " 'ent_type_sequence': [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  3,\n",
       "  4,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  2,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1],\n",
       " 'ent_indices': [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  1,\n",
       "  0,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  1,\n",
       "  0,\n",
       "  -1,\n",
       "  -1,\n",
       "  2,\n",
       "  -1,\n",
       "  -1,\n",
       "  2,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.stored_info[\"example\"][\"emerging.test_22\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "test_multiple = None\n",
    "for (doc_key, subtoken_map, sample) in test.data:\n",
    "    if doc_key == \"emerging.test_22\":\n",
    "        test_multiple = (doc_key, subtoken_map, sample)\n",
    "        break\n",
    "with open(\"tests/data/wnut_nested_batch_1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(test_multiple, file)\n",
    "\n",
    "with open(\"tests/data/wnut_nested_batch_10.pkl\", \"wb\") as file:\n",
    "    res = [test_multiple, *test.data[:9]]\n",
    "    print(len(res))\n",
    "    pickle.dump(res, file)\n",
    "\n",
    "with open(\"tests/data/wnut_batch_1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(train.data[0], file)\n",
    "\n",
    "with open(\"tests/data/wnut_batch_10.pkl\", \"wb\") as file:\n",
    "    pickle.dump(train.data[:10], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6666666666666667, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/3, 5//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing.tensorize import ner_collate_fn\n",
    "import pickle\n",
    "\n",
    "with open(\"tests/data/wnut_batch_10.pkl\", \"rb\") as file:\n",
    "            data_point = pickle.load(file)\n",
    "(doc_keys, subtoken_maps, batch) = ner_collate_fn(data_point)\n",
    "assert len(subtoken_maps) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  31,\n",
       "  32,\n",
       "  32,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  35],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  29,\n",
       "  29,\n",
       "  29,\n",
       "  29,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  31],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  28],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  24,\n",
       "  25],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  27],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  29,\n",
       "  30,\n",
       "  30,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  34,\n",
       "  35],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  40,\n",
       "  41],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  27,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  29],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  29,\n",
       "  29,\n",
       "  30])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtoken_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinloebbert/opt/miniconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5Model\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5Model.from_pretrained(\"t5-small\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    ").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "# forward pass\n",
    "outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/loebbert/projects'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\"/\" + os.path.join(*os.getcwd().split(os.path.sep)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.metrics import F1ASP\n",
    "\n",
    "metric = F1ASP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.update([(2, 3, 5)], [])\n",
    "metric.update([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6530612707138062"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.statistics_json import create_dataset_stats\n",
    "\n",
    "asp_inputs, asp_entities = create_dataset_stats(\"data/conll03/asp/conll03_train.json\",\n",
    "                     \"data/conll03/asp/conll03_dev.json\",\n",
    "                     \"data/conll03/asp/conll03_test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Sentences  Tokens  Entities\n",
       " train       8564  203621     23484\n",
       " dev         2176   51362      5938\n",
       " test        1948   46435      5640,\n",
       "        Total     LOC    MISC     ORG     PER\n",
       " train  23484  7132.0  3438.0  6319.0  6595.0\n",
       " dev     5938  1834.0   922.0  1341.0  1841.0\n",
       " test    5640  1663.0   702.0  1659.0  1616.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asp_inputs, asp_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    23484\n",
       "dev       5938\n",
       "test      5640\n",
       "Name: asdf, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitiy = asp_entities[\"Total\"].copy()\n",
    "entitiy.name = \"asdf\"\n",
    "entitiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    23484\n",
       "dev       5938\n",
       "test      5640\n",
       "Name: asdf2, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitiy2 = asp_entities[\"Total\"].copy()\n",
    "entitiy2.name = \"asdf2\"\n",
    "entitiy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    23484\n",
       "dev       5938\n",
       "test      5640\n",
       "Name: asdf, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asdf</th>\n",
       "      <th>asdf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>23484</td>\n",
       "      <td>23484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>5938</td>\n",
       "      <td>5938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>5640</td>\n",
       "      <td>5640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        asdf  asdf2\n",
       "train  23484  23484\n",
       "dev     5938   5938\n",
       "test    5640   5640"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.concat([entitiy, entitiy2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORG': 6319.0,\n",
       " 'entity_len': 34018.0,\n",
       " 'MISC': 3438.0,\n",
       " 'PER': 6595.0,\n",
       " 'LOC': 7132.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_asp[\"train_entities\"].loc[\"sum\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_len</th>\n",
       "      <th>tokens_sent_count</th>\n",
       "      <th>extended_len</th>\n",
       "      <th>extended_sent_count</th>\n",
       "      <th>entities_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>51362.000000</td>\n",
       "      <td>3472.000000</td>\n",
       "      <td>51362.000000</td>\n",
       "      <td>3472.000000</td>\n",
       "      <td>5938.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.803692</td>\n",
       "      <td>1.068308</td>\n",
       "      <td>15.803692</td>\n",
       "      <td>1.068308</td>\n",
       "      <td>1.827077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.603389</td>\n",
       "      <td>0.252312</td>\n",
       "      <td>12.603389</td>\n",
       "      <td>0.252312</td>\n",
       "      <td>1.777810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tokens_len  tokens_sent_count  extended_len  extended_sent_count  \\\n",
       "sum    51362.000000        3472.000000  51362.000000          3472.000000   \n",
       "count   3250.000000        3250.000000   3250.000000          3250.000000   \n",
       "mean      15.803692           1.068308     15.803692             1.068308   \n",
       "std       12.603389           0.252312     12.603389             0.252312   \n",
       "min        1.000000           1.000000      1.000000             1.000000   \n",
       "25%        7.000000           1.000000      7.000000             1.000000   \n",
       "50%       11.000000           1.000000     11.000000             1.000000   \n",
       "75%       24.000000           1.000000     24.000000             1.000000   \n",
       "90%       34.000000           1.000000     34.000000             1.000000   \n",
       "max      109.000000           2.000000    109.000000             2.000000   \n",
       "\n",
       "       entities_count  \n",
       "sum       5938.000000  \n",
       "count     3250.000000  \n",
       "mean         1.827077  \n",
       "std          1.777810  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          2.000000  \n",
       "90%          4.000000  \n",
       "max         20.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.statistics_json import create_dataset_stats\n",
    "\n",
    "stats_mine = create_dataset_stats(\"data/conll03/mine/conll03_train.json\",\n",
    "                                 \"data/conll03/mine/conll03_dev.json\",\n",
    "                                 \"data/conll03/mine/conll03_test.json\")\n",
    "stats_mine[\"test_inputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>entity_len</th>\n",
       "      <th>MISC</th>\n",
       "      <th>PER</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1656.0</td>\n",
       "      <td>8087.000000</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>1662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1656.0</td>\n",
       "      <td>5628.000000</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>1662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.436923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ORG   entity_len   MISC     PER     LOC\n",
       "sum    1656.0  8087.000000  693.0  1617.0  1662.0\n",
       "count  1656.0  5628.000000  693.0  1617.0  1662.0\n",
       "mean      1.0     1.436923    1.0     1.0     1.0\n",
       "std       0.0     0.655608    0.0     0.0     0.0\n",
       "min       1.0     1.000000    1.0     1.0     1.0\n",
       "25%       1.0     1.000000    1.0     1.0     1.0\n",
       "50%       1.0     1.000000    1.0     1.0     1.0\n",
       "75%       1.0     2.000000    1.0     1.0     1.0\n",
       "90%       1.0     2.000000    1.0     1.0     1.0\n",
       "max       1.0     6.000000    1.0     1.0     1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_mine[\"test_entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_len</th>\n",
       "      <th>tokens_sent_count</th>\n",
       "      <th>extended_len</th>\n",
       "      <th>extended_sent_count</th>\n",
       "      <th>entities_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>203621.000000</td>\n",
       "      <td>14833.000000</td>\n",
       "      <td>203621.000000</td>\n",
       "      <td>14833.000000</td>\n",
       "      <td>23429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14041.000000</td>\n",
       "      <td>14041.000000</td>\n",
       "      <td>14041.000000</td>\n",
       "      <td>14041.000000</td>\n",
       "      <td>14041.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.501887</td>\n",
       "      <td>1.056406</td>\n",
       "      <td>14.501887</td>\n",
       "      <td>1.056406</td>\n",
       "      <td>1.668613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.602756</td>\n",
       "      <td>0.232251</td>\n",
       "      <td>11.602756</td>\n",
       "      <td>0.232251</td>\n",
       "      <td>1.527363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>113.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tokens_len  tokens_sent_count   extended_len  extended_sent_count  \\\n",
       "sum    203621.000000       14833.000000  203621.000000         14833.000000   \n",
       "count   14041.000000       14041.000000   14041.000000         14041.000000   \n",
       "mean       14.501887           1.056406      14.501887             1.056406   \n",
       "std        11.602756           0.232251      11.602756             0.232251   \n",
       "min         1.000000           1.000000       1.000000             1.000000   \n",
       "25%         6.000000           1.000000       6.000000             1.000000   \n",
       "50%        10.000000           1.000000      10.000000             1.000000   \n",
       "75%        22.000000           1.000000      22.000000             1.000000   \n",
       "90%        32.000000           1.000000      32.000000             1.000000   \n",
       "max       113.000000           3.000000     113.000000             3.000000   \n",
       "\n",
       "       entities_count  \n",
       "sum      23429.000000  \n",
       "count    14041.000000  \n",
       "mean         1.668613  \n",
       "std          1.527363  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          2.000000  \n",
       "90%          4.000000  \n",
       "max         20.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.statistics_json import create_dataset_stats\n",
    "\n",
    "stats_hugginface = create_dataset_stats(\"data/conll03/huggingface/conll03_train.json\",\n",
    "                                  \"data/conll03/huggingface/conll03_dev.json\",\n",
    "                                  \"data/conll03/huggingface/conll03_test.json\")\n",
    "stats_hugginface[\"train_inputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>entity_len</th>\n",
       "      <th>MISC</th>\n",
       "      <th>PER</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>6297.0</td>\n",
       "      <td>33954.000000</td>\n",
       "      <td>3403.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>7129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6297.0</td>\n",
       "      <td>23429.000000</td>\n",
       "      <td>3403.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>7129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.449230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ORG    entity_len    MISC     PER     LOC\n",
       "sum    6297.0  33954.000000  3403.0  6600.0  7129.0\n",
       "count  6297.0  23429.000000  3403.0  6600.0  7129.0\n",
       "mean      1.0      1.449230     1.0     1.0     1.0\n",
       "std       0.0      0.698081     0.0     0.0     0.0\n",
       "min       1.0      1.000000     1.0     1.0     1.0\n",
       "25%       1.0      1.000000     1.0     1.0     1.0\n",
       "50%       1.0      1.000000     1.0     1.0     1.0\n",
       "75%       1.0      2.000000     1.0     1.0     1.0\n",
       "90%       1.0      2.000000     1.0     1.0     1.0\n",
       "max       1.0     10.000000     1.0     1.0     1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_hugginface[\"train_entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset conll2003 (/home/loebbert/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████| 3/3 [00:00<00:00, 684.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags = {\n",
    "    'O': 0,\n",
    "    'B-PER': 1,\n",
    "    'I-PER': 2,\n",
    "    'B-ORG': 3,\n",
    "    'I-ORG': 4,\n",
    "    'B-LOC': 5,\n",
    "    'I-LOC': 6,\n",
    "    'B-MISC': 7,\n",
    "    'I-MISC': 8\n",
    "}\n",
    "reversed_ner_tags = {v: k for k, v in ner_tags.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in dataset:\n",
    "    with open(\"datasets/conll03/huggingface/\"+part+\".txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        for item in dataset[part]:\n",
    "            for line in [\"\\t\".join([token, \"x\", \"x\", reversed_ner_tags[ner_tag_id]]) for token, ner_tag_id in zip(item[\"tokens\"], item[\"ner_tags\"])]:\n",
    "                file.write(line + \"\\n\")\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "torch.Size([5])\n",
      "torch.Size([25])\n",
      "torch.Size([15])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "input_ids = torch.ones(80)\n",
    "indices = [15, 20, 45, 60]\n",
    "\n",
    "tensors = torch.tensor_split(input_ids, indices)\n",
    "for t in tensors:\n",
    "    print(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(tensors).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dropout = 0.3\n",
    "np.random.choice([0, 1], size=4, p=[dropout, 1-dropout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't read config from 1 paths\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"/home/loebbert/projects/thesis/finetuning/gazetteers_result_2.pkl\", \"rb\") as file:\n",
    "    results = pkl.load(file)\n",
    "\n",
    "res_df = results.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_f1</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>config/adam_weight_decay</th>\n",
       "      <th>config/asp_activation</th>\n",
       "      <th>config/asp_hidden_dim</th>\n",
       "      <th>config/search_algorithm</th>\n",
       "      <th>config/search_topk</th>\n",
       "      <th>config/task_learning_rate</th>\n",
       "      <th>config/train_search_dropout</th>\n",
       "      <th>config/warmup_ratio</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.654042</td>\n",
       "      <td>71.183806</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>fffb4245</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_09-47-23</td>\n",
       "      <td>1682322443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>629</td>\n",
       "      <td>ann</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218601</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.631965</td>\n",
       "      <td>87.628655</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>b83b4bea</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_11-35-55</td>\n",
       "      <td>1682328955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.099777</td>\n",
       "      <td>relu</td>\n",
       "      <td>230</td>\n",
       "      <td>ann</td>\n",
       "      <td>18</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.234543</td>\n",
       "      <td>0.289003</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.631195</td>\n",
       "      <td>116.259573</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>76ca7be4</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_12-06-15</td>\n",
       "      <td>1682330775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.094136</td>\n",
       "      <td>relu</td>\n",
       "      <td>860</td>\n",
       "      <td>bm25</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.353384</td>\n",
       "      <td>0.519838</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630824</td>\n",
       "      <td>74.290744</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4044e653</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_10-28-36</td>\n",
       "      <td>1682324916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.215376</td>\n",
       "      <td>relu</td>\n",
       "      <td>267</td>\n",
       "      <td>ann</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.266730</td>\n",
       "      <td>0.477340</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.629875</td>\n",
       "      <td>87.943766</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1f084c5d</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_12-18-46</td>\n",
       "      <td>1682331526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.136545</td>\n",
       "      <td>relu</td>\n",
       "      <td>888</td>\n",
       "      <td>bm25</td>\n",
       "      <td>18</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.224164</td>\n",
       "      <td>0.577699</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.628111</td>\n",
       "      <td>107.446711</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>33be0f90</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_11-45-19</td>\n",
       "      <td>1682329519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.289109</td>\n",
       "      <td>relu</td>\n",
       "      <td>312</td>\n",
       "      <td>bm25</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.427798</td>\n",
       "      <td>0.565588</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.627193</td>\n",
       "      <td>101.860703</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>9f6478ea</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_13-01-45</td>\n",
       "      <td>1682334105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.435410</td>\n",
       "      <td>relu</td>\n",
       "      <td>660</td>\n",
       "      <td>ann</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.175368</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.600583</td>\n",
       "      <td>65.711740</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>9ee5bb1c</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_13-28-56</td>\n",
       "      <td>1682335736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.416804</td>\n",
       "      <td>relu</td>\n",
       "      <td>283</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.716911</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.595967</td>\n",
       "      <td>120.647928</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>c2196dee</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_11-27-09</td>\n",
       "      <td>1682328429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.257472</td>\n",
       "      <td>tanh</td>\n",
       "      <td>429</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>27</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.837805</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.594354</td>\n",
       "      <td>56.067287</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>d1853c93</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_13-34-56</td>\n",
       "      <td>1682336096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.083828</td>\n",
       "      <td>relu</td>\n",
       "      <td>535</td>\n",
       "      <td>ann</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.582664</td>\n",
       "      <td>0.156198</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.593245</td>\n",
       "      <td>81.387188</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>ba2393fa</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_10-03-22</td>\n",
       "      <td>1682323402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.359307</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>423</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.257918</td>\n",
       "      <td>0.748925</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.592154</td>\n",
       "      <td>92.315422</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5c61864c</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_12-26-32</td>\n",
       "      <td>1682331992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.375553</td>\n",
       "      <td>relu</td>\n",
       "      <td>140</td>\n",
       "      <td>bm25</td>\n",
       "      <td>33</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.589144</td>\n",
       "      <td>0.282841</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.590774</td>\n",
       "      <td>98.303556</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>fd1b0535</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_10-45-01</td>\n",
       "      <td>1682325901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.321744</td>\n",
       "      <td>relu</td>\n",
       "      <td>730</td>\n",
       "      <td>bm25</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.534103</td>\n",
       "      <td>0.607147</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.589536</td>\n",
       "      <td>73.337407</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6fd1ee78</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_12-35-10</td>\n",
       "      <td>1682332510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.444342</td>\n",
       "      <td>relu</td>\n",
       "      <td>921</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>17</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.463635</td>\n",
       "      <td>0.132320</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.588408</td>\n",
       "      <td>85.973253</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>b94b6da7</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_11-55-13</td>\n",
       "      <td>1682330113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.206162</td>\n",
       "      <td>relu</td>\n",
       "      <td>611</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>19</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>0.211762</td>\n",
       "      <td>0.761242</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.586053</td>\n",
       "      <td>110.608444</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>63ca941a</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_10-21-05</td>\n",
       "      <td>1682324465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.047323</td>\n",
       "      <td>tanh</td>\n",
       "      <td>367</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>28</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.205342</td>\n",
       "      <td>0.399442</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.585903</td>\n",
       "      <td>74.281826</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>fa1f9557</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_10-36-22</td>\n",
       "      <td>1682325382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.288114</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>631</td>\n",
       "      <td>ann</td>\n",
       "      <td>21</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.636926</td>\n",
       "      <td>0.859993</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.584006</td>\n",
       "      <td>92.957126</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>e1abbdca</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_10-56-08</td>\n",
       "      <td>1682326568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.207170</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>940</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>26</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.360613</td>\n",
       "      <td>0.570139</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.583640</td>\n",
       "      <td>80.667958</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>373c7e51</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_11-12-48</td>\n",
       "      <td>1682327568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.045392</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>985</td>\n",
       "      <td>bm25</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.632058</td>\n",
       "      <td>0.120602</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.574198</td>\n",
       "      <td>61.503129</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>39e26a07</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_12-41-49</td>\n",
       "      <td>1682332909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.333402</td>\n",
       "      <td>tanh</td>\n",
       "      <td>598</td>\n",
       "      <td>ann</td>\n",
       "      <td>16</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.753092</td>\n",
       "      <td>0.531948</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.569497</td>\n",
       "      <td>90.124144</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>c08fe035</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_13-09-40</td>\n",
       "      <td>1682334580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.146105</td>\n",
       "      <td>relu</td>\n",
       "      <td>534</td>\n",
       "      <td>bm25</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.566961</td>\n",
       "      <td>0.973593</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.565980</td>\n",
       "      <td>52.423934</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>84b84c0d</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_12-10-59</td>\n",
       "      <td>1682331059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.026228</td>\n",
       "      <td>relu</td>\n",
       "      <td>916</td>\n",
       "      <td>bm25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.648135</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.547241</td>\n",
       "      <td>69.919230</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>9c2a6270</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_11-05-36</td>\n",
       "      <td>1682327136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.498558</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>461</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.800106</td>\n",
       "      <td>0.821115</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.540123</td>\n",
       "      <td>52.463782</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6bba7236</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_13-14-06</td>\n",
       "      <td>1682334846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.469644</td>\n",
       "      <td>relu</td>\n",
       "      <td>110</td>\n",
       "      <td>bm25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.761979</td>\n",
       "      <td>0.034078</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.526398</td>\n",
       "      <td>68.175364</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3d89422d</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_13-21-29</td>\n",
       "      <td>1682335289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>relu</td>\n",
       "      <td>102</td>\n",
       "      <td>ann</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.804011</td>\n",
       "      <td>0.747841</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.516129</td>\n",
       "      <td>51.453744</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0a1be002</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_12-53-06</td>\n",
       "      <td>1682333586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.050469</td>\n",
       "      <td>relu</td>\n",
       "      <td>690</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.968727</td>\n",
       "      <td>0.387608</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>57.032325</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>52eea9df</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_09-53-54</td>\n",
       "      <td>1682322834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>913</td>\n",
       "      <td>ann</td>\n",
       "      <td>28</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>0.109014</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.455379</td>\n",
       "      <td>57.858363</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>e3ae8f08</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_13-39-52</td>\n",
       "      <td>1682336392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.150610</td>\n",
       "      <td>tanh</td>\n",
       "      <td>404</td>\n",
       "      <td>ann+reranking</td>\n",
       "      <td>22</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.921099</td>\n",
       "      <td>0.372691</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.448749</td>\n",
       "      <td>58.252464</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1ea0daaa</td>\n",
       "      <td>59317406875f4cea8b5b49062b0f9c6d</td>\n",
       "      <td>2023-04-24_12-47-05</td>\n",
       "      <td>1682333225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.017327</td>\n",
       "      <td>relu</td>\n",
       "      <td>479</td>\n",
       "      <td>bm25</td>\n",
       "      <td>29</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.964841</td>\n",
       "      <td>0.816585</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      val_f1  time_this_iter_s   done  timesteps_total  episodes_total  \\\n",
       "0   0.654042         71.183806  False              NaN             NaN   \n",
       "11  0.631965         87.628655  False              NaN             NaN   \n",
       "14  0.631195        116.259573  False              NaN             NaN   \n",
       "4   0.630824         74.290744  False              NaN             NaN   \n",
       "16  0.629875         87.943766  False              NaN             NaN   \n",
       "12  0.628111        107.446711  False              NaN             NaN   \n",
       "22  0.627193        101.860703  False              NaN             NaN   \n",
       "26  0.600583         65.711740  False              NaN             NaN   \n",
       "10  0.595967        120.647928  False              NaN             NaN   \n",
       "27  0.594354         56.067287  False              NaN             NaN   \n",
       "2   0.593245         81.387188  False              NaN             NaN   \n",
       "17  0.592154         92.315422  False              NaN             NaN   \n",
       "6   0.590774         98.303556  False              NaN             NaN   \n",
       "18  0.589536         73.337407  False              NaN             NaN   \n",
       "13  0.588408         85.973253  False              NaN             NaN   \n",
       "3   0.586053        110.608444  False              NaN             NaN   \n",
       "5   0.585903         74.281826  False              NaN             NaN   \n",
       "7   0.584006         92.957126  False              NaN             NaN   \n",
       "9   0.583640         80.667958  False              NaN             NaN   \n",
       "19  0.574198         61.503129  False              NaN             NaN   \n",
       "23  0.569497         90.124144  False              NaN             NaN   \n",
       "15  0.565980         52.423934  False              NaN             NaN   \n",
       "8   0.547241         69.919230  False              NaN             NaN   \n",
       "24  0.540123         52.463782  False              NaN             NaN   \n",
       "25  0.526398         68.175364  False              NaN             NaN   \n",
       "21  0.516129         51.453744  False              NaN             NaN   \n",
       "1   0.476190         57.032325  False              NaN             NaN   \n",
       "28  0.455379         57.858363  False              NaN             NaN   \n",
       "20  0.448749         58.252464  False              NaN             NaN   \n",
       "\n",
       "    training_iteration  trial_id                     experiment_id  \\\n",
       "0                    5  fffb4245  59317406875f4cea8b5b49062b0f9c6d   \n",
       "11                   5  b83b4bea  59317406875f4cea8b5b49062b0f9c6d   \n",
       "14                   5  76ca7be4  59317406875f4cea8b5b49062b0f9c6d   \n",
       "4                    5  4044e653  59317406875f4cea8b5b49062b0f9c6d   \n",
       "16                   5  1f084c5d  59317406875f4cea8b5b49062b0f9c6d   \n",
       "12                   5  33be0f90  59317406875f4cea8b5b49062b0f9c6d   \n",
       "22                   5  9f6478ea  59317406875f4cea8b5b49062b0f9c6d   \n",
       "26                   5  9ee5bb1c  59317406875f4cea8b5b49062b0f9c6d   \n",
       "10                   5  c2196dee  59317406875f4cea8b5b49062b0f9c6d   \n",
       "27                   5  d1853c93  59317406875f4cea8b5b49062b0f9c6d   \n",
       "2                    5  ba2393fa  59317406875f4cea8b5b49062b0f9c6d   \n",
       "17                   5  5c61864c  59317406875f4cea8b5b49062b0f9c6d   \n",
       "6                    5  fd1b0535  59317406875f4cea8b5b49062b0f9c6d   \n",
       "18                   5  6fd1ee78  59317406875f4cea8b5b49062b0f9c6d   \n",
       "13                   5  b94b6da7  59317406875f4cea8b5b49062b0f9c6d   \n",
       "3                    7  63ca941a  59317406875f4cea8b5b49062b0f9c6d   \n",
       "5                    5  fa1f9557  59317406875f4cea8b5b49062b0f9c6d   \n",
       "7                    5  e1abbdca  59317406875f4cea8b5b49062b0f9c6d   \n",
       "9                    5  373c7e51  59317406875f4cea8b5b49062b0f9c6d   \n",
       "19                   5  39e26a07  59317406875f4cea8b5b49062b0f9c6d   \n",
       "23                   5  c08fe035  59317406875f4cea8b5b49062b0f9c6d   \n",
       "15                   5  84b84c0d  59317406875f4cea8b5b49062b0f9c6d   \n",
       "8                    5  9c2a6270  59317406875f4cea8b5b49062b0f9c6d   \n",
       "24                   5  6bba7236  59317406875f4cea8b5b49062b0f9c6d   \n",
       "25                   5  3d89422d  59317406875f4cea8b5b49062b0f9c6d   \n",
       "21                   5  0a1be002  59317406875f4cea8b5b49062b0f9c6d   \n",
       "1                    5  52eea9df  59317406875f4cea8b5b49062b0f9c6d   \n",
       "28                   2  e3ae8f08  59317406875f4cea8b5b49062b0f9c6d   \n",
       "20                   5  1ea0daaa  59317406875f4cea8b5b49062b0f9c6d   \n",
       "\n",
       "                   date   timestamp  ...  warmup_time  \\\n",
       "0   2023-04-24_09-47-23  1682322443  ...     0.002532   \n",
       "11  2023-04-24_11-35-55  1682328955  ...     0.002532   \n",
       "14  2023-04-24_12-06-15  1682330775  ...     0.002532   \n",
       "4   2023-04-24_10-28-36  1682324916  ...     0.002532   \n",
       "16  2023-04-24_12-18-46  1682331526  ...     0.002532   \n",
       "12  2023-04-24_11-45-19  1682329519  ...     0.002532   \n",
       "22  2023-04-24_13-01-45  1682334105  ...     0.002532   \n",
       "26  2023-04-24_13-28-56  1682335736  ...     0.002532   \n",
       "10  2023-04-24_11-27-09  1682328429  ...     0.002532   \n",
       "27  2023-04-24_13-34-56  1682336096  ...     0.002532   \n",
       "2   2023-04-24_10-03-22  1682323402  ...     0.002532   \n",
       "17  2023-04-24_12-26-32  1682331992  ...     0.002532   \n",
       "6   2023-04-24_10-45-01  1682325901  ...     0.002532   \n",
       "18  2023-04-24_12-35-10  1682332510  ...     0.002532   \n",
       "13  2023-04-24_11-55-13  1682330113  ...     0.002532   \n",
       "3   2023-04-24_10-21-05  1682324465  ...     0.002532   \n",
       "5   2023-04-24_10-36-22  1682325382  ...     0.002532   \n",
       "7   2023-04-24_10-56-08  1682326568  ...     0.002532   \n",
       "9   2023-04-24_11-12-48  1682327568  ...     0.002532   \n",
       "19  2023-04-24_12-41-49  1682332909  ...     0.002532   \n",
       "23  2023-04-24_13-09-40  1682334580  ...     0.002532   \n",
       "15  2023-04-24_12-10-59  1682331059  ...     0.002532   \n",
       "8   2023-04-24_11-05-36  1682327136  ...     0.002532   \n",
       "24  2023-04-24_13-14-06  1682334846  ...     0.002532   \n",
       "25  2023-04-24_13-21-29  1682335289  ...     0.002532   \n",
       "21  2023-04-24_12-53-06  1682333586  ...     0.002532   \n",
       "1   2023-04-24_09-53-54  1682322834  ...     0.002532   \n",
       "28  2023-04-24_13-39-52  1682336392  ...     0.002532   \n",
       "20  2023-04-24_12-47-05  1682333225  ...     0.002532   \n",
       "\n",
       "    config/adam_weight_decay config/asp_activation config/asp_hidden_dim  \\\n",
       "0                   0.100000                  tanh                   629   \n",
       "11                  0.099777                  relu                   230   \n",
       "14                  0.094136                  relu                   860   \n",
       "4                   0.215376                  relu                   267   \n",
       "16                  0.136545                  relu                   888   \n",
       "12                  0.289109                  relu                   312   \n",
       "22                  0.435410                  relu                   660   \n",
       "26                  0.416804                  relu                   283   \n",
       "10                  0.257472                  tanh                   429   \n",
       "27                  0.083828                  relu                   535   \n",
       "2                   0.359307             gelu_fast                   423   \n",
       "17                  0.375553                  relu                   140   \n",
       "6                   0.321744                  relu                   730   \n",
       "18                  0.444342                  relu                   921   \n",
       "13                  0.206162                  relu                   611   \n",
       "3                   0.047323                  tanh                   367   \n",
       "5                   0.288114             gelu_fast                   631   \n",
       "7                   0.207170             gelu_fast                   940   \n",
       "9                   0.045392             gelu_fast                   985   \n",
       "19                  0.333402                  tanh                   598   \n",
       "23                  0.146105                  relu                   534   \n",
       "15                  0.026228                  relu                   916   \n",
       "8                   0.498558             gelu_fast                   461   \n",
       "24                  0.469644                  relu                   110   \n",
       "25                  0.009024                  relu                   102   \n",
       "21                  0.050469                  relu                   690   \n",
       "1                   0.004796             gelu_fast                   913   \n",
       "28                  0.150610                  tanh                   404   \n",
       "20                  0.017327                  relu                   479   \n",
       "\n",
       "    config/search_algorithm  config/search_topk  config/task_learning_rate  \\\n",
       "0                       ann                  10                   0.000300   \n",
       "11                      ann                  18                   0.003981   \n",
       "14                     bm25                  34                   0.000639   \n",
       "4                       ann                  13                   0.000183   \n",
       "16                     bm25                  18                   0.004161   \n",
       "12                     bm25                  33                   0.000590   \n",
       "22                      ann                  28                   0.000564   \n",
       "26            ann+reranking                  10                   0.000767   \n",
       "10            ann+reranking                  27                   0.003952   \n",
       "27                      ann                   7                   0.002995   \n",
       "2             ann+reranking                  18                   0.002566   \n",
       "17                     bm25                  33                   0.001581   \n",
       "6                      bm25                  35                   0.000865   \n",
       "18            ann+reranking                  17                   0.003930   \n",
       "13            ann+reranking                  19                   0.004343   \n",
       "3             ann+reranking                  28                   0.002720   \n",
       "5                       ann                  21                   0.003617   \n",
       "7             ann+reranking                  26                   0.001834   \n",
       "9                      bm25                  26                   0.003407   \n",
       "19                      ann                  16                   0.004024   \n",
       "23                     bm25                  30                   0.001114   \n",
       "15                     bm25                   3                   0.001590   \n",
       "8             ann+reranking                  30                   0.001059   \n",
       "24                     bm25                   3                   0.002280   \n",
       "25                      ann                  27                   0.001797   \n",
       "21            ann+reranking                   5                   0.003171   \n",
       "1                       ann                  28                   0.003503   \n",
       "28            ann+reranking                  22                   0.002073   \n",
       "20                     bm25                  29                   0.004732   \n",
       "\n",
       "    config/train_search_dropout  config/warmup_ratio  \\\n",
       "0                      0.000000             0.218601   \n",
       "11                     0.234543             0.289003   \n",
       "14                     0.353384             0.519838   \n",
       "4                      0.266730             0.477340   \n",
       "16                     0.224164             0.577699   \n",
       "12                     0.427798             0.565588   \n",
       "22                     0.368627             0.175368   \n",
       "26                     0.217400             0.716911   \n",
       "10                     0.002121             0.837805   \n",
       "27                     0.582664             0.156198   \n",
       "2                      0.257918             0.748925   \n",
       "17                     0.589144             0.282841   \n",
       "6                      0.534103             0.607147   \n",
       "18                     0.463635             0.132320   \n",
       "13                     0.211762             0.761242   \n",
       "3                      0.205342             0.399442   \n",
       "5                      0.636926             0.859993   \n",
       "7                      0.360613             0.570139   \n",
       "9                      0.632058             0.120602   \n",
       "19                     0.753092             0.531948   \n",
       "23                     0.566961             0.973593   \n",
       "15                     0.648135             0.524064   \n",
       "8                      0.800106             0.821115   \n",
       "24                     0.761979             0.034078   \n",
       "25                     0.804011             0.747841   \n",
       "21                     0.968727             0.387608   \n",
       "1                      0.989725             0.109014   \n",
       "28                     0.921099             0.372691   \n",
       "20                     0.964841             0.816585   \n",
       "\n",
       "                                               logdir  \n",
       "0   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "11  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "14  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "4   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "16  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "12  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "22  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "26  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "10  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "27  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "2   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "17  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "6   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "18  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "13  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "3   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "5   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "7   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "9   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "19  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "23  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "15  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "8   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "24  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "25  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "21  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "1   /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "28  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "20  /home/loebbert/projects/thesis/finetuning/tune...  \n",
       "\n",
       "[29 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by=[\"val_f1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by=[\"val_f1\"], ascending=False).index.values[:2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'asp_hidden_dim': 860,\n",
       "  'asp_activation': 'relu',\n",
       "  'task_learning_rate': 0.0006388453739889119,\n",
       "  'adam_weight_decay': 0.09413583800496884,\n",
       "  'warmup_ratio': 0.5198380477628091,\n",
       "  'search_algorithm': 'bm25',\n",
       "  'search_topk': 34,\n",
       "  'train_search_dropout': 0.35338427271411543,\n",
       "  'plm_pretrained_name_or_path': 't5-base',\n",
       "  'plm_tokenizer_name': 't5-small',\n",
       "  'model_max_length': 4096,\n",
       "  'mention_start_token': '<m>',\n",
       "  'mention_end_token': '</m>',\n",
       "  'asp_dropout_rate': 0.3,\n",
       "  'asp_init_std': 0.02,\n",
       "  'num_labels': 6,\n",
       "  'max_nest_depth': 1,\n",
       "  'beam_size': 1,\n",
       "  'plm_learning_rate': 5e-05,\n",
       "  'plm_scheduler': 'linear_with_warmup',\n",
       "  'task_scheduler': 'linear_with_warmup',\n",
       "  'adam_eps': 1e-08,\n",
       "  'num_epochs': 20,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'batch_size': 40,\n",
       "  'train_len': 3394,\n",
       "  'fused': True,\n",
       "  'use_labels': True,\n",
       "  'use_mentions': False,\n",
       "  'prepend_search_results': False,\n",
       "  'filter_exact_match': False,\n",
       "  'filter_same_document': False,\n",
       "  'search_data_type': 'gazetteers',\n",
       "  'seed': 42,\n",
       "  'train_search_shuffle': False,\n",
       "  'data_path': '/home/loebbert/projects/thesis/finetuning/tune',\n",
       "  'name': 'gazetteers',\n",
       "  'precision': 'bf16-mixed'},\n",
       " {'asp_hidden_dim': 230,\n",
       "  'asp_activation': 'relu',\n",
       "  'task_learning_rate': 0.003981039177591235,\n",
       "  'adam_weight_decay': 0.09977663247649064,\n",
       "  'warmup_ratio': 0.28900287725463936,\n",
       "  'search_algorithm': 'ann',\n",
       "  'search_topk': 18,\n",
       "  'train_search_dropout': 0.234542984910455,\n",
       "  'plm_pretrained_name_or_path': 't5-base',\n",
       "  'plm_tokenizer_name': 't5-small',\n",
       "  'model_max_length': 4096,\n",
       "  'mention_start_token': '<m>',\n",
       "  'mention_end_token': '</m>',\n",
       "  'asp_dropout_rate': 0.3,\n",
       "  'asp_init_std': 0.02,\n",
       "  'num_labels': 6,\n",
       "  'max_nest_depth': 1,\n",
       "  'beam_size': 1,\n",
       "  'plm_learning_rate': 5e-05,\n",
       "  'plm_scheduler': 'linear_with_warmup',\n",
       "  'task_scheduler': 'linear_with_warmup',\n",
       "  'adam_eps': 1e-08,\n",
       "  'num_epochs': 20,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'batch_size': 40,\n",
       "  'train_len': 3394,\n",
       "  'fused': True,\n",
       "  'use_labels': True,\n",
       "  'use_mentions': False,\n",
       "  'prepend_search_results': False,\n",
       "  'filter_exact_match': False,\n",
       "  'filter_same_document': False,\n",
       "  'search_data_type': 'gazetteers',\n",
       "  'seed': 42,\n",
       "  'train_search_shuffle': False,\n",
       "  'data_path': '/home/loebbert/projects/thesis/finetuning/tune',\n",
       "  'name': 'gazetteers',\n",
       "  'precision': 'bf16-mixed'},\n",
       " {'asp_hidden_dim': 629,\n",
       "  'asp_activation': 'tanh',\n",
       "  'task_learning_rate': 0.00029999999999999987,\n",
       "  'adam_weight_decay': 0.1,\n",
       "  'warmup_ratio': 0.21860103276831117,\n",
       "  'search_algorithm': 'ann',\n",
       "  'search_topk': 10,\n",
       "  'train_search_dropout': 0.0,\n",
       "  'plm_pretrained_name_or_path': 't5-base',\n",
       "  'plm_tokenizer_name': 't5-small',\n",
       "  'model_max_length': 4096,\n",
       "  'mention_start_token': '<m>',\n",
       "  'mention_end_token': '</m>',\n",
       "  'asp_dropout_rate': 0.3,\n",
       "  'asp_init_std': 0.02,\n",
       "  'num_labels': 6,\n",
       "  'max_nest_depth': 1,\n",
       "  'beam_size': 1,\n",
       "  'plm_learning_rate': 5e-05,\n",
       "  'plm_scheduler': 'linear_with_warmup',\n",
       "  'task_scheduler': 'linear_with_warmup',\n",
       "  'adam_eps': 1e-08,\n",
       "  'num_epochs': 20,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'batch_size': 40,\n",
       "  'train_len': 3394,\n",
       "  'fused': True,\n",
       "  'use_labels': True,\n",
       "  'use_mentions': False,\n",
       "  'prepend_search_results': False,\n",
       "  'filter_exact_match': False,\n",
       "  'filter_same_document': False,\n",
       "  'search_data_type': 'gazetteers',\n",
       "  'seed': 42,\n",
       "  'train_search_shuffle': False,\n",
       "  'data_path': '/home/loebbert/projects/thesis/finetuning/tune',\n",
       "  'name': 'gazetteers',\n",
       "  'precision': 'bf16-mixed'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results = []\n",
    "for i in res_df.sort_values(by=[\"val_f1\"], ascending=False).index.values[:3].tolist():\n",
    "    best_results.append(results[i].config)\n",
    "best_results.reverse()\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asp_hidden_dim': 355,\n",
       " 'asp_dropout_rate': 0.3,\n",
       " 'asp_init_std': 0.019999999999999976,\n",
       " 'asp_activation': 'gelu_fast',\n",
       " 'plm_learning_rate': 4.999999999999997e-05,\n",
       " 'task_learning_rate': 0.0013868381781415849,\n",
       " 'adam_eps': 9.999999999999984e-09,\n",
       " 'adam_weight_decay': 0.1,\n",
       " 'warmup_ratio': 0.6483865273543568,\n",
       " 'use_labels': True,\n",
       " 'use_mentions': True,\n",
       " 'prepend_search_results': False,\n",
       " 'filter_exact_match': False,\n",
       " 'filter_same_document': False,\n",
       " 'search_algorithm': 'bm25',\n",
       " 'search_topk': 5,\n",
       " 'train_search_dropout': 0.6317431305015401,\n",
       " 'train_search_shuffle': False,\n",
       " 'plm_pretrained_name_or_path': 't5-base',\n",
       " 'plm_tokenizer_name': 't5-small',\n",
       " 'model_max_length': 4096,\n",
       " 'mention_start_token': '<m>',\n",
       " 'mention_end_token': '</m>',\n",
       " 'num_labels': 6,\n",
       " 'max_nest_depth': 1,\n",
       " 'beam_size': 1,\n",
       " 'plm_scheduler': 'linear_with_warmup',\n",
       " 'task_scheduler': 'linear_with_warmup',\n",
       " 'num_epochs': 20,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'batch_size': 40,\n",
       " 'train_len': 3394,\n",
       " 'fused': True,\n",
       " 'search_data_type': 'sentences',\n",
       " 'seed': 42,\n",
       " 'data_path': '/home/loebbert/projects/thesis/finetuning/tune',\n",
       " 'name': 'sentences',\n",
       " 'precision': 'bf16-mixed'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[5].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation.lowner import lowner_to_json\n",
    "\n",
    "lowner_to_json(\n",
    "    \"/home/loebbert/projects/thesis/data/mlowner/en/train_lower.txt\",\n",
    "    \"/home/loebbert/projects/thesis/data/mlowner/en/dev_lower.txt\",\n",
    "    \"/home/loebbert/projects/thesis/data/mlowner/en/test_sub_lower.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e5a11972c14e87ce33da35f9e8cfb8d2d805c21d78b4667cb8561a4997eaab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
