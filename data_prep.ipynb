{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Build ASR pipeline\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/envs/haystack/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from pipelines.evaluation import get_or_filter_from_list, setup_database\n",
    "import json\n",
    "\n",
    "error_database_size = 0.5\n",
    "filters = {\n",
    "    \"train\": [\"train\"],\n",
    "    \"dev\": [\"train\", \"dev\"],\n",
    "    \"test\": [\"train\", \"dev\", \"test\"]\n",
    "}\n",
    "seed = 42\n",
    "error_document_id_filter = defaultdict(list)\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "error_document_store, error_search = setup_database(\n",
    "    \"ann_10_gazetteers_error_dataset_868514705\", \"ann\", 10)\n",
    "\n",
    "with open(\"/home/loebbert/projects/thesis/evaluations/false_positives.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    false_positives = json.load(file)\n",
    "\n",
    "for part in filters:\n",
    "    current_filter = get_or_filter_from_list(\"dataset\", filters[part])\n",
    "    current_filter[\"$not\"] = {  # type: ignore\n",
    "        \"doc_id\": [doc_id for doc_id in false_positives[part]]\n",
    "    }\n",
    "    doc_count = error_document_store.get_document_count(\n",
    "        current_filter)  # type: ignore\n",
    "    filter_mask = rng.choice(doc_count,\n",
    "                                int(doc_count * error_database_size),\n",
    "                                replace=False).tolist()\n",
    "    docs = error_document_store.get_all_documents(\n",
    "        filters=current_filter)  # type: ignore\n",
    "    for search_mask, doc in enumerate(docs):\n",
    "        if search_mask in filter_mask and doc.id not in error_document_id_filter[\n",
    "                part]:\n",
    "            error_document_id_filter[part].append(doc.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 706\n",
      "dev 1040\n",
      "test 1498\n"
     ]
    }
   ],
   "source": [
    "for key, values in error_document_id_filter.items():\n",
    "    print(key, len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = {\n",
    "    \"tokens\": [\n",
    "        \"@paulwalk\", \"It\", \"'s\", \"the\", \"view\", \"from\", \"where\", \"I\", \"'m\",\n",
    "        \"living\", \"for\", \"two\", \"weeks\", \".\", \"Empire\", \"State\", \"Building\",\n",
    "        \"=\", \"ESB\", \".\", \"Pretty\", \"bad\", \"storm\", \"here\", \"last\", \"evening\",\n",
    "        \".\"\n",
    "    ],\n",
    "    \"extended\": [\n",
    "        \"@paulwalk\", \"It\", \"'s\", \"the\", \"view\", \"from\", \"where\", \"I\", \"'m\",\n",
    "        \"living\", \"for\", \"two\", \"weeks\", \".\", \"Empire\", \"State\", \"Building\",\n",
    "        \"=\", \"ESB\", \".\", \"Pretty\", \"bad\", \"storm\", \"here\", \"last\", \"evening\",\n",
    "        \".\"\n",
    "    ],\n",
    "    \"entities\": [{\n",
    "        \"type\": \"location\",\n",
    "        \"start\": 14,\n",
    "        \"end\": 17\n",
    "    }, {\n",
    "        \"type\": \"location\",\n",
    "        \"start\": 18,\n",
    "        \"end\": 19\n",
    "    }],\n",
    "    \"doc_id\":\n",
    "    \"wnut_train_0\"\n",
    "}\n",
    "sentence = \" \".join(doc[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "results = error_search.run(query=sentence,\n",
    "                           params={\n",
    "                               \"filters\": {\n",
    "                                   \"$and\": {\n",
    "                                       \"$not\": {\n",
    "                                           \"doc_id\": [doc[\"doc_id\"]],\n",
    "                                           \"content\": sentence,\n",
    "                                           \"_id\":\n",
    "                                           error_document_id_filter[\"train\"]\n",
    "                                       },\n",
    "                                       **{\n",
    "                                           \"$or\": [{\n",
    "                                               \"dataset\": [\"train\"]\n",
    "                                           }]\n",
    "                                       }\n",
    "                                   }\n",
    "                               }\n",
    "                           })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = error_document_store.get_all_documents(\n",
    "    filters={\n",
    "        \"$and\": {\n",
    "            \"$not\": {\n",
    "                \"doc_id\": [doc[\"doc_id\"]],\n",
    "                \"content\": sentence,\n",
    "                \"_id\": error_document_id_filter[\"dev\"]\n",
    "            },\n",
    "            **get_or_filter_from_list(\"dataset\", filters[\"dev\"])\n",
    "        }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3190"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_document_store.get_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document: {'content': 'NYC', 'content_type': 'text', 'score': 0.5011589979241876, 'meta': {'data_type': 'gazetteers', 'type': 'location', 'doc_id': ['wnut_train_442', 'wnut_train_473', 'wnut_train_1830', 'wnut_train_2098', 'wnut_train_2248', 'wnut_train_2478'], 'dataset': ['train']}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '3e40989e0035845aed63ad3b9989e9ac'}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation error:  datasets/wnut/emerging.test.conll 18828 ['Advertise', 'I-creative-work']\n",
      "Annotation error:  datasets/wnut/emerging.test.conll 18829 ['Anything', 'I-creative-work']\n"
     ]
    }
   ],
   "source": [
    "from data_preparation.wnut import wnut_to_json\n",
    "\n",
    "wnut_to_json(\"datasets/wnut/wnut17train.conll\", \n",
    "                  \"datasets/wnut/emerging.dev.conll\",\n",
    "                  \"datasets/wnut/emerging.test.conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation.conll03 import conll03_to_json\n",
    "\n",
    "conll03_to_json(\"data/conll03/mine/train.txt\",\n",
    "                \"data/conll03/mine/dev.txt\",\n",
    "                \"data/conll03/mine/test.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': {'short': 'location'},\n",
       " 'group': {'short': 'group'},\n",
       " 'corporation': {'short': 'corporation'},\n",
       " 'person': {'short': 'person'},\n",
       " 'creative-work': {'short': 'creative-work'},\n",
       " 'product': {'short': 'product'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['For',\n",
       "  'more',\n",
       "  'info',\n",
       "  'about',\n",
       "  'this',\n",
       "  'and',\n",
       "  'local',\n",
       "  'views',\n",
       "  'on',\n",
       "  'the',\n",
       "  'matter',\n",
       "  'check',\n",
       "  'out',\n",
       "  'where',\n",
       "  'OP',\n",
       "  'took',\n",
       "  'this',\n",
       "  'from',\n",
       "  '.'],\n",
       " 'extended': ['For',\n",
       "  'more',\n",
       "  'info',\n",
       "  'about',\n",
       "  'this',\n",
       "  'and',\n",
       "  'local',\n",
       "  'views',\n",
       "  'on',\n",
       "  'the',\n",
       "  'matter',\n",
       "  'check',\n",
       "  'out',\n",
       "  'where',\n",
       "  'OP',\n",
       "  'took',\n",
       "  'this',\n",
       "  'from',\n",
       "  '.'],\n",
       " 'entities': [Entity(type='creative-work', start=6, end=8)]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinloebbert/opt/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing.tokenize import tokenize_json\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "\n",
    "tokenize_json(tokenizer,\n",
    "              \"datasets/wnut/wnut17train.json\",\n",
    "              \"datasets/wnut/emerging.dev.json\",\n",
    "              \"datasets/wnut/emerging.test.json\",\n",
    "              \"datasets/wnut/wnut_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conll03_train: dropped 5 inst_ids: 8884 10279 13068 13234 13672\n",
      "conll03_dev: dropped 8 inst_ids: 1055 2184 2185 2594 2595 2616 2617 2903\n",
      "conll03_test: dropped 8 inst_ids: 33 46 47 202 203 1841 3198 3199\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing.tokenize import tokenize_json\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "\n",
    "tokenize_json(tokenizer, \"datasets/conll03/conll03_train.json\",\n",
    "              \"datasets/conll03/conll03_dev.json\",\n",
    "              \"datasets/conll03/conll03_test.json\",\n",
    "              \"datasets/conll03/conll03_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels can have multiple values concatenated via commas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing.tensorize import NERDataProcessor\n",
    "from data_preprocessing.tokenize import MENTION_START, MENTION_END\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "tokenizer.add_tokens(MENTION_START)\n",
    "tokenizer.add_tokens(MENTION_END)\n",
    "\n",
    "config = {\n",
    "    \"mention_start_token\": MENTION_START,\n",
    "    \"mention_end_token\": MENTION_END\n",
    "}\n",
    "\n",
    "processor = NERDataProcessor(config, tokenizer,\n",
    "                             \"datasets/wnut/wnut17train.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/emerging.dev.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/emerging.test.t5-small.jsonlines\",\n",
    "                             \"datasets/wnut/wnut_types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/wnut/cached.tensors.t5-small.bin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.get_cache_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = processor.get_tensor_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': 'emerging.test_22',\n",
       " 'sentence': ['▁Rep',\n",
       "  'ly',\n",
       "  'ing',\n",
       "  '▁to',\n",
       "  '▁another',\n",
       "  '▁question',\n",
       "  ',',\n",
       "  '▁B',\n",
       "  'ham',\n",
       "  're',\n",
       "  '▁said',\n",
       "  '▁the',\n",
       "  '▁jaw',\n",
       "  'ans',\n",
       "  '▁deployed',\n",
       "  '▁at',\n",
       "  '▁places',\n",
       "  '▁such',\n",
       "  '▁as',\n",
       "  '▁Si',\n",
       "  'a',\n",
       "  'chen',\n",
       "  '▁Gla',\n",
       "  'cier',\n",
       "  '▁are',\n",
       "  '▁provided',\n",
       "  '▁with',\n",
       "  '▁the',\n",
       "  '▁best',\n",
       "  '-',\n",
       "  'quality',\n",
       "  '▁winter',\n",
       "  '▁clothing',\n",
       "  '.',\n",
       "  '</s>'],\n",
       " 'input_sentence': ['▁named',\n",
       "  '▁entity',\n",
       "  '▁recognition',\n",
       "  ':',\n",
       "  '▁Rep',\n",
       "  'ly',\n",
       "  'ing',\n",
       "  '▁to',\n",
       "  '▁another',\n",
       "  '▁question',\n",
       "  ',',\n",
       "  '▁B',\n",
       "  'ham',\n",
       "  're',\n",
       "  '▁said',\n",
       "  '▁the',\n",
       "  '▁jaw',\n",
       "  'ans',\n",
       "  '▁deployed',\n",
       "  '▁at',\n",
       "  '▁places',\n",
       "  '▁such',\n",
       "  '▁as',\n",
       "  '▁Si',\n",
       "  'a',\n",
       "  'chen',\n",
       "  '▁Gla',\n",
       "  'cier',\n",
       "  '▁are',\n",
       "  '▁provided',\n",
       "  '▁with',\n",
       "  '▁the',\n",
       "  '▁best',\n",
       "  '-',\n",
       "  'quality',\n",
       "  '▁winter',\n",
       "  '▁clothing',\n",
       "  '.',\n",
       "  '</s>'],\n",
       " 'target_sentence': ['▁Rep',\n",
       "  'ly',\n",
       "  'ing',\n",
       "  '▁to',\n",
       "  '▁another',\n",
       "  '▁question',\n",
       "  ',',\n",
       "  '<m>',\n",
       "  '<m>',\n",
       "  '▁B',\n",
       "  'ham',\n",
       "  're',\n",
       "  '</m>',\n",
       "  '</m>',\n",
       "  '▁said',\n",
       "  '▁the',\n",
       "  '<m>',\n",
       "  '▁jaw',\n",
       "  'ans',\n",
       "  '</m>',\n",
       "  '▁deployed',\n",
       "  '▁at',\n",
       "  '▁places',\n",
       "  '▁such',\n",
       "  '▁as',\n",
       "  '<m>',\n",
       "  '<m>',\n",
       "  '<m>',\n",
       "  '▁Si',\n",
       "  'a',\n",
       "  'chen',\n",
       "  '▁Gla',\n",
       "  'cier',\n",
       "  '</m>',\n",
       "  '</m>',\n",
       "  '</m>',\n",
       "  '▁are',\n",
       "  '▁provided',\n",
       "  '▁with',\n",
       "  '▁the',\n",
       "  '▁best',\n",
       "  '-',\n",
       "  'quality',\n",
       "  '▁winter',\n",
       "  '▁clothing',\n",
       "  '.',\n",
       "  '</s>'],\n",
       " 'subtoken_map': [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24],\n",
       " 'ent_type_sequence': [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  3,\n",
       "  4,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  2,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1],\n",
       " 'ent_indices': [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  1,\n",
       "  0,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  1,\n",
       "  0,\n",
       "  -1,\n",
       "  -1,\n",
       "  2,\n",
       "  -1,\n",
       "  -1,\n",
       "  2,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.stored_info[\"example\"][\"emerging.test_22\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "test_multiple = None\n",
    "for (doc_key, subtoken_map, sample) in test.data:\n",
    "    if doc_key == \"emerging.test_22\":\n",
    "        test_multiple = (doc_key, subtoken_map, sample)\n",
    "        break\n",
    "with open(\"tests/data/wnut_nested_batch_1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(test_multiple, file)\n",
    "\n",
    "with open(\"tests/data/wnut_nested_batch_10.pkl\", \"wb\") as file:\n",
    "    res = [test_multiple, *test.data[:9]]\n",
    "    print(len(res))\n",
    "    pickle.dump(res, file)\n",
    "\n",
    "with open(\"tests/data/wnut_batch_1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(train.data[0], file)\n",
    "\n",
    "with open(\"tests/data/wnut_batch_10.pkl\", \"wb\") as file:\n",
    "    pickle.dump(train.data[:10], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6666666666666667, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/3, 5//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing.tensorize import ner_collate_fn\n",
    "import pickle\n",
    "\n",
    "with open(\"tests/data/wnut_batch_10.pkl\", \"rb\") as file:\n",
    "            data_point = pickle.load(file)\n",
    "(doc_keys, subtoken_maps, batch) = ner_collate_fn(data_point)\n",
    "assert len(subtoken_maps) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  31,\n",
       "  32,\n",
       "  32,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  35],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  29,\n",
       "  29,\n",
       "  29,\n",
       "  29,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  31],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  28],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  24,\n",
       "  25],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  27],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  29,\n",
       "  30,\n",
       "  30,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  34,\n",
       "  35],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  40,\n",
       "  41],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  27,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  29],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  24,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  29,\n",
       "  29,\n",
       "  30])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtoken_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinloebbert/opt/miniconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5Model\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5Model.from_pretrained(\"t5-small\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    ").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "# forward pass\n",
    "outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/loebbert/projects'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\"/\" + os.path.join(*os.getcwd().split(os.path.sep)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.metrics import F1ASP\n",
    "\n",
    "metric = F1ASP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.update([(2, 3, 5)], [])\n",
    "metric.update([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6530612707138062"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.statistics_json import create_dataset_stats\n",
    "\n",
    "asp_inputs, asp_entities = create_dataset_stats(\"data/conll03/asp/conll03_train.json\",\n",
    "                     \"data/conll03/asp/conll03_dev.json\",\n",
    "                     \"data/conll03/asp/conll03_test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Sentences  Tokens  Entities\n",
       " train       8564  203621     23484\n",
       " dev         2176   51362      5938\n",
       " test        1948   46435      5640,\n",
       "        Total     LOC    MISC     ORG     PER\n",
       " train  23484  7132.0  3438.0  6319.0  6595.0\n",
       " dev     5938  1834.0   922.0  1341.0  1841.0\n",
       " test    5640  1663.0   702.0  1659.0  1616.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asp_inputs, asp_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    23484\n",
       "dev       5938\n",
       "test      5640\n",
       "Name: asdf, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitiy = asp_entities[\"Total\"].copy()\n",
    "entitiy.name = \"asdf\"\n",
    "entitiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    23484\n",
       "dev       5938\n",
       "test      5640\n",
       "Name: asdf2, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitiy2 = asp_entities[\"Total\"].copy()\n",
    "entitiy2.name = \"asdf2\"\n",
    "entitiy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    23484\n",
       "dev       5938\n",
       "test      5640\n",
       "Name: asdf, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asdf</th>\n",
       "      <th>asdf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>23484</td>\n",
       "      <td>23484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>5938</td>\n",
       "      <td>5938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>5640</td>\n",
       "      <td>5640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        asdf  asdf2\n",
       "train  23484  23484\n",
       "dev     5938   5938\n",
       "test    5640   5640"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.concat([entitiy, entitiy2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORG': 6319.0,\n",
       " 'entity_len': 34018.0,\n",
       " 'MISC': 3438.0,\n",
       " 'PER': 6595.0,\n",
       " 'LOC': 7132.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_asp[\"train_entities\"].loc[\"sum\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_len</th>\n",
       "      <th>tokens_sent_count</th>\n",
       "      <th>extended_len</th>\n",
       "      <th>extended_sent_count</th>\n",
       "      <th>entities_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>51362.000000</td>\n",
       "      <td>3472.000000</td>\n",
       "      <td>51362.000000</td>\n",
       "      <td>3472.000000</td>\n",
       "      <td>5938.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.803692</td>\n",
       "      <td>1.068308</td>\n",
       "      <td>15.803692</td>\n",
       "      <td>1.068308</td>\n",
       "      <td>1.827077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.603389</td>\n",
       "      <td>0.252312</td>\n",
       "      <td>12.603389</td>\n",
       "      <td>0.252312</td>\n",
       "      <td>1.777810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tokens_len  tokens_sent_count  extended_len  extended_sent_count  \\\n",
       "sum    51362.000000        3472.000000  51362.000000          3472.000000   \n",
       "count   3250.000000        3250.000000   3250.000000          3250.000000   \n",
       "mean      15.803692           1.068308     15.803692             1.068308   \n",
       "std       12.603389           0.252312     12.603389             0.252312   \n",
       "min        1.000000           1.000000      1.000000             1.000000   \n",
       "25%        7.000000           1.000000      7.000000             1.000000   \n",
       "50%       11.000000           1.000000     11.000000             1.000000   \n",
       "75%       24.000000           1.000000     24.000000             1.000000   \n",
       "90%       34.000000           1.000000     34.000000             1.000000   \n",
       "max      109.000000           2.000000    109.000000             2.000000   \n",
       "\n",
       "       entities_count  \n",
       "sum       5938.000000  \n",
       "count     3250.000000  \n",
       "mean         1.827077  \n",
       "std          1.777810  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          2.000000  \n",
       "90%          4.000000  \n",
       "max         20.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.statistics_json import create_dataset_stats\n",
    "\n",
    "stats_mine = create_dataset_stats(\"data/conll03/mine/conll03_train.json\",\n",
    "                                 \"data/conll03/mine/conll03_dev.json\",\n",
    "                                 \"data/conll03/mine/conll03_test.json\")\n",
    "stats_mine[\"test_inputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>entity_len</th>\n",
       "      <th>MISC</th>\n",
       "      <th>PER</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1656.0</td>\n",
       "      <td>8087.000000</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>1662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1656.0</td>\n",
       "      <td>5628.000000</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>1662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.436923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ORG   entity_len   MISC     PER     LOC\n",
       "sum    1656.0  8087.000000  693.0  1617.0  1662.0\n",
       "count  1656.0  5628.000000  693.0  1617.0  1662.0\n",
       "mean      1.0     1.436923    1.0     1.0     1.0\n",
       "std       0.0     0.655608    0.0     0.0     0.0\n",
       "min       1.0     1.000000    1.0     1.0     1.0\n",
       "25%       1.0     1.000000    1.0     1.0     1.0\n",
       "50%       1.0     1.000000    1.0     1.0     1.0\n",
       "75%       1.0     2.000000    1.0     1.0     1.0\n",
       "90%       1.0     2.000000    1.0     1.0     1.0\n",
       "max       1.0     6.000000    1.0     1.0     1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_mine[\"test_entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_len</th>\n",
       "      <th>tokens_sent_count</th>\n",
       "      <th>extended_len</th>\n",
       "      <th>extended_sent_count</th>\n",
       "      <th>entities_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>203621.000000</td>\n",
       "      <td>14833.000000</td>\n",
       "      <td>203621.000000</td>\n",
       "      <td>14833.000000</td>\n",
       "      <td>23429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14041.000000</td>\n",
       "      <td>14041.000000</td>\n",
       "      <td>14041.000000</td>\n",
       "      <td>14041.000000</td>\n",
       "      <td>14041.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.501887</td>\n",
       "      <td>1.056406</td>\n",
       "      <td>14.501887</td>\n",
       "      <td>1.056406</td>\n",
       "      <td>1.668613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.602756</td>\n",
       "      <td>0.232251</td>\n",
       "      <td>11.602756</td>\n",
       "      <td>0.232251</td>\n",
       "      <td>1.527363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>113.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tokens_len  tokens_sent_count   extended_len  extended_sent_count  \\\n",
       "sum    203621.000000       14833.000000  203621.000000         14833.000000   \n",
       "count   14041.000000       14041.000000   14041.000000         14041.000000   \n",
       "mean       14.501887           1.056406      14.501887             1.056406   \n",
       "std        11.602756           0.232251      11.602756             0.232251   \n",
       "min         1.000000           1.000000       1.000000             1.000000   \n",
       "25%         6.000000           1.000000       6.000000             1.000000   \n",
       "50%        10.000000           1.000000      10.000000             1.000000   \n",
       "75%        22.000000           1.000000      22.000000             1.000000   \n",
       "90%        32.000000           1.000000      32.000000             1.000000   \n",
       "max       113.000000           3.000000     113.000000             3.000000   \n",
       "\n",
       "       entities_count  \n",
       "sum      23429.000000  \n",
       "count    14041.000000  \n",
       "mean         1.668613  \n",
       "std          1.527363  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          2.000000  \n",
       "90%          4.000000  \n",
       "max         20.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.statistics_json import create_dataset_stats\n",
    "\n",
    "stats_hugginface = create_dataset_stats(\"data/conll03/huggingface/conll03_train.json\",\n",
    "                                  \"data/conll03/huggingface/conll03_dev.json\",\n",
    "                                  \"data/conll03/huggingface/conll03_test.json\")\n",
    "stats_hugginface[\"train_inputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>entity_len</th>\n",
       "      <th>MISC</th>\n",
       "      <th>PER</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>6297.0</td>\n",
       "      <td>33954.000000</td>\n",
       "      <td>3403.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>7129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6297.0</td>\n",
       "      <td>23429.000000</td>\n",
       "      <td>3403.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>7129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.449230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ORG    entity_len    MISC     PER     LOC\n",
       "sum    6297.0  33954.000000  3403.0  6600.0  7129.0\n",
       "count  6297.0  23429.000000  3403.0  6600.0  7129.0\n",
       "mean      1.0      1.449230     1.0     1.0     1.0\n",
       "std       0.0      0.698081     0.0     0.0     0.0\n",
       "min       1.0      1.000000     1.0     1.0     1.0\n",
       "25%       1.0      1.000000     1.0     1.0     1.0\n",
       "50%       1.0      1.000000     1.0     1.0     1.0\n",
       "75%       1.0      2.000000     1.0     1.0     1.0\n",
       "90%       1.0      2.000000     1.0     1.0     1.0\n",
       "max       1.0     10.000000     1.0     1.0     1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_hugginface[\"train_entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset conll2003 (/home/loebbert/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████| 3/3 [00:00<00:00, 684.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags = {\n",
    "    'O': 0,\n",
    "    'B-PER': 1,\n",
    "    'I-PER': 2,\n",
    "    'B-ORG': 3,\n",
    "    'I-ORG': 4,\n",
    "    'B-LOC': 5,\n",
    "    'I-LOC': 6,\n",
    "    'B-MISC': 7,\n",
    "    'I-MISC': 8\n",
    "}\n",
    "reversed_ner_tags = {v: k for k, v in ner_tags.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in dataset:\n",
    "    with open(\"datasets/conll03/huggingface/\"+part+\".txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        for item in dataset[part]:\n",
    "            for line in [\"\\t\".join([token, \"x\", \"x\", reversed_ner_tags[ner_tag_id]]) for token, ner_tag_id in zip(item[\"tokens\"], item[\"ner_tags\"])]:\n",
    "                file.write(line + \"\\n\")\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loebbert/miniconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "torch.Size([5])\n",
      "torch.Size([25])\n",
      "torch.Size([15])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "input_ids = torch.ones(80)\n",
    "indices = [15, 20, 45, 60]\n",
    "\n",
    "tensors = torch.tensor_split(input_ids, indices)\n",
    "for t in tensors:\n",
    "    print(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(tensors).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dropout = 0.3\n",
    "np.random.choice([0, 1], size=4, p=[dropout, 1-dropout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't read config from 1 paths\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"/home/loebbert/projects/thesis/finetuning/sentences_result_3.pkl\", \"rb\") as file:\n",
    "    results = pkl.load(file)\n",
    "\n",
    "res_df = results.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_f1</th>\n",
       "      <td>0.763514</td>\n",
       "      <td>0.760839</td>\n",
       "      <td>0.7151</td>\n",
       "      <td>0.705544</td>\n",
       "      <td>0.699222</td>\n",
       "      <td>0.699084</td>\n",
       "      <td>0.694484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <td>156.800921</td>\n",
       "      <td>168.276965</td>\n",
       "      <td>96.0914</td>\n",
       "      <td>126.166562</td>\n",
       "      <td>99.639483</td>\n",
       "      <td>114.005274</td>\n",
       "      <td>144.391847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>done</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timesteps_total</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodes_total</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_iteration</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <td>2ef43fcc</td>\n",
       "      <td>348ce964</td>\n",
       "      <td>2371d2fb</td>\n",
       "      <td>ca7ed2cc</td>\n",
       "      <td>3e72a6df</td>\n",
       "      <td>0ce1cc67</td>\n",
       "      <td>d4862515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>fa045ffd58d44e999a58f60a835834a5</td>\n",
       "      <td>fa045ffd58d44e999a58f60a835834a5</td>\n",
       "      <td>fa045ffd58d44e999a58f60a835834a5</td>\n",
       "      <td>fa045ffd58d44e999a58f60a835834a5</td>\n",
       "      <td>fa045ffd58d44e999a58f60a835834a5</td>\n",
       "      <td>fa045ffd58d44e999a58f60a835834a5</td>\n",
       "      <td>fa045ffd58d44e999a58f60a835834a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2023-04-24_20-32-58</td>\n",
       "      <td>2023-04-24_21-22-42</td>\n",
       "      <td>2023-04-24_19-48-39</td>\n",
       "      <td>2023-04-24_18-34-15</td>\n",
       "      <td>2023-04-24_20-06-07</td>\n",
       "      <td>2023-04-24_22-06-31</td>\n",
       "      <td>2023-04-24_21-47-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>1682361178</td>\n",
       "      <td>1682364162</td>\n",
       "      <td>1682358519</td>\n",
       "      <td>1682354055</td>\n",
       "      <td>1682359567</td>\n",
       "      <td>1682366791</td>\n",
       "      <td>1682365623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_total_s</th>\n",
       "      <td>1609.492136</td>\n",
       "      <td>1697.833143</td>\n",
       "      <td>1055.302273</td>\n",
       "      <td>1296.822273</td>\n",
       "      <td>1046.666183</td>\n",
       "      <td>1166.159775</td>\n",
       "      <td>1459.169328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pid</th>\n",
       "      <td>1091150</td>\n",
       "      <td>1091150</td>\n",
       "      <td>1091150</td>\n",
       "      <td>1091150</td>\n",
       "      <td>1091150</td>\n",
       "      <td>1091150</td>\n",
       "      <td>1091150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hostname</th>\n",
       "      <td>pop-os</td>\n",
       "      <td>pop-os</td>\n",
       "      <td>pop-os</td>\n",
       "      <td>pop-os</td>\n",
       "      <td>pop-os</td>\n",
       "      <td>pop-os</td>\n",
       "      <td>pop-os</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_ip</th>\n",
       "      <td>192.168.0.12</td>\n",
       "      <td>192.168.0.12</td>\n",
       "      <td>192.168.0.12</td>\n",
       "      <td>192.168.0.12</td>\n",
       "      <td>192.168.0.12</td>\n",
       "      <td>192.168.0.12</td>\n",
       "      <td>192.168.0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_restore</th>\n",
       "      <td>1609.492136</td>\n",
       "      <td>1697.833143</td>\n",
       "      <td>1055.302273</td>\n",
       "      <td>1296.822273</td>\n",
       "      <td>1046.666183</td>\n",
       "      <td>1166.159775</td>\n",
       "      <td>1459.169328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warmup_time</th>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config/adam_weight_decay</th>\n",
       "      <td>0.496375</td>\n",
       "      <td>0.304715</td>\n",
       "      <td>0.335081</td>\n",
       "      <td>0.190287</td>\n",
       "      <td>0.337649</td>\n",
       "      <td>0.296544</td>\n",
       "      <td>0.144251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config/asp_activation</th>\n",
       "      <td>relu</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>gelu_fast</td>\n",
       "      <td>relu</td>\n",
       "      <td>tanh</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config/asp_hidden_dim</th>\n",
       "      <td>142</td>\n",
       "      <td>201</td>\n",
       "      <td>180</td>\n",
       "      <td>583</td>\n",
       "      <td>706</td>\n",
       "      <td>312</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config/search_algorithm</th>\n",
       "      <td>bm25</td>\n",
       "      <td>bm25</td>\n",
       "      <td>ann</td>\n",
       "      <td>bm25</td>\n",
       "      <td>bm25</td>\n",
       "      <td>ann</td>\n",
       "      <td>bm25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config/search_topk</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config/task_learning_rate</th>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.004432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config/train_search_dropout</th>\n",
       "      <td>0.211266</td>\n",
       "      <td>0.121144</td>\n",
       "      <td>0.447002</td>\n",
       "      <td>0.262073</td>\n",
       "      <td>0.506951</td>\n",
       "      <td>0.557225</td>\n",
       "      <td>0.334562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config/warmup_ratio</th>\n",
       "      <td>0.184452</td>\n",
       "      <td>0.905381</td>\n",
       "      <td>0.353922</td>\n",
       "      <td>0.754626</td>\n",
       "      <td>0.648387</td>\n",
       "      <td>0.038395</td>\n",
       "      <td>0.825348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logdir</th>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "      <td>/home/loebbert/projects/thesis/finetuning/tune...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            6   \\\n",
       "val_f1                                                                0.763514   \n",
       "time_this_iter_s                                                    156.800921   \n",
       "done                                                                     False   \n",
       "timesteps_total                                                            NaN   \n",
       "episodes_total                                                             NaN   \n",
       "training_iteration                                                          10   \n",
       "trial_id                                                              2ef43fcc   \n",
       "experiment_id                                 fa045ffd58d44e999a58f60a835834a5   \n",
       "date                                                       2023-04-24_20-32-58   \n",
       "timestamp                                                           1682361178   \n",
       "time_total_s                                                       1609.492136   \n",
       "pid                                                                    1091150   \n",
       "hostname                                                                pop-os   \n",
       "node_ip                                                           192.168.0.12   \n",
       "time_since_restore                                                 1609.492136   \n",
       "timesteps_since_restore                                                      0   \n",
       "iterations_since_restore                                                    10   \n",
       "warmup_time                                                           0.002392   \n",
       "config/adam_weight_decay                                              0.496375   \n",
       "config/asp_activation                                                     relu   \n",
       "config/asp_hidden_dim                                                      142   \n",
       "config/search_algorithm                                                   bm25   \n",
       "config/search_topk                                                           8   \n",
       "config/task_learning_rate                                             0.001348   \n",
       "config/train_search_dropout                                           0.211266   \n",
       "config/warmup_ratio                                                   0.184452   \n",
       "logdir                       /home/loebbert/projects/thesis/finetuning/tune...   \n",
       "\n",
       "                                                                            8   \\\n",
       "val_f1                                                                0.760839   \n",
       "time_this_iter_s                                                    168.276965   \n",
       "done                                                                     False   \n",
       "timesteps_total                                                            NaN   \n",
       "episodes_total                                                             NaN   \n",
       "training_iteration                                                          10   \n",
       "trial_id                                                              348ce964   \n",
       "experiment_id                                 fa045ffd58d44e999a58f60a835834a5   \n",
       "date                                                       2023-04-24_21-22-42   \n",
       "timestamp                                                           1682364162   \n",
       "time_total_s                                                       1697.833143   \n",
       "pid                                                                    1091150   \n",
       "hostname                                                                pop-os   \n",
       "node_ip                                                           192.168.0.12   \n",
       "time_since_restore                                                 1697.833143   \n",
       "timesteps_since_restore                                                      0   \n",
       "iterations_since_restore                                                    10   \n",
       "warmup_time                                                           0.002392   \n",
       "config/adam_weight_decay                                              0.304715   \n",
       "config/asp_activation                                                gelu_fast   \n",
       "config/asp_hidden_dim                                                      201   \n",
       "config/search_algorithm                                                   bm25   \n",
       "config/search_topk                                                           8   \n",
       "config/task_learning_rate                                             0.001427   \n",
       "config/train_search_dropout                                           0.121144   \n",
       "config/warmup_ratio                                                   0.905381   \n",
       "logdir                       /home/loebbert/projects/thesis/finetuning/tune...   \n",
       "\n",
       "                                                                            4   \\\n",
       "val_f1                                                                  0.7151   \n",
       "time_this_iter_s                                                       96.0914   \n",
       "done                                                                     False   \n",
       "timesteps_total                                                            NaN   \n",
       "episodes_total                                                             NaN   \n",
       "training_iteration                                                          10   \n",
       "trial_id                                                              2371d2fb   \n",
       "experiment_id                                 fa045ffd58d44e999a58f60a835834a5   \n",
       "date                                                       2023-04-24_19-48-39   \n",
       "timestamp                                                           1682358519   \n",
       "time_total_s                                                       1055.302273   \n",
       "pid                                                                    1091150   \n",
       "hostname                                                                pop-os   \n",
       "node_ip                                                           192.168.0.12   \n",
       "time_since_restore                                                 1055.302273   \n",
       "timesteps_since_restore                                                      0   \n",
       "iterations_since_restore                                                    10   \n",
       "warmup_time                                                           0.002392   \n",
       "config/adam_weight_decay                                              0.335081   \n",
       "config/asp_activation                                                gelu_fast   \n",
       "config/asp_hidden_dim                                                      180   \n",
       "config/search_algorithm                                                    ann   \n",
       "config/search_topk                                                           4   \n",
       "config/task_learning_rate                                             0.001876   \n",
       "config/train_search_dropout                                           0.447002   \n",
       "config/warmup_ratio                                                   0.353922   \n",
       "logdir                       /home/loebbert/projects/thesis/finetuning/tune...   \n",
       "\n",
       "                                                                            0   \\\n",
       "val_f1                                                                0.705544   \n",
       "time_this_iter_s                                                    126.166562   \n",
       "done                                                                     False   \n",
       "timesteps_total                                                            NaN   \n",
       "episodes_total                                                             NaN   \n",
       "training_iteration                                                          10   \n",
       "trial_id                                                              ca7ed2cc   \n",
       "experiment_id                                 fa045ffd58d44e999a58f60a835834a5   \n",
       "date                                                       2023-04-24_18-34-15   \n",
       "timestamp                                                           1682354055   \n",
       "time_total_s                                                       1296.822273   \n",
       "pid                                                                    1091150   \n",
       "hostname                                                                pop-os   \n",
       "node_ip                                                           192.168.0.12   \n",
       "time_since_restore                                                 1296.822273   \n",
       "timesteps_since_restore                                                      0   \n",
       "iterations_since_restore                                                    10   \n",
       "warmup_time                                                           0.002392   \n",
       "config/adam_weight_decay                                              0.190287   \n",
       "config/asp_activation                                                gelu_fast   \n",
       "config/asp_hidden_dim                                                      583   \n",
       "config/search_algorithm                                                   bm25   \n",
       "config/search_topk                                                           6   \n",
       "config/task_learning_rate                                             0.001539   \n",
       "config/train_search_dropout                                           0.262073   \n",
       "config/warmup_ratio                                                   0.754626   \n",
       "logdir                       /home/loebbert/projects/thesis/finetuning/tune...   \n",
       "\n",
       "                                                                            5   \\\n",
       "val_f1                                                                0.699222   \n",
       "time_this_iter_s                                                     99.639483   \n",
       "done                                                                     False   \n",
       "timesteps_total                                                            NaN   \n",
       "episodes_total                                                             NaN   \n",
       "training_iteration                                                          10   \n",
       "trial_id                                                              3e72a6df   \n",
       "experiment_id                                 fa045ffd58d44e999a58f60a835834a5   \n",
       "date                                                       2023-04-24_20-06-07   \n",
       "timestamp                                                           1682359567   \n",
       "time_total_s                                                       1046.666183   \n",
       "pid                                                                    1091150   \n",
       "hostname                                                                pop-os   \n",
       "node_ip                                                           192.168.0.12   \n",
       "time_since_restore                                                 1046.666183   \n",
       "timesteps_since_restore                                                      0   \n",
       "iterations_since_restore                                                    10   \n",
       "warmup_time                                                           0.002392   \n",
       "config/adam_weight_decay                                              0.337649   \n",
       "config/asp_activation                                                     relu   \n",
       "config/asp_hidden_dim                                                      706   \n",
       "config/search_algorithm                                                   bm25   \n",
       "config/search_topk                                                           5   \n",
       "config/task_learning_rate                                             0.001387   \n",
       "config/train_search_dropout                                           0.506951   \n",
       "config/warmup_ratio                                                   0.648387   \n",
       "logdir                       /home/loebbert/projects/thesis/finetuning/tune...   \n",
       "\n",
       "                                                                            10  \\\n",
       "val_f1                                                                0.699084   \n",
       "time_this_iter_s                                                    114.005274   \n",
       "done                                                                     False   \n",
       "timesteps_total                                                            NaN   \n",
       "episodes_total                                                             NaN   \n",
       "training_iteration                                                          10   \n",
       "trial_id                                                              0ce1cc67   \n",
       "experiment_id                                 fa045ffd58d44e999a58f60a835834a5   \n",
       "date                                                       2023-04-24_22-06-31   \n",
       "timestamp                                                           1682366791   \n",
       "time_total_s                                                       1166.159775   \n",
       "pid                                                                    1091150   \n",
       "hostname                                                                pop-os   \n",
       "node_ip                                                           192.168.0.12   \n",
       "time_since_restore                                                 1166.159775   \n",
       "timesteps_since_restore                                                      0   \n",
       "iterations_since_restore                                                    10   \n",
       "warmup_time                                                           0.002392   \n",
       "config/adam_weight_decay                                              0.296544   \n",
       "config/asp_activation                                                     tanh   \n",
       "config/asp_hidden_dim                                                      312   \n",
       "config/search_algorithm                                                    ann   \n",
       "config/search_topk                                                           7   \n",
       "config/task_learning_rate                                             0.001931   \n",
       "config/train_search_dropout                                           0.557225   \n",
       "config/warmup_ratio                                                   0.038395   \n",
       "logdir                       /home/loebbert/projects/thesis/finetuning/tune...   \n",
       "\n",
       "                                                                            9   \n",
       "val_f1                                                                0.694484  \n",
       "time_this_iter_s                                                    144.391847  \n",
       "done                                                                     False  \n",
       "timesteps_total                                                            NaN  \n",
       "episodes_total                                                             NaN  \n",
       "training_iteration                                                          10  \n",
       "trial_id                                                              d4862515  \n",
       "experiment_id                                 fa045ffd58d44e999a58f60a835834a5  \n",
       "date                                                       2023-04-24_21-47-03  \n",
       "timestamp                                                           1682365623  \n",
       "time_total_s                                                       1459.169328  \n",
       "pid                                                                    1091150  \n",
       "hostname                                                                pop-os  \n",
       "node_ip                                                           192.168.0.12  \n",
       "time_since_restore                                                 1459.169328  \n",
       "timesteps_since_restore                                                      0  \n",
       "iterations_since_restore                                                    10  \n",
       "warmup_time                                                           0.002392  \n",
       "config/adam_weight_decay                                              0.144251  \n",
       "config/asp_activation                                                     relu  \n",
       "config/asp_hidden_dim                                                      464  \n",
       "config/search_algorithm                                                   bm25  \n",
       "config/search_topk                                                           8  \n",
       "config/task_learning_rate                                             0.004432  \n",
       "config/train_search_dropout                                           0.334562  \n",
       "config/warmup_ratio                                                   0.825348  \n",
       "logdir                       /home/loebbert/projects/thesis/finetuning/tune...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by=[\"val_f1\"], ascending=False)[:7].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by=[\"val_f1\"], ascending=False).index.values[:2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'asp_hidden_dim': 201,\n",
       "  'asp_activation': 'gelu_fast',\n",
       "  'task_learning_rate': 0.001427004141277835,\n",
       "  'adam_weight_decay': 0.3047154488657352,\n",
       "  'warmup_ratio': 0.9053807192033322,\n",
       "  'search_algorithm': 'bm25',\n",
       "  'search_topk': 8,\n",
       "  'train_search_dropout': 0.1211443957902944,\n",
       "  'plm_pretrained_name_or_path': 't5-base',\n",
       "  'plm_tokenizer_name': 't5-small',\n",
       "  'model_max_length': 4096,\n",
       "  'mention_start_token': '<m>',\n",
       "  'mention_end_token': '</m>',\n",
       "  'asp_dropout_rate': 0.3,\n",
       "  'asp_init_std': 0.02,\n",
       "  'num_labels': 6,\n",
       "  'max_nest_depth': 1,\n",
       "  'beam_size': 1,\n",
       "  'plm_learning_rate': 5e-05,\n",
       "  'plm_scheduler': 'linear_with_warmup',\n",
       "  'task_scheduler': 'linear_with_warmup',\n",
       "  'adam_eps': 1e-08,\n",
       "  'num_epochs': 40,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'batch_size': 40,\n",
       "  'train_len': 3394,\n",
       "  'fused': True,\n",
       "  'use_labels': True,\n",
       "  'use_mentions': True,\n",
       "  'prepend_search_results': False,\n",
       "  'filter_exact_match': False,\n",
       "  'filter_same_document': False,\n",
       "  'search_data_type': 'sentences',\n",
       "  'seed': 42,\n",
       "  'train_search_shuffle': False,\n",
       "  'data_path': '/home/loebbert/projects/thesis/finetuning/tune',\n",
       "  'name': 'sentences',\n",
       "  'precision': 'bf16-mixed'},\n",
       " {'asp_hidden_dim': 142,\n",
       "  'asp_activation': 'relu',\n",
       "  'task_learning_rate': 0.0013480523331922776,\n",
       "  'adam_weight_decay': 0.49637507889057786,\n",
       "  'warmup_ratio': 0.184451637360714,\n",
       "  'search_algorithm': 'bm25',\n",
       "  'search_topk': 8,\n",
       "  'train_search_dropout': 0.21126587935893093,\n",
       "  'plm_pretrained_name_or_path': 't5-base',\n",
       "  'plm_tokenizer_name': 't5-small',\n",
       "  'model_max_length': 4096,\n",
       "  'mention_start_token': '<m>',\n",
       "  'mention_end_token': '</m>',\n",
       "  'asp_dropout_rate': 0.3,\n",
       "  'asp_init_std': 0.02,\n",
       "  'num_labels': 6,\n",
       "  'max_nest_depth': 1,\n",
       "  'beam_size': 1,\n",
       "  'plm_learning_rate': 5e-05,\n",
       "  'plm_scheduler': 'linear_with_warmup',\n",
       "  'task_scheduler': 'linear_with_warmup',\n",
       "  'adam_eps': 1e-08,\n",
       "  'num_epochs': 40,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'batch_size': 40,\n",
       "  'train_len': 3394,\n",
       "  'fused': True,\n",
       "  'use_labels': True,\n",
       "  'use_mentions': True,\n",
       "  'prepend_search_results': False,\n",
       "  'filter_exact_match': False,\n",
       "  'filter_same_document': False,\n",
       "  'search_data_type': 'sentences',\n",
       "  'seed': 42,\n",
       "  'train_search_shuffle': False,\n",
       "  'data_path': '/home/loebbert/projects/thesis/finetuning/tune',\n",
       "  'name': 'sentences',\n",
       "  'precision': 'bf16-mixed'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results = []\n",
    "for i in res_df.sort_values(by=[\"val_f1\"], ascending=False).index.values[:2].tolist():\n",
    "    best_results.append(results[i].config)\n",
    "best_results.reverse()\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asp_hidden_dim': 355,\n",
       " 'asp_dropout_rate': 0.3,\n",
       " 'asp_init_std': 0.019999999999999976,\n",
       " 'asp_activation': 'gelu_fast',\n",
       " 'plm_learning_rate': 4.999999999999997e-05,\n",
       " 'task_learning_rate': 0.0013868381781415849,\n",
       " 'adam_eps': 9.999999999999984e-09,\n",
       " 'adam_weight_decay': 0.1,\n",
       " 'warmup_ratio': 0.6483865273543568,\n",
       " 'use_labels': True,\n",
       " 'use_mentions': True,\n",
       " 'prepend_search_results': False,\n",
       " 'filter_exact_match': False,\n",
       " 'filter_same_document': False,\n",
       " 'search_algorithm': 'bm25',\n",
       " 'search_topk': 5,\n",
       " 'train_search_dropout': 0.6317431305015401,\n",
       " 'train_search_shuffle': False,\n",
       " 'plm_pretrained_name_or_path': 't5-base',\n",
       " 'plm_tokenizer_name': 't5-small',\n",
       " 'model_max_length': 4096,\n",
       " 'mention_start_token': '<m>',\n",
       " 'mention_end_token': '</m>',\n",
       " 'num_labels': 6,\n",
       " 'max_nest_depth': 1,\n",
       " 'beam_size': 1,\n",
       " 'plm_scheduler': 'linear_with_warmup',\n",
       " 'task_scheduler': 'linear_with_warmup',\n",
       " 'num_epochs': 20,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'batch_size': 40,\n",
       " 'train_len': 3394,\n",
       " 'fused': True,\n",
       " 'search_data_type': 'sentences',\n",
       " 'seed': 42,\n",
       " 'data_path': '/home/loebbert/projects/thesis/finetuning/tune',\n",
       " 'name': 'sentences',\n",
       " 'precision': 'bf16-mixed'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[5].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation.lowner import lowner_to_json\n",
    "\n",
    "lowner_to_json(\n",
    "    \"/home/loebbert/projects/thesis/data/mlowner/en/train_lower.txt\",\n",
    "    \"/home/loebbert/projects/thesis/data/mlowner/en/dev_lower.txt\",\n",
    "    \"/home/loebbert/projects/thesis/data/mlowner/en/test_sub_lower.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e5a11972c14e87ce33da35f9e8cfb8d2d805c21d78b4667cb8561a4997eaab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
